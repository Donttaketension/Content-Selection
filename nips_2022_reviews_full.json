{
  "The Hessian Screening Rule": {
    "review1": {
      "rating": "3: Reject: For instance, a paper with technical flaws, weak evaluation, inadequate reproducibility and incompletely addressed ethical considerations.",
      "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
      "summary": "The paper proposes a screening strategy for L1 sparse modelings. The basic idea is to use a prediction of an optimal solution as a function of the regularization parameter, derived from optimal conditions (which is aka solution path). The authors further propose combining working set selection screening by predicted solution with so-called strong rule to make screening more efficient. ",
      "strengths_and_weaknesses": "Overall, the paper is easy to follow and technical quality is fine. The purpose is clear and the procedure is written in detail. However, a critical issue is that the idea of main proposal (Hessian screening) is not novel. Approaches based on a similar idea have been studies in the context of the path following though it is not fully mentioned. Detailed comments are as follows.\n\nClosely related papers in the path following literature are missed. For example, since the following two papers contains conceptually quite similar approaches, the difference should have been discussed in detail, though currently nothing is mentioned:\n[Rosset2004] S. Rosset, Following Curved Regularized Optimization Solution Paths, NeurIPS 2004. \n[Park2006] M. Y. Park and T. Hastie, L1 Regularization Path Algorithm for Generalized Linear Models, Journal of the Royal Statistical Society: Series B (Statistical Methodology), 2006.\n\nThe proposed algorithm can be seen as a so-called 'predictor-corrector' method in general (e.g., discussed in [Park2006]). Further, [Park2006] also discusses the working set selection based on the update equation (6).\n\nTherefore, most importantly, the idea using Theorem 3.1 to predict the variable c (working set criterion) of the next \\lambda has been already known. Therefore, I do not think the concept of 'Hessian screening' is novel.\n\n[Rosset2004] also discusses a similar idea of approach (Hessian based update) based on an essentially quite similar theoretical property to Theorem 3.1. Further, this paper also provides the error analysis of the predictor.\n\nCombination with strong rule and additional adjustment would be novel, but its technical significance is a bit marginal because these are quite simple heuristics.\n\nTechniques in the 'Updating the Hessian' paragraph have been also known (the same techniques repeatedly discussed in the path following literature). \n\nThe 'Warm Starts' has also been widely known (e.g., [Park2006]).\n\nMinor comments:\n- Since Theorem 3.1 has been widely known, it should clarify more explicitly rather than noting it only in the footnote.  ",
      "questions": "Convergence to the optimal solution is not mentioned. Could you give any information about the optimality of solution in a sense of the KKT conditions of (1)?",
      "limitations": "In Section 5, limitations were discussed.",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "2 fair",
      "presentation": "3 good",
      "contribution": "1 poor",
      "code_of_conduct": "Yes"
    },
    "review2": {
      "rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
      "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
      "summary": "This paper studies the predictor screening rules over the lasso optimization problem. It proposes a Hessian screening rule which utilizes the second-order information. This rule is effective not only in screening but also in accurate warm starts. Updating the second-order information has high computational complexity, and to deal with it, this work replies on the sweep operator. In the experiments, the proposed rule is compared to many baselines and outperforms them significantly on both simulated and real-world data.\n\n",
      "strengths_and_weaknesses": "Originality\n\nPrevious works on screening rules overlooked the study on the second-order information. Thus I think the direction of this work novel. The proposed rule takes the warm start and the Hessian matrix computation problems into account, and resolves them soundly. Besides, the insightful discussions on the proposed screening rule are provided. They are helpful to understand the rule and to differentiate this approach with previous methods. Therefore, I think the contributions of the work novel.\n\nQuality\n\nI am satisfactory with most contents of this paper. The paper presents a clear overview of the question and previous rules both in words and math. The proposed rule is based on the Hessian matrix and is actually in a form of the second-order Taylor approximation. Speeding up the Hessian matrix computation is based on the sweep operator and the warm starts also benefit from the Hessian matrix. These arguments are demonstrated in the experiments. As far as I checked, the theoretical analyses have no problem.\n\nHowever, I have a concern with the study method. Normally, people select the predictors for better fitting accuracy, but this paper relies heavily on the time cost and the minimum number of active predictors to measure the performance. I am curious about why not including fitting accuracy.\n \nClarity\n\nThe paper is clearly written for me. I can easily follow the contents on the approach and the experiment.\n\nSignificance\n\nThe idea of the approach is sound and practical performance is better than baselines. However, because just the lasso problem is involved, I am afraid that the audience will be very limited. Therefore, I think the significance of this paper is limited.",
      "questions": "See the concerns in the above section.",
      "limitations": "Yes",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "2 fair",
      "presentation": "3 good",
      "contribution": "2 fair",
      "code_of_conduct": "Yes"
    },
    "review3": {
      "rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
      "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
      "summary": "A Hessian screening rule for lasso and its generalized linear model extension for logistic regression was presented to take advantage of the high-order information for more efficient screening, specifically in cases with highly correlated predictors/covariates. The proposed Hessian screening rule together with several speedup tricks has been shown to be effective in both simulated and real datasets. ",
      "strengths_and_weaknesses": "The proposed Hessian screening rule extends the Strong Rule and Working Set by taking advantage of the high-order information for more efficient screening, specifically in cases with highly correlated predictors/covariates. The Hessian screening rule together with several speedup tricks has been shown to be effective in both simulated and real datasets. \n\nIt is not clear based on the current presentation why the Hessian rule can be less conservation from Section 3. In addition to Theorem 3.1, some theoretical analysis for that may help further improve the quality of the submission. The actual final screening in fact was based on the modifications as described from line 133 to 151. It may be interesting also to have ablation comparison to see clearly what led to improved efficiency. \n\nSince, the screening rules are not \"safe\", in particular for logistic regression. In addition to investigating the efficiency, the authors may also need to provide the performance comparison with respect to both predictor selection and model prediction accuracy. \n\nIn the real data experiments, the authors may want to provide some explanations why the Hessian rule performs significantly worse on arcene and rcv2 datasets, for which p is much larger than n, especially for arcene. It is clearly not the case when p is similar as n as discussed in Section 5. \n\nFinally, there are language problems in the submission. For example, in line 188-189 (page 5): \"... this is not a surprising find.\"  In line 257-258 (page 7), \"we also stop the path whenever the number of coefficients ever to be active predictors exceeds p.\" The number of coefficients can be equal to p but will never exceed p. The authors may need to improve the presentation of the submission. ",
      "questions": "1. Are there any theoretical guarantee that the Hessian rule will be always less conservative than the Strong rule or Working Set method? \n\n2. How the corresponding prediction accuracy of the resulting models by different screening rules? Are the final \"screened\" predictors all the same as the ones from the optimal solution from the model fitting without screening? \n\n3. There are multiple screening rules published more recently, including: https://proceedings.neurips.cc/paper/2020/hash/11348e03e23b137d55d94464250a67a2-Abstract.html, how does the Hessian screening rule compare with these new rules? ",
      "limitations": "N/A.",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "3 good",
      "presentation": "3 good",
      "contribution": "3 good",
      "code_of_conduct": "Yes"
    },
    "review4": {
      "rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
      "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
      "summary": "The paper proposes a heuristic (non-safe) screening rule to deal with l1-regularized estimation problems such as linear regression and logistic regression. The proposed method can be viewed as a generalization of the strong rule used in the glmnet, which only used first-order information.  The paper reports experiments on both synthetic data and real-world data to illustrate the performance of the proposed method.",
      "strengths_and_weaknesses": "Strengths:\n* the paper addresses an interesting problem in l1-regularized estimation for linear regression and logistic regression. Screening rules are an effective strategy to speed up such estimation.\n* Although the proposed rule is heuristic in nature, the simplicity in its formulation and the effectiveness shown in the experiments offers some advantages of the proposed method. This is also a not-so-common approach that makes use of second-order information for screening.\n* Experiments are exhaustive. six well-known alternative methods are compared on a wide variety of synthetic and real-world data.\n\nWeakness:\n* The authors may consider carrying out experiments on other settings covered by the proposed method such as poison regression and elastic net. It may also be interesting (somewhat orthgonal) to understand how the proposed method performs or scale compared to SGD based approach on very large datasets.",
      "questions": "I don't have additional questions for the authors.",
      "limitations": "Limitations are discussed in the paper.",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "3 good",
      "presentation": "3 good",
      "contribution": "2 fair",
      "code_of_conduct": "Yes"
    },
    "review5": {
      "title": "General Response to All Reviewers",
      "comment": "We would first like to thank all of the reviewers for their hard work and constructive feedback!\n\nWe recently discovered that our implementation of the Hessian updates involved the accidental construction of a dense diagonal matrix, which caused our method to underperform for the experiments with sparse designs and $\\ell_1$-regularized logistic regression. Most importantly, **note that this only affected our method**. We have now re-run the experiments on real data and note that our method now performs best also for rcv1, which was previously a notable exception in our results. Please see the paper for updated results. Note that the updated results differ slightly from the ones in the submitted version due to changes on the benchmarking machine, but that these changes do not alter any of our conclusions. We have also updated the results section slightly as well as the second paragraph of the discussion in light of these changes.\n\nIn addition to this, we have also extended our results in the supplementary with two more experiments:\n\n- In F.7 (supplement) we provide an ablation analysis which investigates how the various features of our screening algorithm influence the time to fit a regularization path. For the final revision we will extend this experiment to additional scenarios.\n- In F.8 (supplement) we provide a runtime breakdown for the entire path to study how time is spent along the path on screening, Hessian updates, and optimization (coordinate descent) for three data sets.\nWe believe that these two experiments provide additional insight into the performance of our method and hope that the reviewers are able to spare the time to consider them."
    },
    "review6": {
      "metareview": "This papers proposed a Hessian screening rule for lasso and its generalized linear model extension for logistic regression. The proposed screening rules have been demonstrated to be effective in both simulated and real datasets. The idea is novel and the evaluation is convincing. The authors mention that extensions to MCP and SCAD may also be possible, even though the objective may not be convex. A brief discussion will be helpful. ",
      "recommendation": "Accept",
      "confidence": "Less certain",
      "award": "No"
    },
    "review7": {
      "title": "Paper Decision",
      "decision": "Accept",
      "comment": ""
    }
  },
  "Langevin Autoencoders for Learning Deep Latent Variable Models": {
    "review1": {
      "rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
      "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
      "summary": "This paper presents Amortized Langevin Dynamics (ALD), a scalable MCMC algorithm that can be used to sample from high dimensional deep latent variable models. \n\nUnlike competing MCMC algorithms that need to rely on per-datapoint iterations, ALD can sample from the correct posterior distribution by performing updates to an encoder. This gives rise to Langevin Autoencoders, a family of deep LVMs that relies on ALD. \n\nExperiments on a number of benchmark datasets show that Langevin Autoencoders outperform competing models while maintaining scalability. \n\n \n\n \n\n",
      "strengths_and_weaknesses": "STRENGTHS \n\nMost applications of deep LVMs use variational methods to approximate the intractable posterior distribution.\nVariational methods are however inherently biased, since they try to approximate a complex posterior distribution with distributions from a typically simple variational family (e.g. Gaussian). \n\nThis is not an issue in sample-based MCMC methods, but they do not scale for high dimensional deep LVMs trained on large datasets, since they require expensive per-datapoint iterations. \n\nThis paper provides a novel solution to this, that relies on applying amortization ideas to MCMC methods. \nThe idea of obtaining samples from the posterior distribution by updating an encoder that data points to latent variables is very interesting to me, as it preserves the scalability of variational methods while not making any strong assumption on the approximate posterior distribution.\nAlso, theoretical and empirical results show that ALD matches the correct stationary posterior distribution even for the complex posterior distributions that are typical of DLVMs.\n\nI believe this paper can have an impact in the neurips community, since it can inspire a new research direction on enoder-based MCMC methods that use amortization and avoid datapoint-wise iterations.\n\n\nWEAKNESSES \n\nThere are some experimental improvements that I believe could further increase the impact of this paper.\n\n1. You state that the goal of the experiments is to show that ALD works, and not that of achieving SOTA results, which is ok. However, for this type of paper that presents a method that can be readily applied to any deep LVM, trying it out on a more SOTA architecture would have made the results much more compelling. The fact that you have not done it makes me wonder if there are some complications to applying it to more complex architectures.\n\n2. How can one monitor the convergence of the MCMC chain? Which convergence diagnostics have you used? \n\n3. Did you ever get in situations where the MH acceptance rate was too low/high? \n\n4. What are the training times of the different models considered in the experiments?\n\n\n Minor comments:\n\n* typo in title: variabel -> variable \n\n* line 29. The issue is not that the distribution is tractable as it is implied in the sentence. The issue is that the posterior for these types of models is complex, so the tractable distributions we use are not a good approximation. \n\n* line 41: \"in test time\" -> \"at test time\" \n\n\n",
      "questions": "See comments in the \"weaknesses\" section.",
      "limitations": "Yes",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "4 excellent",
      "presentation": "4 excellent",
      "contribution": "4 excellent",
      "code_of_conduct": "Yes"
    },
    "review2": {
      "rating": "6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.",
      "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
      "summary": "The paper introduces amorized Langevin dynamics (ALD), a method for initializing Langevin dynamics in the function parameter space that makes it efficient to perform posterior sampling. Based on this method, the paper presents the Langevin autoencoder (LAE), a deep latent variable model that is easy to implement and has competitive performance compared to similar existing methods.",
      "strengths_and_weaknesses": "Strengths:\n- The preliminaries and the core method are explained clearly. The drawbacks of existing MCMC and variational inference methods motivate the main ideas very well.\n- The algorithm of LAE is presented very clearly (Algorithm 2).\n- The idea of performing Langevin sampling in encoder parameter space seems quite novel and interesting. Proof is given on why this MCMC in the encoder parameter space will converge to the true data posterior.\n\nWeaknesses:\n- Although it doesn't get in the way of understanding the key ideas, the writing can certainly be improved at a couple of places. Examples include \"a more straightforward and sophisticated framework\" (line 48), \"replacing MCMC on the latent space into the encoder's parameter space\" (line 52) and \"we substitue it for its evidence lower bound\" (line 277, I believe it should be the other way around). Should be easy to fix.\n- I find the claim that ALD \"completely removes datapoint-wise iterations\" slightly misleading, since it does so trivially by turning datapoint-wise iterations into parameter space iterations. In essence it still relies on the encoder (up to the second to last layer) to initialize the MCMC in a high-density region, which is still pretty similar to Hoffman (2017). Maybe it can be shown that this method can have the same or better performance with less MCMC iterations than Hoffman, at which point it would be interesting to discuss why moving to parameter space gives such an advantage.\n- Without providing details on hyperparameter search (which can influence results greatly), the experimental results might not be sufficient for concluding that the LAE \"outperforms\" the existing methods. As mentioned in the last point, I think it would be really beneficial to show how the performance of the Hoffman (2017) model is influenced by the number of MCMC steps used.",
      "questions": "- In Hoffman (2017) the encoder parameters are updated via gradient descent on the ELBO. However in this work the gradients are taken w.r.t. $V$ instead. I did not find derivations for this gradient update. How is this gradient update justified? What is the objective function in this case?\n- What do you think could be the reason behind the efficiency of performing MCMC in the parameter space instead of the data space?",
      "limitations": "The main limitation of the method seems to be the requirement that the size of the last linear encoder layer needs to be larger than the batch size. This is addressed in the experimental section 5.1.",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "3 good",
      "presentation": "3 good",
      "contribution": "2 fair",
      "code_of_conduct": "Yes"
    },
    "review3": {
      "rating": "5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.",
      "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
      "summary": "The paper deals with performing Langevin dynamics as a form of sampling, only using an amortisation mechanism. This reduces the computational overhead of performing the sampling. The method is then verified on synthetic and generated data sets\n",
      "strengths_and_weaknesses": "The paper is very clearly written and cleanly presented. It is worth mentioning that the authors also did a very good job introducing other related works (albeit a bit late in the text at section 4).\nMore so I think The main theorem is an important one. The idea of unfing the generated Markov chains with respect to the data set is novel.\nIn top of that using amortisation is a fantastic idea for a Markovian process since the lack of time correlation can make this efficient much like Mori Zwanzig operators untangle non markovian processes \nThat being said, there are a few things I am a bit worried about. It seems like to sample the ELBO there is a need to resample all the chains ?\n",
      "questions": "You have used EM numerical solver, which has a lof of well defined numerical stability criterion, for example : Higham, D.J., 2001. An algorithmic introduction to numerical simulation of stochastic differential equations. SIAM review, 43(3), pp.525-546. Did you check any of them ?\n\nWhat is really fascinating about Langevin dynamics is that for a certain class you derive a shadow lemma which means you are tractable towards your \u201creal\u201d underlying distribution for example : https://arxiv.org/abs/1107.2967\nCan this analysis somehow improve the theorem on G\n",
      "limitations": "Yes",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "3 good",
      "presentation": "4 excellent",
      "contribution": "3 good",
      "code_of_conduct": "Yes"
    },
    "review4": {
      "metareview": "The problem addressed in this paper is the one of inference in deep generative latent variable model. The paper proposes a novel approach with an amortized approximation to the joint distribution of data and latent. \n\nAll three reviewers liked the paper with one reviewer being a bit concerned about the soundness of the MCMC convergence proof.  In this meta-reviewers' opinion the algorithm (Alg 2) is sound although there might be subtleties here because it mixes posterior parameter updates with generative model parameter updates and latent samples.\n\nThe paper is original, clear and numerical evaluations sufficient so acceptance is recommended.",
      "recommendation": "Accept",
      "confidence": "Certain",
      "award": "No"
    },
    "review5": {
      "title": "Paper Decision",
      "decision": "Accept",
      "comment": ""
    }
  },
  "Uni[MASK]: Unified Inference in Sequential Decision Problems": {
    "review1": {
      "rating": "9: Very Strong Accept: Technically flawless paper with groundbreaking impact on at least one area of AI/ML and excellent impact on multiple areas of AI/ML, with flawless evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
      "confidence": "5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.",
      "summary": "This submission proposed a new framework, Uni[MASK], which performs unified inference in sequential decision problems, using different masking schemes. \n\nThe authors demonstrated that randomly sampling masking schemes help the bidirectional transformer model being able to do behavior cloning, rewarding conditioning, dynamics modeling and more.\n\nThe experiments are first on grid-world and then extended to Mujoco-physics Maze2D environment. The comparison between single-task, multi-task, random-task, with finetune are through and solid, integrating the theory with practice, and quite convincing. The experiments in Mujoco-physics Maze2D environment shows that Uni[MASK] framework outperforms baselines, such as Feedforward Neural Network and Decision Transformer.\n\nI fully endorse that this submission is a wonderful work: well designed experiments, diplomatic and sound illustration and the novelty of unifying decision making through Uni[MASK] and bidirectional models.",
      "strengths_and_weaknesses": "Strengths:\n* Uni[MASK] unifies inference task in sequential decision problems.\n* The illustration of motivation, theory and experiments design is convincing and sound, written and presented very well.\n* The authors demonstrate how randomly sampling masking schemes at training time produces a single multi-inference-task model that can do behavior cloning, reward-conditioning, dynamics modeling and more.\n* The authors test how training on many tasks affects single-task performance.\n* The authors show how fine-tuning models trained with random masking consistently outperforms single-task models.\n* The proposed Hypothesis H1 ( {multi-task, random-mask, finetune} > single-task) and H2 ( {random-mask > multi-task} ) make sense intuitively, as \"H1 test whether models indeed learn richer representations by training on multiple inference tasks\" and H2 test \"whether training on all possible tasks by randomly sampling maskings at training time is better than selecting a set of specific maskings\"\n* The results from well designed experiments strongly support hypothesis H1 and H2.\n* The authors extensively analyze how different training regimes (combination of single-task, multi-task, random mask, fintune) affect performance. The analysis is very convincing to me.\n* The authors also make experiments comparison with GPT-like architectures, and the analysis is also very convincing: \"We find that while using GPT seems to yield similar performance to BERT for context length five, using GPT seems to give an advantage for longer sequence lengths,\" and \"This suggests that if one were able to use a GPT architecture and train it with random masking and fine-tuning, it might be possible to get the best of both worlds.\"\n\nWeakness:\n* Relative short context lengths, and the experiments is mainly on the grid world (4 * 4), if the grid size increases, it might further improve this work.\n",
      "questions": "From line 285 to line 2899, \"A clear avenue of future work would therefore be to get the \u201cbest of both worlds\u201d: long sequences and benefits of random-mask pre-training by using a GPT-like architectures, with our random-mask and finetune training regimes. This which would require finding ways to make GPT act like a bidirectional model \u2013 for which recent methods in NLP might offer a useful starting point\". In the rebuttal period, may I know the opinion from the authors, why making GPT act like a bidirectional model is important in the decision making scenario? The answers to this question would make me (maybe other readers) understand this paper better.",
      "limitations": "* Relative short context lengths. Experiments with longer context lengths would make this submission more convincing.\n* The experiments are mainly on the grid world (grid size is 4* 4). If the grid sizes increase more, this work would become more persuasive.",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "4 excellent",
      "presentation": "4 excellent",
      "contribution": "4 excellent",
      "code_of_conduct": "Yes"
    },
    "review2": {
      "rating": "7: Accept: Technically solid paper, with high impact on at least one sub-area, or moderate-to-high impact on more than one areas, with good-to-excellent evaluation, resources, reproducibility, and no unaddressed ethical considerations.",
      "confidence": "3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.",
      "summary": "This paper presents the Uni[MASK] framework, which generalizes masked language modeling (in natural language processing) to more general sequence decision problems. Given actions, states and optional property tokens (such as the return-to-go), multiple tasks such as behavioral cloning, reward-conditional offline RL, forward dynamics, etc., may be represented by specific masking schemes. The authors propose to train a model by using a randomized masking scheme (instead of single-task only or with a fixed set of tasks). Such a Uni[Mask] model may also be fine-tuned on a given task afterwards. A pre-trained Uni[MASK] model often performs comparably to single-task training, and fine-tuning further improves results.\n\n[Post author response] I updated the rating I assigned to this paper, in particular because of the correction to the originally misleading discussion.\n",
      "strengths_and_weaknesses": "**Strengths**\n\nThe proposed approach neatly formalizes multiple tasks under a general masking framework.\n\nTraining a Uni[MASK] model, then finetuning it on a given task, generally leads to better results than single-task training only.\n\nThe approach is tested in both discrete (MiniGrid) and continuous (Maze2D) environments.\n\n**Weaknesses**\n\nThe discussion around line 200 is misleading. In figure 7, multi-task performs worse than single-task (although sometimes negligibly), which doesn't support H1.\n\nThe distinction between BERT-like and GPT-like models should be described more clearly (see question below).\n\nThe MiniGrid environment appears to be very simple. I would be interested in seeing how well the approach scales with larger grids.",
      "questions": "**Questions**\n\nMost important question: Could you please clarify exactly what you mean by \"BERT\" architecture vs \"GPT\" architecture, and how they interact with the masking schemes you propose? In NLP, BERT uses a transformer encoder (self-attention) with some masked inputs whereas GPT uses a transformer decoder (causal self-attention, i.e. not looking at the future).\n\nL160+: Should there be a reward for shorter paths? Otherwise, there could be useless \n\nL190: Why no test data?\n\nL212: Do you mean figure 15 in the appendix? In general, figures referred in the main text should also be within the paper itself.\n\n**Suggestion**\n\nPlease move the description of random masking (end of appendix 1) and appendix 2 to the main text. This is too important to leave out.\n\n**Other**\n\nL235: This points to the wrong appendix.",
      "limitations": "Some limitations are discussed.",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "3 good",
      "presentation": "3 good",
      "contribution": "3 good",
      "code_of_conduct": "Yes"
    },
    "review3": {
      "rating": "8: Strong Accept: Technically strong paper, with novel ideas, excellent impact on at least one area, or high-to-excellent impact on multiple areas, with excellent evaluation, resources, and reproducibility, and no unaddressed ethical considerations.",
      "confidence": "4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.",
      "summary": "Proposes an approach to using a single bidirectional transformer to accomplish many different reinforcement learning tasks, including behavior cloning, (sub)goal conditioning, and conditioning on properties more generally. It accomplishes this by creating a sequence of out of the (state, action, properties) for all timesteps, then either (1) training on a single type of mask, (2) training across many masking styles drawn from fixed set, and (3) randomly masking positions in the sequence. (2) and (3) can be finetuned in single task fashion. They evaluate on a toy gridworld and the mujoco 2d maze tasks. They find that Uni[MASK] performs better across both given a short truncated sequence, but it underperforms a GPT model for longer sequences. They attribute this to difficulties in training BERT models.",
      "strengths_and_weaknesses": "\n\t- originality\n\t\t- Concurrent work suggests that the core ideas of this paper are in the air (see: foundation posterior, multigame decision transformer, The UL2 paper on unifying masking schemes).\n\t- quality\n\t\t- The paper is well executed. It has simple experiments which verify the core claims.\n\t\t- My main concern is that the length 10 context experiments underperforming. Would like to see more study of this instead of alluding to claims that BERT has this known failure mode.\n\t- clarity\n\t\t- The paper is well written and a pleasant read. It adequately cites prior work, and it does a great job of explaining and illustrating the core ideas.\n\t- significance\n\t\t- The paper is a solid contribution to the literature. Overall, its core findings and technique align with concurrent and prior work.",
      "questions": "\n\t1. Clarify which task is shown in table 1. The grid world or maze?\n\t2. Consider expanding on what position vs. timestep encoding is in the body of the paper (line 231)?\n\t3. The \"bert has no mouth and must speak\" paper was withdrawn\n\t4. Take a look at XLNet and NADE style masking, which would allow combining benefits of GPT and BERT\n\t5. One possibile reason the longer sequence is failing is because it is never exposed to many masked positions in a row at the end of the sequence. Randomized decoding as in xlnet might help here, or applying more structured masking (such as blocking out spans instead of ). See the uni\n\t\t1. Perhaps training on both multitask and \n\t6. What happens if you train on both multitask and random masking? \n\t7. Potential improvements\n\t\t1. Vary the sequence lengths instead of holding fixed\n\t\t\t1. This is more natural for GPT style models, but can be done with XLNet/NADE approaches as well\n\t\t\t2. How might Uni[MASK] handle the full length 200 timestep sequences instead of truncating to last 5/10?\n\t\t2. Ideally would have more complicated tasks than the two presented\n\t\t3. Consider studying how \n\t8. Relevant concurrent work: foundation posterior, which applies a similar approach to inference in probabilistic programs (i.e. generalized bayesian networks) in Stan.\n\t9. nits\n\t\t1. works -> work in line 300",
      "limitations": "There are no major concerns with this paper",
      "ethics_flag": "No",
      "ethics_review_area": [],
      "soundness": "3 good",
      "presentation": "4 excellent",
      "contribution": "3 good",
      "code_of_conduct": "Yes"
    },
    "review4": {
      "title": "General Response to Reviewers",
      "comment": "We thank the reviewers for their insightful and constructive feedback! \n\nWe are encouraged that you had an overall positive impression of our work: saying that it \u201cneatly formalizes multiple tasks under a general masking framework\u201d (Reviewer 4afK) and constitutes a \u201csolid contribution to the literature\u201d (Reviewer YeV6). We also appreciate that Reviewer SqCy thought this paper was a \u201cwonderful work\u201d with \u201cwell designed experiments, diplomatic and sound illustration and the novelty of unifying decision making through Uni[MASK] and bidirectional models\u201d.\n\n**Missing information from the main text**\n\nSome of your concerns relate to missing information from the main text which is important for the understanding of the paper: we have tried our best to incorporate some of this in the newly uploaded version, but haven\u2019t been able to do so fully because of space constraints. That being said, we\u2019d like to emphasize that all relevant details needed to reproduce the work are still included in the Appendix and the source code will be made available by the time of the conference if the paper is accepted. If the paper is accepted we will make sure to incorporate everything you requested into the main manuscript (as the camera ready version can have an extra page of content).\n\n**Bigger grid for the minigrid task**\n\nIn terms of the experimental setup, Reviewer YeV6 mentioned that more complex tasks could have further strengthened our work. Reviewers SqCy and 4afK specifically point to the small size of our minigrid as one area of possible improvement. In light of this, we ran one additional set of experiments with a larger minigrid (equivalent to Figure 9 in the Appendix, but for a larger minigrid).\n\nThe bigger minigrid is 16 by 16 instead of 6 by 6. Utilizable state space (not occupied by walls) is 13 for prior experiments (4 by 4 minus interior walls) vs 183 for the current ones (14 by 14 minor interior walls), meaning this is a ~14x increase in state space. The mechanics of the environment are the same (there is a key, a locked door, and a goal location). Context length was left at 10 timesteps, as changing it would have required hyperparameter tuning (which would have been tough given time constraints of the rebuttal period). Training hyperparameters were left unchanged with the exception of making some runs longer.\n\nThe training data was collected in a similar approach to the one in the smaller minigrid. The only difference was that we increased the rationality parameter of the expert to be slightly higher before running any experiment (we did not tune the parameter), so that the expert would be slightly less random and make more progress in the task within the 10-timestep horizon.\n\n**Results figure [here](https://i.postimg.cc/1RLs4f5Q/myplot.png)**. Let us know if you have trouble accessing it \u2013 we couldn't include it directly in the response.\n\nWe see that the results mostly follow the same trends as those in the main paper, with the main difference being that multi-task training performs somewhat better on behavior cloning, reward conditioning, and goal-conditioning (at the expense of worse performance on past and future inference). This strengthens the support of H1 relative to Figure 9, while still supporting H2 for the most part (in 6/8 tasks, random mask training performs better than multi-task).\n\nWe hope you find these additional experiments a sign of the applicability of our method.\n\n------\n\nWe try to address your individual concerns below, and are happy to answer any further questions."
    },
    "review5": {
      "metareview": "This paper extends masked language modeling to other sequential decision making problems. The idea is simple (which is a plus), the experiments are thorough, and the results are convincing. All reviewers agreed this is a good paper. I recommend acceptance.",
      "recommendation": "Accept",
      "confidence": "Certain",
      "award": "No"
    },
    "review6": {
      "title": "Paper Decision",
      "decision": "Accept",
      "comment": ""
    }
  },
  "CW-ERM: Improving Autonomous Driving Planning with Closed-loop Weighted Empirical Risk Minimization": {},
  "Identifying the Context Shift between Test Benchmarks and Production Data": {},
  "Neural Unbalanced Optimal Transport via Cycle-Consistent Semi-Couplings": {},
  "Privacy-Preserving Machine Learning for Collaborative Data Sharing via Auto-encoder Latent Space Embeddings": {},
  "Differentially Private CutMix for Split Learning with Vision Transformer": {},
  "DeepJoint: Robust Survival Modelling Under Clinical Presence Shift": {},
  "Fast kinematics modeling for conjunction with lens image modeling": {},
  "PatchRot: A Self-Supervised Technique for Training Vision Transformers": {},
  "DARTFormer: Finding The Best Type Of Attention": {},
  "Self-supervised detection of atmospheric phenomena from remotely sensed synthetic aperture radar imagery": {},
  "Deconvolving Detector Effects for Distribution Moments": {},
  "Conformal Semantic Keypoint Detection with Statistical Guarantees": {},
  "Active Learning with Table Language Models": {},
  "A View From Somewhere: Human-Centric Face Representations": {},
  "Towards Reasoning-Aware Explainable VQA": {},
  "[Re] Graph Edit Networks": {},
  "Generation Probabilities are Not Enough: Improving Error Highlighting for AI Code Suggestions": {}
}