{
  "The Hessian Screening Rule": {
    "review1": {
      "summary": "The paper proposes a screening strategy for L1 sparse modelings. The basic idea is to use a prediction of an optimal solution as a function of the regularization parameter, derived from optimal conditions (which is aka solution path). The authors further propose combining working set selection screening by predicted solution with so-called strong rule to make screening more efficient. ",
      "strengths_and_weaknesses": "Overall, the paper is easy to follow and technical quality is fine. The purpose is clear and the procedure is written in detail. However, a critical issue is that the idea of main proposal (Hessian screening) is not novel. Approaches based on a similar idea have been studies in the context of the path following though it is not fully mentioned. Detailed comments are as follows.\n\nClosely related papers in the path following literature are missed. For example, since the following two papers contains conceptually quite similar approaches, the difference should have been discussed in detail, though currently nothing is mentioned:\n[Rosset2004] S. Rosset, Following Curved Regularized Optimization Solution Paths, NeurIPS 2004. \n[Park2006] M. Y. Park and T. Hastie, L1 Regularization Path Algorithm for Generalized Linear Models, Journal of the Royal Statistical Society: Series B (Statistical Methodology), 2006.\n\nThe proposed algorithm can be seen as a so-called 'predictor-corrector' method in general (e.g., discussed in [Park2006]). Further, [Park2006] also discusses the working set selection based on the update equation (6).\n\nTherefore, most importantly, the idea using Theorem 3.1 to predict the variable c (working set criterion) of the next \\lambda has been already known. Therefore, I do not think the concept of 'Hessian screening' is novel.\n\n[Rosset2004] also discusses a similar idea of approach (Hessian based update) based on an essentially quite similar theoretical property to Theorem 3.1. Further, this paper also provides the error analysis of the predictor.\n\nCombination with strong rule and additional adjustment would be novel, but its technical significance is a bit marginal because these are quite simple heuristics.\n\nTechniques in the 'Updating the Hessian' paragraph have been also known (the same techniques repeatedly discussed in the path following literature). \n\nThe 'Warm Starts' has also been widely known (e.g., [Park2006]).\n\nMinor comments:\n- Since Theorem 3.1 has been widely known, it should clarify more explicitly rather than noting it only in the footnote.  "
    },
    "review2": {
      "summary": "This paper studies the predictor screening rules over the lasso optimization problem. It proposes a Hessian screening rule which utilizes the second-order information. This rule is effective not only in screening but also in accurate warm starts. Updating the second-order information has high computational complexity, and to deal with it, this work replies on the sweep operator. In the experiments, the proposed rule is compared to many baselines and outperforms them significantly on both simulated and real-world data.\n\n",
      "strengths_and_weaknesses": "Originality\n\nPrevious works on screening rules overlooked the study on the second-order information. Thus I think the direction of this work novel. The proposed rule takes the warm start and the Hessian matrix computation problems into account, and resolves them soundly. Besides, the insightful discussions on the proposed screening rule are provided. They are helpful to understand the rule and to differentiate this approach with previous methods. Therefore, I think the contributions of the work novel.\n\nQuality\n\nI am satisfactory with most contents of this paper. The paper presents a clear overview of the question and previous rules both in words and math. The proposed rule is based on the Hessian matrix and is actually in a form of the second-order Taylor approximation. Speeding up the Hessian matrix computation is based on the sweep operator and the warm starts also benefit from the Hessian matrix. These arguments are demonstrated in the experiments. As far as I checked, the theoretical analyses have no problem.\n\nHowever, I have a concern with the study method. Normally, people select the predictors for better fitting accuracy, but this paper relies heavily on the time cost and the minimum number of active predictors to measure the performance. I am curious about why not including fitting accuracy.\n \nClarity\n\nThe paper is clearly written for me. I can easily follow the contents on the approach and the experiment.\n\nSignificance\n\nThe idea of the approach is sound and practical performance is better than baselines. However, because just the lasso problem is involved, I am afraid that the audience will be very limited. Therefore, I think the significance of this paper is limited."
    },
    "review3": {
      "summary": "A Hessian screening rule for lasso and its generalized linear model extension for logistic regression was presented to take advantage of the high-order information for more efficient screening, specifically in cases with highly correlated predictors/covariates. The proposed Hessian screening rule together with several speedup tricks has been shown to be effective in both simulated and real datasets. ",
      "strengths_and_weaknesses": "The proposed Hessian screening rule extends the Strong Rule and Working Set by taking advantage of the high-order information for more efficient screening, specifically in cases with highly correlated predictors/covariates. The Hessian screening rule together with several speedup tricks has been shown to be effective in both simulated and real datasets. \n\nIt is not clear based on the current presentation why the Hessian rule can be less conservation from Section 3. In addition to Theorem 3.1, some theoretical analysis for that may help further improve the quality of the submission. The actual final screening in fact was based on the modifications as described from line 133 to 151. It may be interesting also to have ablation comparison to see clearly what led to improved efficiency. \n\nSince, the screening rules are not \"safe\", in particular for logistic regression. In addition to investigating the efficiency, the authors may also need to provide the performance comparison with respect to both predictor selection and model prediction accuracy. \n\nIn the real data experiments, the authors may want to provide some explanations why the Hessian rule performs significantly worse on arcene and rcv2 datasets, for which p is much larger than n, especially for arcene. It is clearly not the case when p is similar as n as discussed in Section 5. \n\nFinally, there are language problems in the submission. For example, in line 188-189 (page 5): \"... this is not a surprising find.\"  In line 257-258 (page 7), \"we also stop the path whenever the number of coefficients ever to be active predictors exceeds p.\" The number of coefficients can be equal to p but will never exceed p. The authors may need to improve the presentation of the submission. "
    },
    "review4": {
      "summary": "The paper proposes a heuristic (non-safe) screening rule to deal with l1-regularized estimation problems such as linear regression and logistic regression. The proposed method can be viewed as a generalization of the strong rule used in the glmnet, which only used first-order information.  The paper reports experiments on both synthetic data and real-world data to illustrate the performance of the proposed method.",
      "strengths_and_weaknesses": "Strengths:\n* the paper addresses an interesting problem in l1-regularized estimation for linear regression and logistic regression. Screening rules are an effective strategy to speed up such estimation.\n* Although the proposed rule is heuristic in nature, the simplicity in its formulation and the effectiveness shown in the experiments offers some advantages of the proposed method. This is also a not-so-common approach that makes use of second-order information for screening.\n* Experiments are exhaustive. six well-known alternative methods are compared on a wide variety of synthetic and real-world data.\n\nWeakness:\n* The authors may consider carrying out experiments on other settings covered by the proposed method such as poison regression and elastic net. It may also be interesting (somewhat orthgonal) to understand how the proposed method performs or scale compared to SGD based approach on very large datasets."
    },
    "review5": {
      "summary": null,
      "strengths_and_weaknesses": null
    },
    "review6": {
      "summary": null,
      "strengths_and_weaknesses": null
    },
    "review7": {
      "summary": null,
      "strengths_and_weaknesses": null
    }
  },
  "Langevin Autoencoders for Learning Deep Latent Variable Models": {
    "review1": {
      "summary": "This paper presents Amortized Langevin Dynamics (ALD), a scalable MCMC algorithm that can be used to sample from high dimensional deep latent variable models. \n\nUnlike competing MCMC algorithms that need to rely on per-datapoint iterations, ALD can sample from the correct posterior distribution by performing updates to an encoder. This gives rise to Langevin Autoencoders, a family of deep LVMs that relies on ALD. \n\nExperiments on a number of benchmark datasets show that Langevin Autoencoders outperform competing models while maintaining scalability. \n\n \n\n \n\n",
      "strengths_and_weaknesses": "STRENGTHS \n\nMost applications of deep LVMs use variational methods to approximate the intractable posterior distribution.\nVariational methods are however inherently biased, since they try to approximate a complex posterior distribution with distributions from a typically simple variational family (e.g. Gaussian). \n\nThis is not an issue in sample-based MCMC methods, but they do not scale for high dimensional deep LVMs trained on large datasets, since they require expensive per-datapoint iterations. \n\nThis paper provides a novel solution to this, that relies on applying amortization ideas to MCMC methods. \nThe idea of obtaining samples from the posterior distribution by updating an encoder that data points to latent variables is very interesting to me, as it preserves the scalability of variational methods while not making any strong assumption on the approximate posterior distribution.\nAlso, theoretical and empirical results show that ALD matches the correct stationary posterior distribution even for the complex posterior distributions that are typical of DLVMs.\n\nI believe this paper can have an impact in the neurips community, since it can inspire a new research direction on enoder-based MCMC methods that use amortization and avoid datapoint-wise iterations.\n\n\nWEAKNESSES \n\nThere are some experimental improvements that I believe could further increase the impact of this paper.\n\n1. You state that the goal of the experiments is to show that ALD works, and not that of achieving SOTA results, which is ok. However, for this type of paper that presents a method that can be readily applied to any deep LVM, trying it out on a more SOTA architecture would have made the results much more compelling. The fact that you have not done it makes me wonder if there are some complications to applying it to more complex architectures.\n\n2. How can one monitor the convergence of the MCMC chain? Which convergence diagnostics have you used? \n\n3. Did you ever get in situations where the MH acceptance rate was too low/high? \n\n4. What are the training times of the different models considered in the experiments?\n\n\n Minor comments:\n\n* typo in title: variabel -> variable \n\n* line 29. The issue is not that the distribution is tractable as it is implied in the sentence. The issue is that the posterior for these types of models is complex, so the tractable distributions we use are not a good approximation. \n\n* line 41: \"in test time\" -> \"at test time\" \n\n\n"
    },
    "review2": {
      "summary": "The paper introduces amorized Langevin dynamics (ALD), a method for initializing Langevin dynamics in the function parameter space that makes it efficient to perform posterior sampling. Based on this method, the paper presents the Langevin autoencoder (LAE), a deep latent variable model that is easy to implement and has competitive performance compared to similar existing methods.",
      "strengths_and_weaknesses": "Strengths:\n- The preliminaries and the core method are explained clearly. The drawbacks of existing MCMC and variational inference methods motivate the main ideas very well.\n- The algorithm of LAE is presented very clearly (Algorithm 2).\n- The idea of performing Langevin sampling in encoder parameter space seems quite novel and interesting. Proof is given on why this MCMC in the encoder parameter space will converge to the true data posterior.\n\nWeaknesses:\n- Although it doesn't get in the way of understanding the key ideas, the writing can certainly be improved at a couple of places. Examples include \"a more straightforward and sophisticated framework\" (line 48), \"replacing MCMC on the latent space into the encoder's parameter space\" (line 52) and \"we substitue it for its evidence lower bound\" (line 277, I believe it should be the other way around). Should be easy to fix.\n- I find the claim that ALD \"completely removes datapoint-wise iterations\" slightly misleading, since it does so trivially by turning datapoint-wise iterations into parameter space iterations. In essence it still relies on the encoder (up to the second to last layer) to initialize the MCMC in a high-density region, which is still pretty similar to Hoffman (2017). Maybe it can be shown that this method can have the same or better performance with less MCMC iterations than Hoffman, at which point it would be interesting to discuss why moving to parameter space gives such an advantage.\n- Without providing details on hyperparameter search (which can influence results greatly), the experimental results might not be sufficient for concluding that the LAE \"outperforms\" the existing methods. As mentioned in the last point, I think it would be really beneficial to show how the performance of the Hoffman (2017) model is influenced by the number of MCMC steps used."
    },
    "review3": {
      "summary": "The paper deals with performing Langevin dynamics as a form of sampling, only using an amortisation mechanism. This reduces the computational overhead of performing the sampling. The method is then verified on synthetic and generated data sets\n",
      "strengths_and_weaknesses": "The paper is very clearly written and cleanly presented. It is worth mentioning that the authors also did a very good job introducing other related works (albeit a bit late in the text at section 4).\nMore so I think The main theorem is an important one. The idea of unfing the generated Markov chains with respect to the data set is novel.\nIn top of that using amortisation is a fantastic idea for a Markovian process since the lack of time correlation can make this efficient much like Mori Zwanzig operators untangle non markovian processes \nThat being said, there are a few things I am a bit worried about. It seems like to sample the ELBO there is a need to resample all the chains ?\n"
    },
    "review4": {
      "summary": null,
      "strengths_and_weaknesses": null
    },
    "review5": {
      "summary": null,
      "strengths_and_weaknesses": null
    }
  },
  "Uni[MASK]: Unified Inference in Sequential Decision Problems": {
    "review1": {
      "summary": "This submission proposed a new framework, Uni[MASK], which performs unified inference in sequential decision problems, using different masking schemes. \n\nThe authors demonstrated that randomly sampling masking schemes help the bidirectional transformer model being able to do behavior cloning, rewarding conditioning, dynamics modeling and more.\n\nThe experiments are first on grid-world and then extended to Mujoco-physics Maze2D environment. The comparison between single-task, multi-task, random-task, with finetune are through and solid, integrating the theory with practice, and quite convincing. The experiments in Mujoco-physics Maze2D environment shows that Uni[MASK] framework outperforms baselines, such as Feedforward Neural Network and Decision Transformer.\n\nI fully endorse that this submission is a wonderful work: well designed experiments, diplomatic and sound illustration and the novelty of unifying decision making through Uni[MASK] and bidirectional models.",
      "strengths_and_weaknesses": "Strengths:\n* Uni[MASK] unifies inference task in sequential decision problems.\n* The illustration of motivation, theory and experiments design is convincing and sound, written and presented very well.\n* The authors demonstrate how randomly sampling masking schemes at training time produces a single multi-inference-task model that can do behavior cloning, reward-conditioning, dynamics modeling and more.\n* The authors test how training on many tasks affects single-task performance.\n* The authors show how fine-tuning models trained with random masking consistently outperforms single-task models.\n* The proposed Hypothesis H1 ( {multi-task, random-mask, finetune} > single-task) and H2 ( {random-mask > multi-task} ) make sense intuitively, as \"H1 test whether models indeed learn richer representations by training on multiple inference tasks\" and H2 test \"whether training on all possible tasks by randomly sampling maskings at training time is better than selecting a set of specific maskings\"\n* The results from well designed experiments strongly support hypothesis H1 and H2.\n* The authors extensively analyze how different training regimes (combination of single-task, multi-task, random mask, fintune) affect performance. The analysis is very convincing to me.\n* The authors also make experiments comparison with GPT-like architectures, and the analysis is also very convincing: \"We find that while using GPT seems to yield similar performance to BERT for context length five, using GPT seems to give an advantage for longer sequence lengths,\" and \"This suggests that if one were able to use a GPT architecture and train it with random masking and fine-tuning, it might be possible to get the best of both worlds.\"\n\nWeakness:\n* Relative short context lengths, and the experiments is mainly on the grid world (4 * 4), if the grid size increases, it might further improve this work.\n"
    },
    "review2": {
      "summary": "This paper presents the Uni[MASK] framework, which generalizes masked language modeling (in natural language processing) to more general sequence decision problems. Given actions, states and optional property tokens (such as the return-to-go), multiple tasks such as behavioral cloning, reward-conditional offline RL, forward dynamics, etc., may be represented by specific masking schemes. The authors propose to train a model by using a randomized masking scheme (instead of single-task only or with a fixed set of tasks). Such a Uni[Mask] model may also be fine-tuned on a given task afterwards. A pre-trained Uni[MASK] model often performs comparably to single-task training, and fine-tuning further improves results.\n\n[Post author response] I updated the rating I assigned to this paper, in particular because of the correction to the originally misleading discussion.\n",
      "strengths_and_weaknesses": "**Strengths**\n\nThe proposed approach neatly formalizes multiple tasks under a general masking framework.\n\nTraining a Uni[MASK] model, then finetuning it on a given task, generally leads to better results than single-task training only.\n\nThe approach is tested in both discrete (MiniGrid) and continuous (Maze2D) environments.\n\n**Weaknesses**\n\nThe discussion around line 200 is misleading. In figure 7, multi-task performs worse than single-task (although sometimes negligibly), which doesn't support H1.\n\nThe distinction between BERT-like and GPT-like models should be described more clearly (see question below).\n\nThe MiniGrid environment appears to be very simple. I would be interested in seeing how well the approach scales with larger grids."
    },
    "review3": {
      "summary": "Proposes an approach to using a single bidirectional transformer to accomplish many different reinforcement learning tasks, including behavior cloning, (sub)goal conditioning, and conditioning on properties more generally. It accomplishes this by creating a sequence of out of the (state, action, properties) for all timesteps, then either (1) training on a single type of mask, (2) training across many masking styles drawn from fixed set, and (3) randomly masking positions in the sequence. (2) and (3) can be finetuned in single task fashion. They evaluate on a toy gridworld and the mujoco 2d maze tasks. They find that Uni[MASK] performs better across both given a short truncated sequence, but it underperforms a GPT model for longer sequences. They attribute this to difficulties in training BERT models.",
      "strengths_and_weaknesses": "\n\t- originality\n\t\t- Concurrent work suggests that the core ideas of this paper are in the air (see: foundation posterior, multigame decision transformer, The UL2 paper on unifying masking schemes).\n\t- quality\n\t\t- The paper is well executed. It has simple experiments which verify the core claims.\n\t\t- My main concern is that the length 10 context experiments underperforming. Would like to see more study of this instead of alluding to claims that BERT has this known failure mode.\n\t- clarity\n\t\t- The paper is well written and a pleasant read. It adequately cites prior work, and it does a great job of explaining and illustrating the core ideas.\n\t- significance\n\t\t- The paper is a solid contribution to the literature. Overall, its core findings and technique align with concurrent and prior work."
    },
    "review4": {
      "summary": null,
      "strengths_and_weaknesses": null
    },
    "review5": {
      "summary": null,
      "strengths_and_weaknesses": null
    },
    "review6": {
      "summary": null,
      "strengths_and_weaknesses": null
    }
  },
  "CW-ERM: Improving Autonomous Driving Planning with Closed-loop Weighted Empirical Risk Minimization": {},
  "Identifying the Context Shift between Test Benchmarks and Production Data": {},
  "Neural Unbalanced Optimal Transport via Cycle-Consistent Semi-Couplings": {},
  "Privacy-Preserving Machine Learning for Collaborative Data Sharing via Auto-encoder Latent Space Embeddings": {},
  "Differentially Private CutMix for Split Learning with Vision Transformer": {},
  "DeepJoint: Robust Survival Modelling Under Clinical Presence Shift": {},
  "Fast kinematics modeling for conjunction with lens image modeling": {},
  "PatchRot: A Self-Supervised Technique for Training Vision Transformers": {},
  "DARTFormer: Finding The Best Type Of Attention": {},
  "Self-supervised detection of atmospheric phenomena from remotely sensed synthetic aperture radar imagery": {},
  "Deconvolving Detector Effects for Distribution Moments": {},
  "Conformal Semantic Keypoint Detection with Statistical Guarantees": {},
  "Active Learning with Table Language Models": {},
  "A View From Somewhere: Human-Centric Face Representations": {},
  "Towards Reasoning-Aware Explainable VQA": {},
  "[Re] Graph Edit Networks": {},
  "Generation Probabilities are Not Enough: Improving Error Highlighting for AI Code Suggestions": {}
}