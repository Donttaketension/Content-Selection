{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "687c2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_parquet(\"hf://datasets/Paper2Poster/Paper2Poster/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d86ef115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>conference</th>\n",
       "      <th>year</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>image_url</th>\n",
       "      <th>qa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biologically-inspired adaptive learning in the...</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>2023</td>\n",
       "      <td>https://openreview.net/pdf?id=WjHYgEfXiV</td>\n",
       "      <td>https://neurips.cc/media/PosterPDFs/NeurIPS%20...</td>\n",
       "      <td>{\\n    \"detail\": {\\n        \"questions\": {\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Hessian Screening Rule</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://proceedings.neurips.cc/paper_files/pap...</td>\n",
       "      <td>https://neurips.cc/media/PosterPDFs/NeurIPS%20...</td>\n",
       "      <td>{\\n    \"detail\": {\\n        \"questions\": {\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Transformers, parallel computation, and logari...</td>\n",
       "      <td>ICML</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://arxiv.org/pdf/2402.09268</td>\n",
       "      <td>https://icml.cc/media/PosterPDFs/ICML%202024/3...</td>\n",
       "      <td>{\\n    \"detail\": {\\n        \"questions\": {\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Tangent Kernels for Axis-Aligned Tree E...</td>\n",
       "      <td>ICML</td>\n",
       "      <td>2024</td>\n",
       "      <td>https://arxiv.org/pdf/2109.04983</td>\n",
       "      <td>https://icml.cc/media/PosterPDFs/ICML%202024/3...</td>\n",
       "      <td>{\\n    \"detail\": {\\n        \"questions\": {\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CW-ERM: Improving Autonomous Driving Planning ...</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>2022</td>\n",
       "      <td>https://arxiv.org/pdf/2210.02174</td>\n",
       "      <td>https://neurips.cc/media/PosterPDFs/NeurIPS%20...</td>\n",
       "      <td>{\\n    \"detail\": {\\n        \"questions\": {\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title conference  year  \\\n",
       "0  Biologically-inspired adaptive learning in the...    NeurIPS  2023   \n",
       "1                         The Hessian Screening Rule    NeurIPS  2022   \n",
       "2  Transformers, parallel computation, and logari...       ICML  2024   \n",
       "3  Neural Tangent Kernels for Axis-Aligned Tree E...       ICML  2024   \n",
       "4  CW-ERM: Improving Autonomous Driving Planning ...    NeurIPS  2022   \n",
       "\n",
       "                                           paper_url  \\\n",
       "0           https://openreview.net/pdf?id=WjHYgEfXiV   \n",
       "1  https://proceedings.neurips.cc/paper_files/pap...   \n",
       "2                   https://arxiv.org/pdf/2402.09268   \n",
       "3                   https://arxiv.org/pdf/2109.04983   \n",
       "4                   https://arxiv.org/pdf/2210.02174   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://neurips.cc/media/PosterPDFs/NeurIPS%20...   \n",
       "1  https://neurips.cc/media/PosterPDFs/NeurIPS%20...   \n",
       "2  https://icml.cc/media/PosterPDFs/ICML%202024/3...   \n",
       "3  https://icml.cc/media/PosterPDFs/ICML%202024/3...   \n",
       "4  https://neurips.cc/media/PosterPDFs/NeurIPS%20...   \n",
       "\n",
       "                                                  qa  \n",
       "0  {\\n    \"detail\": {\\n        \"questions\": {\\n  ...  \n",
       "1  {\\n    \"detail\": {\\n        \"questions\": {\\n  ...  \n",
       "2  {\\n    \"detail\": {\\n        \"questions\": {\\n  ...  \n",
       "3  {\\n    \"detail\": {\\n        \"questions\": {\\n  ...  \n",
       "4  {\\n    \"detail\": {\\n        \"questions\": {\\n  ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94df03d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd6255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3140772b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openreview\n",
    "\n",
    "# API V2\n",
    "client = openreview.api.OpenReviewClient(\n",
    "    baseurl='https://api2.openreview.net',\n",
    "    username='aaditya.deshpande@tcs.com',\n",
    "    password='Aadityamd@0207'\n",
    ")\n",
    "\n",
    "# API V1\n",
    "client_v1 = openreview.Client(\n",
    "    baseurl='https://api.openreview.net',\n",
    "    username='aaditya.deshpande@tcs.com',\n",
    "    password='Aadityamd@0207'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7aa845",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_v2 = client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "377e7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:40<00:00, 33.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'title': 'Conditional Matrix Flows for Gaussian Graphical Models',\n",
       "  'forum': 'GYnbubCXhE',\n",
       "  'reply': {'content': {'summary': {'value': 'This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets.'},\n",
       "    'soundness': {'value': '3 good'},\n",
       "    'presentation': {'value': '3 good'},\n",
       "    'contribution': {'value': '3 good'},\n",
       "    'strengths': {'value': 'Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \\n\\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated.'},\n",
       "    'weaknesses': {'value': 'Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost.'},\n",
       "    'questions': {'value': 'In synthetic data example, why did you choose to have more samples than dimensions ( $n>d$ )? Since in that case GGM can be obtained with matrix inverse, and no need for penalized objective.'},\n",
       "    'limitations': {'value': 'Limitations were not discussed.'},\n",
       "    'flag_for_ethics_review': {'value': ['No ethics review needed.']},\n",
       "    'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'},\n",
       "    'confidence': {'value': '4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.'},\n",
       "    'code_of_conduct': {'value': 'Yes'}},\n",
       "   'id': '8DQ2f2lWKF',\n",
       "   'number': 4,\n",
       "   'cdate': 1688722229692,\n",
       "   'tcdate': 1688722229692,\n",
       "   'mdate': 1702411518763,\n",
       "   'tmdate': 1702411518763,\n",
       "   'signatures': ['NeurIPS.cc/2023/Conference/Submission15533/Reviewer_CnQu'],\n",
       "   'nonreaders': [],\n",
       "   'readers': ['everyone'],\n",
       "   'writers': ['NeurIPS.cc/2023/Conference',\n",
       "    'NeurIPS.cc/2023/Conference/Submission15533/Reviewer_CnQu'],\n",
       "   'forum': 'GYnbubCXhE',\n",
       "   'replyto': 'GYnbubCXhE',\n",
       "   'invitations': ['NeurIPS.cc/2023/Conference/Submission15533/-/Official_Review',\n",
       "    'NeurIPS.cc/2023/Conference/-/Edit'],\n",
       "   'domain': 'NeurIPS.cc/2023/Conference',\n",
       "   'license': 'CC BY 4.0',\n",
       "   'version': 2}},\n",
       " {'title': 'Conditional Matrix Flows for Gaussian Graphical Models',\n",
       "  'forum': 'GYnbubCXhE',\n",
       "  'reply': {'content': {'summary': {'value': 'This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \\nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\\\geq1}$ is used).'},\n",
       "    'soundness': {'value': '3 good'},\n",
       "    'presentation': {'value': '4 excellent'},\n",
       "    'contribution': {'value': '2 fair'},\n",
       "    'strengths': {'value': '1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \\n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\\n3. Using sub-l1 norm is suitable for structure learning. \\n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \\n5. The paper is well-written, and the relevant work is sufficiently discussed.    \\n6. Due to its flexibility, the proposed method has the potential of having a large impact.'},\n",
       "    'weaknesses': {'value': 'Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \\n\\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \\n\\nMinor suggestion: \\n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \\n2. Fix minor typos e.g. the end sentence period in line 214.'},\n",
       "    'questions': {'value': '* In line 141, what do you mean by \"contradiction\"?'},\n",
       "    'limitations': {'value': 'The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \\n\\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.'},\n",
       "    'flag_for_ethics_review': {'value': ['No ethics review needed.']},\n",
       "    'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'},\n",
       "    'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'},\n",
       "    'code_of_conduct': {'value': 'Yes'}},\n",
       "   'id': '4gZSINDkER',\n",
       "   'number': 3,\n",
       "   'cdate': 1688702134033,\n",
       "   'tcdate': 1688702134033,\n",
       "   'mdate': 1702411518854,\n",
       "   'tmdate': 1702411518854,\n",
       "   'signatures': ['NeurIPS.cc/2023/Conference/Submission15533/Reviewer_pTVu'],\n",
       "   'nonreaders': [],\n",
       "   'readers': ['everyone'],\n",
       "   'writers': ['NeurIPS.cc/2023/Conference',\n",
       "    'NeurIPS.cc/2023/Conference/Submission15533/Reviewer_pTVu'],\n",
       "   'forum': 'GYnbubCXhE',\n",
       "   'replyto': 'GYnbubCXhE',\n",
       "   'invitations': ['NeurIPS.cc/2023/Conference/Submission15533/-/Official_Review',\n",
       "    'NeurIPS.cc/2023/Conference/-/Edit'],\n",
       "   'domain': 'NeurIPS.cc/2023/Conference',\n",
       "   'license': 'CC BY 4.0',\n",
       "   'version': 2}},\n",
       " {'title': 'Conditional Matrix Flows for Gaussian Graphical Models',\n",
       "  'forum': 'GYnbubCXhE',\n",
       "  'reply': {'content': {'summary': {'value': 'This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution.'},\n",
       "    'soundness': {'value': '2 fair'},\n",
       "    'presentation': {'value': '3 good'},\n",
       "    'contribution': {'value': '2 fair'},\n",
       "    'strengths': {'value': '- Well written paper.\\n\\n        - Illustrative toy experiments.'},\n",
       "    'weaknesses': {'value': '- The proposed method is a combination of already known techniques.\\n\\n        - The experimental section is weak as only a single real problem is considered.\\n\\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\\n\\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\\n\\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros.'},\n",
       "    'questions': {'value': 'None'},\n",
       "    'limitations': {'value': 'The authors have not commented on the limitations of their approach.'},\n",
       "    'flag_for_ethics_review': {'value': ['No ethics review needed.']},\n",
       "    'rating': {'value': '5: Borderline accept: Technically solid paper where reasons to accept outweigh reasons to reject, e.g., limited evaluation. Please use sparingly.'},\n",
       "    'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'},\n",
       "    'code_of_conduct': {'value': 'Yes'}},\n",
       "   'id': '7JKoCjh5YL',\n",
       "   'number': 2,\n",
       "   'cdate': 1688388422621,\n",
       "   'tcdate': 1688388422621,\n",
       "   'mdate': 1702411518947,\n",
       "   'tmdate': 1702411518947,\n",
       "   'signatures': ['NeurIPS.cc/2023/Conference/Submission15533/Reviewer_3sWQ'],\n",
       "   'nonreaders': [],\n",
       "   'readers': ['everyone'],\n",
       "   'writers': ['NeurIPS.cc/2023/Conference',\n",
       "    'NeurIPS.cc/2023/Conference/Submission15533/Reviewer_3sWQ'],\n",
       "   'forum': 'GYnbubCXhE',\n",
       "   'replyto': 'GYnbubCXhE',\n",
       "   'invitations': ['NeurIPS.cc/2023/Conference/Submission15533/-/Official_Review',\n",
       "    'NeurIPS.cc/2023/Conference/-/Edit'],\n",
       "   'domain': 'NeurIPS.cc/2023/Conference',\n",
       "   'license': 'CC BY 4.0',\n",
       "   'version': 2}},\n",
       " {'title': 'Conditional Matrix Flows for Gaussian Graphical Models',\n",
       "  'forum': 'GYnbubCXhE',\n",
       "  'reply': {'content': {'summary': {'value': 'This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way.'},\n",
       "    'soundness': {'value': '3 good'},\n",
       "    'presentation': {'value': '3 good'},\n",
       "    'contribution': {'value': '3 good'},\n",
       "    'strengths': {'value': \"The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea.\"},\n",
       "    'weaknesses': {'value': \"The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso.\"},\n",
       "    'questions': {'value': '- in the frequentist case, how does the proposed framework compares against more classical techniques to obtain the solution paths, e.g., iterative reweighted l1-norm? '},\n",
       "    'limitations': {'value': 'The authors adequately addressed the limitations of their proposed framework. '},\n",
       "    'flag_for_ethics_review': {'value': ['No ethics review needed.']},\n",
       "    'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'},\n",
       "    'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'},\n",
       "    'code_of_conduct': {'value': 'Yes'}},\n",
       "   'id': 'ImVCECqCY5',\n",
       "   'number': 1,\n",
       "   'cdate': 1687904558111,\n",
       "   'tcdate': 1687904558111,\n",
       "   'mdate': 1702411519040,\n",
       "   'tmdate': 1702411519040,\n",
       "   'signatures': ['NeurIPS.cc/2023/Conference/Submission15533/Reviewer_vqBu'],\n",
       "   'nonreaders': [],\n",
       "   'readers': ['everyone'],\n",
       "   'writers': ['NeurIPS.cc/2023/Conference',\n",
       "    'NeurIPS.cc/2023/Conference/Submission15533/Reviewer_vqBu'],\n",
       "   'forum': 'GYnbubCXhE',\n",
       "   'replyto': 'GYnbubCXhE',\n",
       "   'invitations': ['NeurIPS.cc/2023/Conference/Submission15533/-/Official_Review',\n",
       "    'NeurIPS.cc/2023/Conference/-/Edit'],\n",
       "   'domain': 'NeurIPS.cc/2023/Conference',\n",
       "   'license': 'CC BY 4.0',\n",
       "   'version': 2}}]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venue_id = \"NeurIPS.cc/2023/Conference\"  # example\n",
    "venue_group = client_v2.get_group(venue_id)\n",
    "submission_name = venue_group.content[\"submission_name\"][\"value\"]\n",
    "target_titles = {\n",
    "    \"Conditional Matrix Flows for Gaussian Graphical Models\",\n",
    "}\n",
    "\n",
    "def norm(s):\n",
    "    return str(s).strip().lower()\n",
    "\n",
    "def get_title(sub):\n",
    "    t = sub.content['title']['value'] if isinstance(sub.content.get(\"title\"), dict) else sub.content.get(\"title\")\n",
    "    #if isinstance(t, dict) and \"value\" in t:\n",
    "    #    return t[\"value\"]\n",
    "    return t\n",
    "\n",
    "reply_type = \"Official_Review\"  # or \"Meta_Review\", \"Decision\", etc.\n",
    "submissions = client_v2.get_all_notes(\n",
    "    invitation=f\"{venue_id}/-/{submission_name}\",\n",
    "    details=\"replies\"\n",
    ")\n",
    "\n",
    "wanted = {norm(t) for t in target_titles}\n",
    "\n",
    "replies = []\n",
    "for submission in submissions:\n",
    "    title = get_title(submission)\n",
    "    if norm(title) not in wanted:\n",
    "        continue\n",
    "\n",
    "    for reply in submission.details.get(\"replies\", []):\n",
    "        if any(inv.endswith(reply_type) for inv in reply.get(\"invitations\", [])):\n",
    "            replies.append({\n",
    "                \"title\": title,\n",
    "                \"forum\": submission.id,\n",
    "                \"reply\": reply\n",
    "            })\n",
    "\n",
    "replies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "57b83140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d712ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "efbdcc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Conditional Matrix Flows for Gaussian Graphical Models',\n",
       " 'forum': 'GYnbubCXhE',\n",
       " 'reply': {'content': {'summary': {'value': 'This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \\nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\\\geq1}$ is used).'},\n",
       "   'soundness': {'value': '3 good'},\n",
       "   'presentation': {'value': '4 excellent'},\n",
       "   'contribution': {'value': '2 fair'},\n",
       "   'strengths': {'value': '1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \\n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\\n3. Using sub-l1 norm is suitable for structure learning. \\n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \\n5. The paper is well-written, and the relevant work is sufficiently discussed.    \\n6. Due to its flexibility, the proposed method has the potential of having a large impact.'},\n",
       "   'weaknesses': {'value': 'Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \\n\\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \\n\\nMinor suggestion: \\n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \\n2. Fix minor typos e.g. the end sentence period in line 214.'},\n",
       "   'questions': {'value': '* In line 141, what do you mean by \"contradiction\"?'},\n",
       "   'limitations': {'value': 'The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \\n\\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.'},\n",
       "   'flag_for_ethics_review': {'value': ['No ethics review needed.']},\n",
       "   'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'},\n",
       "   'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'},\n",
       "   'code_of_conduct': {'value': 'Yes'}},\n",
       "  'id': '4gZSINDkER',\n",
       "  'number': 3,\n",
       "  'cdate': 1688702134033,\n",
       "  'tcdate': 1688702134033,\n",
       "  'mdate': 1702411518854,\n",
       "  'tmdate': 1702411518854,\n",
       "  'signatures': ['NeurIPS.cc/2023/Conference/Submission15533/Reviewer_pTVu'],\n",
       "  'nonreaders': [],\n",
       "  'readers': ['everyone'],\n",
       "  'writers': ['NeurIPS.cc/2023/Conference',\n",
       "   'NeurIPS.cc/2023/Conference/Submission15533/Reviewer_pTVu'],\n",
       "  'forum': 'GYnbubCXhE',\n",
       "  'replyto': 'GYnbubCXhE',\n",
       "  'invitations': ['NeurIPS.cc/2023/Conference/Submission15533/-/Official_Review',\n",
       "   'NeurIPS.cc/2023/Conference/-/Edit'],\n",
       "  'domain': 'NeurIPS.cc/2023/Conference',\n",
       "  'license': 'CC BY 4.0',\n",
       "  'version': 2}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "220d268e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': {'summary': {'value': 'This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \\nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\\\geq1}$ is used).'},\n",
       "  'soundness': {'value': '3 good'},\n",
       "  'presentation': {'value': '4 excellent'},\n",
       "  'contribution': {'value': '2 fair'},\n",
       "  'strengths': {'value': '1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \\n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\\n3. Using sub-l1 norm is suitable for structure learning. \\n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \\n5. The paper is well-written, and the relevant work is sufficiently discussed.    \\n6. Due to its flexibility, the proposed method has the potential of having a large impact.'},\n",
       "  'weaknesses': {'value': 'Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \\n\\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \\n\\nMinor suggestion: \\n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \\n2. Fix minor typos e.g. the end sentence period in line 214.'},\n",
       "  'questions': {'value': '* In line 141, what do you mean by \"contradiction\"?'},\n",
       "  'limitations': {'value': 'The authors should compare their method with the relevant structure learning lierature and reveal its points of strength as well as its limitations. \\n\\nThis work is theoretical/methodological and does not have any positive or negative social/ethical impact on its own.'},\n",
       "  'flag_for_ethics_review': {'value': ['No ethics review needed.']},\n",
       "  'rating': {'value': '6: Weak Accept: Technically solid, moderate-to-high impact paper, with no major concerns with respect to evaluation, resources, reproducibility, ethical considerations.'},\n",
       "  'confidence': {'value': '3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.'},\n",
       "  'code_of_conduct': {'value': 'Yes'}},\n",
       " 'id': '4gZSINDkER',\n",
       " 'number': 3,\n",
       " 'cdate': 1688702134033,\n",
       " 'tcdate': 1688702134033,\n",
       " 'mdate': 1702411518854,\n",
       " 'tmdate': 1702411518854,\n",
       " 'signatures': ['NeurIPS.cc/2023/Conference/Submission15533/Reviewer_pTVu'],\n",
       " 'nonreaders': [],\n",
       " 'readers': ['everyone'],\n",
       " 'writers': ['NeurIPS.cc/2023/Conference',\n",
       "  'NeurIPS.cc/2023/Conference/Submission15533/Reviewer_pTVu'],\n",
       " 'forum': 'GYnbubCXhE',\n",
       " 'replyto': 'GYnbubCXhE',\n",
       " 'invitations': ['NeurIPS.cc/2023/Conference/Submission15533/-/Official_Review',\n",
       "  'NeurIPS.cc/2023/Conference/-/Edit'],\n",
       " 'domain': 'NeurIPS.cc/2023/Conference',\n",
       " 'license': 'CC BY 4.0',\n",
       " 'version': 2}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replies[1].get(\"reply\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0555f988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(s):\n",
    "    return str(s).strip().lower()\n",
    "\n",
    "def get_reviews(title, conference, year, reply_type=\"Official_Review\"):\n",
    "    '''given a title, conference, year, and reply type, fetches summary, strengths, and weaknesses from the each review from OpenReview'''\n",
    "    venue_id = f\"{conference}.cc/{year}/Conference\"\n",
    "    target_title = norm(title)\n",
    "    reviews = {}\n",
    "    submissions = client.get_all_notes(invitation=f\"{venue_id}/-/{submission_name}\", details=\"replies\")\n",
    "    replies = []\n",
    "    for submission in submissions:\n",
    "        t = target_title\n",
    "        for reply in submission.details.get(\"replies\", []):\n",
    "            if any(inv.endswith(reply_type) for inv in reply.get(\"invitations\", [])):\n",
    "                replies.append({\"title\": t, \"forum\": submission.id, \"reply\": reply})\n",
    "    \n",
    "    for i in range (len(replies)):\n",
    "        summary = replies[i].get(\"reply\").get(\"content\").get(\"summary\").get(\"value\") if replies[i].get(\"reply\").get(\"content\").get(\"summary\") else None\n",
    "        strengths = replies[i].get(\"reply\").get(\"content\").get(\"strengths\").get(\"value\") if replies[i].get(\"reply\").get(\"content\").get(\"strengths\") else None\n",
    "        weaknesses = replies[i].get(\"reply\").get(\"content\").get(\"weaknesses\").get(\"value\") if replies[i].get(\"reply\").get(\"content\").get(\"weaknesses\") else None\n",
    "        reviews[f\"review_{i+1}\"] = {\"summary\": summary, \"strengths\": strengths, \"weaknesses\": weaknesses}\n",
    "    return reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef29a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:06<00:00, 51.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'review_1': {'summary': 'Paper introduces a framework to detect and categorize different model uncertainty types in classification setting. Proposer model-agnostic (with some assumptions of model structure) uncertainty quantification (UQ) relies on kernel density estimation on latent space representation by defining scores for OOD, Bnd, and IDM examples. Proposed approach is empirically evaluated using toy data as well as real MNIST and UCI datasets. Some of the limitations of existing UQ are examined as well as ability to use new uncertainty categorisation as flagging method to filter out training example to learn more accurate models.',\n",
       "  'strengths': 'To my knowledge, paper presents a novel approach to categorise different predictive uncertainty types in classification setting. The proposal is well-structured with appropriate theoretical background, and especially practical evaluation which includes both toy illustration of properties as well as real data evaluation of MNIST variants and UCI datasets. Proposed framework shows simple yet effective solution that seems to improve existing approaches in practice and is bringing new knowledge for analysing existing UQ methods.\\n\\nSummary of strengths\\n- Novel view on uncertainty quantification\\n- Work in practice, at least in given classification tasks\\n- Well-made empirical evaluation (see also weaknesses)',\n",
       "  'weaknesses': 'There are some weaknesses that could further improve the presentation and usefulness of proposed framework. Analysis of different model architectures (i.e. latent space) with proposed density estimation could be further extend to show how these behave with different level of uncertainty in the datasets to justify the modelling choices. Also, the analysis of verifying DAUC concentrates only on MNIST variants, but it could be useful to examine different types of data with different noise and uncertainty levels.\\n\\nSummary of weaknesses\\n- Limited analysis of model assumptions and density estimation\\n- Somewhat limited type of datasets and model architectures evaluated\\n- Some polishing of text here and there (see questions)\\n'},\n",
       " 'review_2': {'summary': 'I have read the other reviews and all rebuttals. The other reviewers are positive overall, and the authors provided very detailed and thorough rebuttals. I have increased my score from \"5: Borderline accept\" to \"6: Weak Accept\".\\n***\\n***\\n***\\n***\\n\\n\\nThe authors propose an approach for categorizing examples which are flagged as uncertain by uncertainty estimation methods (e.g., deep ensembles, MC-dropout) into three classes: out-of-distribution examples (OOD), boundary examples (Bnd) and examples in regions of high in-distribution misclassification (IDM). They propose  a method for post-hoc uncertainty categorization, utilizing latent space / feature-space based density models.',\n",
       "  'strengths': 'The paper is very well written overall, I enjoyed reading it. More or less everything is clearly described and explained. The authors definitely seem knowledgeable, they have done a thorough job putting together the paper. I liked the color coding in Section 4. \\n\\nSection 3.3 is interesting. The proposed confusion density matrix is novel (I think) and makes some intuitive sense, it is a pretty neat idea.\\n\\nThe example in Section 4.1 is quite neat, it provides good intuition.\\n\\nThe use case in Section 4.4 seems potentially useful.',\n",
       "  'weaknesses': 'I find it quite difficult to judge the technical contribution and impact of the proposed approach. Doing OOD detection based on feature-space density is not new (see e.g. Sun et al., \"Out-of-distribution detection with deep nearest neighbors\", ICML 2022), and I am not sure how useful the Bnd/IDM categorization actually is in practice.\\n\\nThe authors show two use cases in Section 4.3 and 4.4. However, in Section 4.3 the only concrete conclusion seems to be that DE is most apt at flagging the OOD class, but this is not really a new finding? And while the results in Section 4.4 do seem quite promising, the method is here only applied to MNIST?\\n\\nIn fact, the proposed method is never applied to any dataset with more than ~10 classes? Can it be difficult to apply to a dataset with e.g. 1000 classes? What happens to the confusion density matrix computation, does it become expensive? And what happens if the corpus C_{c1 --> c2} is empty for some pairs of classes?\\n\\n\\nSmall thing:\\n- I found Section 3.3.1 a bit confusing at first, I had to get through Definition 4 before I understood the paragraph above. In particular, I was a bit confused by \"The first situation where high uncertainty arises, is when g(x) is close to latent representations of validation examples that have been correctly assigned a label that differs from the predicted one\".'},\n",
       " 'review_3': {'summary': 'In this paper, the authors present a unique approach for classifying uncertainty into distinct categories, providing insights into the reasons behind labeling a particular sample as suspicious or highly uncertain. They develop a kernel density-based confusion density matrix for any neural network which separates suspicious data samples from the uncertainty estimator into three categories: out-of-distribution (OOD), samples near the decision boundary, and misclassified samples. The paper outlines the methodology for constructing this density-based matrix and compares the performance of existing uncertainty estimators using this proposed categorization. Empirical studies and results are provided, demonstrating how this classification can in fact improve the training of predictive models and highlight the reasons for model failure. ',\n",
       "  'strengths': 'In my opinion, this categorization process of determining what uncertainties actually flag (OOD, bnd etc.) is the main contribution. Importantly, the paper shows that this is a general framework applicable to any classification model (having a reasonably sized no. of classes). The paper demonstrates experiments on a variety of benchmarks contributing to its efficacy. Also, the paper is well written and simple to follow.',\n",
       "  'weaknesses': 'See questions.'},\n",
       " 'review_4': {'summary': 'This paper proposes a model-agnostic framework named DAUC to categorize uncertain examples flagged by UQ methods, which introduces the confusion density matrix and provides post-hoc categorization for model uncertainty. Besides, this paper categorizes suspicious examples identified by a given uncertainty method into OOD, Bnd and IDM three classes.',\n",
       "  'strengths': '1. This paper focuses on samples that remain suspect in uncertain methods, and proposes a model-agnostic density-based approach to mitigate this problem.\\n2. The overall writing structure of this paper is clear, and the core ideas expressed are clear too.\\n',\n",
       "  'weaknesses': '1. Why are the uncertain samples of the model divided into three categories? It is only mentioned in the abstract (i.e., a kernel-based approximation of the misclassification density), but there is no relevant description in the paper. \\n2. The four classes in Figure 1 should be changed to three classes, corresponding to the paper.\\n3. In the Categorizing Uncertainty part of the Section introduction, it is mentioned that DAUC is a model-agnostic method, but in the experimental part, we do not see the model-agnostic of DAUC.\\n'},\n",
       " 'review_5': {'summary': 'This paper explores the phenomenon of models using easy-to-learn spurious features (aka, shortcuts) instead of reliable but harder-to-learn true features. They find in their theoretical that max-margin relies on the spurious feature while controlling for uniforming margin induces learning the true feature. With this insight, they try numerous loss functions that provide a bias towards uniform margins and find improved worst-group accuracy on a variety of tasks.',\n",
       "  'strengths': '* Experiments show good results for their methods.',\n",
       "  'weaknesses': \"* The informal statement of Theorem 1 in the main text is too vague in my opinion. In particular, it's not stated what the regime of $n$ is and how these other quantities interact with it. \\n* The graphs are tough to read (too small) and the legends overlap with the plots.\"},\n",
       " 'review_6': {'summary': 'Having had my concerns addressed by the authors I have updated my score.\\n-----------------------------------------------------------------------------------------\\n\\n\\n\\n* The paper proposes an explanation for why neural networks tend to learn spurious features over stable fratures which lead to a lower loss and better performance.\\n* The main argument for this is due to the maxmargin losses induced through cross entropy, to counter this the authors propose several losses which induce a uniform margin.\\n* The authors propose a nice example and demonstrate the results on vision and language datasets.',\n",
       "  'strengths': '* The paper addresses a very important topic of the simplicity bias, and goes a significant way in addressing it. \\n* The comments and explanations are clear and concise, and follow a clear narrative.\\n* I find the arguments that inductive bias towards uniform margins for perception tasks to be convincing.\\n* The experiments are well conducted and clearly support their statements',\n",
       "  'weaknesses': '* I find the scatter approach to testing many margin based losses a little un elegant, I would rather know which is the most effective in the paper and then see the results for other attempted losses in the Appendix. But this is just me preference.\\n* Is Corollary one explicitly followed up with an experiment? I would like to know if it actually exhibits this behaviour or is there just the potential to?\\n* The experimental datasets are rather limited, Waterbirds, CelebA, Wilds etc. Not a negative per se, but it would be nice to see authors trying to improve the testing framework for this probelm.'},\n",
       " 'review_7': {'summary': 'This paper provides an in-depth analysis of the phenomenon of \"shortened learning\" in machine learning models, especially in the context of perceptual tasks. The authors confirm that basic empirical risk minimization (ERM) methods tend to prefer models that depend on shortcut features, even when models can achieve zero loss using only stable features. They attribute this to ERM\\'s inductive bias to maximize margins across all samples. To address this, the authors propose an alternative loss function biased inductively with a uniform margin called MARG-CTRL. The paper demonstrates that MARG-CTRL mitigates shortcut learning on multiple vision and language tasks without the use of annotations of the shortcut feature in training or even validation. They also show that MARG-CTRL performs on par or better than the more complex and costly two-step shortcut mitigation method.',\n",
       "  'strengths': '-This paper presents a thorough analysis of the shortcut learning problem. \\n-The authors propose a novel solution, MARG-CTRL, which has been shown to effectively mitigate shortcut learning in several tasks.\\n-The paper is well-written and easy to understand.',\n",
       "  'weaknesses': '-Although MARG-CTRL is shown to perform well across different tasks, it is not clear how MARG-CTRL perform in scenarios where the shortcut features and the stable features are highly correlated.\\n-The paper compares MARG-CTRL with two-stage shortcut-mitigating methods like JTT and CNC, it would be helpful to understand the specific scenarios where MARG-CTRL outperforms these methods and where it does not.'},\n",
       " 'review_8': {'summary': 'This paper theoretecally and empirically showed that the inductive bias of default- ERM maximizing the margin causes shortcut learning in  a linear perception task.\\nIt proposed uniform margins that leads to models that depend more on the stable than the shortcut feature and suggested loss functions encourage uniform-margin solutions.',\n",
       "  'strengths': 'This paper analyzes shortcut learning theoretically in terms of margin maximization.\\nI have not seen an analysis from this perspective before.\\nIt also proposes the concept of uniform margin from theory and suggests a method to prevent shortcut learning.',\n",
       "  'weaknesses': 'The theory itself has limited applicability due to the linear model, and we do not know how well it can actually be explained in general terms in actual deep learning models.'},\n",
       " 'review_9': {'summary': 'This paper proposed a method to advance adversarial contrastive learning by utilizing a technique called causal reasoning. The adversarial invariant regularization (AIR) proposed in this paper demonstrated a style factor. Additionally, the effectiveness of the proposed method was empirically shown using CIFAR10 and CIFAR100.',\n",
       "  'strengths': '- Theoretically, it explained how the KL divergence can provide invariant regularization.\\n- The paper is well organized and most explanations are clearly written and easy to understand the approach and the theoretical explanations.',\n",
       "  'weaknesses': \"- The theoretical analysis of this paper (section 3.2 and section 3.3) appears to apply adversarial examples to the theorem shown in paper [1], which seems closer to an application rather than a novel combination, resulting in a perceived lack of originality.\\n- Although most theorems and reasoning methods are well explained, expressing which input types the KL divergence loss of SIR and AIR applies to would be more effective for reproducing this paper through implementation.\\n- Furthermore, the performance gain shown in robustness experiments from the proposed regularization is considered to have low significance as it is less than 1% in most datasets and tasks.\\n- Also, there is insufficient explanation as to why the proposed method is more helpful for self-supervised adversarial robustness than existing methods, making it difficult to verify the experimental significance of the proposed method. Especially in the experimental results, AIR helps both clean performance and robustness compared to SIR, but there is no clear justification for why these two components should be used simultaneously.\\n- It is unclear why a model trained with SIR and AIR regularization for adversarial x and natural x performs well against common corruption.\\n- As it's a self-supervised pretraining method, the fact that experiments were only conducted on small datasets (CIFAR10, CIFAR100) leaves concerns about its applicability.\\n\\n[1] Mitrovic et al., REPRESENTATION LEARNING VIA INVARIANT CAUSAL MECHANISMS, ICLR 2021\"},\n",
       " 'review_10': {'summary': 'This paper proposes to tackle adversarial contrastive learning via causal reasoning. Specifically, the authors discuss the scenario where adversarial examples are involved in standard invariant regularization. The authors also provide analysis of proposed invariant regularization to justify the rationality. The experiments on different datasets show improvement compared with baselines.',\n",
       "  'strengths': '1. The paper is well-written and easy to follow.\\n2. Taking adversarial example in the SIR via Markov condition seems natural and the analysis could provide some insights.\\n3. The experiments on various datasets show improvement.\\n',\n",
       "  'weaknesses': 'I have several concerns:\\n\\n1. The comparison with other baselines is missing in Table 4, such as ACL with SIR and DynACL with SIR.\\n2. The authors conduct experiments on ResNet family. However, WideResNet backbone networks are always evaluated in the field of adversarial robustness. I wonder whether the superiority of IR can be generalized to different networks.\\n\\nMinors:\\n\\nIt seems a typo in Eq. 8, the KL divergence should be computed between $\\\\tau_i$ and $\\\\tau_j$.\\n\\n'},\n",
       " 'review_11': {'summary': 'This paper proposes a novel adversarial contrastive learning method, which introduces causal reasoning method to obtain robust feature representation and enforce independence from style factors. The idea is simple and effective. In addition, the experiments are sufficient to prove the effectiveness of the proposed method. The source codes are released.',\n",
       "  'strengths': '1. The idea is interesting and easy to understand.\\n2. The theoretical analysis is detailed and proves the effectiveness of the proposed method.\\n',\n",
       "  'weaknesses': '1. The improvement of the proposed method is limited.\\n2. Without causal reasoning, this paper only proposes two distribution alignment regularizations in the adversarial samples to obtain robust feature representation. Thus, this paper is an incremental work based on ACL and DynACL.\\n3. I want to see the performance of this paper in the large-scale datasets, such as sub-imagenet.'},\n",
       " 'review_12': {'summary': 'The authors propose AIR to regulate the the process of contrastive learning. They first analyze the causal graph of contrastive learning under the adversarial setting, and try to enforce  $p\\\\left(y^R | \\\\tilde x\\\\right)\\\\cdot p\\\\left(\\\\tilde x | x\\\\right)$ (Eq.4) to be invariant under different interventions. Intuitively, this regularizer would force the crafted adversarial examples to be style-independent and thus the learned representations shall enjoy better robustness. ',\n",
       "  'strengths': 'The core idea of this paper is technically novel and clearly presented.\\n\\nExperiments are reported by applying the proposed AIR / SIR terms to ACL / DynACL, and consistent performance gains are observed. Ablation studies for different values of $\\\\lambda_1$ and $\\\\lambda_2$ are also provided, to verify the effectiveness of the AIR term itself.\\n\\nThe authors also provide theoretical results to justify the rationality of the AIR term.',\n",
       "  'weaknesses': 'The proposed method would require more tunning since it incorporates two more hyper-parameters $\\\\lambda_1$ and $\\\\lambda_2$, and we can see from Table 7 that these two hyper-parameters interact in a non-trival way. For example, when compared with the case that only AIR is leveraged ($\\\\lambda_1=0,\\\\ \\\\lambda_2>0$), incorporating AIR with SIR (i.e., $\\\\lambda_1>0,\\\\ \\\\lambda_2>0$) could result in better **robust accuracy**.\\n\\nLittle type in Eq. 8: two augmentations in KL divergence should be different.\\n\\n--- Update ---\\nAfter reading additional experimented provieded by the authors, I decide to raise my score to 8.'},\n",
       " 'review_13': {'summary': 'This paper explores the subject of representation learning, focusing on two aspects: discrimination and diversity. Contrastive learning (CL) exhibits superior discrimination capabilities but suffers from limited diversity. Conversely, masked image modeling (MIM) offers greater diversity but shows weaker discrimination abilities.\\n\\nThe paper presents three insightful observations and integrates the benefits of both approaches, optimizing them for downstream tasks. In this context, \"hybrid distillation\" refers to the process where models are distilled using both contrastive learning (CL) for discrimination enhancement, and masked image modeling (MIM) for improving diversity. To reduce the training cost, the paper also proposes a token dropping strategy.',\n",
       "  'strengths': 'The paper has a solid experimental design to first re-examine discrimination and diversity, then propose its method and last to show its improvements on different downstream tasks. The idea is simple but effective and intuitive.',\n",
       "  'weaknesses': '- Please ensure that the term \"asymmetric X\" is used consistently throughout the paper. The document refers to several variants of the term, including \"asymmetric attention,\" \"asymmetric architecture,\" \"asymmetric decoder,\" and \"asymmetric designs.\" It would be beneficial to differentiate between these concepts and clarify which is the primary focus of the paper.\\n\\n- On line 104, the paper introduces the notation I() and H() to represent the mutual information and entropy, respectively, but does not explain how these quantities are calculated. For clarity, consider adding a brief explanation or citation for the methods used to estimate mutual information and entropy from the data. \\n\\n- Similarly, on line 156 the notation S\\' is introduced without explanation. Please consider defining or explaining how S\\' is derived.\\n\\n- When \"feature distillation\" is mentioned on line 106, adding a reference to the specific feature distillation approach used in the experiments would help clarify this concept for readers. Providing a citation would allow readers to refer to details of the feature distillation method.'},\n",
       " 'review_14': {'summary': 'The paper conducts sufficient experiments and theoretical analysis on diversity and discrimination. \\nMeanwhile,  the authors propose a simple yet effective hybrid distillation that combines contrastive learning pre-train and MIM pre-train.\\nThis hybrid distillation achieves significant improvement on downstream tasks.\\n',\n",
       "  'strengths': '- The paper is well written, with sufficient experiments and analysis. \\n- The accuracy improvement is significant.',\n",
       "  'weaknesses': '- The paper has some minor typo errors.\\n'},\n",
       " 'review_15': {'summary': 'This paper introduce a new distillation method that complimentary harmonizes two distillation method of different properties.',\n",
       "  'strengths': '* Hybrid Distillation obtained higher accuracies than DeiT, MAE, and CLIP using them.\\n* Explanation with analyses (NMI, AHD, and attention map visualization)\\n* The paper is clearly written',\n",
       "  'weaknesses': '* When I read the explanation in the method section, the proposed method seems very inefficient compared to methods without distillation (e.g., MAE, DINO). It would be better to compare quantitatively with throughput and total training hours.\\n\\n* Some values in tables are different to original values in references.\\n    * The COCO detection performance of MAE in this paper and MAE paper are different. The AP^box and AP^mask of MAE are reported as 50.3% and 44.9% in MAE paper while they are reported as 48.4% and 42.6% in this paper, respectively.\\n    * The transfer learning result of MAE toward Naturalist19 is also different to the value in MAE paper. MAE paper report it as 80.5% for ViT-B while this paper report it as 75.2%.\\n\\n* Are the explanations provided in the preliminary section the author’s own contributions or are they similar analyses  conducted and explained in other references? If they are the author’s contributions, which points can be regarded as novel?\\n\\n* Some points are not understandable\\n    * The authors distilled the features of the supervised and CL models and MIM models to features of the different layers in student model regarding diversity and discriminatively. However, in the current design, the distillation performed on the last layer affect the front layers without detaching back-propagation of the distillation loss. Is this the intended situation?\\n'},\n",
       " 'review_16': {'summary': 'This work presents Hybrid Distillation, which attempts to distill from both supervised/CL and MIM frameworks. The work begins by revealing certain observations regarding the interplay between self-supervised pre-training and the concepts of diversity and discrimination. Subsequently, the authors propose the Hybrid Distillation technique that leverages token relations from the MIM teacher and feature maps from the supervised/CL teacher for knowledge distillation purposes.',\n",
       "  'strengths': 'The findings on the relationship between diversity and architecture are interesting',\n",
       "  'weaknesses': '1. The presentation quality of this work is bad due to the following reasons:\\n\\ni) Section 2 lacks an explanation of the experimental setup, For example, what is the design and architecture of the distillation? How are different decoders used for DeiT distillation? \\n\\nii) The description of the metrics, such as the average head distance and normalized mutual information, is inadequate. There is insufficient clarification regarding the existence of multiple attention distances for each layer and how they reflect diversity. Furthermore, the explanation of how NMI reflects discrimination is absent.\\n\\niii) The analysis of the figures lacks details, making it challenging to comprehend the meaning conveyed by the illustrated figures.\\n\\n2. The authors state that \"Mask Reconstruction of High-Level Semantics Does not Help Improve Diversity.\" However, previous studies [1][2][3][4] have distilled knowledge from high-level semantics and achieved high performance. Does this imply that high performance can still be attained with low diversity? If so, why should we care about diversity?\\n\\n3. The correlation between the observations made and the design of the proposed Hybrid Distillation method is weak. For instance, how does the discovery of the \"Asymmetric Decoder\" inspire the proposed Hybrid Distillation approach?\\n\\n4. The absence of a discussion and comparison of relevant works is noticeable. Numerous related works, such as [5][6][7], should have been included and compared.\\n\\n5. Unfair comparisons are made in this work. While the proposed approach is distilled from multiple networks, it is only compared with methods that distill knowledge from a single network. Strong baselines that employ distillation from multiple networks should also be incorporated for a fair evaluation.\\n\\n\\n[1] IBOT : IMAGE BERT PRE-TRAINING WITH ONLINE TOKENIZER\\n\\n[2] DINOv2: Learning Robust Visual Features without Supervision\\n\\n[3] Masked Feature Prediction for Self-Supervised Visual Pre-Training \\n\\n[4] BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokenizers\\n\\n[5] Mimco: Masked image modeling pre-training with contrastive teacher.\\n\\n[6] Layer Grafted Pre-training: Bridging Contrastive Learning And Masked Image Modeling For Label-Efficient Representations\\n\\n[7] Contrastive Masked Autoencoders are Stronger Vision Learners'},\n",
       " 'review_17': {'summary': 'This paper introduces a new hybrid distillation method for Vision Transformer. It is hybrid in the sense that two teacher models pre-trained by two different approaches, namely Contrastive Learning and Masked Image Modeling, are adopted in the distillation. In this way, the student model inherit both the diversity from MIM pre-trained teacher model and the discriminability from the CL pre-trained teacher model. Further more, a progressive masking strategy is adopted to reduce redundancy during distillation. Experiments on multiple popular classification/detection/segmentation benchmarks demonstrate the effectiveness of the proposed approach.',\n",
       "  'strengths': 'The idea of adopting two homgeneous teacher models is interetsing. Intuitively, a good design allows the student model to learn the advantages of both teacher models.',\n",
       "  'weaknesses': \"1. I find many experimental details in the explorative model evaluation part (section 2) are missing, making it hard for readers to assess the soundness of those experiments. Note that these experiments are crucial for justifying the motivation of this work. My questions are listed as follows: \\na) What kind of distillation approach is used here? Is it the same as the one used in Hybrid Distillation, or just naive feature distillation? Also, details like where to distill and distill objectives are missing. \\nb) Why are the average head distance and normalizedmutual information good indicators of the discrimination power and diversity of the learnt representations? And how are the so called `discrimination and diversity` related to the downstream performances? So far I have only seen very vague definition of these two metrics, and I am not sure if they are solid proofs that teacher models pre-trained by different objectives do have different advantages that the student must learn. \\nc) The notations need further clarification. For instance, in Figure 2(a), the caption says 'various decoder' , indicating the curves are the values of NMI of the decoder. While there is actually a curve for `no decoder`, indicating the curves are the values of NMI of the encoder. These notations are very confusing.\\nd) The authors claim that `The Increase in Diversity Derives from the Asymmetric Designs`, but there are no ablation on if the symmetric design of MIM architecture would lead to the same diversity. The closet design is in section 2.4, but its objective is to reconstruct high-level features from the teacher model.\\n\\n2. Similarly, some implementation details about the Hybrid Distillation itself are missing. For example, I do not believe the student is solely trained by the distillation objective. Is there also a supervised training objective like cross-entropy loss? The authors should make it more clear. \\n\\n3. I wonder how did the authors get the results of baseline methods. For example, in table 1, CLIP ViT-B achieves an accuracy of 83.6 on IN-1K, and CLIP ViT-L achieves an accuracy of 86.1. These numbers are too good to be zero-shot results, so I have to assume they are fine-tuning results. Yet, based on [1], fine-tuning CLIP ViT-B achieves an accuracy of 85.7, and CLIP ViT-L achieves an accuracy of 88.0 on IN-1K, which have achieved better or on par performance comapred to the Hybrid Distillation (85.1 for ViT-B, 88.0 for ViT-L). In this case, the proposed Hybrid Distillation approach does not seems to show enough empirical gain.\\n\\n4. As already discussed in the limitation section in the supplemental material, the gain of Hybrid Distillation over Distill-CLIP is not so significant (only 0.3\\\\% on IN-1K with ViT-B).\\n\\nReferences\\n[1] Dong X, Bao J, Zhang T, et al. CLIP Itself is a Strong Fine-tuner: Achieving 85.7% and 88.0% Top-1 Accuracy with ViT-B and ViT-L on ImageNet[J]. arXiv preprint arXiv:2212.06138, 2022.\"},\n",
       " 'review_18': {'summary': 'The authors propose the notion of equitable partitions from graph isomorphism literature in order to partition the nodes of a network according to their structural roles. They study two optimization problems for approximately recovering such equitable partitions. Analogous to the SBM model, the authors devise the RIP (role-infused partition) stochastic model and validate their findings on this model. ',\n",
       "  'strengths': 'The paper is very well-written. The proposed cost functions for computing approximate equitable partitions are very well-motivated and natural. Approximate versions of the Weisfeiler-Leman algorithm is an important question which deserves much study. The proposed RIP model is a very satisfcatory benchmark for role discovery.',\n",
       "  'weaknesses': 'The experimental work is inadequate in order to understand the impact of the proposed formalism to real-world data (Section 5, Experiment 3). The considered datasets are too few, specialized and small-sized in order to deduce that approximate equitable partitions (and approximate Weisfeiler-Leman) is at the core of role discovery.  '},\n",
       " 'review_19': {'summary': 'The paper considers a relaxed definition of the coarsest equitable partition (CEP), which equals the final partition of Weisfeiler-Leman or the color refinement algorithm in the original version. The authors allow to specify the number of cells of the partition and derive a related optimization problem. From this, an algorithm for role discovery is derived, outperforming techniques such as role2vec on real-world graphs.',\n",
       "  'strengths': '* The concept of structural roles is closely related to the Weisfeiler-Leman algorithm and fundamental for graph learning.\\n* The relaxation of the final WL partition with a fixed number of cells is novel.\\n* The RIP model for graph generation is innovative.',\n",
       "  'weaknesses': '* Algorithm 1 is not analyzed sufficiently. It would be interesting to have approximation guarantees. Moreover, it would be nice to investigate the case where $k$ equals the number of cells in the cEP. I believe that the current version would not guarantee that the cEP is found since the cluster method obtains only $X$ as an argument neglecting $H$, which should be required to guarantee this. Is this correct?\\n* Several other methods compute relaxed WL partitions without allowing to specify $k$ and are discussed in section 2.1. These could also be used in the experimental comparison to assess the advantages of the proposed method.'},\n",
       " 'review_20': {'summary': 'This paper presents a novel perspective on the problem of node role extraction in complex networks, highlighting its distinctions from community detection. The authors propose a definition of node roles and introduce two optimization problems based on graph-isomorphism tests, the Weisfeiler-Leman algorithm, and equitable partitions. Theoretical guarantees are provided, and the approach is validated using a newly introduced \"role-infused partition benchmark\" that allows for stochastic assignment of different roles to nodes in sampled networks. The findings contribute to network analysis, graph mining, and the development of reduced order models for dynamical processes on networks.',\n",
       "  'strengths': '- The research topic, role discovery in graphs, is very important and is worth studying, especially compared to the community detection problem, role discovery is also important but lacks attention.\\n\\n- The design of the model based on equitable partitions is technically sound and theoretically guaranteed.\\n\\n- Experimental results on several datasets from different perspectives show the effectiveness of the proposed method.',\n",
       "  'weaknesses': '- Baseline selection. Some relevant and/or important baselines have not been compared.\\n\\n- Downstream tasks. The proposed method is not tested on widely used downstream tasks to show its effectiveness.\\n\\n- Dataset. There are some more widely used datasets for role discovery that are not used in this paper.'},\n",
       " 'review_21': {'summary': 'The paper offers a new perspective on the problem of role extraction while defining node roles based on the ideas of equitable partitions and and graph-isomorphism tests, the Weisfeiler-Leman algorithm. The paper studies two associated optimization problems (cost functions) inspired by graph isomorphism testing and provides theoretical guarantees for their solutions.  To validate the approach, a novel \"role-infused partition benchmark\" is introduced, enabling the generation of networks where nodes possess different roles in a stochastic manner.',\n",
       "  'strengths': '(+) The paper offers a new perspective on node role extraction, focusing on equitable partitions and providing a principled stochastic notion of node roles. This approach adds to the existing methods in the field and offers a new way to define and quantify node roles in complex networks.\\n\\n(+) The paper presents a quantitative definition of node roles based on equitable partitions, allowing for the numerical measurement of deviation from an exact equivalence. This provides a more nuanced understanding of node roles compared to traditional definitions.\\n\\n(+) The technical aspects of the paper are thorough and detailed. Also, the technical details aeem to be correct. \\n\\n(+) Numerical experiments show the effectiveness and superiority of the proposed method over a graph neural network, GIN, for three different tasks. ',\n",
       "  'weaknesses': '(-) While the paper briefly mentions different categories of node role extraction approaches (graphlet-based, walk-based, and matrix-factorization-based), it does not provide a detailed comparison or analysis of how the proposed equitable partitions approach compares to these existing methods. A more rigorous comparative analysis, including performance metrics and evaluation on benchmark datasets, would strengthen the paper\\'s contribution and demonstrate the advantages of the proposed approach.\\n\\n(-)  The idea of Equitable partitions for node role discovery is interesting. However, the details regarding \"why this approach\" makes sense is missing. There can be other ways too? Why this method should work? At a conceptual level, a more rigorous explanation related to the definition of roles based on equitable partition is missing. I think this is crucially important. In other words, the paper focuses on providing details of \"designing\" and approach based on EP, while leaving details of \"why this is appropriate\"\\n\\n(-) A more thorough literature review might be needed. For instance, the following paper provides a nice simple algorithm for computing equitable partitions. (I am not sure it is better or worse; however it might be handy to have a look at it.)\\n    \\n- Zhang et al., \"Upper and Lower Bounds for Controllable Subspaces of Networks of Diffusively Coupled Agents,\" IEEE Transactions on Automatic control, 2014.\\n\\nAlso, there is some recent work on counting subgraphs (that may define node roles based on the structural attributes of the graph), for instance, \\n\\n- Hassan et al., \"Computing Graph Descriptors on Edge Streams.\" ACM Transactions on Knowledge Discovery from Data, 2023.\\n\\n(-) The paper introduces a family of cost functions to assess the quality of a role partitioning. However, it does not thoroughly discuss the selection, design, or properties of these cost functions. Providing a more in-depth exploration and analysis of the different cost functions, their properties, and how they relate to the problem of node role extraction would enhance the technical understanding of the proposed approach.\\n\\n(-) It is unclear how the ground truth for the sampled adjacency matrices is computed  in Experiment 1 of Section 5. Moreover, GIN is a relatively old graph neural network. There are recent methods that show better results on several downstream tasks and could have been considered for baseline comparisons. Some of these works include the work of Bouritsas et al, and Ramp\\\\\\'a\\\\v{s}ek et al, below.\\n\\n- Bouritsas et al., \"Improving graph neural network expressivity via subgraph isomorphism counting,\" IEEE Transactions on Pattern Analysis and Machine Intelligence. 2022 Feb 24;45(1):657-68.\\n\\n- Ramp\\\\\\'a\\\\v{s}ek, et al., \"Recipe for a general, powerful, scalable graph transformer,\" Advances in Neural Information Processing Systems. 2022.'},\n",
       " 'review_22': {'summary': 'As I am not an expert in causal inference nor in SDEs, I will start with summarising the goal of the paper how I understood by reading it and some references therein. This summary will certainly reveal my ignorance regarding this research area, but I prefer to give this transparency and hope my review will be weighted accordingly. \\nOrdinary and stochastic differential equations (SDEs) can be interpreted as modelling the influence among elements of a dynamical system. Therefore, they offer a tool for causal inference. For example, when making an intervention to a dynamical system, this intervention can be defined by a change to the corresponding SDE, resulting in “post-intervention” SDE. Previously, it was shown that if we can identify the generator of the original SDE, then we can use this result to obtain the distribution of the post-intervention SDE. \\n\\nThis paper derives sufficient conditions for the identifiability of the generator of linear SDEs with both additive and multiplicative noise. The authors conduct simulation experiments to assess the validity of their theoretical results.',\n",
       "  'strengths': 'The paper is generally well-written and clearly structured and, although technical, well readable. \\n\\nThe theoretical results which seem to be the major contribution of the paper are tested in an intuitive simulation study. The simulation experiments and results are described clearly and concisely.',\n",
       "  'weaknesses': 'The beginning of the introduction is good, but in the following paragraphs, the motivation for the importance of identifiability in SDE from a causal inference point of view is not well-explained. \\nI had to refer to [16] to find a clear explanation of how SDE can be used for causal inference. \\n\\nSDE (1) is referenced in the introduction but appears only later in section 2.1.\\n\\nThe simulation experiment nicely illustrate the derived identifiability conditions. However, an example of how this can used for causal inference is not shown. Given that performing causal inference with SDE is one of the central motivations of this work, I think it would be essential to provide a concrete example of how this can be achieved using the contributions of this paper.'},\n",
       " 'review_23': {'summary': 'The present work considers the problem of identifying the generators of autonomous linear\\nstochastic differential equations (SDEs) with an additive or multiplicative\\nnoise term from the law of its solution process (e.g., in case of additive noise\\nthis is a Gaussian process) with a given fixed initial state. The authors derive\\ngeneric sufficient conditions for this and use the knowledge gained to expand\\nthe model interpretability from a geometric point of view. The applicability of\\nthe theoretical results is shown in the context of causal inference using linear\\nSDEs and empirical evidence is provided by a (small) set of simulations.',\n",
       "  'strengths': \"In recent years, modeling random dynamics had great impact into deep learning by\\nproposing so called Neural SDE (NSDE) models. Since SDEs are ubiquitously used\\nfor modelling real world data, research interest in NSDEs rapidly grew.\\nHowever, we still know very little about the often hidden systematics of these\\nmodels and in particular the design of problem-specific function classes is a\\nchallenge without a deeper understanding of it. Therefore, I appreciate this\\nwork's attempt to make a systematic contribution to solving the mystery behind\\nrandom dynamic modeling.\\n\\nFurther, the content is well organized, with very few exceptions, has no\\nspelling or grammatical flaws and is original to the best of my knowledge. Empirical evidence is accessed through\\nexperiments on toy data. Code examples are included in the supplementary\\nmaterial. \",\n",
       "  'weaknesses': 'It is not the value of the approach I am concerning here, but the shortcomings\\nrelated to the clarity of the submission and the technical soundness which I\\nwill address with examples in the following:\\n\\n- W1: Although the use of SDEs has rapidly gained prominence in the NeurIPS\\n  contributor landscape in recent years, I would argue it still represents a\\n  rather subtopic, not easily accessible to every contributor. On the other hand, the generator theory for SDEs is more of\\n  an advanced topic. Hence, in the context of its central role in this paper, it is\\n  desirable to add a (gentle) introduction to the topic for the wider NeurIPS\\n  audience. To illustrate this deficiency with an example: In Sec. In Section\\n  2.3 the authors talk about SDEs generators without giving a definition, and\\n  later in Section 2.1 the reader discovers that it is an operator on function\\n  spaces.\\n\\n- W2: Starting from l. 184 including Lemma 3.2 and the interpretation of\\n  identifiability conditions from a geometric perspective, i.e., the generator\\n  of the SDE (1) is identifiable from $x_0$ when not all the given vectors\\n  are confined to an $A$-invariant proper subspace of $\\\\mathbb{R}^d$, I found\\n  difficult to access; similar in the case of multiplicative noise (l. 269ff.).\\n  Can you phrase the idea in an easier manner? I think what I\\'m saying\\n  is that the amount of technical detail presented diminishes the value of the\\n  result.\\n\\n- W3: In my opinion, the presentation of the causal interpretation of SDEs in\\n  Section. 2.3 as a subsection to \"Model and Problem Formulation\" is confusing\\n  since this topic is more an example of the application of generator\\n  identification of SDEs than a contribution to the problem definition of the\\n  latter in general.\\n\\n- W4: Identifying the solution process of autonomous linear SDEs with additive\\n  noise term as in Eq. (1) by Gaussian processes is necessary for the results in\\n  the present work, e.g., cf. Lemma 3.1. This statement is justified by the\\n  identification of generators by properties of the law of such Gaussian\\n  solution processes with a given fixed initial state. I am wondering if the\\n  authors also assume the solution process to be Gaussian in case of linear SDEs with multiplicative noise as in Eq.\\n  (3) (because the method of solving for m(t) and P(t) is involved in the proof\\n  of Theorem 3.4 in Sec. A.7 in the appendix) because this proves wrong in the general case; e.g., in case of a geometric\\n  Brownian motion which is a solution to a linear SDE with multiplicative noise\\n  term.\\n\\n- W5: Simulations are only presented in a very limited scenario on (very) low\\n  dimensional toy datasets. In real world applications, e.g., modeling (multivariate) time\\n  series data, the state variable dimension $d$ is often significantly larger\\n  than 10 (cf. I. Silva et al. [52]). In order to create added value for such models, e.g., NSDEs, the\\n  approach has to be tested in this extended framework.\\n\\nHowever, I would like to reiterate my appreciation for the authors\\' interest in\\nexpanding the field of modelling random dynamics. I\\'m sure that by working on\\nthe deficiencies mentioned, the work will gain in value\\nand will deliver an enriching contribution to the community.'},\n",
       " 'review_24': {'summary': 'This paper derives some sufficient conditions for identifying linear stochastic differential equations (SDEs). The validity of the identifiability conditions is clarified on synthetic simulation data.',\n",
       "  'strengths': '- The identification problem of ordinary/stochastic differential equations has been a hot topic in machine learning community, but the condition for identification seems to be relatively overlooked. The paper could raise a good question about it. \\n- The paper is well-motivated and makes a technically solid contribution.',\n",
       "  'weaknesses': '- The paper focuses on linear SDEs. They are very simple models and, to the best of my knowledge, are rarely applied to modern problems of system identification. Thus, the paper’s contribution is very limited and not impactful. \\n- The paper emphases its contribution to reliable causal inference, but the experiments don’t include causal inference task. How the derived sufficient conditions benefits the causal inference task remains to be clear.'},\n",
       " 'review_25': {'summary': 'This article derives relationships for identifying generators of linear SDEs in both the case of additive and multiplicative noise. It is written in a very classically statistical manor, with a great number of citations from the statistical research community.',\n",
       "  'strengths': 'This article identifies two apparently unresolved issues from stochastic differential equations and solves them.\\n\\nI thank the authors for their thoughtful discussion in the rebuttal process.',\n",
       "  'weaknesses': 'This article assumes a high understanding of statistics, and unfortunately this is not my field. I do not have the expertise to review the proofs in this article. I think the article could do a better job at explaining the relevance of this topic to the broader machine learning community. Excluding the unpublished (arxiv) citations, it looks to me like there are only two published articles cited in the ML community, and both of those articles seem only tangentially related to the work in this article. The presentation of this article appears to be quite good for a pure-statistical research community.\\n\\n- All of the proofs claimed in this article are in the appendices of their article. While I know this is standard practice, technically NeurIPS appendices are un-reviewed (and in practice they are criminally under-reviewed). In my own field, this has led to an increased number of incorrect results being published, cited, and propagated through the research community. Because reviewers like me cannot assess the validity of the results claimed in this article, I worry that this may also happen in statistics. For this reason, I am giving a low-confidence rejection. If I see that other reviewers make good points attesting to the validity of the theory, I will change my recommendation.\\n- Throughout the article there are many forward-references (e.g., on line 25, the reader has no idea what the matrix \"A\" means, in lines 31 and 32, the equations (1) and (3) are referenced without being introduced first, etc.) which make for a hard experience for the reader.\\n- Clerically, one could order the citations so that they appear in increasing order (e.g., in line 19, [4, 34, 45])\\n- Line 39 - 41: The argument for uniqueness is not clear from this statement.\\n- Line 69: I think you mean \"are commutative\"\\n- The sectioning in this article does not quite make sense to me. The pagraph \"We know that both the SDE (1) and SDE (3) ...\" which appears in Section 2.2, actually talks about both the content in Sections 2.1 and 2.2.\\n- Inconsistent citations throughout. For instance, some articles are cited using the lowercase \"volume\" while others do not use the abbreviation for a volume at all (e.g., 61(11): 1038-1044) -- this citation style should be consistent.\\n- The citation also contain many mis-capitalizations (odes vs ODEs, SIAM vs Siam), typos, duplicated authors [21], and clerical errors.\\n- There are a lot of citations of unpublished material; a small number of recent arxiv publications is fine in this community, but some are missing any references alltogether, e.g.,  [13] and [24].'},\n",
       " 'review_26': {'summary': 'This paper addresses the interventional identifiability of two classes of stochastic differential equations. Theoretical results are illustrated with simulation of identifiable and non-identifiable cases. ',\n",
       "  'strengths': 'The paper is carefully written and the theoretical results appear sound, although I could not check the proofs in detail. ',\n",
       "  'weaknesses': 'My main concern is whether the target audience for this paper is really NeurIPS. Considering myself one of relatively few in the NeurIPS community with some familiarity with both causality and (to a limited extent) with SDE, I have a hard time making sense of the contribution. Although the presentation of the framework of reference [16] for causality with SDE is interesting, it is quite challenging to get an intuition of the concrete cases for which this framework is relevant: the defined interventions are static (not time dependent) and I have a hard time to imagine in which application we need the heavy toolbox of SDEs to model static interventions, which moreover are constrained to always start from the exact same point in state space. The paper does not really help, neither with justifying this framework nor with providing some intuitions. \\n\\nMoreover, the paper is written in a quite confusing way, at least for a non expert in SDEs: after introducing \"standard\" SDE based on Brownian motion in Eqs. (1) and (3), we are introduced in Lemma 2.1 and above with SDEs based on integrating Levy processes (and not being explained what is this). Then we move on to talking about Ito diffusion processes (Propostion 2.1) with an equation of the generator exhibited, although we have not being told at any time, even roughly, what a generator is for a stochastic process. \\n\\nI can imagine the results may be relevant for a mathematical journal, but if the authors what to target the ML/causality community, there is a lot of work to do on the manuscript to keep only the essential mathematical concepts, explain them well with reduced formalism, and convey intuition of why this is relevant to the NeurIPS readership interested in causality and time series.\\n\\nAdditionally, if I risk myself on evaluating the importance/novelty of the key results of this work, they resemble standard results on characterizing the set of states reachable by some classes of Markov chains in general state space. I can imagine there are also fairly standard results for this question in the context of SDEs, and the rank constraint of Theorem 3.3 is not very surprising when considering the dimension of the subspace reachable from a fixed initial point. Given the whole state space is explored, again I can imagine identifying the generator boils down to exploiting standard results. I am left wondering whether this result really deserves a new paper that addresses it exclusively (meaning: without exhibiting any concrete problem where it is relevant and helpful).  '},\n",
       " 'review_27': {'summary': 'This paper presents conditions for identifying the generator of a linear stochastic differential equation (SDE) with additive and multiplicative noise. The authors derive sufficient conditions for identifying the generator of both types of SDEs and offer geometric interpretations. \\n',\n",
       "  'strengths': 'I think this paper is theoretically sound. ',\n",
       "  'weaknesses': '1. It would be great if there are practical examples for motivating readers. It’s hard to evaluate the papers’ practical importance because there are no practical scenarios and simulations. \\n2. In the introduction, the link between causal inference and the identiability of the SDE is weak. Is the goal to identify the “generator” of the post-interventional stochastic process when only observational process is available?'},\n",
       " 'review_28': {'summary': 'This paper proposes an algorithm, TAILOR, that iteratively and adaptively selects candidate active learning algorithm to gather class-balanced examples. Experimental results demonstrate that TAILOR achieves comparable or better performance than the best of the candidate algorithms. ',\n",
       "  'strengths': 'The paper presents a new active learning algorithm and provides some theoretical analysis. Good empirical results are reported. ',\n",
       "  'weaknesses': 'The presentation of the paper leaves much to be desired, and its contribution appears to be quite limited. Additionally, the paper contains improper or insufficiently supported claims, such as “meta algorithm”, “focus on class imbalanced setting”, and “the first adaptive algorithm selection strategy”. \\n\\n\\n1. The organization and content selection are unsatisfactory. \\n\\n(1) The introduction is not well motivated or presented. The framework illustrated in Figure 1 is an adaptive active learning procedure, and it is difficult to build connection with a multi-armed bandit problem from such a figure. It is not very proper to report a result figure in the introduction as well. \\n\\n(2) Algorithm 1 is not the contribution of this paper but was included on page 4 with a lot of space.  Since most contents of section 3.2 are from the literature, the presentation can be largely compressed. \\n\\n(3) Much space of the paper is not on the main contribution of the paper. The proposed algorithm TAILOR is only presented in 4.3.  \\n\\n(4) Throughout the overall paper (in particular section 4), method presentation, previous work review, and contribution claims are jumbled together without a clear and logical structure of presentation.\\n\\n\\n\\n2. The presentation of the paper lacks sufficient clarity.   \\n\\n(1) In 4.2, the notations and concepts are not well explained. For example, what is the 1-sub-Gaussian distribution?  What does it mean by stating “Nature reveals weighting vector v^t”?  \\n\\n(2) Section 4.2 also fails to present a clear and principled connection of the proposed active learning setting to the bandit problem. \\n\\n(3) The Equations are not well explained. For example, the “\\\\lor” operator in the class diversity reward is not described. \\n\\n\\n\\n3. Authors claim the algorithm as a meta algorithm. The TAILOR algorithm in Algorithm 2 didn’t show any meta-learning process. The meta concept needs to be clarified. \\n\\n\\n\\n4. The paper claims on focusing on class imbalanced setting,  but  fails to provide any substantial discussion or analysis on this aspect, except for conducting experiments on datasets with class-imbalance. \\n\\n\\n\\n5. The reward functions proposed in 4.1 are heuristic and lack principled connections to the model performance. There are no discussions on how to choose reward functions on different datasets.   \\n\\n\\n\\n6. The claim of “the first adaptive algorithm selection strategy for deep active learning” is not proper. Adaptive active learning has been studied in the active learning literature. Most active learning strategies developed in the literature are not dependent on the classifiers, and hence there is no need to distinguish linear models from deep models from the active learning perspective. In particular, the proposed active learning method has no special ties to deep models. \\n\\n\\n\\n7. Many related works on adaptive active learning or meta active learning are missing, e.g., [1,2,3]. \\n[1] “Adaptive Active Learning for Image Classification”. 2013. \\n[2] “Active Learning with Multi-label SVM Classification”. 2013. \\n[3] “Meta-Learning for Batch Mode Active Learning”, 2018.\\n'},\n",
       " 'review_29': {'summary': 'Selecting the most appropriate active learning algorithm for a given dataset poses a significant challenge when applying active learning in real-world scenarios. This challenge stems from the fact that the performance of different active learning strategies could vary significantly across various scenarios and datasets. The paper introduces an interactive and adaptive algorithm selection strategy inspired by the concept of multi-armed bandit. By employing carefully designed reward functions, the proposed strategy can identify a subset of acquisition functions that yield maximum rewards. The authors prove that their selection algorithm exhibits a tighter bound on the Bayesian regret. Experimental evaluations conducted on both multi-class and multi-label classification tasks illustrate the promising performance of the proposed approach in terms of accuracy. ',\n",
       "  'strengths': '* Given the diverse nature of datasets, it is crucial to carefully consider and evaluate various active learning algorithms to achieve optimal performance and effectiveness. The concept of reducing the selection of acquisition functions to a multi-armed bandit problem is interesting as it allows the election process to incorporate accumulated rewards, providing a valuable approach for algorithm selection.\\n* The proposed method demonstrates adaptability to both multi-class and multi-label classification tasks by utilizing well-designed reward functions that suitably capture the task-specific requirements.\\n* Additionally, the authors present a proof establishing that the proposed selection algorithm outperforms an existing algorithm with a higher bound on Bayesian regret, although the reviewer did not thoroughly examine the soundness of the proof.',\n",
       "  'weaknesses': \"* The class imbalance issue is dealt with through a proper designed reward function, discussed in section 4.1. The idea of the inversely weighting each class based on its samples is not supervising, given that the weight scheme has been widely used in imbalanced semi supervised learning. The main concern is rather the empirical studies. Even though Figure 3(c) seems to show that the proposed method could deal with the imbalance problem, there is lack of studies about how tolerate the proposed method to different class imbalance ratios. Instead of showing the number of samples in the rarest class, it is better to plot the imbalance ratio. Furthermore, it is not clear how the imbalance issue is handled in the multi-label classification tasks.\\n* With respect to Assumption 3.1, it basically assumes to choose the top B samples ranked based on, for example uncertainty/least confidence scores. However, there are other methods, in particularly, some diversity-based AL methods, that choose the samples using clustering, which cannot be directly converted into an iterative selection process.\\n* The efficiency aspect of the proposed method is not adequately discussed in the paper. Consideration of efficiency factors, such as computational cost or time complexity, would provide a more holistic evaluation of the proposed method's practicality and real-world applicability.\\n\"},\n",
       " 'review_30': {'summary': 'The paper proposed TAILOR, a Thompson Sampling framework for active learning algorithm selection for unlabeled, possibly imbalanced datasets by framing it as a multi-arm bandit problem. The authors compared with random Meta and another meta-framework ALBL, along with other AL methods on 10 multi-class multi-label vision datasets and concluded their framework new art.',\n",
       "  'strengths': 'Originality:\\n\\nThe work is deemed original based on its discussion with related work.\\n\\nClarity & quality:\\n\\nThe work is well written with great graphics like Figure 1 to illustrate key ideas. The appendix is also very helpful information. \\n\\nSignificance:\\n\\nThe work is relevant to the broader community of active learning and computer vision. The technical contribution it makes is solid in terms that the TAILOR does show improved AL efficacy compared with individual AL methods.',\n",
       "  'weaknesses': \"I have a suggestion for clarity: Add / explain what is the pool of AL algorithms that TAILOR considers at the very beginning of the paper (perhaps the intro part) as the plot shows 81 algs are considered (which can raise confusion for readers)\\n\\nMy major concern about the paper lies in the necessity of the different pieces of the reward function. I think an ablation study on the three different types of rewards function would do great help towards readers' understanding of relative contributions of their modules.\\n\"},\n",
       " 'review_31': {'summary': 'This paper proposes a new method for algorithm selection in active learning. The problem is treated as a multi-armed bandit problem and the proposed method is based on Thompson sampling. Extensive experiments are conducted on several datasets, including both multi-class and multi-label classification setting.',\n",
       "  'strengths': '1. The paper is well-written and easy to follow.\\n2. The new reward functions designed for label balance are interesting. \\n3. The authors provide regret analysis and the proposed method enjoys better regret bound than the standard linear contextual bandit algorithm.\\n4. The experimental results are comprehensive, including several benchmarks and two settings. TAILOR is comparable to the best candidate algorithm and even performs better than the best candidate for multi-label setting.',\n",
       "  'weaknesses': \"1. My major concern is the motivation behind active learning algorithm selection. For all the multi-class datasets, BADGE is almost always the best algorithm. Are there any datasets where BADGE does not perform well?\\n2. What's the time efficiency of TAILOR? Is TAILOR less efficient than the single algorithm?\\n\\nMinor:\\nThe figure is somewhat difficult to read the specific numbers. It would be better to provide an additional table.\"},\n",
       " 'review_32': {'summary': 'This paper proposes a novel algorithm called TAILOR  that adaptively chooses the active learning algorithm from the candidate set of multiple algorithms.  Novel reward functions are proposed that encourage choosing the algorithm such that both class diversity, as well as informativeness, are maintained while selecting unlabeled samples for the annotation. A strong theoretical justification is provided to demonstrate the effectiveness of the proposed TAILOR algorithm using regret analysis. The extensive evaluation conducted on various multiclass (imbalanced) and multilabel datasets demonstrates the ability of the proposed technique to produce comparable/better accuracy compared to the data-specific best candidate active learning strategy.\\n',\n",
       "  'strengths': '1. This paper has unified the strength of existing active learning algorithms into the single TAILOR framework. This avoids the burden of finding an effective active learning algorithm for a given specific problem.\\n2. The authors have provided sufficient novelty in this paper. Specifically, considering the deep active learning setting, the reward function design along with the bandit setting seems novel and non-trivial to me.\\n3. The extensive experimentation is conducted considering multiple datasets under  multiclass and multilabel settings. This enhances the credibility of the effectiveness of the proposed TAILOR framework.\\n4. The theoretical analysis showing better regret bounds for the proposed TAILOR algorithm compared to linear contextual bandits seems to be a very important contribution.',\n",
       "  'weaknesses': '1. The experimentation is conducted using a single ResNet-18 architecture. Having experimental results on multiple architectures, especially more powerful ones, such as ResNet101, ViT would be helpful to even strengthen the effectiveness of the proposed technique. \\n2. The impact of \\\\gamma (line 281)  is missing. I would expect to see the performance variation with respect to different \\\\gamma values (some ablation study would be helpful).\\n3. One of the crucial components is the reward that is designed to maximize the participation of the data samples from the minority (rarest) classes in an imbalanced data setting. It would be interesting to see how the involvement of those minority (rarest) class data samples affects minority class performance. An ablation study comparing the rarest class performance of the proposed TAILOR framework with regard to different baselines would be interesting.'},\n",
       " 'review_33': {'summary': 'In this paper, a new Taxonomic context pIrors Discovering and Aligning (TIDA) which exploits the relationship of samples under various granularity is proposed. TIDA comprises two key components: i) A taxonomic context discovery module that constructs a set of hierarchical prototypes in the latent space to discover the underlying taxonomic context priors; ii) A taxonomic context-based prediction alignment module that enforces consistency across hierarchical predictions to build the reliable relationship between classes among various granularity and provide additions supervision. ',\n",
       "  'strengths': '1. The authors identify the importance of multi-granularity priors in the context of OSSL and introduce the taxonomic context priors for solving the OSSL problem.\\n2. A uniformed OSSL framework, which can discover taxonomic context priors without any extra supervision is proposed. With the proposed cross-hierarchical prediction alignment, the framework can effectively enhance the performance of the model.\\n3. This paper is easy to follow.',\n",
       "  'weaknesses': 'The hyper-parameter $\\\\alpha$ and $\\\\beta$ depends on the specific datasets and for different datasets, experiments need to be conducted to determine the value. '},\n",
       " 'review_34': {'summary': 'This paper tackles open-world semi-supervised learning and proposes to use multi-granularity labels as taxonomic context priors to leverage hierarchical supervision to enhance representation learning and improve the quality of pseudo labels. A taxonomic context discovery module is used to construct hierarchical prototypes; a taxonomic context-based prediction alignment module is applied to enforce consistency across multi-granularity predictions. ',\n",
       "  'strengths': '1. The motivation and idea of this paper are clear and well-explained. Multi-granularity supervision is introduced to improve the representation of base and novel classes. The alignment among each granularity is enforced.',\n",
       "  'weaknesses': '1. Additional baselines are needed for comparison: \\n\\n[1] Pu N, Zhong Z, Sebe N. Dynamic Conceptional Contrastive Learning for Generalized Category Discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 7579-7588.\\n\\n[2] Zhang S, Khan S, Shen Z, et al. Promptcal: Contrastive affinity learning via auxiliary prompts for generalized novel category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 3479-3488.\\n\\n[3] Vaze S, Han K, Vedaldi A, et al. Generalized category discovery[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022: 7492-7501.\\n\\n[4] Wen X, Zhao B, Qi X. A Simple Parametric Classification Baseline for Generalized Category Discovery[J]. arXiv preprint arXiv:2211.11727, 2022.\\n\\n[5] Chiaroni F, Dolz J, Masud Z I, et al. Mutual information-based generalized category discovery[J]. arXiv preprint arXiv:2212.00334, 2022.\\n\\n2. The actual number of classes must be known. Otherwise, it is difficult to determine how many classes should be defined for sub-class, target-class, and super-class, respectively. \\n\\n3. The real composition of the sub-class and super-class may not go exactly as designed. It is difficult to guarantee each sub-class only contains samples of one target class, and each target-class only belongs to one super-class.'},\n",
       " 'review_35': {'summary': \"Previous research has primarily focused on using pre-defined single-granularity labels as priors for recognizing novel classes. However, classes naturally adhere to a taxonomy, enabling classification at multiple levels of granularity and offering richer supervision through underlying relationships. To address this, this paper proposes TIDA (Taxonomic context pIrors Discovering and Aligning), a unified framework that leverages sample relationships across various levels of granularity. TIDA discovers multi-granularity semantic concepts as taxonomic context priors (e.g., sub-class, target-class, and super-class) to enhance representation learning and improve pseudo label quality. Extensive experiments on seven datasets demonstrate TIDA's significant performance improvement, achieving a new state-of-the-art.\",\n",
       "  'strengths': '1. The motivation is clear and convincing. It is reasonable that taxonomic context priors are helpful to extract discriminative features.\\n2. The writing is clear. I like the figures in this paper.\\n3. Experiments effectively verify the effectiveness of this work. Comprehensive experimental results are provided in the supplementary material.',\n",
       "  'weaknesses': '1. The necessity of constructing taxonomic priors remains unclear. Various methods, such as using WordNet [1], can extract taxonomic priors among categories. I think that there is insufficient evidence to support the essentiality of constructing taxonomic priors in typical scenarios.\\n\\n[1] I Am Going MAD: Maximum Discrepancy Competition for Comparing Classifiers Adaptively. ICLR 2020.\\n\\n2. Some works, especially [2], on the taxonomic structure lack proper citation and comparison.\\n\\n[2] Open-world Semi-supervised Novel Class Discovery. IJCAI 2023.\\n\\n3. The Introduction section lacks high-level statements regarding the construction and correctness of taxonomic priors.  need to find these information in the Methodology section.'},\n",
       " 'review_36': {'summary': 'This paper addresses the open-world semi-supervised learning (OSSL) problem and proposes taxonomic context priors discovering and aligning (TIDA), which considers the taxonomic hierarchy of classes.\\n\\nBasically, the proposed method is based on [19], which assigns pseudo-labels to unlabeled samples by means of the Sinkhorn-Knopp algorithm. The proposed method is characterized by Taxonomic Context Discovery (TCD), which uses the sum of the losses at different hierarchical levels and Taxonomic Context-based Prediction Alignment (TCA), which adjusts the similarity between the feature and the class prototype by incorporating the weights based on the similarities between the prototypes at different hierarchical levels.\\n\\nExperimental results on seven datasets show that the proposed method achieves better accuracy than existing methods.\\n',\n",
       "  'strengths': '* This paper proposes an OSSL method focusing on class hierarchy, which has not been considered in the past as far as I know. (However, as discussed below, similar ideas have already been considered in related problems.)\\n\\n* The theoretical justification of the proposed method is discussed based on the principle of the EM algorithm (lower bound maximization of log-likelihood).\\n\\n* Exhaustive experiments using seven datasets show that the proposed method is consistently more accurate than existing methods.\\n',\n",
       "  'weaknesses': 'a. The idea of discovering unknown classes by focusing on the class hierarchy has been explored in the past [46], so the high-level novelty would be somewhat limited.\\n\\nb. In this paper, the number of unknown classes is known, which is not realistic. The supplementary material shows the experimental results for the case where the number of unknown classes is unknown (Tables V and VI). However, only the results for the case with the best clustering accuracy are presented. I do not think this is realistic, since clustering accuracy is not always evaluable in practice.\\n\\nc. The base networks used in the experiments are limited to ResNet-18/-50. Testing with more modern networks such as ViT and vision-language models would be nice to emphasize the effectiveness of the proposed method.\\n\\nd. Table 3 shows that accuracy improves when both TCP and TCA are used, but always degrades when TCA is not used. The reason for this is not clear.\\n\\ne. The results in Figure 4 suggest that the appropriate number of super-classes and sub-classes may differ depending on the dataset. Justification is needed.\\n\\nf. Some typos: \\n\\nL10: pIrors -> prIors\\n\\nL199: Sinkhorn-Koppn -> Sinkhorn-Knopp\\n'},\n",
       " 'review_37': {'summary': 'The paper introduces a novel Cluster Information Transfer (CIT) mechanism to enhance the generalization capability of Graph Neural Networks (GNNs) in the presence of structural shifts. The authors provide theoretical analysis, showing that the impact of cluster information on the classifier diminishes during transfer. They demonstrate that the CIT mechanism can be easily incorporated into existing models and showcase its effectiveness through extensive experiments. Overall, the paper highlights the value of the CIT mechanism in improving GNN generalization and supports its claims with comprehensive empirical evidence.',\n",
       "  'strengths': '- The paper includes both theoretical analysis and numerical results, providing a well-rounded evaluation of the proposed approach.\\n- The idea presented in the paper is clear and well-motivated, addressing an important problem.\\n- The experiments conducted in the paper are extensive and provide convincing evidence to support the claims made by the authors.',\n",
       "  'weaknesses': '- The experiments in section 2 are not sufficient.\\n- The descriptions of the experimental settings are unclear and could benefit from more detailed and precise explanations.\\n- There are some typos present in the paper that should be addressed for improved clarity and readability.'},\n",
       " 'review_38': {'summary': 'The paper tackles an important question of learning invariant representations of GNNs. The authors show that once the test graph pattern shifts, the reliability of GNNs becomes compromised. Then they propose the cluster information transfer mechanism, which can be easily combined with current GNNs to improve their robustness on structure shift. The authors present numerical experiments that suggest that the proposed mechanism is effective.',\n",
       "  'strengths': '1.\\tI enjoyed reading the paper. The presentation is clear and mostly easy to follow. \\n\\n2.\\tClear results on different scenarios, well-backed by experiments.\\n\\n3.\\tThe CIT mechanism is interesting and with technical analysis.\\n',\n",
       "  'weaknesses': '1.\\tIn section 2, why GAT performs worse than GCN?\\n\\n2.\\tIn fig.2, the model uses the node representation learned by GNNs to obtain clusters, so does the representation learned by different layers affect the clustering process?\\n\\n3.\\tThe authors mentioned that the graph OOD benchmark is built, so why the datasets used in the experiments are still the traditional graphs?\\n'},\n",
       " 'review_39': {'summary': 'This paper focuses on the invariant learning of graph neural networks and proposes a cluster information transfer mechanism with two statistics: the mean of cluster and the variance of cluster. The authors prove that with CIT mechanism, the model is able to capture the cluster independent information, so as to improve the generalization ability across different structure shifts. Experiments on different graph benchmarks show promising results of CIT mechanism.',\n",
       "  'strengths': 'Introduction and background parts are clearly written and motivate this study well. The research problem is important, the ideas are clearly clarified and all the technical steps are easy to follow. The paper provides the comprehensive experiments on different kinds of graphs to evaluate the performance of the proposed model.\\n',\n",
       "  'weaknesses': 'No specific discussions on structure shift. Time complexity analysis is not provided. The CIT mechanism is not explained sufficiently. '},\n",
       " 'review_40': {'summary': 'The paper introduces a new mechanism called Cluster Information Transfer (CIT) to improve the generalization ability of GNNs to various and unknown test graphs with structure shift. The CIT mechanism enhances the diversity of nodes by combining different cluster information with the nodes, which helps GNNs learn invariant representations. The paper presents experimental results on several benchmark datasets, demonstrating that the proposed CIT-GNN model outperforms existing GNN models in terms of accuracy and macro-F1 score. ',\n",
       "  'strengths': '- The paper is easy to understand.\\n- While the theory analysis is straightforward, it provides theoretically support for the proposed method.\\n- The experiments are extensive and the results look promising.\\n',\n",
       "  'weaknesses': \"- **Fair Novelty:** The proposed method is essentially an embedding transformation function that aims to eliminate the statistic variance between clusters that causes bias and hinders generalization. The novelty comes from the clustering mechanism and the augmented training using adjusted node embeddings. However, the spectral clustering mechanism has been introduced previously, and the transformation is relatively straightforward.\\n- **Assumptions and scope of the solution:** My second concern is about the assumptions of this paper. The paper generally assumes that there exist cluster / structural shifts between training and testing datasets. While structure could change across environments, the node labels remain invariant. The paper also implicitly assumes the node embeddings in different clusters are subject to Multivariate Gaussian distributions. These assumptions should be made explicit and formal. Moreover, the scope of structural shifts needs to be clarified. I understand that the variant of graph density or node degree can be one factor, but do other factors, e.g., edge homophily, also contribute to the shifts? A more general scope should be discussed in order to ensure its applicability.\\n- **More validation about the claim:** The examples in the introduction considers the shifts between sparse and dense graphs. One simple baseline to mitigate it is to augment the datasets or clusters via DropEdge and AddEdge compared to modifying node embeddings. While I understand that the graph structure is complex in the real world, as the authors claimed (Line 57-59), it would be good to experimentally validate the effectiveness of the method with a simple baseline that modifies the graph structure.  \\n- **Lack of real datasets with natural shifts**: The experiments are somewhat synthetic in the sense that the training and testing sets are splitted with strong structural shifts. I wonder the performance of this method on datasets with more natural shifts, e.g., ogbn-arxiv, where the training and testing sets are splitted based on the time difference.\\n- **Missing Related Works:** It is unclear how the proposed clustering objective differs from the existing group clustering methods, e.g., Zhou et al. [1].\\n\\n**Minor:**\\n\\n- I feel Section 2 is not very informative since the setting is simple and the conclusion is not surprising. It would be good to demonstrate the structural shifts in more real settings or just combine this section to the introduction.\\n- In Line139 and 149, $m$ and $M$ are both used to indicate the number of clusters. It's better to make it consistent.\\n\\nIn general, the angle of mitigating structure shifts is interesting. However, several things above should be solved or clarified to understand its generality and effectiveness.\\n\\n\\n[1] Towards Deeper Graph Neural Networks with Differentiable Group Normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu.\"},\n",
       " 'review_41': {'summary': 'This paper aims to handle the structure shift problem in GNN. The paper proposed a novel approach -- Cluster Information Transfer (CIT) to address this challenge. CIT first computes cluster center representation during training. CIT then extract the cluster center from the node embedding to retrieve the cluster-independent information. Finally CIT transfers the cluster-independent information to another random cluster center, allowing the model to learn structure-independent knowledges.',\n",
       "  'strengths': '+ Previous works like EERM, SR-GNN majorly focus on data distribution shifts on graphs, while this paper focus on graph structural shift which is of potential research interest.\\n+ The method proposed in the paper can be applied on various existing GNN backbones, the method can also fit into different type of tasks and graphs.\\n+ This paper is well-written and is easy to follow.',\n",
       "  'weaknesses': '- The CIT method proposed in the paper is not well supported by theorem.  Theoretical analysis only shows that CIT weakens the affect of cluster information. However, the paper still need to answer why it is necessary to transfer nodes across clusters using Eq.8 (If the cluster information is harmful, why not just remove it?) and why can the model learn invariant representations from this process. \\n- The method introduces a lot of additional hyper-parameters which are sensitive to the results, which are all tuned by grid-search according to the experiments settings. Finally, the accuracy improvements in the experiments is not remarkable compared with other baselines.\\n- The method is only evaluated on small graphs with several thousand nodes, making it unknown whether the method can be applied to larger graphs.'},\n",
       " 'review_42': {'summary': 'Studies on the expressive power of Graph Neural Networks (GNNs) have garnered extensive attention. However, these studies have been limited to flat GNNs. Some hierarchical pooling methods, such as diff-pool, have been proposed. Evaluating the ability of pooling operations directly is challenging, so the performance of downstream tasks is often used as a measure. However, this approach is overly empirical and susceptible to other factors.\\n\\nIn this paper, the authors propose to use the ability to retain graph information to measure the power of pooling operations. Specifically, this paper first provides sufﬁcient conditions for a pooling operator to fully preserve the expressive power of the MP layers before it. Then, it reviews, classifies existing pooling operators. \\n',\n",
       "  'strengths': '1. This paper first studied on the expressive power of graph pooling in graph neural networks.\\n\\n2. This paper categorizes the existing pooling methods based on whether they preserve the expressive ability of the Message Passing (MP) layer.\\n',\n",
       "  'weaknesses': \"1. Given that simple global sum pooling can attain the same expressive capability as 1-WL (e.g., GIN), the rationale behind employing a complex pooling method that achieves no gain in expressive ability might be questioned.\\n\\n\\n2. The research lacks adequate experimentation. Ultimately, the investigation into enhancing or maintaining the expressive ability of Graph Neural Networks (GNNs) is driven by their impact on downstream tasks. However, the paper's classification performance is only evaluated on an extremely small dataset, which fails to provide sufficient convincing evidence.\\n\\n3. The presentation requires improvement. For instance, reporting averages on different types of datasets in graph classification experiments, as shown in Figure 3, seems unusual and could be better structured. \\n\\n4. There exists a disparity between Condition 1 of Theorem 1 and the corresponding explanation in line 137, i.e., $\\\\mathcal{X}_1^L \\\\neq \\\\mathcal{X}_2^L $. The summation of the sets is not equal, is not equivalent to the formula in line 137.\\n\"},\n",
       " 'review_43': {'summary': 'This paper presents a study on the performance and expressiveness of various pooling operators in Graph Neural Networks (GNNs) in both theoretical and empirical ways. In detail, the authors identify the sufficient conditions that a pooling operator must satisfy to fully preserve the expressive power of the original GNN model. The authors also propose an experimental approach to evaluate the performance of various graph pooling operators and their theoretical results. The empirical results align with the theoretical findings, showing that pooling operators that satisfy the aforementioned conditions achieve the highest average accuracy. Despite aggressive pooling, these operators retain all the necessary information and perform as well as the GNN without a pooling layer. On the other hand, non-expressive pooling operators achieve significantly lower accuracy. The paper also demonstrates that pooling operators based on a normalized random cluster assignment matrix or the complement graph yield lower performance, which challenges the notion that such operators are comparable to regular ones. In summary, this paper makes a valuable contribution to the field of GNNs by investigating the expressive power of pooling operators in GNNs.',\n",
       "  'strengths': '**Originality**: The paper is highly original in its focus on the performance and expressiveness of various pooling operators in GNNs. The authors propose a novel experimental approach to evaluate these operators, and they derive sufficient conditions for a pooling operator to fully preserve the expressive power of the message-passing layers before it. This provides a universal and theoretically-grounded criterion for choosing among existing pooling operators or designing new ones. The exploration of unconventional pooling operators also adds to the originality of the work.\\n\\n**Quality**: The quality of the paper is good in the rigorous theoretical analysis and comprehensive empirical evaluation. The authors align their empirical findings with their theoretical predictions well. \\n\\n**Clarity**: The paper is organized and well-written. The theoretical analysis is clearly explained, and the presentation of the experimental results is easy to follow.\\n\\n**Significance**: The findings in this paper contribute to a solid and necessary step in the understanding of pooling operators in GNNs. The theoretical conditions they propose for preserving the expressive power of message-passing layers and the new dataset could guide the design of new pooling operators.',\n",
       "  'weaknesses': '- Since the proposed EXPWL1 dataset serves as an important contribution to the paper, the authors could provide more information about the dataset, i.e. at least provide certain example graph pairs.\\n\\n- The experiments are kind of insufficient. First, the results in Table 1 are conducted under limited conditions with a pool ratio = 0.1 (excluding the pool ratio = 0.5 for Graclus and ECPool due to issues in implementation). It would be more comprehensive to see and discuss how the pooling operators compare to each other under different pool ratios. Second, the results in Table 3 in supplementary material do not contain the ones for Rand-dense, Cmp-Graclus, and Rand-sparse pooling operators. The comparison to these operators is necessary since the authors want to disprove the argument in [1] that such operators are comparable to the regular ones. Currently, the comparison is only done on a synthetic dataset.\\n\\n\\n[1] D. Mesquita, A. Souza, and S. Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220–2231, 2020.'},\n",
       " 'review_44': {'summary': 'This paper analyzes the expressive power of pooling operators in Graph Neural Networks (GNNs) and derives three conditions for a pooling operator to fully preserve the expressive power of the Message Passing (MP) layers preceding it. The derived conditions are as follows: \\n\\na) The pooling operator should extract different features for non-isomorphic graphs that are distinguishable using the Weisfeiler-Lehman (WL) test. \\n\\nb) All nodes in the original graph must contribute to the creation of supernodes.\\n\\nc) The features of the supernodes (denoted as X^P) should be a convex combination of the features of the nodes X^L.\\n\\nThe paper presents controlled experiments along with theoretical support to validate and support their findings.',\n",
       "  'strengths': '1 - The paper is well-written and easy to follow. \\n2 - The hypothesis is nicely executed in a controlled set of experiments. \\n3 - Theoretical analysis has been provided to support the findings. \\n4 - Sufficient review of the literature and pooling operators is provided. \\n5 - Clear categorization and analysis of the pooling operators are provided.',\n",
       "  'weaknesses': '1 - Selected real-world graph classification datasets are chosen. I was wondering why MUTAG, PTC_MR, IMDB-B are IMDB-MULTI left out\\n2 - A comparison with pooling operators such as global_add, global_sum and global_max might provide a better overview of the effectiveness of these pooling operators.  '},\n",
       " 'review_45': {'summary': 'The authors present a comprehensive analysis of pooling operations in Graph Neural Networks (GNNs) from both theoretical and practical perspectives. Additionally, they introduce a refined dataset, EXPWL1, specifically designed to facilitate the analysis of the expressiveness of pooling operations. Remarkably, the empirical evaluation aligns with the theoretical discoveries.',\n",
       "  'strengths': '1. The content is presented in a clear and organized manner, and the figures are well-drawn and visually appealing.\\n2. The theoretical portion of the work is effectively presented and explained.\\n3. The experimental section contains a thorough explanation of the setup and a comprehensive evaluation of the results.\\n',\n",
       "  'weaknesses': '1. The discussion on the limitations of the work is absent.\\n2. Figure 3 is missing std bars.\\n'},\n",
       " 'review_46': {'summary': 'The paper analyzes the expressive power of pooling (not to be confused with readout) in message passing GNNs (MP-GNNs). The paper gives a condition (in Theorem 1) on the construction of the POOL function, under which there is a choice of the MP-GNN which can separate the same graphs that the 1-WL test can separate. Using these conditions, well known pooling methods are classified as expressive and non-expressive. A new dataset of pairs of graphs that can be separated by 1-WL is introduced, on which the theoretical results are demonstrated.',\n",
       "  'strengths': 'The paper is mostly clear, and the topic of pooling in GNNs has practical importance. The theoretical analysis is sound (up to some issue with its interpretation that I discuss below). The classification of well known pooling methods as expressive and non-expressive, in view of Theorem 1, is potentially useful for practitioners, especially as the experimental results on the new dataset strongly support this theoretical classification. The approach is a natural extension of expressivity analysis such as in \"How powerful are graph neural networks?\" and “Deep sets.”\\n',\n",
       "  'weaknesses': 'The discussion on the injectivity of pooling should be put in the right context and setting. What is shown around Theorem 1 is that there is a specific way to predefine the MP functions in such a way that the whole network, including POOL, is injective. The construction does not show that POOL is injective for general message passing functions with trainable parameters (for any choice of the parameters). See more details on this point in “Questions” below. Once this is fixed, I can improve my rating.'},\n",
       " 'review_47': {'summary': 'summary: The paper proposes a mitigation approach for backdoor attacks in ML (attacks where a model predicts target classes for poisoned samples when triggered by the adversary). The authors analyze the relationship between backdoor risk and adversarial risk [adversarial examples and poisoned samples] to create an upper bound for the backdoor risk, identify --Shared Adversarial Examples-- between the poisoned model and the fine-tuned model (which can successfully activate the backdoor) and then formulate an optimization or a purification problem for mitigating backdoor attacks (Shared Adversarial Unlearning) to break the connection between poisoned samples and the target label, such that they are either classified correctly by the fine-tuned model or differently by the two models. The authors further thoroughly analyze their approach, comparing it with six other SOTA defense methods on seven types of backdoor attacks with different model structures and datasets.\\n\\n',\n",
       "  'strengths': 'The paper targets an important problem. The approach is novel and the thorough analysis of several key metrics indicates the efficacy of the approach. \\n',\n",
       "  'weaknesses': '\\n* Many  important part are in the supplemental materials, including some of the approaches such as the SAU implementation using SGD to unlearn the SAEs, the all to all case, and multi-trigger in threat model (section 3.1) is unclear.\\n\\n'},\n",
       " 'review_48': {'summary': 'This paper analysed the relationship between adversarial examples and poisoned examples. \\nThen, this paper proposed a fine-tuning strategy to purify the poisoned model. ',\n",
       "  'strengths': '1 This paper is easy to follow. \\n\\n2 This paper provides some experiments that support the proposed method. \\n\\n3 This paper has some experimental analyses that can lead to the proposed method. ',\n",
       "  'weaknesses': \"1 It seems this paper used many  ill-established notions such as backdoor risk, shared adversarial risk, vanilla adversarial risk, etc..  To the best of my knowledge, I haven't heard to backdoor risk in any machine learning/AI books. \\n\\n2 Adversarial training has the issue of high computational overhead, which could limit the practicality of the proposed method in real-world applications.\\n\\n3 The key reference is missing. This paper also need to compared with the paper [1]. \\nPrevious work [1] has proposed to tackle with backdoor attacks with multiple adversarial perturbations (L_p adversarial attack and spatial adversarial attack). I encourage the authors to discuss the differences between both works and explore more types of adversarial attack such as spatial adversarial attacks [2] or perceptual adversarial attacks [3].  Besides, some popular backdoor attacks do not satisfy Assumption 1 such as BadNets which has a large L_p norm. \\n\\n[1] On the Effectiveness of Adversarial Training against Backdoor Attacks. TNNLS 2023.\\n\\n[2] Spatially Transformed Adversarial Examples. ICLR 2018.\\n\\n[3] Perceptual Adversarial Robustness: Defense Against Unseen Threat Models. ICLR 2021.\"},\n",
       " 'review_49': {'summary': 'This paper proposes a method to defend against backdoor attacks in deep neural networks through adversarial training techniques. By exploring the connection between adversarial examples and poisoned samples, the authors propose an upper bound for backdoor risk and a bi-level formulation for mitigating backdoor attacks in poisoned models. The proposed approach can identify shared adversarial examples and unlearns them to break the connection between the poisoned sample and the target label.',\n",
       "  'strengths': '- This paper explores the connection between adversarial examples and backdoor attacks, which is interesting.\\n\\n- Extensive experiments are conducted to evaluate the performance of the proposed method.\\n\\n- The paper is well written and easy to read.',\n",
       "  'weaknesses': '- Some important related works are missing. There are some existing works that study provable/certified robustness against backdoor attacks or data poisoning [1,2,3]. However, the authors do not mention those works in the paper. It would be interesting if the authors could compare their method with those works.\\n\\n- This paper assumes that the trigger magnitude is bounded by a norm, which may degrade the practicality of the proposed method. In practice, it is entirely possible for the attacker to adopt triggers with very large magnitudes, and the proposed method may not work in this case.\\n\\n- The proposed method relies on a clean dataset to achieve the defense goal, and the quality of the dataset may affect the performance of the proposed method. However, it is not clear how to obtain a clean dataset with high quality in practice.\\n\\n     [1] RAB: Provable Robustness Against Backdoor Attacks. IEEE S&P 2022.\\n\\n     [2] Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks. AAAI 2022.\\n\\n     [3] BagFlip: A Certified Defense against Data Poisoning. NeurIPS 2022.'},\n",
       " 'review_50': {'summary': 'This paper proposes a Shared Adversarial Unlearning (SAU) method for mitigating backdoor attacks. The motivation behind this method is the recognition that not all adversarial samples are effective for backdoor defense. Therefore, it is important to identify the adversarial samples that truly contribute to backdoor defense during adversarial training. The authors derive an upper bound on the backdoor risk from benign model and backdoor model predictions, and optimize the generation of backdoor samples based on this bound. Experimental results demonstrate the effectiveness of the method in purifying the backdoor model.',\n",
       "  'strengths': '- Clear research motivation, well-structured writing, and provides ample theoretical support. \\n- Comprehensive comparison results with mainstream backdoor defense methods on multiple datasets, confirm its effectiveness.\\n',\n",
       "  'weaknesses': \"- Adversarial training often involves complex min-max optimization problems, making it difficult to apply in practical training. However, existing defense work, such as ABL, achieves efficient backdoor removal by detecting suspicious backdoor samples and performing unlearning (gradient ascent) training. ABL's unlearning paradigm is evidently a simpler and more direct backdoor removal strategy. Therefore, it would be interesting to explore the combination of the adversarial sample generation strategy proposed in this paper with ABL's unlearning paradigm, simplifying the optimization process of the proposed adversarial training. It would be helpful if the authors could provide some theoretical or empirical results.\\n\\n- From Table 3 in the experiments, it is apparent that the proposed SAU method fails to effectively defend against the WaNet attack with full-image triggers on the TinyImageNet dataset (attack success rate after defense is as high as 85.75%). In other words, when the image scale or trigger norm increases, the SAU method may face defense failures. The authors need to provide a reasonable explanation and corresponding countermeasures to demonstrate the generalization performance of the SAU method.\\n\\n- If the attacker is aware of the defender's adversarial training strategy, can they generate corresponding backdoor trigger samples based on the adversarial training and launch attacks? In such a scenario, is the SAU defense effective?\\n\\n- To my knowledge, adversarial defense is sensitive to the scale of clean data. In the experiments, the authors state that the defense method requires 5% clean samples. How much will the accuracy and defense performance of SAU decline when the scale of clean samples drops below 1%?\\n\\n- There is a lack of comparison with more advanced defense benchmarks, such as the recently proposed RNP [1].\\n\\nOverall, the authors of this paper highlight the differential impact of different types of adversarial samples on backdoor defense during adversarial training. While there are optimization uncertainties and application limitations, such as the difficulty in scaling to large models, associated with mitigating backdoor attacks through adversarial training, the authors' findings provide new insights into the relationship between adversarial samples and backdoor unlearning. Therefore, if the authors can address the aforementioned concerns and related questions, I would be happy to increase the score.\\n\\n[1] Yige Li, Xixiang Lyu, Xingjun Ma, et al, Reconstructive Neuron Pruning for Backdoor Defense, ICML, 2023.\\n\"},\n",
       " 'review_51': {'summary': 'The authors argue that the normalization of the gradient in the SAM model during the ascent step is beneficial. In particular, classic SAM is shown theoretically and empirically in certain scenarios to not-diverge and to be able to drift along the minima manifold. This implies that SAM is more robust in the choice of the step-sizes compared to the unnormalized SAM.',\n",
       "  'strengths': '- The paper is in general well-written and accessible despite being a theoretical work.\\n- The included examples help the understanding of the ideas.\\n- The theoretical results seem convincing and sensible, but I have not verified the technical details.',\n",
       "  'weaknesses': '- I think the similarities and differences to Wen 2023 and Compagnoni 2023 could have been discussed more broadly.'},\n",
       " 'review_52': {'summary': '**I have read the rebuttal and raised the score to a 7.** This paper studies the importance of the normalization step in SAM (normalizing the gradient used to perturb the weights) for stability and effectiveness at finding a flat region in a manifold of minima (drifting along a continuum of minima). They provide the following theoretical explanations:\\n- On a strongly convex, smooth loss and some specific nonconvex settings, for the same range of learning rates, unnormalized SAM may diverge while normalized SAM does not i.e. the SAM perturbation has to be sufficiently small for convergence. Normalized SAM stabilizes within some local neighborhood around the minimizer (this has been shown previously in Bartlett 2022).  \\n- Considering the model x*y for some convex loss, where the flattest solution lies at x,y=0, they show that USAM and GD both get stuck after reaching a closer sharper solution (x=0, y > 0), while SAM keeps drifting towards the origin after getting close to a minima (x=0, y > 0). Their contribution here is showing that without the normalization step, the perturbations become too small. \\n\\nFor these reasons, they empirically show (in a sparse coding problem) that the normalization step of SAM allows SAM to stably achieve flat minima in comparison to large learning rate GD or unnormalized SAM which may both have problems with divergence.',\n",
       "  'strengths': '**Significance:** The unnormalized SAM has been studied theoretically as a simplification for SAM, and the contributions of the paper emphasize why this simplification may change the dynamics of SAM entirely. \\n**Clarity/quality:** The paper is well motivated, easy to read, and thorough. All theoretical conclusions are sound and are supported by clear empirical trends.',\n",
       "  'weaknesses': \"The main weakness is significance as unnormalized SAM which the paper focuses on studying is not utilized in practice and the conclusions of the work, though confirms normalization is good, does not provide further prescriptive insight. The characterizations of normalized SAM conducted in the paper have already been shown in previous works, and the new contribution is solely characterizing how unnormalized SAM is different. Yet, unnormalized SAM only appears in a couple works that theoretically analyze SAM but does not appear in practice. As pointed out by the authors, previous works (Wen 2022, Bartlett 2022) have already shown that normalized SAM stabilizes around a local neighborhood around a minima and it achieves flatter minima by continuing to drift along the manifold. The contribution of this work is to formalize how the perturbation needs to be sufficiently small for convergence, but sufficiently large around the manifold of minimas to find the flat solution, which is achieved by normalization. Yet these conclusions, especially the former, seems a bit intuitive/obvious. Additionally, previous theoretical works have indicated that USAM can be tuned to achieve similar performance to SAM (Andriuschenko 2022). Though there exists a difference between USAM and SAM in the toy models in the paper, there aren't any experiments that indicate that not normalizing is a problem on real datasets and models (that USAM requires delicate tuning, or doesn't work at all in terms of achieve similar training curve and test performance as SAM). Perhaps adding such an experiment would help amend the first concern.\\n\\n-- \\nMinor fixes:\\nLine 248 diverges --> divergence\"},\n",
       " 'review_53': {'summary': '- The paper investigates the difference between SAM and Unclipped SAM (USAM) in terms of stabilizing and drifting along the manifold.\\n- The paper reveals a significant disadvantage in USAM compared to SAM, which was previously thought to be similar in various papers.\\n- The paper provides mathematical and experimental evidence to support their ideas in diverse settings.',\n",
       "  'strengths': '- Overall, the idea of investigating the difference between SAM and USAM is clear and interesting.\\n- The paper identifies the role of normalization and highlights that USAM behaves more like GD than SAM, potentially getting stuck in local minima and requiring careful tuning.\\n- The mathematical proofs are clear and offer unique insights compared to previous papers, such as [1].\\n\\n[1] An SDE for Modeling SAM: Theory and Insights (ICML’23)',\n",
       "  'weaknesses': 'Please refer to questions.'},\n",
       " 'review_54': {'summary': 'The paper investigates the role of the normalization term in the recently proposed optimization algorithm Sharpness-Aware Minimization (SAM). The authors theoretically, and empirically, study the differences among  SAM, its un-normalized counterpart USAM, and gradient descent, under multiple settings (strongly convex and smooth losses, a non-convex case, single-neuron linear networks, sparse coding), and conclude with two key takeaways: normalization in SAM helps (1) stabilize algorithm iterates, and (2) enables the algorithm to drift near minima. ',\n",
       "  'strengths': '- The paper thoroughly investigates the role of normalization across many different settings, and convincingly show the benefit of the normalization term. \\n- The authors provide clear key takeaways for why normalization helps, with both empirical and theoretical support.\\n- The paper makes a solid contribution to our understanding of why normalization is beneficial\\n- The authors compared the impact of tuning the learning rate and perturbation radius between SAM and USAM',\n",
       "  'weaknesses': '- Empirical verification on real-world tasks is limited. For example, generating more results similar to Figure 5 would strengthen the papers conclusions. \\n- While having a deeper understanding of a specific term in an optimizer adds value, the overall question of the work does not feel like a pressing issue in ML. The takeaway of the rigorous work is to use the original version of SAM, which most people who use SAM already do. '},\n",
       " 'review_55': {'summary': 'This work investigates the role of the normalization factor $1/||\\\\nabla L(x,w)||$ in the perturbation step of the Sharpness-Aware Minimization (SAM) algorithm. To this end, the authors compare the behavior of gradient descent, SAM and a version of SAM without the normalization (USAM) via experiments and extensive theoretical analysis. The authors find that USAM lacks some of SAMs beneficial properties: On the one hand, it is harder to choose an appropriate perturbation radius for USAM and on the other hand, the ‘drifting along minima’, which is thought to be connected to SAMs empirical success, only occurs in a restricted manner.',\n",
       "  'strengths': 'The paper is very well written and polished. The motivation (understanding the effects of the normalization factor in the perturbation step of SAM) is outlined clearly. The theoretical analysis is thorough. The toy experiments are clever and well-designed to isolate the effects that are to be investigated, and mostly support and illustrate the conclusions arising from the theoretical analysis.',\n",
       "  'weaknesses': 'The authors essentially provide extensive theoretical analysis and toy experiments on why USAM works worse than SAM, which often stems from the fact that the gradient magnitude changes during training. USAM is however not a relevant algorithm in practice - it was only introduced as a simplified version of SAM for easier theoretical analysis. The insights on why SAM works in the first place are thus limited (e.g. that SAM can drift along minima was analyzed in [1], and adding that normalization is important for this to happen adds little to the understanding of SAM).\\n\\nApart from [2], where USAM was found to work similarly to SAM for a ResNet on CIFAR, it is further unclear how well USAM works in realistic scenarios. While the authors provide some insights (in 2.3 and 3.3), the settings in those experiments are fairly restrictive (one focuses on early-stage training and the other on an adversarial initialisation) and (nicely) highlight isolated effects when dropping the normalization factor. While I think that negative results (like, _In contrast to SAM, USAM does not work in practice, and here we explain why_) can be of value to the community, it is thus unclear to me if the results presented in the paper are indeed relevant for practical neural network training with SAM (or USAM). Presenting results of several models trained with SGD, SAM and USAM on e.g. CIFAR10 & CIFAR100 over a range of $\\\\rho$ values would bring insights on this and bridge the gap between the analysis and potential practical implications of this paper. In particular, one could e.g. show that for practical deep learning settings picking $\\\\rho$ is indeed more difficult, or that USAM does not find well-generalizing minima (due to the restricted drifting along minima).\\n\\n[1] Peter L. Bartlett, Philip M. Long and Olivier Bousque. The Dynamics of Sharpness-Aware Minimization: Bouncing Across Ravines and Drifting Towards Wide Minima. Arxiv preprint\\n\\n[2] Maksym Andriushchenko and Nicolas Flammarion. Towards understanding sharpness-aware Minimization. ICML 2022'},\n",
       " 'review_56': {'summary': 'The authors design a novel approach to make it possible for clients equipped with different model structures to cooperate in the federated learning framework. Specifically, the server will reassemble models into different parts and assemble them together. After that, they propose a similarity-based approach to match the most fitted model with the clients’ models and distribute them back to the clients respectively. To emphasize the advantages over the KD-based approaches, the authors discuss different perspectives of using public datasets. Finally, they address the effectiveness of the algorithm using experiment results under the IID and non-IID setting compared with other baselines.',\n",
       "  'strengths': '1. This paper presents a new way to achieve personalized federated learning using heterogeneous model reassembly, which is significantly different from existing work.\\n2. The authors aim to design a new model to alleviate the issue of performance drop caused by introducing public data on the server, especially when its data distribution is different from that of clients. \\n3. The authors conduct extensive experiments on different settings, including 12 clients, 100 clients, IID, non-IID, and public data with labels and without labels. The experimental results demonstrate the effectiveness of the proposed model.',\n",
       "  'weaknesses': '1. The training of stitching layers is not significantly clear. Are they trained with the other parts of the networks or trained separately? The authors can provide a description of how the networks are trained after they are stitched together.\\n2. Since the generated candidates may change for different runs, are the results averaged by multiple runs?\\n3. The font size used in Figure 1 is too small.'},\n",
       " 'review_57': {'summary': 'In this paper, the authors introduce a technique that tackles the challenge of enabling collaboration among client models with different network structures in federated learning. Unlike traditional knowledge distillation (KD)-based approaches, the proposed model involves dividing the heterogeneous models into distinct parts and subsequently reassembling them. This unique reassembling approach fosters model diversity, facilitating personalized local training at each client. The proposed technique alleviates the adverse impact of utilizing public datasets on the server. By providing experimental results, the authors establish the effectiveness of their proposed model.',\n",
       "  'strengths': \"- Overall, the paper is well-written and easy to follow. The motivations behind the research are clearly articulated, and the experimental results presented are both sufficient and convincing. \\n\\n- The introduction of the novel reassembling technique to federated learning is a significant contribution. This approach opens up new avenues for achieving model personalization, which has the potential to inspire further exploration by researchers in the field.\\n\\n- The authors' inclusion of an empirical analysis that explores the negative impact of utilizing heterogeneous public data on the server is a notable and valuable aspect of this work. Moreover, the proposed reassembling solution effectively mitigates this issue, providing a practical and effective resolution.\",\n",
       "  'weaknesses': '- In the experiments, the authors use four self-designed CNN-based models for saving computational resources. However, there are some lightweight models, such as MobileNets, used in previous FL work. Incorporating these lightweight models would enhance the comprehensiveness of the experimental evaluation and provide a broader perspective on the proposed approach.\\n- Figure 1 is a little hard to read, and I suggest the authors use one setting as an example to demonstrate the challenge of using heterogeneous public data and put other results in Section 4.4.\\n- Adding a readme file to the source code package would be a useful addition.'},\n",
       " 'review_58': {'summary': 'The authors designed a method to train a model with FL when clients have heterogeneous model architectures. They designed a model reassembly technique that stitches together parts of DNNs. pFedHR also creates personalised models for each client without requiring server-side data or explicit human guidance. ',\n",
       "  'strengths': '- Heterogeneous FL is an important problem \\n- The paper is well-written and easy to understand\\n- The authors compared their approach with number of existing algorithms ',\n",
       "  'weaknesses': '- The reason to stitch together heterogeneous architectures is not very well motivated. There are many other approaches that aim to learn personalised model for a set of clients with heterogeneous capabilities. For example FjORD [https://arxiv.org/abs/2102.13451]  train a number of subnets using adaptive dropout, HeteroFL [https://arxiv.org/abs/2010.01264] is another model where a superset is trained and submodes are used to address heterogeneity in FL, FedRolex [https://arxiv.org/abs/2212.01548], or [https://arxiv.org/abs/2210.16105] all use weight sharing to address similar tasks.\\n\\nThe authors should discuss what is the main advantage/motivation of having heterogeneous architectures stitched together over other approaches where the computational complexity of a model can be scaled up/down, and possibly compare with some of the above methods. \\n\\n- Most experiments were done with few clients (N=12 up to 100). This is very small and might be unrealistic in real-=world applications where we might have million of clients participating in FL. It would be great to show how things scale up. '},\n",
       " 'review_59': {'summary': 'The paper proposes to use the recently published model reassembly technique (NeurIPS 2022) to obtain personalized models through federated learning. At each round, the server collects the current models from the clients and uses reassembly to generate new candidate models, potentially training some stitching layers using a public datasets. Then the closest candidate model (again similarity is evaluated through the public dataset) is sent back to the client who can (later) train its own model distilling knowledge from the candidate model. By using the public dataset only for a few selected operations, the proposed scheme should be more robust to deviations from the training dataset and the public one.\\n',\n",
       "  'strengths': '* The idea to use reassembly for federated learning is a novel one to the best of my knowledge \\n* Experimental results are promising and the robustness to the choice of the public dataset is definitely an important plus of the proposed approach.\\n',\n",
       "  'weaknesses': '* In the proposed scheme, the server does not keep historical aggregate information about the training, as for example it does under FedAvg by storing the last version of the shared model.  Historical information is rather kept at the client, which at each round performs a local training with knowledge distillation from the candidate model selected by the server during the previous communication round to which the client participated.  As a consequence the method does not seem suited for large-scale cross-device settings where clients may be selected only a few times. The authors have considered clients\\' sampling rates between 1/3 and 1/10. I expect performance to decrease significantly for lower rates.\\n* The proposed solution requires the server to maintain the identity of the each client (to be able to send back the relevant candidate model). This prevents the applicability of privacy-preserving techniques like secure aggregation. Note that there are other personalized approaches which do not have this constraints (e.g., Ditto, FedEM,...)\\n* Computational overhead. If I understood correctly, the server needs to train the stitching part for every possible client/candidate-model pair, i.e., to train in total BM models, which poses a significant load on the server. \\n* Complexity of the proposed solution. It would have been good to perform an ablation study to evaluate if all pFedHR steps are really needed. For example, what if the clients\\' models are directly compared and the closest one is sent as candidate model to the client without performing any reassembly and stitching?\\n* The candidate model can be more complex than the client\\'s model. There is then an implicit assumption that, while the client has selected a given model size for example on the basis of its computational and memory capabilities, it is still able to use a more complex model for knowledge distillation at training time\\n* The comparison with the previous literature is not always clear. Two examples:\\n\\t1. a limitation of previous literature would be that \"the averaging process significantly diminishes the characteristics of individual local models\" I found this sentence too vague.\\n\\t2. \"however, FedDF trains a global model with different settings compared with our approach.\"  Again, this is too vague, what is the difference with FedDF in a few words?\\n* compute\\n\\t* the authors checked the compute checkbox but I was not able to find any information about computation in the paper or in the supplementary material\\n* reproducibility\\n\\t* while the code is provided there is no readme file about how to use it and how to reproduce the results in the paper.\\n* minors:\\n\\t* footnote numbers should go after punctuation marks\\n\\t* report the number of clients for table 4\\n\\t* typos: bettwen and cadidates \\n'},\n",
       " 'review_60': {'summary': 'This paper proposes an active learning approach for semantic segmentation using multi-class label queries. Different from dominant class labeling methods, where an oracle is asked to select the most dominant class by a single click, this paper instead designs a multi-class labeling approach that asks the oracle for a multi-hot vector that indicates all classes existing in the given region. Experiments on two benchmarks, Cityscapes and PASCAL VOC 2012, demonstrate promising performance with a significant reduction in annotation cost.',\n",
       "  'strengths': '1. Reducing annotation costs for segmentation tasks is a long-standing and crucial task. This paper considers active learning to select informative regions from training data and asks an oracle to label them on a limited budget, which is a potential research direction to allow large-scale and annotation-efficient training for segmentation tasks.\\n2. The proposed method is reasonable and technically sound.\\n3. The experimental results are comprehensive and verify the effectiveness of the proposed method.\\n4. The overall paper is well-written and easy to follow.',\n",
       "  'weaknesses': '1. In stage 1, the total training objective comprises three loss terms. While the sensitivity analysis of the balanced terms $\\\\lambda$ is provided in the supplementary material, I am still wondering whether any findings or insights to determine the importance of each loss term.  More insights or clarifications are encouraged.\\n2. In Figure 7(a), why does the gain of label localization (%) from the method w/ prototype decrease when the number of clicks increases? More clarifications are suggested.'},\n",
       " 'review_61': {'summary': 'This work introduces a new active learning framework for semantic segmentation, involving a novel query design that uses a multi-hot vector for class representation with in a region, two novel loss functions for effective multi-class label supervision, and an acquisition function considering class uncertainty and balance in a local region. This approach optimizes label usage, enhancing supervision and efficiency in semantic segmentation tasks. ',\n",
       "  'strengths': '1) The motivation of this work is clear and interesting. In my opinion, the main strength of this paper lies in the proposed query based on multi-class labels. To be specific, the traditional dominant class labeling suffer from more annotation time per click and bad performance. Therefore, this paper proposed a novel multi-class labeling query and customized two loss and acquisition function for multi-class labeling to handle this problem.\\n2) The quantitative experimental results are impressive. Only 4% clicks can reach 95% mIoU of the fully-supervised model.\\n3) Most of this paper are easy to understand.\\n',\n",
       "  'weaknesses': '- In my view, the Merged Positive Loss and Prototypical Pixel Loss proposed in this paper are essentially minor modifications to the Cross Entropy Loss from a technical standpoint. The Acquisition Function proposed in the paper simply introduces a hyper-parameter to the existing Acquisition Function, incorporating the concept of multi-class. \\n\\n'},\n",
       " 'review_62': {'summary': 'This manuscript proposes a new issue on active segmentation from multi-class label query. Concretely, the authors are motivated from the shortcomings of existing active learning paradigm, i.e., [1][2] query the whole image pixel annotations, which costs annotation; [3] selects pixels for annotation, which performs with less generalization. To this end, this manuscirpt follows the compromis that actively annotating the uncertain regions with annotating region-level categories and propose a new query design from multi-hot response. To tackle the issues including uncertain region selecting, category ambiguity, and the absence of fine-grained pixel supervision, the manuscript deviced: a region selection strategy (a.k.a.,  acquisition function), training with class-ambiguity loss functions (stage 1 training), self-train learning (stage 2 training). Then, the authors conducted experiments on various benchmarks of semantic segmentation to show their effectiveness. \\n\\n[1] Samarth Sinha, Sayna Ebrahimi, and Trevor Darrell. Variational adversarial active learning. In Proc. IEEE/CVF International Conference on Computer Vision (ICCV), 2019.\\n[2] Lin Yang, Yizhe Zhang, Jianxu Chen, Siyuan Zhang, and Danny Z Chen. Suggestive annotation: A deep active learning framework for biomedical image segmentation. In Proc. Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2017.\\n[3] Gyungin Shin, Weidi Xie, and Samuel Albanie. All you need are a few pixels: semantic segmentation with pixelpick. In Proc. IEEE/CVF International Conference on Computer Vision (ICCV), 2021.',\n",
       "  'strengths': '1. The draft is beautiful and clear to view. The figures arrayed in Sec. 3 indeed assist me a lot in understanding the detailed methdology and  pipeline.\\n2. The idea of annotate region-level omni-class is novel. Intuitively, it makes a compromis between image-level with pixel-level as authors claimed in the manuscript. \\n3. The experiments show that the proposed method is effective in saving annotation budget and promise segmentation performance.',\n",
       "  'weaknesses': '1. The manuscripts required double-check in some details. For example, in L28, \"Early approaches consider an entire image as a sample and ask for its pixel-wise class labels [48, 60], or select individual pixels and query the oracle for their class labels [46]; they turned out to be suboptimal since the former lacks the diversity of samples [40] and the latter is less 30 budget-efficient as a query provides supervision for only a single pixel.\" It is obvious that indivdual pixel-annotation lacks diversity, while whole image annotation costs heavily. But the author happened to claim the opposite of these two points. \\n2. Despite that the authors deviced a novel issue in segmenting from region-level multi-class query, the method presented seems to be A+B+C style to me. Moreover, the composition seems not to be novel. Firstly, learning from multi-labels for pre-defined sample-level (i.e., region in this paper, image in learning from multi-class classification) via merging pixel loss is not novel. Secondly, Prototypical Pixel Loss and learning from pseudo labels are very common treatment in self-train paradigm, as cited by authors. Actually, I cannot grab the novelty of the manuscript in methdology design. If I misunderstood some points, it will be better to highlight the contributions and add necessary discussion with previous works.\\n3. The comparison experiments on region selection (a.k.a., acquisition function) with other classic strategy, e.g., KNN, Margin, et. al are missing. Sample selection is of vital importance for active learning, while the authors seems to narrow down the importance to this part.'},\n",
       " 'review_63': {'summary': 'The paper studied active learning for semantic segmentation. Instead of using each pixel as a query for annotation, this paper used a super-pixel as a query. Since each super-pixel may contain multi-class labels, thus a multi-class labeling scheme is used instead of dominant class labeling. However, it introduced the class ambiguity issue in training since it assigns multi-class labels to each super-pixel region.  The authors proposed a two-step learning method, effectively utilizing the supervision of multi-class labels.  Extensive experiments were conducted to valid the proposed method, where promising results were reported.  ',\n",
       "  'strengths': '++ The idea is quite interesting and practical. Using superpixels as active learning query unit is sensible. Assigning multi-class labels to the superpixels is also quite effective with the proposed two-step learning scheme. \\n\\n++ The paper is well written and easy to follow. I like the figures provided in the paper, they are quite informative. \\n\\n++ Good performance, clearly performance gain is obtained comparing with that of dominant class labeling. \\n\\n++  The training scheme includes merged positive loss and prototypical pixel loss, both of which are well designed loss functions. Both are insightful from my perspective. \\n\\n   ',\n",
       "  'weaknesses': '\\n--  It would be interesting to see how the two hyperparameters in Eq. (10) affect the performance. \\n\\n--  It would be better if the number of clicks in Fig.4 can start from 0 instead of 100k. Then we can study the extreme case where very limited number of clicks are provided. \\n'},\n",
       " 'review_64': {'summary': 'This paper presents the concept of H-duality, which refers to the duality between optimization algorithms. The notion involves two sets of algorithms: 1) those that efficiently reduce the function value, and 2) those that efficiently reduce the gradient magnitude. The authors create the H matrix, which contains the coefficients of previous gradient evaluations at time step t, for all fixed step size first-order methods. They define the anti-transpose of H, denoted as H^A, as the H-dual of H.\\n\\nIn the main theorem, the authors demonstrate that if there exists an algorithm that reduces the function value using matrix H, then there is another algorithm that minimizes the gradient magnitude using H^A. This duality property is applicable to both discrete time and continuous time first-order optimization algorithms.\\n\\nLeveraging this duality property for composite objectives, the authors utilize a proximal-based first-order method that minimizes the function value. Subsequently, they propose a novel algorithm that minimizes the gradient value.',\n",
       "  'strengths': 'The introduction of duality between algorithms is a concept presented to the optimization community. This idea not only aids in establishing equivalence between algorithms but also proves valuable in conducting convergence analysis for these algorithms.',\n",
       "  'weaknesses': 'The proposed duality, while introducing a novel perspective, has certain limitations as it does not encompass a broader class of algorithms and loss functions commonly used in machine learning. For instance, it requires the convergence of the last iterate and overlooks convergence based on average iterates. Additionally, it assumes the objective to be convex and L-smooth, which may not always hold in practical Machine Learning scenarios. As a result, the paper primarily pertains to optimization theory rather than providing specific optimization techniques tailored to machine learning applications, especially for stochastic algorithms frequently used in this field.\\n\\nThe paper lacks a clear explanation of how discovering this equivalence between algorithms can facilitate the development of better optimization techniques. For instance, in cases where the objective is convex and the gradient vanishes (\\\\nabla f* = 0), it is evident that achieving convergence based on function values can easily translate to convergence based on gradient magnitudes.\\n\\nAnother aspect that remains unclear in the paper is whether algorithms that are H-dual to each other exhibit similar convergence rates. For instance, in the gradient descent (GD) example, it is observed that the gradient norm can attain a rate of O(1/N^2) under certain conditions. Consequently, it is ambiguous whether two dual algorithms have identical convergence rates or if one may achieve a better rate. In the former case, it becomes necessary to conduct separate convergence analyses for each algorithm to account for potential differences in their rates.'},\n",
       " 'review_65': {'summary': 'This paper shows an intriguing symmetry in convex optimization between first-order methods that efficiently minimizes the function value and those that efficiently minimizes the squared gradient norm. In particular, they show that if a specific Lyapunov function upper bounds the function value suboptimality for Algorithm A, then a corresponding Lyapunov function would upper bound the squared gradient norm for Algorithm B, which is the \"dual\" of Algorithm A. This duality relation is further extended to continuous-time dynamics. By using this new tool, the authors propose a new parameterized family of methods for reducing the squared gradient norm, as well as a new composite minimization method that improves the state-of-the-art by a constant factor. ',\n",
       "  'strengths': '- I find the results in this paper interesting and novel. At the surface, accelerated methods for reducing the function value seem quite distinct from those for reducing the gradient norm, and the mechanism for the latter is somehow mysterious. Surprisingly, the authors uncover a one-to-one correspondence between these two families of algorithms. This new concept of H-duality could help us better understand OGM-G type algorithms and design better and practical ones for minimizing the gradient norm. \\n- Moreover, the paper is very well-written. While the underlying proofs require heavy notations and tedious calculations, the authors manage to make the main theorems quite accessible and clearly explain the high-level ideas. ',\n",
       "  'weaknesses': \"Overall, I don't find any major issues with this paper. While this might be too much to ask, I feel that I still don't have a good intuition for H-duality theorem or why it makes sense to reverse the combining coefficients, except that the algebra indicates so. Still, I believe this could be the first step towards some more fundamental understanding.  \"},\n",
       " 'review_66': {'summary': 'This paper studies the duality for optimization algorithms. As claimed by the authors, the notion they present is distinct form any previously known duality or symmetry relations. In this work, the authors present a one-to-one correspondence between methods efficiently minimizing function values and methods efficiently minimizing gradient magnitude, which is called H-duality. Using H-duality, a clearer understanding of the symmetry between FGM/OGM and OGM-G and a new class of methods efficiently reducing gradient magnitudes can be obtained. The authors claim that their new composite minimization method achieve better results than state-of-the-art methods in efficiently reducing gradient magnitude in the composite minimization setup.',\n",
       "  'strengths': '1. This paper presents a novel notion of duality.\\n2. The theory of H-duality seems to be sound.\\n',\n",
       "  'weaknesses': '1. The relevance to NeurIPS is a concern. Actually, this paper studies the duality for optimization algorithms, which is an important problem in Optimization and Control. I am not sure whether NeurIPS is the right place.\\n2. In the Section 4 “New method efficiently reducing gradient mapping norm: (SFG)”, the authors claim that their method (SFG) is faster than FISTA-G by a constant factor of 5.28 while having substantially simpler coefficients. In the paper which presented FISTA-G, two graph were given to describe different methods’ effectiveness on reducing the gradient magnitude. But the result of experiments can’t be found in the paper, which make the comparison between SFG and FISTA-G is lack of persuasiveness. Could you add the result of experiments to describe the comparison between SFG and FISTA-G?\\n'},\n",
       " 'review_67': {'summary': 'This work defines H-duality, which is a one-to-one correspondence between methods that minimize function values and methods that minimize gradient magnitudes, under the assumption that the objective function is convex and $L$-smooth. It is proved in both discrete and continuous time dynamics that, when one method satisfies a convergence condition, the convergence of its H-duality correspondence can also be guaranteed. Furthermore, a new class of methods is derived by applying H-duality to a known class of FSFOMs, and the H-duality convergence theorem can be used to establish the convergence of the new methods.',\n",
       "  'strengths': '1. To the best of my knowledge, the concept of H-duality proposed in this work is novel, and the theorems which establish the equivalence between convergence conditions of two algorithms and their H-duality are also novel.\\n\\n2. This work demonstrates that the proposed H-duality can be useful, by using it to establish a symmetry property between pairs of methods, to prove the convergence of them, and to derive new methods.\\n\\n3. The paper is in general well written, and the sketch of proof helps readers more easily understand the techniques in the proof. ',\n",
       "  'weaknesses': '1. It should be noted that this work only applies to $L$-smooth and convex objective functions, and the value of $L$ is required be known as a prior, since it is used in the methods.\\n\\n2. If I understand correctly, the number of iterations $N$ is fixed in advance, which could also limit the applicability of this work. (details in question 1)'},\n",
       " 'review_68': {'summary': 'This paper introduces novel notion of H-duality, which shows unexpected connection between time-reversed coefficients of methods and optimality w.r.t. gradient norm or function value.',\n",
       "  'strengths': 'Very inspiring work, introduced notion is quite curious. I think that such an idea will be interesting to most of readers. The contribution of this paper is primarily theoretical which could make it \"intermediate\" for those readers who work in practical field of ML, but I believe that introduced notions can help theorists to develop the theory of optimisation taking into account more important details, which will impact on practice in the end. Especially such abstract works can affect theory the most, if the introduced notion is really helpful and fundamental, which can be confirmed only by the time, but I see it necessary to present such ideas to community to \"test\" them. Idea seems to be novel: my experience doesn\\'t tell me attempts to introduced such a parallels in methods constructions in terms of duality notion.',\n",
       "  'weaknesses': 'I do not see significant weaknesses. Proof presented in the paper are correct, but assumption are expressful enough to make proofs simple in cases where they are satisfied. In the best case, more detailed development of these concepts should lead to simplification and weakening of assumptions by showing from when do they arise in many cases.'},\n",
       " 'review_69': {'summary': 'This paper presents novel symmetry-breaking constraints for optimizing trained graph neural networks (GNNs) and addresses the graph isomorphism issue. The authors develop two mixed-integer optimization formulations and evaluate their methods in the context of molecular design. ',\n",
       "  'strengths': \"1. **Relevance and Application**: The paper addresses the important issue of GNN optimization and demonstrates practical utility through molecular design application.\\n\\n2. **Empirical Evidence**: The authors provide convincing experimental results supporting their claims, underscoring the proposed method's effectiveness.\\n\\n3. **Clarity**: The manuscript is well-written, presenting complex ideas with notable clarity.\\n\",\n",
       "  'weaknesses': '1. **Insufficient exploration of S1 and S3 compatibility**: The paper falls short in exploring whether S1 and S3 requirements can coexist for certain indexings of a connected graph with features.  \\n\\n2. **Insufficient explanation of structure feasibility constraints**: There is a lack of clarity concerning the interplay between structure feasibility constraints C1 - C21 and the indexing process. Specifically, the paper does not elucidate the number of these constraints that are related to indexing and if they are compatible with S3.  \\n'},\n",
       " 'review_70': {'summary': 'This paper suggests using a symmetry breaking indexing for nodes in a graph. The argument is that for inverse problems, such as molecule design, graph isomorphism results in finding many equivalent solutions. The symmetry breaking indices are supposed to partially alleviate this redundancy. They use pre-trained GNN (based on GraphSage) for computer-aided molecule design (CAMD). During the design, they use Mixed-Integer Programming (MIP) (solved using Gurobi) to solve a set of constraints to make the molecules chemically realistic as well as constraints arising from their indexing scheme. \\n\\nThey conduct experiments on QM7 and QM9 and find that the symmetry breaking methods perform much better. They show more successful runs (i.e. producing molecules satisfying the constraints) and achieve this in a fraction of the time, compared to models without symmetry breaking. ',\n",
       "  'strengths': 'The paper makes a good case for how adding an ordering (indexing nodes in a specific manner) can dramatically improve inverse problems on graphs, e.g. designing molecules, solved using MIP. \\nThe paper is well structured and discusses the literature in good depth. It explains the algorithm and experimental setup. The results are also very strong for the experiments.  ',\n",
       "  'weaknesses': 'The experiments show that with the indexing, MIP converges much faster. Table 1 states that MIP find many feasible solutions for each setting and set of constraints. One thing I hope the authors can assess (maybe using a Weisfeiler-Lehman hash or similar; see questions below) is how much the symmetry breaking *actually* removes isomorphic solutions, compared to the runs without symmetry breaking. they could do it for a small setting, maybe QM9, N=3 or 4. The goal would be two fold: \\n1. To show that the symmetry breaking indeed removed many isomorphic molecules\\n2. to check how the diversity of solutions in the symmetry broken case compares with the diversity of molecule found in the vanilla algorithm. \\n\\nI was also hoping some kind of baseline could be discussed, but I understand that to have a fair comparison they need to use the same pretrained GNNs with and without symmetry breaking.  \\n\\nAlso, the claims about generality of the approach and applicability to other graph problems, though reasonable, lack any substantive evidence or hint as to how to do it concretely. I suggest wither softening the claims or giving some hints as to why that is. \\n\\nIn terms of structure, I think the proof of theorem 1 is not necessary to be in the main text and occupies too much space. Instead some version of the last two tables in the appendix could be more useful in the main text. '},\n",
       " 'review_71': {'summary': 'This paper investigates the optimization of trained GNNs. This is a permutation-invariant problem and all points on an orbit of the symmetric group have the same performance. The authors proposed some symmetry-breaking approaches to have smaller search space and hence less redundancy and more efficient optimization. The correctness is proved theoretically and the efficiency is examined numerically.',\n",
       "  'strengths': '1. Optimizing a trained GNN is an important topic in practice and breaking symmetry can reduce the redundancy in many optimization problems.\\n2. The authors provide the theoretical guarantee of the proposed algorithm.\\n3. The numerical results look nice. It is reasonable to expect such improvement since the MIP formulation does have large symmetry group.',\n",
       "  'weaknesses': '1. I do not think this paper has enough literature review on detecting and breaking MIP symmetry -- how do previous work detect symmetry? what is the cost for symmetry detection? what is the connection/difference between previous symmetry-breaking approaches and the proposed approach? I think Gurobi can detect symmetry but the computational cost might depend on the size of the symmetry group. For optimizing GNNs, the symmetry group is obvious (just the permutation group). So one does not need to detect the symmetry and can design problem-specific symmetry-breaking approaches. Those ideas/background should be discussed more in the paper.\\n2. As the authors discuss in Section 4, the numerical experiments are not general enough, but I think the current experiments have already shown that the approach is promising.'},\n",
       " 'review_72': {'summary': 'To overcome the symmetry issue when solving inverse problems on trained GNNs, this paper proposes two types of symmetry-breaking constraints to break symmetry. The authors construct an indexing algorithm, and prove that the resulting graph indexing satisfies the proposed symmetry-breaking constraints.  They also develop two mixed-integer optimization formulations in the case where the input\\ngraph is not fixed. ',\n",
       "  'strengths': '1. The symmetry issue which this paper aims to overcome is important, and the proposed indexing is a general approach that applies in many kinds of situations. \\n2. The theoretical analysis is solid, and the proof seems to be correct. ',\n",
       "  'weaknesses': '1. The experiments are not persuasive enough. The reasons are as follows. \\n\\n(1) For Sec 3.1 (Mixed-integer optimization formulation for molecular design): In my opinion, a formulation itself WITHOUT experimental verification should not be thought of as a contribution. \\n\\n(2) For Sec 3.2 (Counting feasible structures: performance of symmetry breaking): The experimental results (Table 1) do not have baselines. \\n\\n2. There is no related work analysis (except a little description in Introduction). That makes it a little hard to justify the originality. For example, “The second formulation generalizes the big-M formulation for GraphSAGE in [70]” (L197). However, the authors did not explain how the big-M formulation looks like, in which way the proposed formulation generalizes it, and are there overlaps between the constraints of the big-M formulation and the proposed ones?'},\n",
       " 'review_73': {'summary': 'This paper addresses the\\xa0bilevel optimization\\xa0problem, which may feature a non-convex lower-level problem with non-unique optimal function values. The\\xa0lower-level problem\\xa0can be transformed into a\\xa0constraint optimization problem\\xa0using\\xa0function value\\xa0or gradient-based constraints. The paper establishes necessary conditions via calmness to evaluate the optimality of\\xa0bilevel optimization problems\\xa0where the\\xa0inner problem\\xa0satisfies the\\xa0PL condition. Based on these conditions, the authors develop the GALET method, which alternately updates the inner and outer variables. The effectiveness of GALET is demonstrated through an experiment involving hyper-data cleaning, which shows that GALET performs comparably to V-PBGD.',\n",
       "  'strengths': 'The main strength of this paper is the proposal of a stationary metric to evaluate the optimality of BLO problems with non-convex lower-level problems. This metric enables to achieve optimal iteration complexity.',\n",
       "  'weaknesses': 'Overall, I have the following concerns and comments about this paper:\\n1.  While formulation (2) is directly equivalent to BLO problem (1), the equivalence of the gradient-based formulation (3) only holds under PL conditions. As a result, it is unclear whether the proposed stationary condition is applicable in cases where the inner function of BLO does not satisfy the PL condition. Do you think it is feasible to extend the proposed stationary condition to the more general non-convex setting?\\n\\n2. As checked, it appears that the values of $\\\\beta$, $N$ $\\\\alpha$, and $\\\\eta_1$  are closely related in the analysis. However, in Theorem 2 and Lemma 4,  the authors merely simplify these parameters to the order of $\\\\mathcal{O}(1)$. As a result, the theoretical results do not elucidate the relationship between these parameters. It would be helpful if the authors could provide more details on how these parameters are related to each other in the main results.\\n\\n3. Figure 1 shows the stationary score of function value-based and gradient-based formulations (2) and (3) under different initializations. It is unclear which algorithm is adopted to solve the function value-based problems. It may affect the value of the KKT measure over iteration. Could you provide more information regarding the details of this result?\\n\\n4.  The main results presented by the authors focus solely on iteration complexity and do not provide information on the gradient oracle complexity or Hessian-vector complexity. Could you provide the complexity of the gradient and Hessian vector? It would be beneficial to include information on how these complexities depend on various Lipschitz constants and the PL constant $\\\\mu_g$. In addition, the strongly convex function is a special example of the PL function. It would be helpful to compare the results of GALET for strongly convex inner functions to those in the existing literature.\\n\\n5. The proposed method, GALET, is a second-order method, while the V-PBGD method is a fully first-order method. The authors have claimed complexity improvements over V-PBGD. But, from the numerical experiments, I did not observe any advantages over the first-order V-PBGD method, as expected.  It raised the question of whether the second-order information helped in your experiments. It would be helpful if you could provide additional evidence to clarify the performance of the experiments. '},\n",
       " 'review_74': {'summary': 'The paper studies unconstrained bilevel optimization under the PL condition at the lower level. All previous work is limited to strongly-convex lower-level problems. The authors propose a new convergence criterion for this setting based on stationary-point seeking reformulation, supporting it with the calmness and constraint-qualification arguments. The algorithm is a slight variant of recent Hessian-inverse-free methods for strongly-convex lower-level cases. Convergence analysis is performed with standard smoothness assumptions in deterministic settings (with access to true gradients and Hessians). The algorithm is demonstrated via the MNIST data-hyperclearning experiment.',\n",
       "  'strengths': \"The paper extends the existing literature to problems with PL lower level. Bilevel optimization is a fast-moving area, and this extension is a timely contribution to the literature. I haven't seen yet the PL condition considered in the context of Bilevel optimization (even though it appeared several times in min-max literature, and the underlying idea is not quite different). \\n\\n- The convergence criterion is well-supported by calmness and constraint-qualification arguments. \\n\\n- Presentation is clear and easy to follow.\",\n",
       "  'weaknesses': 'Overall, the algorithmic idea is essentially the same as previously developed algorithms. \\n\\n- For instance, the work in [11] considered the same algorithm with strongly-convex lower-level objectives, to avoid Hessian-inverse estimation. The idea is essentially to solve a linear equation efficiently, which can be done in various ways (e.g., by running the GD on a quadratic function). This work does the same, the only difference is to force the initializer $w_0$ to be at 0, so that GD converges to the minimum-norm solution (the pseudo-inverse solution). However, the same argument does not seem to be applicable to SGD or non-zero initialization. Furthermore, this seems why Assumption 2 is required: lower-bound for non-zero singular values for all $y$. Given that the lower-level objective is already $\\\\mu$-PL, another assumption seems redundant. \\n\\n- The paper only considers deterministic cases, but most previous work can also handle stochastic gradients and Hessian oracles. Though this paper seems to be hard to be extended to stochastic analysis. \\n\\n- I think there are several technical issues that need more justification. Please see the questions below.'},\n",
       " 'review_75': {'summary': 'This work studies an important problem of bilevel optimization with non-convex lower level function. The authors reformulate the problem as a constraint optimization and prove a constraint qualification (CQ) for the reformulated problem under mild assumptions, and show that other stronger CQ do not hold under the same assumptions. Next, authors introduce the stationarity measure for this problem and propose an algorithm which converges in this measure with minimax optimal rate under the given assumptions. Numerical simulations on synthetic and real data are provided to test the proposed algorithm and compare to other baselines.',\n",
       "  'strengths': 'The paper is well written and easy to follow. The limitations of previous works are well explained and the goal of the paper is clearly stated. The key contribution of the paper is substantially relaxing the assumptions and proving improved iteration complexity for bilevel problems, which matches with the optimal complexity (even for single level problems) in terms of $\\\\epsilon$.',\n",
       "  'weaknesses': \"1. The mathematical clarity of some statements in the main part can be certainly improved. For instance, in Definition 2 (calmness) it is unclear to me if h(x, y) is a function or a map to $\\\\mathbb R^d$, is $q$ a vector or a scalar? I also assume that the statement should hold for any pair (x', y'), not only for one. Although one can eventually infer the answers to these questions from the proofs in the appendix, it is better to be more rigorous. \\n\\n2. In Figure 2, I do not understand what is the difference between the blue and the red boxes (Gradient-based PL-BLO reformulation). \\n\\n3. I suggest to remove the right plot from Figure 5. It does not really make sense to compare the actual convergence rate with the asymptotic theoretical sublunar rate. How the exact constant was chosen? Why GALET is actually faster than theoretically proven 1/K. \\n\\n4. The intuition for convergence of terms $\\\\mathcal R_x$ and $\\\\mathcal R_y$ are well explained before stating Theorem 2. However, why $\\\\mathcal R_w$ converges is not immediately unclear from (20). I suggest to clarify this in the revision.\"},\n",
       " 'review_76': {'summary': 'This paper proposed a generalized alternating method for nonconvex bilevel optimization with PL condition in lower level. Meanwhile, it provided convergence analysis for the proposed method under a new stationary metric. Some experimental results demonstrate efficiency of the proposed method.',\n",
       "  'strengths': 'This paper proposed a generalized alternating method for nonconvex bilevel optimization with PL condition in lower level. Meanwhile, it provided convergence analysis for the proposed method under a new stationary metric. Some experimental results demonstrate efficiency of the proposed method.',\n",
       "  'weaknesses': 'In the paper, some incomprehensible words make it difficult for me to judge whether the conclusion in the paper is correct ? \\n\\nFor example, clearly, the lines 276-277 of the paper (‘’ Note that $\\\\lambda_g>0$ allows $\\\\nabla^2_{yy}g(x,y)$ to have either negative eigenvalues or zero eigenvalues … .’’) are not incorrect. \\n\\nFrom Table 1, the authors said BOME [33] and MGBiO [24] only studied a singleton on $S(x)$. From [33] and [24], they studied the bilevel optimization problem:\\n\\n$$  \\\\min_{x\\\\in \\\\mathbb{R}^{d_x}} f(x,y^*), \\\\quad s.t., \\\\quad y^* \\\\in \\\\arg\\\\min_{y\\\\in \\\\mathbb{R}^{d_y}} g(x,y),$$\\n\\nwhich equals the bilevel problem (1) given in this paper. Thus, I think the BOME [33] and MGBiO [24] also studied non-singleton on $S(x)$.\\n\\nForm this paper, the authors point that they introduce and use a new stationary metric in convergence analysis. It is better? Please detail differences between it and other metrics used in [48,33,24,2,38].'},\n",
       " 'review_77': {'summary': 'This paper aims to study the problem of fairness-aware influence maximization over a community structure under a welfare fairness notion that balances fairness level and influence spread using an exponentially-weighted sum over communities objective with an fractional exponent parameter α expressing inequality aversion. Given an unbiased estimator for the fractional powers from [27], a reverse-influence-sampling approach, adapted from previous works, is applied to the problem that turns the problem into a weighted maximum coverage problem. The number of reverse reachable (RR) samples needed to achieve a good approximation and an algorithm is given that achieves a 1 − 1/e − ε approximation.',\n",
       "  'strengths': 'S1. Revisiting an important problem with an aim to efficiency.\\nS2. Lucrative application of reverse influence sampling approach.\\nS3. Approximation guarantees.',\n",
       "  'weaknesses': 'W1. Limited novelty with respect to previous work in [7].\\nW2. Lack of discussion of the most basic problem case of full fairness.\\nW3. Lack of discussion of and comparison to most recent related work.'},\n",
       " 'review_78': {'summary': 'The authors study a variant of the popular influence maximization problem\\nthat incorporates fairness constraints. Given a partition of the node set\\nof the graph into communities, the goal is to select seeds subject to\\nbudget constraints that maximizes influence as well as reduces the\\ninfluence gap between communities. The authors consider a particular notion\\nof fairness called welfare fairness, where a single parameterized objective\\nfunction can be used to achieve the desired balance between maximizing\\ninfluence and maintaining fairness. The objective function is monotone\\nsubmodular, and therefore, the greedy algorithm guarantees a constant\\napproximation factor as in the case of the traditional influence\\nmaximization problem. Since the greedy algorithm is not scalable to large\\nnetworks, this paper focuses on developing an efficient algorithm using the\\nreverse influence sampling (RIS) approach. The main contributions are an\\nunbiased estimator for the fractional power of the arithmetic mean using\\nTaylor expansion, solving a main hurdle for using RIS approach for welfare\\nfairness objective function, and an analysis of the greedy algorithm based\\non the RIS approach. Experiments are carried out on five social networks to\\nstudy the trade-off between fairness and influence spread.',\n",
       "  'strengths': 'The paper addresses an important topic of scalability in influence\\nmaximization with fairness. The unbiased estimator for the fractional power\\nof the arithmetic mean is a significant contribution of this paper, which\\ncould be applicable to other problems as well. The paper addresses\\nimportant computational and approximation related aspects.\\n\\nThe paper is generally well written.',\n",
       "  'weaknesses': 'The importance of/need for the unbiased estimator is not discussed.\\nFirstly, in Section 3.1, it is pointed out that (\\\\hat{u}_c)^\\\\alpha is a\\nbiased estimator of u_c^\\\\alpha. Suppose we were to use it, how bad would\\nthe outcome be? \\n\\nA second related issue is that the paper does not comment on the complexity\\nof computing the unbiased estimate. When the number of RR sets is large,\\nupdating according to equation (5) can be compute intensive (Algorithm 2\\nline 11).\\n\\nAlso, some approximation of equation (5) must be involved as the summation\\nover n goes from 1 to infinity. The authors do not seem to discuss about\\nthe truncation of the Taylor series and its effect on the accuracy.\\n\\nIn Theorem 1, the role of \\\\epsilon is not clear. It does not seem to\\nfeature in the probability expression or have anything to do with the size\\nof the RR set. In Lemma 4, it is mentioned, but again, its role is not at\\nclear.\\n\\nExperiments section could be much stronger: Considering that the key problem\\naddressed by the paper is scalability, the experiments section does\\nnot provide any analysis of the computation time of the algorithm and how\\nit scales with the size of the networks. It also does not provide any\\nanalysis regarding how truncation of higher order terms in the Taylor\\nseries affect the performance. Thirdly, there is no analysis of how it\\nscales with the size of the RR set. \\n\\nMinor comments:\\nLine 82: \"However, these notions can hardly ...\" It would be better if this\\nsentence was supported by references.\\n\\nLine 197: that covered ... -> that are covered ...\\n\\nLine 219: then it holds ... -> then the following holds: ...\\n\\nLine 231: ... holds at least ... -> holds with probability at least ...'},\n",
       " 'review_79': {'summary': 'The authors apply fairness to the influence maximization problem (IM). On a social network, IM models which node subset should be used to trigger the spread of information to maximize its effects. A motivating application is the selection of leaders for natural disaster preparedness, where in existing methods, minority leaders are disproportionately underrepresented. They are not the first to do this, however they are the first to introduce efficient algorithms for solving IM with welfare fairness, which allows the user to parametrize an objection on sliding scale between total fairness and no fairness at all (i.e., maximum influence spread).\\n\\nThey work in the Independent Cascade model of influence spreading, where each node has a given probability of influencing an adjacent node, and influence is randomly spread according to these probabilities across a number of timesteps. The influence spread, i.e. the objective, is the number of influenced nodes when the process converges. By submodularity, the unfair problem can be solved greedily to a (1-1/e) approximation factor. They assume the given graph is separated into a small number of communities to apply their fairness notion to. While this also admits a greedy approach via Monte Carlo methods, it requires too long to run. \\n\\nTheir main contribution is a (1-1/e-epsilon) approximate and efficient solution to IM under welfare fairness. En route, they provide an unbiased estimator of the fair objective under a number of random seeds for which edges spread influence when. This is harder than the vanilla problem because the objective is raised to a power alpha in [0,1] as opposed to just 1. They show how to use a Taylor series to provide an unbiased estimator. This is used to then compute the marginal expected gain in influence of adding a vertex to their set and thus greedily select the best one.\\n\\nThey also experimentally validate their results on five different, semi-synthetic data (e.g., for their Flixster data, they had to construct community information). They show that the price of fairness and effect of fairness both decrease as the alpha parameter increases, which makes sense since that decreases the fairness impact on the objective. They also show that adding more influence budget generally decreases the price and effect of fairness.',\n",
       "  'strengths': 'To my knowledge, the theoretical results of this paper are substantial and original. It’s always interesting and practical to see how notions of fairness apply to different problems. They are the first to efficiently solve IM under welfare fairness, and their proposal of an unbiased estimator for the marginal influence spread of a vertex seems notable, though I am not particularly familiar with influence literature (e.g., it is possible these methods are pretty standard for influence spreading strategies). From my standpoint, it is a nice result with a solid place in fairness literature.',\n",
       "  'weaknesses': 'While I think the paper is reasonably clear, it can be quite dense at times with its heavy use of notation. I found it particularly hard to follow in Section 3.4, when they pretty much state two lemmas and a theorem, deferring most proofs to the appendix. I think it’s better to explain these things at a high level more and defer formal statements to the end. It was hard to make much of it. In general, I would prefer the paper to undergo more edits for clarity, particularly in Section 3.4, before publication.\\n'},\n",
       " 'review_80': {'summary': 'The paper proposes an algorithm for fair influence maximization. The objective is defined as a sum of powers of a utility function for each cluster, indicating that each cluster should receive some influence. Reducing the exponent will bring the objective to a fairer distribution of influence. An algorithm based on max cover on reverse reachable sets is presented. Optimal number of sets are derived to guarantee $(1-1/e - \\\\epsilon)$-approximation',\n",
       "  'strengths': '- The key idea to convert the powers into sums using the binomial theorem is elegant, as it helps with modifying the existing algorithm on influence maximization for the proposed objective.\\n- Detailed derivations are presented.',\n",
       "  'weaknesses': '- Baselines: While the theoretical guarantee is the key contribution, the experiment part of the paper can be strengthened. How much do we gain from this algorithm compared to some simple heuristics? One may consider simple heuristics like degree. Better heuristics may also be generated, e.g., (1) picking high-degree nodes from each cluster, and (2) using the RR sets in Algorithm 1 but performing max-cover without Eq (5) [maybe similar to performing Influence Maximization independently in each cluster]\\n\\n- The derivation assumes that a fair solution exists, in the form of $b = \\\\max \\\\mathbf{u_c} (S^{\\\\\\\\#})$. The usage of this appears in the proofs, but some indication of how this would impact the main results could be discussed. \\n\\n- The symbol $n$ is overloaded. It is used as an index for the summation as well as the number of nodes. I think the paper will benefit from a table of symbols.\\n'},\n",
       " 'review_81': {'summary': 'This paper aims to study how developmental changes impact visual learning. It used infant egocentric videos to pre-train video autoencoders with self-supervised learning loss. It separated the infant data by age group and evaluated the importance of training with a curriculum aligned with developmental order.',\n",
       "  'strengths': 'The study goal of this paper is interesting. Few has studied the developmental changes in infant visual experience and characterize how those changes impact visual development.',\n",
       "  'weaknesses': '1) The contribution of this paper is limited. The datasets are collected from existing datasets. Only single existing video autoencoder model is used and evaluated. While the goal of the paper is interesting, it is not conducted in a professional way.\\n2) The writing and organization of the paper need much improvement. It is not easy to follow the content of the paper.'},\n",
       " 'review_82': {'summary': 'The work is essentially about an experimental evaluation to show the benefit of curriculum learning using ego-centric videos acquired with from head-mounted cameras and very young children. The authors discuss the use of self-supervised learning on the data ordered according to developmental principles and empirically show the improvement that can be observed on down-stream tasks and benchmark datasets.',\n",
       "  'strengths': 'I find the idea of coupling a developmental approach with curriculum learning very fascinating, and deserving attention. \\nThe main motivations behind the developmental paradigm that inspired the approach are clearly reported.',\n",
       "  'weaknesses': 'I have some main concerns about the clarity of the presentation and the contributions that make me think the work is not yet ready for publication at this conference:\\n\\n- On the motivations behind the developmental approach: I find it fascinating, but somehow in contrast with the use of large data sets and complex architectures. On one side there are children with their visual, cognitive and motor abilities under development, on the other these very complex architectures. For the latter, I think a more convincing justification should be provided on why those have been used. \\n\\n- While the overall inspiration and philosophy of the work are clear (although sometimes maybe not immediately clear for those with no particular knowledge of Cognitive Science) in general, I found a lack in the justifications of the more technical choices. Just as a possible example: from row 157 to row 165, more details in the questions.\\n\\n- Since the main objective was to show the benefit of the developmental approach, my impression is that the limitation correctly highlighted by the authors of having considered just one architecture is too important to be disregarded. In my opinion, showing that the principles observed in these experiments emerge also when changing the architecture is fundamental to speak in favour of the generality of the results'},\n",
       " 'review_83': {'summary': 'The authors aim to explore whether the natural structures and regularities in infant visual experience acquired via video recording when infants wearing head-mounted cameras can facilitate pre-training self-supervised learning representation learners. The authors divide the infant data into 3 groups (according age group) and evaluate the importance of training with a curriculum aligned with developmental order. The other 3 curriculums are designed for comparisons. The experimental results prove the order of the curriculum matter via self-supervised learning tasks and downstream tasks.',\n",
       "  'strengths': '1. Overall the paper is well-written and is easy to understand the goal of the paper.\\n2. In the community, we all know that data is essential. However, we pay less attention to the order of curriculum that infants naturally created for training visual systems. The motivation of the paper is to explore whether the order of the curriculum is essential for visual systems. The authors leverage data curated from a larger corpus of 500 hours of head camera videos collected by infants from 2 to 24 months of age for experiments. They propose a clear experimental protocol and training curriculums for comparisons. In the experiments, they show deep neural networks (i.e., VideoMAE) trained on developmentally-ordered datasets outperformed those trained on “developmentally incorrect” datasets. The discovery of the experiments is valuable to the machine learning community to revisit our training dataset and learning curriculums.\\n3. The pre-trained models are finetuned for downstream tasks. Again, the results show a consistent trend that those trained on developmentally-ordered datasets outperformed those trained on “developmentally incorrect” datasets. This indicates that the order in which humans generate data for learning may therefore be an important contributor to achieving adult-like visual processing. This again provides the community to rethink our training protocols.\\n4. The reviewer particularly enjoys reading section 5.3. Specifically, the authors propose a methodology to probe the learned visual features using the developmentally-ordered datasets to provide a “peak” of infants’ receptive field. The findings could provide a new tool for developmental psychology researchers to design new experiments to validate the effectiveness of the methodology.',\n",
       "  'weaknesses': 'Overall, the reviewer enjoys reading the manuscript and learns a ton. I have the following questions, comments, and suggestions:\\n\\n1. In Sec. 5.3, the authors highlight that it takes 12 components of g0 to explain 95% of the variance; whereas, it takes 33 components for g2. Overall, the larger number for g2 makes sense. The reviewer is surprised by the difference. The reviewer would like to learn from the authors whether the ratio of the two “number of components” could be some indicator. Assuming there is one, the ratio could potentially be used to validate the effectiveness of the learning models. \\n\\n2. The main “concern” of the work is the paragraph in L287 to L300. Indeed, ViT has made tremendous progress in the vision community. The authors further utilize it on the developmentally-ordered dataset. However, as pointed out in the limitation section, there are other learning systems that could be explored. The reviewer is concerning the masking used in VideoMAE is the appropriate learner, while showing promising results in the work. In addition, the recent LLMs show promising results of autoregressive models (prediction of the next frame) compared to BERT-like approaches (filling masked areas). Moreover, self-attention is one of the important components. The reviewer brings these points to highlight the need to explore other existing learners so that we can provide a more thorough perspective to support the statements in L287 to L300.\\n\\n3. Implementation details, Training protocol: while the experimental results do empirically prove the order of curriculum is essential, I wonder how the authors determine the number of iterations. In the experiments, 5000 iterations are used. Does the varying number of iterations influence self-supervised pretraining? Does the varying number of iterations influence finetuning downstream tasks?'},\n",
       " 'review_84': {'summary': 'This paper studies the development of visual intelligence by providing a curriculum for self-supervised video representation learning. The curriculum is aligned with the age order of the infants whose egocentric video data are used as training samples. Experiment results demonstrate that training with data from the youngest infants, who have fewer motor abilities, leads to a faster decrease in both training and validation loss. Additionally, the proposed curriculum improves downstream task performances when evaluated using linear probing.',\n",
       "  'strengths': '- The use of curriculum learning guided video self-supervised learning to study infant visual experience is a novel and interesting idea.\\n- The natural alignment of the curriculum with the age order of infants, based on the egocentric videos recorded, is a commendable aspect of this work.\\n- The paper provides a detailed discussion of the contributions and limitations of the research.',\n",
       "  'weaknesses': '- Regarding the “slowness” of the video, there lacks a quantitative measurement of it, as well as corresponding experiments regarding the curriculum that is aligned with the slowness of the video rather than the age order.\\n\\n-  The iteration number 5000 might be not sufficient for models trained on videos with more dynamics to converge. While ablation studies on iteration numbers are presented in the supplementary material, it would be valuable to continue to increase the iteration number, and include a comparison with Random and Adult baselines for a more comprehensive analysis.\\n\\n- It is recommended to report the video retrieval performance after pre-training with different curricula to provide a more comprehensive evaluation.\\n\\n- In addition to masked image modeling, exploring contrastive learning-based self-supervised learning methods would enhance the scope of the study.\\n\\n- Some minor issues include missing section reference number in line 212.'},\n",
       " 'review_85': {'summary': 'This paper involves finding an inter-group similarity function with (limited) oracle advice when one has access to the intra-group metrics. The authors give theoretical guarantees about their algorithm and claim to have proven lower bounds on the performance of any algorithm.',\n",
       "  'strengths': 'I like this problem. The proposed problem is a nice contribution - but only if its solution improves on the more general learning of the whole metric (without knowledge of the intra-cluster similarities) in the case that the similarities are a metric (the fact that the assumptions of this paper are slightly less restricted than a metric is by itself not enough novelty in my opinion)\\n\\nThe experiments show this algorithm outperforms certain baselines (although similar works are not considered in the experiments).\\n\\nThe paper is well written from a language point of view.',\n",
       "  'weaknesses': 'I do not think that the algorithms themselves are innovative enough for a conference like NeurIPS.\\n\\nFrom Line 437 of the appendix it seems that the true definition of a rare element should be one whose probability that ALL of the N samples lie at distance more than epsilon away is greater than delta (not a single sample as is defined in the paper). Although the definition used doesn’t make Theorem 4.1 incorrect it means the bound is much weaker than it could be.\\n\\nThere seems to be something very wrong with Theorem 2.3…\\n- Firstly, If I limit \\\\delta to 1 then in most cases every element is (\\\\epsilon, \\\\delta) rare so that p_l(\\\\epsilon,delta)=1 and hence the theorem essentially states that with a finite number of samples it is impossible to achieve \\\\epsilon-accuracy with probability no more than \\\\epsilon. This is clearly incorrect.\\n- Secondly, if the instance space is finite then we can always choose a large enough (but still finite) number of samples such that w.h.p. every possible instance is sampled. If we apply the oracle to every pair we have, w.h.p. (a probability arbitrarily close to 1) found the exact similarity function. This contradicts the theorem.\\n\\nIt is not clear how other works compare to the result of this paper when it is a true metric space (since in this case the multiple distribution idea reduces to a single distribution problem). I do not think that handling the slightly more general non-metric case alone is sufficient for acceptance to a conference like NeurIPS.\\n\\nIn Line 287 the authors state that the metric algorithms cannot be used for non-metric. I suspect that they can still actually run but the bounds don’t necessarily hold (please correct me if I’m wrong). Since there is no theoretical comparison to the metric algorithms (when the similarity is a metric) I would have liked to see empirical comparisons to them in the case that it is a metric.\\n\\nA minor weakness is that in many applications you would be able to query instances without actually having sampled them.'},\n",
       " 'review_86': {'summary': 'This paper studies the problem of learning a similarity function of items generated from different distributions. Precisely, there are two groups of items, and the items in each group follow a specific distribution and the group has an intra-cluster metric. This paper wants to learn a cross-group metric from limited number of samples with fairness and PAC error guarantee. This problem is critical for creating fair comparisons of items in heterogeneous groups. \\nFurther, this paper provides upper bound and lower bound analysis on both i) error rates of algorithms with polynomial sample complexity; and ii) the sample complexity of a PAC (\\\\epsilon,\\\\delta) algorithm. From the analysis, I think the bounds on both error rates and sample complexity are reasonably good though still have rooms for improvements. \\nFinally, the authors present the numerical results on real-world data sets. The numerical results show out-performed performance of the proposed algorithms. \\n',\n",
       "  'strengths': \"Novelty: This paper studies an interesting, novel, and theoretical-fundamental problem. The algorithms are not very new, but already show good enough performance in this new problem, so it is okay. Overall, this paper is of high novelty. \\n\\nQuality: The paper has a high quality. The results are complete. It is not common to see well-established lower bound analysis, but this paper does it for both error rates and sample complexity. Also, the upper bounds and lower bounds are reasonably close, and the gaps between them are not very high, which is good enough for initial research. The paper also conducts nice numerical experiments on real-world data to confirm the theoretical conclusions, which strengthen this paper's quality.\\n\\nClarity: This paper is well written. It has a clear story-telling: it introduces the problems, explain the mathematical formulation, state the theoretical results, and present the proofs well. \\n\\nSignificance: In my personal opinion, this is a very important problem in terms of theory, as it is actually understanding the fundamental learnability of aggregating two or multiple metric spaces together. In terms of practice, I am not very confident, but the examples such as the student case given in the paper are convincing. Overall, the I think this paper is significant enough. \",\n",
       "  'weaknesses': 'No major weakness found. The paper is good overall. One minor question: How often would the real-world scenarios have non-complete metrics, as this is an improvement of this paper? '},\n",
       " 'review_87': {'summary': 'The paper is about a mechanism to compare elements  of a set that belong to two distinct distributions when two distinct sets of features for each distribution.   This is a natural problem that arises in many practical settings.  The paper presents the underlying problem and the formal framework with some guarantees assuming some 3rd database (oracle) has answers about comparability of any pair of elements.',\n",
       "  'strengths': \"\\nCompared to other papers I have to review for NeurIPS this year, the authors of this paper go out of their way to explain what they're trying to do and motivate the theoretical results they obtain.\\n\\nThe topic is a good one -- often the same data appear in different databases with different attributes and this paper provides a mechanism to construct a similarity function across different features *assuming* there is an oracle that can compare across different features.\\n\\n\",\n",
       "  'weaknesses': '\\n\\nThe basic idea of this paper is well explained and illustrated.  However, unlike much of the rest of the discussion in this paper, the \"no free lunch\" theorem is not explored in full.  A key question anyone would have is how rare or common is it for max { p_l, p_l\\' } is large and therefore the framework introduced in this paper is not applicable?  The authors could use the datasets they used for experimental results to shed some light on this question.  This is actually the 1st question anyone wishing to use this result would be asking themselves.'},\n",
       " 'review_88': {'summary': \"This work considers PAC-learnable algorithms for estimating a intra-group\\nsimilarity function where:\\n1. intra-group similarity functions are metrics and given in advance,\\n2. inter-group similarities satisfy a notion of the triangle inequality.\\nIt is assumed that points are always labeled by the group to which they belong.\\n\\nThe authors present two algorithms Naive and Cluster, and\\ngive PAC-learning guarantees for them (i.e., the sample complexity needed for\\nthe learned similarity function to be $\\\\varepsilon$-close to the true\\nsimilarity function with probability at least $\\\\delta$). The clustering\\nalgorithm uses a ``representative'' subset of each groups samples before\\nquerying inter-group similarities to reduce the query complexity. The authors\\ngive substantive experiments to empirically study their algorithms.\",\n",
       "  'strengths': '- The \"simple learning algorithm\" is indeed simple and clean with strong\\n  guarantees (Theorem 2.1).\\n- The idea of using $k$ centers from each group\\'s samples as representatives is\\n  a natural improvement over the simple algorithm.\\n- Very good experiments where the authors define a challenging similarity\\n  function to try to recover:\\n  * Creating two groups based on the \"married\" feature is an excellent instance\\n    of what the paper aims to study.\\n  * The benchmark algorithms MLP, RF, and XGB each see at least as many samples\\n    as the proposed algorithms, and are therefore fair (assuming they fully\\n    trained).',\n",
       "  'weaknesses': '- In section 2.1, you say you begin with a simple algorithm, but it is never\\n  described before Theorem 2.1. Consider giving a quick description to the\\n  reader before they take in the theorem statements.\\n- The presentation could be improved slightly: less motivation in the intro and\\n  more details in the main text (e.g., proof sketches).'},\n",
       " 'review_89': {'summary': \"The paper's outstanding qualities lie in its well-articulated presentation and its precise experimental design. It amalgamates the earlier research findings of [Zeng et al., 2021] and [Hızlı et al., 2022] with the innovative notions put forth by [Robins et al., 2022] on indirect effects. The authors tackle pragmatic issues, such as the effects of surgery on a patient's blood sugar levels in relation to their diet, by formulating pertinent questions. For instance, they question whether optimal post-surgery mediation can entirely regulate blood sugar levels, or if there exist uncontrollable surgery-induced effects on blood sugar levels that resist management through mediation and diet adjustments.\\n\\nIn their methodological approach, the authors utilize non-parametric models of the temporal data-generating process. They employ a Marked Point Process (MPP) akin to [Hızlı et al., 2022] for meal intake (the mediating factor) and a non-parametric Gaussian Process (GP) for the outcome. The former is modeled as a combination of a counting process (number of meals) and a dosage process (carb intake per meal) using a non-parametric Poisson Process and the latter as a Gaussian process. The mediator model is trained to predict the mediator based on the intervention and the outcome model is trained with both the mediator and intervention given as input. This approach is put to the test in a series of synthetic experiments, validating its predictive strength against baseline models like Zeng et al., 2021. They further apply it in a real-world setting, successfully reproducing biological insights and potentially addressing the question of the degree to which surgery impacts diet changes.\\n\\nWhile at first glance, this paper might seem to bear similarities to [Hızlı et al., 2022], it stands out through its adept combination of the best methods for examining direct and indirect cause-and-effect relationships in a temporal setting. The paper, with its organized code and clear writing style, has the potential to become a valuable asset. However, I'm leaning towards accepting this paper on the condition that certain concerns regarding its originality and novelty are addressed, which I will detail in the following.\",\n",
       "  'strengths': \"1. The paper is commendable for its realistic problem setup, which is articulated in Section 5.1 dealing with corner cases where the assumptions might falter: the existence of hidden confoundings and the violation of assumptions A.1 to A.3. Such validation is crucial in causal studies to confirm assumptions and identify any unnoticed confoundings that may influence our conclusions. Furthermore, the experiments and predictions are consistent with the clinically significant direct and indirect impacts of bariatric surgery on blood glucose levels.\\n2. The approach to modeling the temporal dynamic is robust, anchoring its foundation on recent, proven work that adds to its credibility.\\n3. The paper's eloquent presentation is worthy of note. The reading experience is enhanced by effective use of color-coding to differentiate between mediator and direct interventions. A minor suggestion would be to consider adaptations for grayscale printed versions of the paper. For instance, the caption of Figure (2) includes light and dark blue color coding, which could be made more distinguishable by slightly altering the arrow patterns.\",\n",
       "  'weaknesses': '1. The theoretical advancement of the study appears relatively marginal. While the exploration of direct vs. indirect causal effects in a temporal setting is engaging and the experiments provide valuable insights, I have some reservations about two of the claimed main contributions:\\n* Dynamic causal mediation with a point process mediator: [Hızlı et al., 2022] have previously introduced point process mediator modeling. The novelty here is questionable, given that in the prior work, the treatment was the mediator itself.\\n* A mediator-outcome model with an external intervention: The distinctiveness here is the training of two models: pre-intervention and post-intervention. However, the applied intervention is overly simplistic, offering limited theoretical innovation or insight. I have proposed, in the \"Questions\" section, the inclusion of the theory behind more complex interventions and experimentation on the simpler case. Yet, as it stands, this contribution mainly replicates the approach from [Hızlı et al., 2022], but uses two models to account for the intervention.\\n2. Table 1 presents results suggesting that the direct causal impact of surgery outweighs its indirect effects. Although the insights from 5.1.3 and 5.1.2 align with existing studies, there seems to be no supportive evidence for this hypothesis. Perhaps incorporating relevant literature explanations into the discussion would be beneficial. While the coherence between findings in 5.1.2 and 5.1.3 lend some validation to the model, it would still be advantageous to have literature support for 5.1.4.'},\n",
       " 'review_90': {'summary': 'The paper defines direct and indirect effects in complex healthcare time-series as dynamic stochastic processes and theoretically provides causal assumptions for identifiability. This model allows for an external intervention influencing both mediator and outcome sequences simultaneously and captures time-delayed interactions among them.',\n",
       "  'strengths': '1.\\tThe authors proficiently present the estimated direct and indirect effects as longitudinal counterfactual trajectories, along with the requisite theoretical causal assumptions for their identification.\\n2.\\tThe method proposed is neat and articulated with good clarity.',\n",
       "  'weaknesses': '1.\\tThe method\\'s scalability to larger datasets poses a concern. There exists many methods specifically designed for high-dimensional mediation analysis in time series [1][2][3]. It would be enlightening to observe how the proposed method compares to these in handling complex datasets.\\n2.\\tTo my understanding, Figure 1a may not accurately depict Zeng et al. 2021 [4]. It seems the original work allows for past mediators to have an influence on future outcomes.\\n\\nReferences\\n\\n[1] Chén, Oliver Y., et al. \"High-dimensional multivariate mediation with application to neuroimaging data.\" Biostatistics 19.2 (2018): 121-136.\\n\\n[2] Zhang, Haixiang, et al. \"Mediation analysis for survival data with high-dimensional mediators.\" Bioinformatics 37.21 (2021): 3815-3821.\\n\\n[3] Luo, Chengwen, et al. \"High-dimensional mediation analysis in survival models.\" PLoS computational biology 16.4 (2020): e1007768.\\n\\n[4] Zeng, Shuxi, et al. \"Causal mediation analysis for sparse and irregular longitudinal data.\" The Annals of Applied Statistics15.2 (2021): 747-767.'},\n",
       " 'review_91': {'summary': 'The paper aims to estimate the direct and indirect treatment effects of healthcare interventions. The authors model the mediator as a point process and propose a non-parametric mediator–outcome model where the mediator is assumed to be a temporal point process that interacts with the outcome process. The authors conduct experiments on a real-world RCT dataset and a semi-synthetic dataset. The experiments on the synthetic dataset show that the proposed model outperforms the baselines on the treatment effect estimation tasks.',\n",
       "  'strengths': '- The authors propose a new approach to model the direct and indirect effects of healthcare interventions.\\n- The authors conduct experiments on both real-world and semi-synthetic datasets. The results demonstrate that the proposed model outperforms the baselines.\\n- The implementation code is available.\\n',\n",
       "  'weaknesses': '- Treatment A, as the confounder, affects both mediator M and outcome Y. M affects Y. \\nThe confounding bias would make the estimation E[Y|A,M] inaccurate. Figure 5 shows the difference of diet density pre- and post-surgery, which demonstrates the existence of confounding bias. Without consideration of the confounders, the direct and indirect treatment effect estimation could be inaccurate.\\n- The authors claim that (A1, A2, A3) might not hold in observational studies and they are not statistically testable. I have the concern that if the assumptions do not hold, can the proposed model be applied to real-world applications? How to evaluate the potential risk of the model.\\n- A1，A2，A3 are very strong assumptions. In real-world settings, the no-unobserved confounder assumption may not hold, so it is necessary to conduct a sensitivity analysis of how sensitive or robust the proposed models are to the unobserved confounders. \\n- Bariatric surgery could cause weight loss. Another mediator weight would significantly change after the surgery.\\n- Some details are missing.  The authors just use diet and surgery to predict blood glucose. Is any detailed information about the diet, like nutrients including sugar, and starch? Are patients’ demographics (weights, age, height) used in the experiments? \\n- It would be better if the authors display the factual prediction performance, like MSE for glucose prediction.\\n- It is unclear what the variables m and o in Eq. (9) mean.\\n'},\n",
       " 'review_92': {'summary': 'This paper studies how to estimate the direct and indirect effctes of healthcare interventions. The general idea of this paper is to model the mediation process and outcome process jointly. More specifically, it considers the mediation process as a temporal point process conditioned on the past mediation, outcome and treatment data. It allows two causal paths: direct path models the direct effect of treatment and indirect path models the path treatment->mediation->outcome. The authors prove that under their three assumptions, the two effects can be represented by two terms in their non-paraametric temporal point process model. Experimental results shows the advantage of their proposed model.',\n",
       "  'strengths': '(1) The proposed model studies an interesting problem: how to distinguish indirect and direct effect, which is important in healthcare\\n\\n(2) The overall design of their causal model are reasonable. Althought their assumptions are not easy to verify on the data, they have tried their best to give convincing analysis to the data.\\n\\n(3) The motivation is clear and convincing.',\n",
       "  'weaknesses': '(1) Did you consider that in real world, the treatment may be correlated with the outcome, leading to bias in the model? Did you try to reduce the issue with IPTW or other method to debias?\\n\\n(2) Some recent related works about handling treatment effect and causal inference with non-parametric temporal point process model are missing. For example, [1] studies the treatment effect in healcare, too. [2] considers how to debias the neural temporal point process in the context of social media analysis. [3] studies how to sample the counterfactual sequences from temporal point process.\\n\\n[1] Gao, Tian, et al. Causal Inference for Event Pairs in Multivariate Point Processes. NeurIPS 2021\\n\\n[2] Zhang, Yizhou, et al. Counterfactual Neural Temporal Point Process for Estimating Causal Influence of Misinformation on Social Media. NeurIPS 2022.\\n\\n[3] Noorbakhsh, Kimia , and M. G. Rodriguez . Counterfactual Temporal Point Processes. NeurIPS 2022.'},\n",
       " 'review_93': {'summary': 'The paper presents a technique to build a decision tree (DT) that uses the predictions from any unsupervised anomaly detection algorithm to split at the nodes when constructing the DT. This is named as the Interior Clustering Tree. The DT will be used to extract interpretable rules.',\n",
       "  'strengths': '1. The approach is useful for explainable anomaly detection and is an important problem domain.',\n",
       "  'weaknesses': \"1. Very similar to [1]. The difference is that in [1] the density is based on KDE, whereas, in the present work the density is based on the anomaly detector. So the technical novelty is less.\\n\\n2. Section 5: Lack of clarity; the procedure should be presented as algorithmic steps.\\n\\n3. We need more than just two datasets for empirical validity. These datasets also seem 'easy' since detection accuracy is very high for all anomaly detection algorithms. With easy datasets, the rules extracted would tend to be short and nicely interpretable. On the other hand, with harder datasets, the rules might be much more complex and difficult to interpret. I am interested in the types of rules extracted for the harder datasets.\\n\\nReferences:\\n\\n[1] Sarah Itani, Fabian Lecron, Philippe Fortemps, A one-class classification decision tree based on kernel density estimation, Applied Soft Computing, Volume 91, 2020 (https://arxiv.org/abs/1805.05021)\"},\n",
       " 'review_94': {'summary': \"The authors propose and Distribution Decomposition Rules and Boundary\\nInference Rules to make black boxes more interpretable.\\n\\nThey use Interior Clustering Tree IC-tree to find distribution\\ndecomposition rules.  The IC-tree algorithm splits the data on a\\nfeature value at each node recursively.  The feature value that\\nmaximizes the gain in gini index before and after the split is chosen\\nat each node.  Gini index is 2p(1-), where p be is the average output\\nof the anomaly detection model f(x), which is the trained neural\\nnetwork model.  The path to each leaf forms a distribution\\ndecomposition rule and each leaf represents a data subset that is in\\nthe same distribution.\\n\\nThe Compositional Boundary Exploration (CBE) algorithm finds a minimal\\nhypercube that encloses the normal data in each distribution (leaf\\nnode).  CBE uniformly samples data points on each hyperplane as initial\\nexplores (centriods), then samples from a Gaussian distributions\\npoints as auxiliary explorers near the centroids within some radius.\\nThe samples are used to query the model to find samples with the\\nlowest probability to be normal (negative examples), these are called\\ncandidate explorers.  They use Fast Gradient Sign Method to perturb\\nthe explorers.  Since the loss function is not known from the model,\\nthey approximate the gradient by the gradient between the model\\noutputs of an initial explorer and an auxiliary explorer with respect\\nto the different in the samples.  The explores are perturbed until the\\nf() indicates it is normal (less than threshold phi).  The\\ncorresponding feature values forms the hyperplanes for the boundaries.\\n\\nThey evaluate 5 existing extraction methods with 4 black-box models and\\n2 datasets.  In addition to TPR and TNR, they measure Fidelity (which\\ncalculates agreement between the black-box model and their extracted\\nrules) and Robustness (which estimates small input perturbations do not\\nchange the model's output).  Their proposed method generally\\noutperforms existing techniques.  Ablation studies were performed to\\naccess the contribution of each component.\\n\\nI have read the authors' responses and commented on them.\",\n",
       "  'strengths': '1.  The proposed algorthms yield interpretables rules with high\\n    fidelity of the black-box models.\\n\\n2.  Empirical results indicate the proposed algorithms generally\\n    outperform existing ones.\\n\\n3.  The paper is generally well written.',\n",
       "  'weaknesses': '1.  Some ideas could be clarified, see questions below.'},\n",
       " 'review_95': {'summary': 'The paper deals with the problem of \"explainable\" unsupervised machine learning (ML) for anomaly detection (AD), with a focus of network intrusion detection (NID). The paper argues that while abundant effort focused on providing _supervised_ ML techniques that are explainable, this is not the case for _unsupervised_ ML methods---which are abundant in NID due to the lack of fine-grained labelled data. The paper hence seeks to rectify such shortage by proposing a novel solution that simultaneously (i) provides \"human-understandable\" explanations; and (ii) allows to derive some \"rules\" that can be used to improve the detection performance of the unlderying network intrusion detection system (NIDS). The proposed method leverages the intuition of \"slicing\" the (training) data into segments that represent a given group of (network) activities, e.g., web or database traffic; and then derive specific rules that describe these activities in an \"humanly understandable way\" and which can be used (if violated) to identify anomalies. The method is rigorously described and its effectiveness is assessed through various experiments on two well-known NID datasets, showing some advantages over existing baselines (which are mostly tailored for supervised ML).',\n",
       "  'strengths': '+ Evaluation on two NID datasets\\n+ Ablation Study\\n+ Rigorous description\\n+ Some design choices \"make sense\"\\n+ The method is rigorously described\\n+ Some ideas are correlated with proofs (in the appendix)\\n+ The paper tackles an open research problem (on the surface) for which limited research is available\\n+ Evaluation considering various parameter settings\\n+ The results show improvement over baselines\\n\\n\\nThe paper addresses an intriguing research problem (\"explainable unsupervised machine learning\") which has high relevance in some real-world applications of ML (i.e., network intrusion detection). The proposed method is rigorously described: some intuitions are sensible, and for others there are proofs provided which increase the overall soundness of the proposed methodology. The evaluation (which is reproducible, since the code is disclosed and the datasets are publicly available) shows improvement over prior work (most of which, however, was not designed to work in the given setting).\\n\\nFinally, the main novelty of this paper resides in addressing an underexplored problem.',\n",
       "  'weaknesses': '## High Level\\n\\n- Unconvincing motivation\\n- Excessively optimistic assumptions\\n- Flawed dataset and poor setup\\n- Questionable metrics \\n- Unclear \"understanding\" assessment\\n\\nDespite some strengths, the paper suffers from various issues which prevent me from recommending inclusion in NeurIPS\\'23 program. Specifically, though the paper seeks to address a \"real-world problem\" (i.e., how security operators deal with ML-NIDS that are not explainable), the proposed method relies on assumptions that can hardly be met in the real world---thereby decreasing the overall significance of the findings. \\n\\nAnother problem pertains the soundness of the experimental procedure, which casts doubts on the validity of the results and, hence, of the conclusions drawn from the paper. \\n\\nFinally, from a \"novelty\" perspective, the techniques used to address the problem tackled by this paper may be (somewhat) novel, but they can be redundant in light of some well-known considerations of the NID context.\\n\\n## Low Level\\n\\nI will provide an extensive description of the abovementioned weaknesses below. I will directly quote some statements made in the paper, and I will also attempt to provide suggestions and plenty of references to support my points.\\n\\n\\n\\n\\n### Unconvincing motivation\\n\\nAlbeit I acknowledge that the goal of providing \"explainable ML\" is relevant, I do not see a strong incentive in providing \"explainable _unsupervised_ ML methods\". This is because practitioners are well-aware that such methods are bound to be inaccurate, since they assume a notion of \"normality\". In a sense, the \"explanation\" for a raised anomaly is that a given data-point deviates from such normality; even practitioners acknowledge this as a fact [D]. This of course leads to a huge amount of false positives, which must be manually triaged _regardless of the explanations_. \\n\\nIn light of this, I did not find a compelling argument (provided in the paper) in favor of focusing on unsupervised ML --- or, at least, not in the context assumed by this paper. Perhaps a potential avenue is using said explanations for \"attack attribution\" [H], but this is never made explicit.\\n\\n### Optimistic assumptions\\n\\nThe method makes some strong assumptions that are too optimistic in real settings. The problem is that the main contribution (allegedly) is addressed at real-world deployments of ML.\\n\\n> We consider the anomaly detection tolerant of noisy data, but their proportion in training dataset is small and we do not have any ground truth labels of the training data.\\n\\nThis is a bold assumption which almost trivialized the entire problem of anomaly detection. If one is confident of having a (large) training set containing \"certain\" benign samples, one can use it as basis for supervised ML by enriching it with malicious samples (e.g., [I]). Unfortunately, in reality, obtaining such a \"clean\" training set requires huge manual effort [D] (and so is determining the threshold which allows for a manageable amount of alerts in operational contexts). Do note that the experimental evaluation assumes a \"perfect\" labelling of the normal samples in the training data (there is no mention of \"noisy\" data).\\n\\nAlso, consider the following statement\\n\\n> For example, a server supports multiple services such as web, email and database. The representations of these services can be disparate and located in different regions in feature space with little transition between the regions, making it infeasible to find a uniform rule set to accurately estimate the original model\\n\\nIn theory, this is correct. In practice, however, addressing this problem is trivial: \"web\", \"email\" and \"database\" are all services that can be easily separated by looking at the source ports of the corresponding communications (potentially with an additional filter based on the IP address). Indeed, one must remember that these methods must be setup and deployed by network administrators---who are well aware of what services are running in their organization.\\n\\n(note that even though here I have criticized the specific example, the consideration above can be extended to any type of potential \"multimodality\" that arises from network data)\\n\\nIn light of this, I fail to see any practical reason in favor of the method proposed in the paper. Perhaps the authors can provide a clear use-case in which the \"multimodality\" of the data is truly problematic to model.\\n\\n### Flawed dataset (and poor experimental setup)\\n\\nThe proposed method is evaluated on two datasets for Network Intrusion Detection (NID), one being the CIC-IDS17. Unfortunately, this dataset is flawed [J, K]. Note that [J] came out in 2021, and it has already been well-received by the NID community, so it is concerning that this paper (which has been submitted to a top-venue such as NeurIPS) performs the experiments on the \"flawed\" variant of this dataset---especially given that a \"fixed\" version exists (provided in [J]). \\n\\nFurthermore, note that [J] clearly stated that some features in this dataset (both the original and fixed version) are redundant for NID purposes (this is especially the case for \"flow-based\" NID [I, L]): however, this paper does not provide any detail about whether precautions have been taken to clean the feature set from \"obvious\" features (note that this also entails the ToN-IoT dataset)\\n\\nFinally, it is unclear whether the experiments have been repeated a sufficient amount of times to derive statistically significant conclusions (as recommended in [B]). The paper states:\\n\\n> The datasets are randomly split by the ratio of 6:2:2 for training, validation and testing\\n\\nThe \"random split\" may bias the results. \\n\\nIn light of this, the experimental setup may not be sound, thereby questioning the overall results. I invite the authors to look into other datasets as well (the works referenced in this review provide plenty of suggestions).\\n\\n\\n### Questionable evaluation metrics\\n\\nI was unable to find a link between the metrics used in the evaluation and the overarching goal of the paper.\\n\\nAccording to the Introduction:\\n\\n> we can present the inferential process of the black-box model in a human-understandable way, and build a surrogate rule-based model for online defense at the same time.\\n\\nHowever, there is nothing in the evaluation that allows one to measure whether the ```inferential process of the black-box model``` is presented in a ```human-understandable way```. This is because the evaluation appears to merely focus on the sheer detection performance of the \"surrogate\" model.\\n\\nTo re-quote a statement in the introduction (with which I fully agree!):\\n\\n> security operators tend to trust human-understandable rules rather than the unintuitive outputs such as labels and numeric values from the complex and incomprehensible models.\\n\\nThere is little in the evaluation that makes me believe that security operators would appreciate the explanations provided by the proposed method. \\n\\nI also have some concerns on the way these metrics are described:\\n\\n> Fidelity (FD), i.e., the ratio of input samples on which the predictions of original model and surrogate model agree over the total samples, which indicates the extent to which humans can trust the explanations\\n\\nI disagree: at best, FD denotes how much the surrogate and original models \"agree\". This says nothing about whether a human can \"trust\" the explanation in the general sense. Indeed, the quoted statement would be correct under the assumption that the original model\\'s explanation are \"correct\". \\n\\n> Robustness (RB), i.e, the persistence to withstand small perturbations of the input that do not change the prediction of the model\\n\\nI am confused here: what is the ```model``` whose prediction should not change? I.e., is it the \"original\" or the \"surrogate\"?\\n\\n### Unclear method for \"understanding\"\\n\\nThis issue follows the previous one. The \"human-understandable way\" to interpret the rules generated by the proposed method is assessed in Section 6.3. However, there is a lack of details in this Section, and the \"conclusions\" appear to be drawn from purely subjective statements.\\n\\nConsider the following:\\n\\n> Such results are easy to be interpreted.\\n\\nHow is this determined?\\n\\n> These explanations are in line with how security experts recognize the attack data.\\n\\nNo reference is provided.\\n\\nPlus, there is a mismatch with Table 4 and the overall assumptions made in the paper. Specifically, the paper assumes an \"unsupervised\" AD task, wherein the specific attack is not known. In light of this, how can a human derive that, e.g., (taken from Table 4):\\n\\n> DDoS attacks use packets of small sizes to achieve\\nasymmetric resource consumption on the victim side,\\nand send packets at a high rate to flood the victim\\n\\n? At most, a human sees some rules (e.g., ```ps_mean > 101.68, iat_mean > 0.063, dur > 12.61```) which -- when not met -- trigger some anomalies. But from here to stating that these anomalies relate to \"DDoS attacks\" there is a long way. For instance, \"violation\" of these rules can very well be related to a port-scanning activity (which can very well be a benign event, e.g., a new host which scans the network after joining it).\\n\\n\\n### Some bold statements in the Introduction\\n\\nBelow is a list of statements made in the Introduction for which I have serious concerns.\\n\\n\\n> it requires no attack/malicious data during the training (i.e., zero-positive learning), which are typically much more sparse and difficult to obtain in contrast with benign data;\\n\\nActually, obtaining \"certain\" benign data can be even harder than acquiring malicious data (see [B]). As a matter of fact, real-world deployments of ML entail very coarse \"labelling\" schemes [A].\\n\\n> it does not fit any known threats, enabling better detection on unforeseen anomalies.\\n\\nBut this also means that some of the raised anomalies have nothing to do with attacks---leading to \"alert fatigue\" (see [C,D,E]).\\n\\n> being self-explained and accurate for high-stake security applications.\\n\\nPlease define \"accurate for high-stake security applications\". Even non-surrogate models have a huge margin of error [C].\\n\\n> Accuracy Loss (CH3). [...] In this case, though these methods can provide model explanation, they cannot meet the need of online deployment which requires high detection accuracy in security applications.\\n\\nI disagree. The \"surrogate\" model has a single objective: provide \"global\" explanations. Therefore, even though such surrogate model may have worse \"accuracy\", it is the \"larger\" model that is meant to be deployed, while the \"surrogate\" is only used for explanation tasks.\\n\\n> We observe that an important reason why simple surrogate models are ineffective is that they cannot learn well about the complex data distribution in high-dimensional space.\\n\\nOn what grounds is this \"observation\" made? Is it just an educated guess, does it derive from original experiments, or is it drawn from prior research?\\n\\n\\n> The extracted rules outperform prior work in terms of diverse metrics including fidelity, robustness, true positive rate and true negative rate\\n\\nThis contradicts what was written at the beginning of the introduction: ```security operators tend to trust human-understandable rules rather than the unintuitive outputs such as labels and numeric values from the complex and incomprehensible models.```. In what way are the metrics mentioned above different from \"numeric values from the complex and incomprehensible models\"?\\n\\n> which meets the demand of improving human trust in black-box models and maintaining high detection accuracy for online deployment.\\n\\nThis is a self-claim: there is no evidence provided that ```fidelity, robustness, tpr, tnr``` meet the described ```demand``` (in terms of explainability).\\n\\n\\n\\n\\n### Some additional issues:\\n\\nThe following is a list of miscellaneous issues I found in this submission; note that these issues are not necessarily \"minor\".\\n\\n* Some relevant works have not been considered. The extensive study carried out in [F] reveals, e.g., [G] -- which specifically focuses on providing \"explainable unsupervised models\".\\n* ```furthur``` typo\\n* I found the following statement to be misleading (and also unnecessary): ```we refer to adversarial attacks [44] and propose a method to approximate the optimal direction to explore the decision boundary```\\n* ```Further, most of their true positive rates cannot meet the requirement of using their rules for online defense, as the sheer amount of attack data they miss can cause huge damages.``` please provide facts instead of writing vague statements such as \"can cause huge damages\". Even a single false negative can lead to \"huge damages\" [D].\\n* I did not find any measure of the \"runtime\" used to train/test the proposed method. \\n* Did the evaluation _really_ take place on a server having an RTX3090 with 8GB of VRAM? (given that the RTX3090 has 24GB of VRAM?)\\n* Did the evaluation _really_ take place on a server having an Intel Xeon with only 8GB of RAM?\\n* To my understanding, the method assumes that the data-points represent \"network flows\" (such is the data contained in the considered datasets). However, there is a huge variability in the ways such flows can be generated (see [I,M]). What would happen if the netflow generator is different? \\n\\n#### EXTERNAL REFERENCES\\n\\n[A]: Van Ede, Thijs, et al. \"Deepcase: Semi-supervised contextual analysis of security events.\" 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 2022.\\n\\n[B]: Apruzzese, Giovanni, Pavel Laskov, and Aliya Tastemirova. \"SoK: The impact of unlabelled data in cyberthreat detection.\" 2022 IEEE 7th European Symposium on Security and Privacy (EuroS&P). IEEE, 2022.\\n\\n[C]: Alahmadi, Bushra A., Louise Axon, and Ivan Martinovic. \"99% False Positives: A Qualitative Study of {SOC} Analysts\\' Perspectives on Security Alarms.\" 31st USENIX Security Symposium (USENIX Security 22). 2022.\\n\\n[D]: Apruzzese, Giovanni, et al. \"The role of machine learning in cybersecurity.\" Digital Threats: Research and Practice 4.1 (2023): 1-38.\\n\\n[E]: Hassan, Wajih Ul, et al. \"Nodoze: Combatting threat alert fatigue with automated provenance triage.\" network and distributed systems security symposium. 2019.\\n\\n[F]: Nadeem, Azqa, et al. \"Sok: Explainable machine learning for computer security applications.\" arXiv preprint arXiv:2208.10605 (2022) [to appear in EuroS&P\\'23]\\n\\n[G]: Wickramasinghe, Chathurika S., et al. \"Explainable unsupervised machine learning for cyber-physical systems.\" IEEE Access 9 (2021): 131824-131843.\\n\\n[H]: Nisioti, Antonia, et al. \"From intrusion detection to attacker attribution: A comprehensive survey of unsupervised methods.\" IEEE Communications Surveys & Tutorials 20.4 (2018): 3369-3388.\\n\\n[I]: Apruzzese, Giovanni, Luca Pajola, and Mauro Conti. \"The cross-evaluation of machine learning-based network intrusion detection systems.\" IEEE Transactions on Network and Service Management (2022).\\n\\n[J]: Liu, Lisa, et al. \"Error Prevalence in NIDS datasets: A Case Study on CIC-IDS-2017 and CSE-CIC-IDS-2018.\" 2022 IEEE Conference on Communications and Network Security (CNS). IEEE, 2022.\\n\\n[K]: Engelen, Gints, Vera Rimmer, and Wouter Joosen. \"Troubleshooting an intrusion detection dataset: the CICIDS2017 case study.\" 2021 IEEE Security and Privacy Workshops (SPW). IEEE, 2021.\\n\\n[L]: Arp, Daniel, et al. \"Dos and don\\'ts of machine learning in computer security.\" 31st USENIX Security Symposium (USENIX Security 22). 2022.\\n\\n[M]: Vormayr, Gernot, Joachim Fabini, and Tanja Zseby. \"Why are my flows different? a tutorial on flow exporters.\" IEEE Communications Surveys & Tutorials 22.3 (2020): 2064-2103.'},\n",
       " 'review_96': {'summary': 'This paper proposes a rule-set extraction method for a black-box anomaly detection model that is trained with only normal or unlabeled data.\\nThere are many methods to interpret the learned model, but, this paper claims that there are few methods designed for anomaly detection.\\nThe proposed method first extracts rules that decompose the complex distribution of normal data into multiple simple distributions and then, in each simple distribution, the decision rules that approximate the decision boundary of the pre-trained model are estimated. \\nBy merging such rules, the proposed method can obtain a surrogate rule-based model of the trained anomaly detector.\\n',\n",
       "  'strengths': '- The problem tackled in this paper is important. There is a demand for interpretable anomaly detection in many industries, including security.\\n- The proposed method is model-agnostic and thus can be applied in many applications.\\n- The proposed method works well in the experiments.',\n",
       "  'weaknesses': \"- There is no discussion or comparison regarding computational costs.\\n- There are several unclear points about the methodology. This may be because I am a non-expert in this area (rule-based methods). I would like to wait for the author's additional explanation in the rebuttal.\"},\n",
       " 'review_97': {'summary': '\\nThis paper proposes an algorithm to count the maximum number of unique items one can get from considering from every individual in a dataset at most l items, while preserving differential privacy.  \\n',\n",
       "  'strengths': \"\\n\\nThe paper offers an (as far as I know) original contribution, which is simple and nice.  The explanation is clear.  The result may be significant to the extent one can cast applications needing to count the number of unique items into the relaxation considered in the current paper.\\nThe paper performs an interesting empirical evaluation, even if it doesn't fully succeed to bring up a convincing application.\\n\",\n",
       "  'weaknesses': '\\nThe paper also proposes a linear time algorithm, which is very nice, but which makes a second approximation, making it even more unclear how to determine whether it is suitable for a specific application.\\n\\n'},\n",
       " 'review_98': {'summary': 'Edit: Overall decision recommendation changed from borderline reject to borderline accept under the expectation that limitations and future work directions as discussed in the reviewer discussion are incorporated into the manuscript.\\n\\nThe manuscript studies the problem of approximating the number of unique items in a multiset under (user-level) differential privacy (DP). Unlike in prior work users can contribute arbitrarily many items to the multiset.\\n\\nThe authors propose to select for each user a subset of contributed items that maximises the total number of unique items. The maximisation problem is solved exactly in polynomial-time via bipartite maximum matching or alternatively a 2-approximation is found in linear-time via a greedy algorithm.',\n",
       "  'strengths': 'S1) Non-trivial results: Sensitivity analysis of approximate DC(D;l) and application of generalized exponential mechanism is interesting.\\n\\nS2) Could be useful: Probability that noisy count is a lower bound can be calibrated and lower bound can be useful to check if certain thresholds are exceeded.\\n\\nS3) Improvement over naive baselines: Computing/approximating DC(D;l) seems clearly preferable to selecting l random items for each user.',\n",
       "  'weaknesses': 'W1) Heavily biased estimator.\\n\\nA DP count would seem to prohibit deterministic lower/upper bounds. While a lower bound w.h.p. could still be useful, most settings would seem to call for an unbiased estimator (see also Q1a & Q1b).\\n\\nW2) Quality of solution unclear.\\n\\nApart from the poorly presented tables that do not clearly indicate the correct count, there is also no analysis of how much more utility could potentially be possible for this problem under a given DP regime. Thus, it is difficult to appreciate the solution in terms of how practically useful it is or how much utility is potentially lost due to the method (see also Q2a & Q2b).\\n\\nW3) Reproducibility\\n\\nWhile the datasets seem to be specified, the submission does not seem to provide code for experiments (see also Q3).\\n\\nW4) Minor: Some parts of the paper are hard to understand. Particularly, Section 3 could focus more on explanations related to the Generalized Exponential Mechanism (GEM) rather than well-known basics.\\n\\nIt would be better to move the basics of DP and basic Exponential/Laplace mechanism to the appendix and instead provide more explanations/intuitions on how the GEM is used in this work, why it is needed and some intuitions how it leads to better results.\\n\\nW5) Minor: Sensitivity analysis of DC(D;l) is missing.\\n\\nIt could be stated more explicitly why if a user is added that contributes X items DC(D;l) can increase by at most X, i.e., the added user cannot improve the solution for the previous users (e.g., due to optimal solution for previous users). That would also make it clearer why the sensitivity analysis for the approximation of DC(D;l) is non-trivial where an added user could potentially improve the solution for the previous users and removing a user could lead to less optimal solutions for the rest of users.'},\n",
       " 'review_99': {'summary': 'The authors study the fundamental problem of counting the number of distinct elements in a dataset\\nin a user-level DP setting, where a user can contribute an unbounded number of items. The main\\ncontribution of the paper is an approach to obtain lower bounds through a bounded sensitivity\\ncount and a bias-variance perspective. The authors give interesting algorithms to compute\\nit quite efficiently, and show a linear time version which trades off efficiency with accuracy.\\nThe algorithms are evaluated empirically and show good performance.',\n",
       "  'strengths': '\\nThe problem is very natural and well motivated. The approach considered in the paper, in terms of\\nbounded sensitivity, seems quite natural, and is connected to a big literature on Lipschitz extension.\\nThe authors give rigorous bounds on the bounds achieved by their algorithms. The empirical results\\nare also interesting, and show reasonable performance. The greedy algorithm is also shown to perform\\nquite well. The presentation is quite good.',\n",
       "  'weaknesses': 'The basic ideas in the paper, and the techniques used in the algorithms are fairly simple. The experiments section could be strengthened'},\n",
       " 'review_100': {'summary': 'Suppose a data set consists of (user, item) pairs. The paper provides an estimate of the count of the number of distinct items that satisfies user level differential privacy. This differs from existing work in two ways. Existing work 1) considers item streams with item, not user, level differential privacy and 2) is highly concerned about computation costs and uses data sketches which have bounded size. \\n\\nIt solves the problem by generating lower bounds with bounded sensitivity by converting the distinct count to a max flow problem.',\n",
       "  'strengths': 'The paper introduces a novel user-level privacy formulation of the distinct count problem. The main ideas are presented well, and it is technically sound.',\n",
       "  'weaknesses': '1. The title could better describe the key feature of the problem, providing user level privacy. Since most distinct counting papers are about approx distinct counting and streaming/distributed algorithms, I think readers have an expectation that this paper would address this given the title and it\\'s a bit of a let down when it doesn\\'t.\\n\\n2. The related work section is somewhat inaccurate in its descriptions. E.g.\\n* Desfointaine et al is a universal result about any distinct counting method which is mergeable. Changing the algorithm design can\\'t get around this. But the results only imply that you can\\'t merge many times and preserve both privacy and accuracy, not that you can\\'t build a private sketch.\\n* Smith et al doesn’t actually analyze the Flajolet-Martin (a.k.a. PCSA) sketch but their own tweak of the LogLog sketch (by Durand and Flajolet). (Though this inaccuracy is totally understandable given their title.)\\n* Dickens et al is also a universal result for any order invariant sketch. \\n* Both Smith et al and Dickens et al are pan private in the streaming setting as well\\n* Note neither claim to provide privacy under merges. \\n\\n3. There is also some related work on private multiparty computation for distinct counts. e.g. \"Privacy-Preserving Secure Cardinality and Frequency Estimation\" Kreuter et al 2020\\n\\n4. The empirical results for the greedy algorithm are nice, but the bound is quite bad for this application since it only gives you an estimate of the correct order of magnitude. It\\'s also not clear what to do in large scale distributed data settings. These are fairly minor weaknesses given the paper\\'s scope though.'},\n",
       " 'review_101': {'summary': 'This paper presents a model-free policy optimization algorithm Optimistic Natural Policy Gradient for online and episodic MDPs. The authors present sample complexity results which are better than existing results for linear MDPs. This makes it computationally efficient and optimal dimension dependence, first of its kind. The algorithm is also similar to popular RL algorithms like PPO which makes it even more interesting. ',\n",
       "  'strengths': 'Technically solid paper with state of the art sample complexity results. The contributions are very well highlighted. The details of the algorithm are well presented by highlighting the key three modules in the algorithm. The paper also studies the online exploration scenario without access to a simulator. ',\n",
       "  'weaknesses': 'Agarwal et. al [2020] did have some experimental results on some environments to verify indeed the proposed algorithm enjoys what is proved theoretically. In this paper, any experimental proof of \"computationally efficient\" is missing.'},\n",
       " 'review_102': {'summary': 'This paper proposes optimistic NPG for online RL, which is computationally efficient and enjoys the polynomial sample complexity while learning near-optimal policies. The paper is well-written and organization is clear.',\n",
       "  'strengths': 'There are several strengths:\\n1. Sample complexity benefits: compared with other computationally efficient policy optimization algorithms, the proposed algorithm in this work has better sample complexity guarantees; (I think this is the major strength)\\n2. The first polynomially sampled policy optimization algorithm under general function approximation.\\n3. Literature comparison and position is clear. The paper is well-written!',\n",
       "  'weaknesses': 'I think this paper is clear and I do not have concern for now.'},\n",
       " 'review_103': {'summary': 'This work proposes a simple-efficient efficient policy optimization algorithm for online RL. When specialized to linear MDPs, the algorithm improves the best known result by a factor of $d$. Moreover, this is the first efficient policy optimization algorithm under general function approximation.',\n",
       "  'strengths': '1 This work is well-written and well-organized.\\n\\n2 This work showcase a generic policy optimization meta-algorithm can be sample efficient. \\n\\n3 The theoretical guarantee outperforms the exisiting result in linear MDPs, and is the first sample efficient policy optimiztion algorithm under general function approximation.',\n",
       "  'weaknesses': '1 When specialized to tabular scenario, the result is worse than the best existing result.\\n\\n2 Under linear MDPs, the dependency on $\\\\epsilon$ is not optimal.'},\n",
       " 'review_104': {'summary': 'The paper presents $\\\\texttt{OPTIMISTIC NPG}$, a new algorithm that combines the natural policy gradient with optimistic policy evaluation to encourage exploration in online RL. The algorithm demonstrates computational efficiency and achieves optimal sample complexity in linear MDPs, outperforming existing state-of-the-art approaches. Furthermore, it extends to general function approximation, making it the first algorithm to achieve polynomial sample complexity for learning near-optimal policies in this broader setting.',\n",
       "  'strengths': '- The authors propose a computationally efficient policy optimization algorithm with improved sample complexity in $d$-dimensional linear MDPs.\\n- The authors Introduce the first on-policy method in the exploration setting that achieves polynomial sample complexity, contrasting with previous off-policy algorithms.\\n- The authors extend the linearMDP algorithm to a general function approximation algorithm, exhibiting polynomial sample complexity measured by the eluder dimension of a function class.',\n",
       "  'weaknesses': '- The technical novelty of the algorithm for a general function class appears unclear, and further explanation is needed on how to construct confidence sets when working with function classes beyond linear functions.\\n- Excluding the issue of computational intractability, Subroutine 3 appears to be applicable to general function classes with bounded eluder dimension. For example, Dong et al. (2021) proved that \"one-layer neural nets do not have polynomially-bounded eluder dimension,\" presenting an exponential eluder dimension. It is challenging to claim that the algorithm proposed in this paper is sample efficient for function classes with such characteristics.\\n\\n\\\\--\\n\\nDong, K., Yang, J., & Ma, T. (2021). Provable model-based nonlinear bandit and reinforcement learning: Shelve optimism, embrace virtual curvature. Advances in Neural Information Processing Systems, 34, 26168-26182.'},\n",
       " 'review_105': {'summary': 'This paper proposes a simple and efficient policy optimization method with rigorous theoretical guarantee. The algorithm combines the natural gradient ascent and the optimistic off policy evaluation and is computationally efficient. They provide the condition under which the algorithm is guaranteed to be efficient and can provably learn the optimal policy. The authors also gave three examples to show the efficiency of the algorithm: tabular case, linear function approximation and general function approximation. They show that their algorithm achieves the optimal dependence on d for linear case which improves the algorithm proposed by Zanette et al, 2021 by a factor of d. They also show that their algorithm is the first one to achieve polynomial sample complexity in general function approximation case. \\n\\nIn general, the proof is sound and also the writing is very good and clear. I like the simplicity of their algorithm.',\n",
       "  'strengths': '1. The algorithm is simple, efficient and easy to understand.\\n2. They provide a sound argument of theory and the proof is sound to my knowledge.\\n3. In linear case, their algorithm achieves the optimal dependence w.r.t. the dimension d with computational efficiency.\\n4. Besides 3, they also provide the sample complexity in tabular and general function approximation case.',\n",
       "  'weaknesses': \"I do not think this paper has any apparent weakness. Though, I still have some minor questions about it.\\n\\n1. In Theorem 1, you claim the result holds with probability at least 1/2, and in Line 207-211,  you claim that you can achieve the probability 1-\\\\delta for any \\\\delta with a sample complexity multiplies by a log factor. I understand that you only need to run the algorithm one for log(1/\\\\delta) times, but how do you 'estimate the values of every output policy to accuracy \\\\eps'? Can you show exactly how you do to achieve this? In this estimation stage, do you need to sample additional online data using the output policy or not?\\n\\n2. In line 223-226, you claim the best sample complexity for policy optimization in the tabular case is H^4 S A / \\\\eps^2. I am not sure whether this is true. Indeed, the Wu et al. you cited expressed their result in the form of regret, and you can of course uniformly sample one policy from the policies output in Wu et al and get the sample complexity. However, in this paper (https://arxiv.org/pdf/2007.13442.pdf), they propose the algorithm BPI-UCBVI for best policy identification (another name of 'policy optimization'?), and they showed the sample complexity to be H^3 S A / \\\\eps^2 log(1/\\\\delta). (This is the second algorithm in their paper and the first one is reward-free version. Even the traditional UCBVI algorithm should be able to achieve the H^3 S A / \\\\eps^2 * polylog(1/\\\\delta). I wonder whether they considered a different setting as you did and whether result you claimed is the best one.\\n\\n3. In all three subroutines about OPE, you split the data into H even disjoint subset. Do you think this splitting is inefficient? I remember in some papers, such as this one (https://arxiv.org/pdf/2106.04895.pdf), they split the data into three instead of H subsets to reduce the sample complexity. Do you think this will help you further reduce the sample complexity in your algorithm?\"},\n",
       " 'review_106': {'summary': 'This paper investigates degree of adaptivity in data impacts the performance of estimating a low-dimensional parameter component in high-dimensional linear models.  The main result is giving an error bound of a low-dimensional component that does not have diension dependence. They propose an estimator TALE. For a special case when there is a single adaptive coordinate and non-adaptive components have zero mean, this estimator is asymptotically normal.\\n\\nThe manuscript is easy to read through and the technical content of the paper appears to be correct albeit some typos:\\n\\nLine 69: Adaptive\\nLine 478 in the appendix: $X_{\\\\mathrm{ad}}$',\n",
       "  'strengths': 'Theoretical results:\\n- The authors define (k,d)-adaptivity to quantify the level of adaptivity along with a concrete example. Using this idea, they can get the upper bound depending on $k$ in stead of full dimension $d$. These results could bridge the gap between iid and arbitrarily adaptive data collection.\\n\\nExperiments:\\n- Compared to other methods like OLS, estimation errors for TALE are in good accordance with a norm distribution.\\n',\n",
       "  'weaknesses': \"Theoretical results:\\n- The main result in this paper demonstrates the advantages of utilizing the $(k,d)$-adaptivity structure, yielding a scaled-MSE bound in the order of $k\\\\log(n)$ instead of $d\\\\log(n). While this is a positive outcome, it's worth considering that the result is based on a different norm, which makes it less convincing.\\n\\nExperiments:\\n- In the introduction,  the paper aims to obtain an estimator with performance dependent on the degree of adaptivity. Besides, the main results highlight that having $k$ in the upper bound. Therefore, I believe it would be better for the authors to experiment with different levels of adaptivity.\\n\"},\n",
       " 'review_107': {'summary': 'As I have communicated with the area chair, I will not be reviewing due to a conflict of interest. Submitting default ratings intended to be ignored below.',\n",
       "  'strengths': 'NA',\n",
       "  'weaknesses': 'NA'},\n",
       " 'review_108': {'summary': 'The paper introduces a new data collection assumption that captures the partially adaptive data and then derives a bound for scaled MSE of order $k\\\\log n$, where $k$ is the number of entries that are collected adaptively.  Finally they also introduce a novel estimator for single coordinate inference which has  an asymptotic normality property.',\n",
       "  'strengths': 'The paper is clearly structured and well-written. The theorems seem solid, and the assumptions are general. The authors also provide a concrete example of $\\\\textit{treatment assignment}$ to showcase the power of their theorems. ',\n",
       "  'weaknesses': '1. The numerical section is focused on the performance of TALE, missing out the numerical verifications for Theorem 3.1 and 3.2, which are the main theorems of the paper. \\n\\n2. There still seem to be some fundamental limitations for the definition of $(k,d)$-adaptivity. For example, $(k,d)$-adaptivity requires a fixed number of entries in covariates $x$ are adaptively collected, which ignore the important scenario when such the number and indices of such entries may vary. \\n\\n3. While the example of $\\\\textit{treatment assignment}$  is very helpful, no comparison has been made against the state-of-the-art statistical tools and no numerical experiments are provided.\\n\\n4. Typo in line 106.\\n\\n'},\n",
       " 'review_109': {'summary': 'This paper considers the issue of adaptive data collection in a linear regression model. To summarize the main idea, let us focus on the leading example in the paper (that is, Example 2.1, treatment assignment). In this example, a patient is treated based on effectiveness of the previous treatments as well as a small number of covariates. When the treatment is assigned adaptively in an unknown way, the treatment effect can be estimated via OLS only at a rate $\\\\sqrt{d/n}$, where $d$ is the dimension of the entire covariate vector (not the dimension of the covariates used for treatment assignment) and $n$ is the sample size. This result is shown by previous work in Khamaru et al. [21] and a simplified version is given as Proposition 2.2 in the paper. One of the main results in the paper is that the centered OLS estimator of the treatment effect attains a better rate of convergence, that is, $\\\\sqrt{k/n}$, where $k-1$ is the dimension of the covariates used for treatment assignment. The inference problem is further studied for the case that $k=1$. That is, the treatment assignment mechanism does not depend on the covariates but on the effectiveness of the previous treatments. The paper proposes an adaptive estimator called Two-stage Adaptive Linear Estimating Equation (TALE) Estimator. The adaptive weights are constructed in a particular fashion to develop asymptotic normality (see Theorem 3.4). Numerical experiments show potential usefulness of the proposed TALE estimator.         ',\n",
       "  'strengths': '- This paper considers a highly important problem in the literature: adaptive data collection (e.g., bandits) is increasingly important in a number of fields. \\n- The paper clarifies the important open question in the literature, that is, \"Can we obtain a good estimator for a low-dimensional parameter component in linear models when the degree of adaptivity is given?\".\\n- The proposed TALE estimator has desirable theoretical properties and shows promising numerical results.',\n",
       "  'weaknesses': '- The non-adaptive component $x_i^{\\\\mathrm{nad}}$ is assumed to be independent of the adaptive component $x_i^{\\\\mathrm{ad}}$ (see lines 84-85). This seems quite strong in the sense that if this is the case, we could just drop the non-adaptive component $x_i^{\\\\mathrm{nad}}$ in the regression model and then we automatically obtain the $\\\\sqrt{k/n}$ rate, provided that the variance of the new regression error, which now includes the omitted part $\\\\theta^\\\\top x_i^{\\\\mathrm{nad}}$, is bounded by a constant that is independent of $d$. Using the scenario in Example 2.1 with $k=1$ (that is, the treatment assignment mechanism depends only on the effectiveness of the previous treatments), it might be preferable to consider the difference-in-means estimator (that is, to include only the intercept term and a treatment indicator) instead of estimating the treatment effect via regression adjustment. It would be useful to carefully discuss the issue of independence between the adaptive and nonadaptive components. '},\n",
       " 'review_110': {'summary': 'In \"Statistical Limits of Adaptive Linear Models: Low-Dimensional Estimation and Inference\" the authors consider the problem of estimating a low-dimensional signal in a high-dimensional linear model where data collection is allowed to be adaptive. The notion of adaptivity employed in this paper restricts itself to k components, meaning that the k first (wlog) covariates are allowed to be adaptive while the remaining are assumed i.i.d. This is in contrast to prior work where all components are allowed to be adaptive which yields very detrimental minimax lower bounds even in the case where only one component is to be estimated. Based on this new notion of adaptivity, the authors propose a scheme to estimate the low-dimensional signal yielding beneficial scaling guarantees, both in mean square error and asymptotic normality.    ',\n",
       "  'strengths': '1. Originality: the authors study a novel scenario and provide a novel scheme with reasonable guarantees. The work has sufficient novelty.\\n2. Quality: the paper is technically sound and the results are appropriately stated.\\n3. Clarity: The main results of the paper and some intuition on how they are established are clear. The example provided could be a bit clearer. I expand on this in the Questions section.\\n4. Significance: This may be to my own ignorance but the significance of the considered model is not entirely clear to me. I again will expand on this in the Questions section.',\n",
       "  'weaknesses': 'I merge this with the Questions section.'},\n",
       " 'review_111': {'summary': 'The paper studies the statistical limits of some adaptive linear models.\\n\\nThe paper defines the notion of $(k,d)$-adaptivity (Definition 2.1), and then it proves, under some conditions and for a $(k,d)$-adaptive model and failure probability $\\\\delta$, that\\n- (Theorem 3.1) the estimation error of the adaptive components is bounded by $k\\\\log(n/\\\\delta)$ if the non-adaptive component has zero mean,\\n- (Theorem 3.2) and similar results hold if the mean of the non-adaptive component is not zero;\\n- (Theorem 3.4) moreover, there exists an estimator (TALE) that enjoys asymptotic normality.\\n\\nThe experiments present an interesting phenomenon: The TALE estimator coincides well with the normal distribution.\\n\\n',\n",
       "  'strengths': 'The paper is written clearly and the presentation is smooth and relatively easy to follow.\\n\\n\\n\\n\\n',\n",
       "  'weaknesses': 'I have a major concern about whether the paper is technically solid and I wish to read the response from the authors:\\n- Regarding Theorems 3.1 and 3.2, could the authors justify how the proof techniques differ from prior works? It appears to me that the two results are basic extensions of prior proofs (so, correct me if I am wrong).\\n- Theorem 3.4 holds only for a single adaptive coordinate. Could the authors elaborate on the difficulty of extending the results for general $(k,d)$-adaptivity?\\n\\n\\nMinor:\\n- the same symbol $\\\\sigma$ is used to represent sigma field, variance of a random variable, and singular values. In my humble opinion, this might be confusing.\\n\\n\\n**NOTE**: I am not an expert on statistics in general and on this particular line of research, so it is not for me to say whether the paper is significant or novel.'},\n",
       " 'review_112': {'summary': 'In this work, the authors embark on exploring the capabilities of prompt tuning in the continuous regime,\\ncontrasting it with fine-tuning, as an initial endeavor toward theoretical comprehension. The authors prove\\nby construction that prompt tuning admits universal approximation within the space of Lipschitz\\nfunctions. Additionally, the authors identified inherent limitations of prompt tuning on single-layer transformers by constructing theoretically difficult datasets for prompt tuning. These limitations are then\\nextended to multi-layer settings under a specific prompt-norm restriction.',\n",
       "  'strengths': '1. The authors characterize the universal nature of prompt tuning by explicitly constructing a transformer\\nnetwork.\\n\\n2. The authors provide a construction-based argument for sequence-to-sequence datasets that cannot be\\nlearned by prompt tuning with a given single-layer transformer.\\n\\n3. The authors provide the lower bound on the required number of parameters for prompt tuning to\\nmemorize any sequence-to-sequence functions.\\n\\n4. The authors provide a sufficient condition for multi-layer transformers, under which datasets with\\nshared output tokens cannot be learned with prompt tuning.\\n\\nOverall, this paper is well written. The hypothesis of these theories is acceptable and the theoretical analysis is solid. \\n',\n",
       "  'weaknesses': 'Please add more experiments to support the theoretical result.'},\n",
       " 'review_113': {'summary': 'This paper presents theoretical analysis of prompt tuning by 1) formally define the attention and prompting operations, 2) deriving the universality of prompt tuning with a strong transformer model, 3) further discussing the limitation of prompt tuning under the case of single and multi-layered transformer models. Explorative experiments on standard models and benchmark datasets demonstrate the correctness of the derived theorems.',\n",
       "  'strengths': '- The paper is well written with clearly defined definitions and theorem presentations.\\n- Exploring prompt tuning from a theoretical perspective is very interesting and important, since better understanding the limitations of prompts is the key to improve prompting techniques.\\n- The theorems seems correct and solid.',\n",
       "  'weaknesses': '- The experimental part is a bit weak compared with the theoretical part. \\n- It will be nice to have some further discussions on how to leverage the current limitations of prompt tuning to design better prompting-based models.'},\n",
       " 'review_114': {'summary': \"This paper focuses on understanding the role and theoretical underpinnings of soft-prompt tuning in transformer-based architectures, which is a technique used to adapt pretrained language models for new tasks. Despite the empirical effectiveness of this method, there's a lack of theoretical understanding of how it differs from tuning the model weights.\\n\\nThe paper takes significant steps in several areas:\\n\\n1. **Universal Approximation Analysis:** The researchers prove a universality result that guarantees the existence of a transformer with a prompt that can approximate any sequence-to-sequence function within the set of Lipschitz functions, which are a class of functions that have a particular property of bounded rate of change.\\n\\n2. **Limitations of Limited-Depth Transformers:** The researchers construct datasets that cannot be memorized by a prompt of any length for a single-layer transformer, demonstrating the inherent limitations of prompt-tuning in this setting. The paper extends the analysis to multi-layer transformer settings, providing conditions under which transformers can only learn from invertible functions. This shows additional limitations of the transformer model.\\n\\n3. **Lower Bound on Tunable Prompt Parameters:** They establish a lower bound on the required number of tunable prompt parameters and compare this with the parameters needed for a low-rank update (LoRA). This helps to illuminate the resource trade-offs between these two methods.\\n\\n4. **Empirical Results:** The researchers also provide empirical results that back up their theoretical findings, adding credibility to their conclusions.\\n\",\n",
       "  'strengths': \"One of the strengths of the paper is its theoretical grounding. It provides a theoretical understanding of the difference between 'tuning parameters before the input' and 'the tuning of model weights'. The paper presents a strong universality result, stating the existence of a strong transformer with a prompt that can approximate any sequence-to-sequence function in the set of Lipschitz functions. \\n\\nIn addition, the paper presents a detailed analysis of the limitations of prompt-tuning, especially for limited-depth transformers. The authors create specific datasets that cannot be memorized by any prompt of any length for a single encoder layer. This analysis provides useful insights into the constraints of prompt-tuning.\\n\\nThe paper is generally easy-to-follow in idea. Although I do not check the theoretical correctness of these proofs.\",\n",
       "  'weaknesses': '\\nWhile this paper takes a commendable effort in delving into the theoretical underpinnings of prompt-tuning in transformer-based architectures, it has several significant shortcomings.\\n\\nFirstly, the focus on sequence-to-sequence encoder models poses a substantial gap in the relevance of these findings to practical, real-world application. The universality of sequence-to-sequence transformers cannot be immediately generalized to decoder models, which are commonly used in practice and can handle an arbitrary number of output tokens. Therefore, the study needs to address how its theoretical results can be extended to these types of models. Without this, the scope of the paper\\'s relevance becomes significantly narrow and its conclusions may not be directly applicable to most use-cases.\\n\\nSecondly, the reliance on the universality results from Yun et al.\\'s work (\"Are transformers universal approximators of sequence-to-sequence functions?\") reduces the novelty of the paper. While it is valid to build upon previous work, the authors have not demonstrated a significant extension or new application of these universality findings. It would be beneficial for the paper to provide more novel insights or extend the known results to a more general setting beyond what is already known from the referenced work.\\n\\nLastly, the exploration of limitations in prompt-tuning is an interesting aspect of the paper. However, the limited breadth of the experiments conducted undermines the impact of these findings. The limitation proofs revolve around specific, constructed single-layer transformers, which do not cover the wide array of transformer architectures used in practice. The implications of these limitations would be far more convincing if the authors could generalize the findings to multi-layer transformers or a wider variety of architectures.\\n\\nTo improve upon these shortcomings, the authors might consider broadening their analysis to include decoder models, providing more novel extensions to the universality results, and expanding the scope of their limitation analysis to apply to a broader range of transformer architectures.'},\n",
       " 'review_115': {'summary': 'This paper wants to provide the insights on \"when and how to perform prompt tuning to adapt a pretrained transformer to downstream tasks\", by theoretically quantifying the universality (i.e., universal approximators) and limitations (i.e., representation capacity) of prompt tuning, in complementing a lot of work focusing on empirically improve soft prompt tuning, such as better initialization or hyper-parameter tuning. Crucially, they show prompt tuning with theoretically very strong transformer models can approximate any seq2seq functions in the set of Lipschitz functions, and they theoretically and empirically show some limitations on weaker transformers (constructed seq2seq datasets as low bounds) by their relatively lower memorization ability. ',\n",
       "  'strengths': '1. This work shows the universality of prompts to the Lipschitz function space, and the limitations of prompt tuning at their memorization ability. The proofs are interesting and well-guaranteed. \\n2. The mathematical derivations do show your deliberate thinking and rigorous reasoning. \\n3. The paper writing is almost well-structured. ',\n",
       "  'weaknesses': '1. Just for curious, you define F_L by directly posting the L-lipschitz functions. However, indeed, this causes some unavoidable confusions to readers, as what are \"L-lipschitz functions\"? Can you provide any context? Especially for some highly theoretical papers?\\n2. Some writings make me confusing, even though the general structure looks good. \\n3. Just one question: Is the first section of universality looks very similar to your cited ICLR work on Transformer\\'s universal approximators?  \\n\\nI am happy to raise scores if you can make this more clear to me, such that this highly theoretical paper can obtain a more rigorous consideration for its ratings.'},\n",
       " 'review_116': {'summary': 'This paper examines the theoretical capacity and limitations of prompt tuning. The authors have demonstrated the possibility of constructing a large transformer model that is sufficient for prompt-tuning to exhibit universal approximation over a Lipschitz function space. However, they have also shown the limitations of prompt tuning compared to model fine-tuning by constructing sequence-to-sequence datasets that cannot be learned by prompt-tuning with a given single-layer transformer, even if the soft-prompt embedding size approaches infinity. Additionally, compared with LoRA, prompt-tuning may require more prompt tokens for exact memorization.',\n",
       "  'strengths': '- Originality\\n    - This paper has pretty good originality. It first theoretically studies the theoretical capacity and limitations of prompt tuning.\\n\\n- Clarity\\n    - The structures are clear and conclusions are emphasized.\\n\\n- Significance\\n    - The problem studied in this paper is important',\n",
       "  'weaknesses': '- The authors have conducted experiments to support the proposed limitation. However, additional experimental verifications may be necessary to reinforce the theoretical claims and demonstrate the impact on a wider range of tasks and datasets.\\n\\n- The authors have created sequence-to-sequence datasets that are simple in structure but cannot be memorized by prompt-tuning for a given transformer model. Therefore, they argue that prompt-tuning has limited expressiveness compared to model fine-tuning. However, is memorization typically necessary in real-world applications? Does memorization lead to overfitting? As I understand it, such a phenomenon could also be viewed as a potential advantage in preventing overfitting and achieving generalization ability in the process of downstream adaptation.\\n\\n- The authors have provided quite a few mathematical proofs and concluded several insights. I wonder whether there are any guidance for practical prompt-tuning applications.  For example, they provide a lower bound on the required number of prompt tokens for exact memorization and point out that such lower bound can be higher than LoRA’s. I would like to know that on which scenarios this could happen and it is recommended to user LoRA rather than prompt-tuning.\\n\\n- The authors need to correct some minor typos.\\n    - line 30, typo:  the or a\\n    - line 503, line 508, are they the same reference?'},\n",
       " 'review_117': {'summary': 'This work tackles the problem of learning the latent causal structure from multiple unpaired domains. Under a linear non-Gaussian condition, this work presents the identifiability guarantees for the joint distribution over the domains and the causal structure within the shared latent partition. Synthetic data experiments are presented to validate the theory.',\n",
       "  'strengths': '1. The problem is well-motivated and timely. Unpaired data are prevalent in the wild, and this work provides a rigorous treatment as the initial step to leverage such data in a principled manner.\\n2. The paper is nicely written, and the theoretical analysis is clearly articulated with sufficient explanations.\\n3. The theoretical techniques are clearly explained. Connections and attributions to prior work are appropriately introduced, which aids the assessment of this paper’s technical contribution.',\n",
       "  'weaknesses': '1. The linear assumptions: practical multi-domain (modal) data-generating processes are often highly nonlinear, e.g., images and text. The applicability of the linear assumption may not be as appealing.\\n2. The heterogeneous noise distributions: pairwise distinct exogenous distributions appear a strong assumption to me and can potentially oversimplify the technical challenge. I would be interested in learning about the necessity of such an assumption.'},\n",
       " 'review_118': {'summary': \"- The paper considers causal representation learning from unpaired multi-domain data, with latent variables both shared and specific to domains.\\n- Its key contribution is a new identifiability result for linear causal models with non-Gaussian noise, linear mixing function, and a number of other assumptions.\\n- In addition, the authors develop a practical representation learning algorithm for this setting and demonstrate it on toy data.\\n\\nI've read the authors' rebuttal. They have addressed my concerns adequately.\",\n",
       "  'strengths': '- Causal representation learning is an interesting, relevant, and mostly unsolved problem.\\n- The setting considered here (observational unpaired multi-domain data) is practical and well-motivated from single-cell biology applications.\\n- The identifiability result is, to the best of my knowledge, novel, and substantially different from existing results.\\n- As far as I can tell, it is also correct, though due to review overload I have not been able to check the proofs properly.\\n- The paper is extraordinarily well-written. The authors manage to be precise, yet still provide intuitive explanations.',\n",
       "  'weaknesses': '- The contribution made here has only one real weakness, and that is the host of strong assumptions underlying the identifiability result: 1D causal variables, linear causal model, no causal effects from shared to domain-specific latents, non-symmetric error distributions, different error distributions for each variable, linear mixing function, full-rank mixing function, observed variables include sufficient \"partially pure children\", and the list goes on. To put it bluntly, this list makes me wonder if this identifiability result present progress on the road to algorithms that work in practice on interesting real-world datasets.\\n    - Of course, strong statements such as CRL identifiability require strong inputs, but these need not be in the form of model assumptions, they could also come from the data side. Perhaps it is a bit out of scope for this paper, but I would be curious if the availability of *interventional* data or some other form of auxiliary data would allow the relaxation of some of these model assumptions.\\n    - While the authors do a good job in providing an intuition for why these assumptions are needed, I would like to know if there are any real-world problems that satisfy them all. This is partially discussed for single-cell data and a few of these assumptions, but could the authors provide a more complete example that ideally satisfies all assumptions?\\n- There are no experiments to speak of, though I also don\\'t think that all papers need experiments.'},\n",
       " 'review_119': {'summary': 'In this paper, the authors address unpaired multi-domain causal representation. In detail, the authors learn the representations of the observed data from different domains that consist of causally. To achieve this, the authors consider the data generation process where the relationship between the latent variables is linear. Based on this generation process, they prove that the joint distribution of observed data and the shared causal structures of latent variables are identifiable.',\n",
       "  'strengths': 'The authors investigate the causal discovery with latent variables from different domains.',\n",
       "  'weaknesses': '1.\\tThere are several works about causal discovery with latent variables under linear and multi-domain case like [1], which also considers the shared causal structure among latent variables and provide identification guarantees. It is suggested that the authors should discuss these works.  \\n2.\\tMoreover, the authors discuss several works about domain translation between unpaired data and claim that none of these works have rigorous identifiability guarantees. However, Multi-domain image generation, image translation, and domain adaptation belong to the proposed setting, and [2][3] have addressed the multi-domain causal representation learning problem recently. And the authors do not consider these works. It is noted that [2][3] considers the multi-domain causal representation learning with nonlinear transformation, which seems to be more general than the proposed setting.  \\n3.\\tAs for the identification of joint distributions, it is not clear why the identification of $l, B$, and $P$ can identify the joint distributions of observed data from multi-domains.   \\n4.\\tIn section 3, the authors assume that the distribution of errors is non-Gaussian for the identification of linear ICA by not allowing asymmetric distribution. But some distribution like the Laplace distribution is symmetric and they can also satisfy the identification of linear ICA.\\n5.\\tAccording to this paper, the authors consider the structure of latent variables to be linear but flexible. In the simulation experiment, the authors only consider three shared latent variables, it is suggested that the authors should consider more latent variables and different structures.  \\n6.\\tBesides, it is suggested that the authors should consider more compared methods and employ other metrics like recall, and precisions to evaluate the performance of causal discovery.  \\n\\n[1] Causal Discovery with Multi-Domain LiNGAM for Latent Factors  \\n[2] Multi-domain image generation and translation with identifiability guarantees  \\n[3] partial disentanglement for domain adaptation'},\n",
       " 'review_120': {'summary': 'The authors study the setting of unsupervised learning where observations belong to several domains, and we only observe the marginal distribution of each domain. A set of latent variables generates the observations, where a subset of latents are shared across domains. The authors provide the first identification results in this setting, assuming that the latents follow a linear SCM, and the observations are an injective linear transformation of the latents. With this model, identifying the (unobserved) joint distribution of the observations equates to identifying the latents. The mapping between the exogenous noises and the observations, as well as the distributions over the exogenous noises, are identified up to signed block permutation. With additional conditions, the authors also identify the causal graph for the latents up to a signed permutation consistent with the topological ordering of the latents. The authors validate their claims with a synthetic data experiment.',\n",
       "  'strengths': 'This is a strong paper that provides the first identifiability results on multiple-domain unsupervised learning where the joint distribution of the observed variables is unobserved. These results are impactful, since this problem setup is well-studied and has practical applications in single-cell biology. Existing approaches are significantly limited by their lack of identifiability, so this paper makes a valuable contribution.\\n\\nThe writing style is rigorous, and definitions, assumptions, and results are explained precisely.',\n",
       "  'weaknesses': 'This paper could be improved with more context on how they are extending existing identification results to achieve theirs. Currently, the authors mention which existing results are being used, but do not provide an intuitive description on why they need to be extended, and how they do so.\\n\\nThe notation could be improved. Capital letters are used to denote matrices, probability measures, vector- and scalar-valued random variables, sets of nodes, and sets of edges. It would improve readability if you used font styles (e.g. lower-case bold for vectors) to differentiate them.'},\n",
       " 'review_121': {'summary': 'The paper proposes a simple yet effective systematic solution to increase GPU usage and throughput during inference. The authors first make an interesting observation that the existing large language models are bounded by memory and the inefficiency is caused by the lack of awareness of the sequence length. Accordingly, the authors first fine-tune a small model DistillBert to predict the sequence length. Based on it, the authors accordingly schedule the generation of queries and deal with mispredictions. The authors conduct experiments with models from 6 billion to 175 billion parameters to evaluate the effectiveness of the proposed system.',\n",
       "  'strengths': '++ The paper solves a practical problem, personally, I think improving the GPU utilization can benefit the community and the deployment of different applications.\\n\\n++ The proposed solution is simple yet effective. Predicting the output sequence length first is a simple and intuitive way to schedule the network and better utilize the GPU. Although incorporating a new model introduces additional lags, the authors show that such overhead is negligible in Figure 6.\\n\\n++ The results look promising; the proposed method allows for larger inference batch size and during the inference, e.g., 32 -> 256 for LLaMA-13B and 4 -> 32 for LLaMA-32B, and hence achieves higher throughput.\\n',\n",
       "  'weaknesses': '-- Subsection Length-aware sequence scheduler in Section 3 is not very intuitive to the readers, especially the ones that are not directly working on the same topic. It would be better to illustrate more on how the bin packing problem is solved and the batching technique in ORCA (with an Algorithm or diagram or more descriptions).\\n\\n-- The authors only evaluate the proposed method on NVIDIA A100 GPU. However, it seems the design is not dependent on the architecture of A100 GPU. It would be better to also evaluate the proposed method on other GPU architectures.\\n\\n-- Minor: Distilbert in L169 and Distil-bert in L155'},\n",
       " 'review_122': {'summary': 'This paper presents a new solution to the challenges of GPU underutilization and increasing batch size in the generation task of Large Language Models (LLMs), rooted in the memory-intensive requirement to retain the K and V values of prior tokens. To tackle these issues, the paper proposes an efficient framework named S^3, which uses a fine-tuned Distillbert model as a predictor to forecast the output sequence length based on an input prompt. This predictive model guides query generation scheduling and manages mispredictions by halting sequences exceeding allocated memory and doubling their assigned memory. The proposed approach increases the maximum configurable batch size in both online and offline scenarios and improves throughput, reporting a throughput increase of up to 6.49 times. Although this paper offers improvements in handling memory allocation for LLM inference, there are some concerns about evaluation and ablation of the proposed techniques.',\n",
       "  'strengths': \"- This paper tackles the vital challenge of predicting output sequence length through a unique DistillBERT-based co-optimization of the system and algorithm. This approach effectively addresses the limitations of existing frameworks, namely HF-Transformer and FasterTransformer, leading to improved throughput while meeting SLO latency.\\n\\n- While larger models typically yield better performance, as the space for K, V caches reduce, effective memory allocation management becomes increasingly essential. The S^3 framework notably elevates the maximum throughput, particularly in larger models.\\n\\n- The S^3 framework optimizes the latency-throughput trade-off by adjusting memory allocation, leaving the model architecture intact and thereby maintaining model perplexity. Operating independently and focusing on performance enhancement, the framework doesn't impact the accuracy of existing LLM models.\\n\\n\",\n",
       "  'weaknesses': \"- While a major contribution of the paper is the prediction of output sequence length, the effectiveness of this proposed predictor isn't thoroughly evaluated. Tables 2 and 3 show a significant difference between the batch size predictions of S^3 and Oracle. The reasons behind this discrepancy need to be explained.\\n\\n- The effectiveness of the predictor appears to vary greatly with the fine-tuning dataset, with accuracies ranging from 65.6% to 98.6%. The paper proposes online learning, but this isn't evaluated. Additionally, the paper lacks an ablation study on the choice of predictor models and sizes.\\n\\n- The paper only compares the latency-throughput trade-off between vanilla systems and S^3 and doesn't compare average throughput and latency in specific tasks. This is crucial, as output sequence length prediction accuracy, which seems to be task-dependent, would likely impact this.\\n\\n- While S^3 meets the SLO limit, its implementation generally results in an increase in end-to-end latency. The paper doesn't adequately address how much each proposed technique contributes to this overhead.\\n\\n- The paper introduces a supervisor component to handle mispredictions, but the description of this technique is unclear. The supervisor appears to allocate double the memory when a previous allocation isn't sufficient. However, in typical scenarios with scarce memory, this could lead to problems if the predictor misestimates the batch size. More detailed explanations of various scenarios would be useful.\\n\"},\n",
       " 'review_123': {'summary': \"The paper tackles the problem of predicting the number of generated tokens for transformers in text generation tasks. This will help with better memory allocation and batch size management. The previous systems either used dynamic memory allocation (Hugging Face) which incurs inference overhead, or preallocated memory for over-estimated output length, limiting the batch size. This paper's prediction of output length achieves a larger batch size, thus increasing the throughput. Experiments show a 6.49x improvement in throughput. The predictor is get by training a Distilbert model.\",\n",
       "  'strengths': '1. The idea is simple but effective.\\n2. The paper is clear, well-written, and easy to read.\\n3. The evaluation is clear and convincing. It contains various settings, including different models, different hardware setups, online/offline with clear information presented (latency breakdown, batch size).',\n",
       "  'weaknesses': '1. It has not been discussed that different models can generate outputs with different lengths.\\n2. The evaluation does not contain different request patterns.\\n3. Missing the evaluation of throughput in term of token/s.'},\n",
       " 'review_124': {'summary': 'The paper proposes a scheme that increases the throughput during inference on Transformer large language models (LLM). Typically, LLMs require large amounts of memory, for model parameters and for the KV (key/value) cache. The KV cache size depends of the output sequence length, which is not known when inference starts. Some implementations allocate memory for the KV cache in small increments, causing large latency, while others preallocate for up to the maximum output sequence length, causing potential memory waste. The authors propose a method, called S3 (scheduling sequences with speculation), that predicts the output length, and allocates the KV cache accordingly. The predictor is a fine-tuned Distilbert model (66M parameters) with small size and fast prediction time. A scheduler batches requests according to a greedy strategy. A supervisor is in charge of checking GPU utilization and handling mispredictions, while at the same time training the predictor in the background. An experimental analysis shows the flexibility of S3 in offering a trade-off between latency and throughput.',\n",
       "  'strengths': 'Transformers are memory and compute intensive. Designing schemes that make better use of memory, thus increasing the latency and/or throughput is an important topic. The proposed solution is simple, and the predictor ran as part of S3 adds negligible overhead. The experimental results show improvements, generating by up to 6.49 times more sequences compared to other existing system.',\n",
       "  'weaknesses': 'The system will need more analysis in the future, based on real traces (which are not available for research community now), and considering realistic service level objectives.'},\n",
       " 'review_125': {'summary': 'This work builds an LLM inference platform, called S^3, around a sequence length predictor.\\nThe sequence length predictor is used to\\n1. batch LLM generations\\n2. pre-allocate kv cache (where all seq have similar predicted seq len)\\nS^3 also has a method for handling seq len prediction errors. They do pipelined generation. They unpad shorter seq to ignore wasting compute.',\n",
       "  'strengths': 'LLM inference is becoming a larger and larger part of the total compute used within large organizations. Decrease inference costs is an extremely impactful line of work.\\n\\nThe analysis of overheads is good.',\n",
       "  'weaknesses': \"\\nFor kv cache pre-allocation, the authors note that pre-allocation limits seq len, not pre-allocating kv cache slows generation. An obvious baseline is pre-allocating for S tokens at a time (eg S=64) and freeing kv cache mem of generations which have finished (this frees mem for the really long generations). This simple baseline would decrease the kv cache concat overhead by a factor of S and eliminates the overhead of the S^3 algo.\\n\\nThe work uses a sequence length predictor to build an LLM inference platform. This is great systems research, I'm not sure it's positioned well for NeurIPS.\\nThe work doesn't show how much of the benefit comes from pipelining vs kv cache preallocation vs seq len batching vs unpading. I'm not sure how much improvement each method is or if we're introducing other overheads by including methods such as seq len prediction.\\n\\nThere are great works on improving LLM inference. Why only compare to ORCA?\\n\\n\"},\n",
       " 'review_126': {'summary': 'The presented work proposes to design the forward and reverse process of diffusion models based on beta distributions (as opposed to Gaussian noise). It also showcases a new loss term based on KL-divergence upper bounds (KLUB) that can aid performance over the conventional ELBO-based diffusion model objective when used to optimize the proposed beta diffusion model. The paper shows that the proposed beta diffusion model can better model/generate synthetic distributions, especially point masses, compared to Gaussian diffusion, but lags behind it when used for CIFAR-10 image generation.',\n",
       "  'strengths': '- The paper is well-written\\n- Alternatives to Gaussian diffusion processes are an interesting and relevant direction\\n- The synthetic experiments give a good intuition on the advantages of beta diffusion over Gaussian diffusion (mostly in terms of modeling point masses)\\n',\n",
       "  'weaknesses': '- Comparison and discussion with related work is lacking. As a result, the novelty of the presented work is hard to assess. While not having a related work section may be okay in some cases, discussing relevant related work thoroughly is very important. In particular, the presented paper completely misses to discuss or even cite any closely related papers on alternative diffusion processes of which at least [1, 2, 3, 4] come to my mind. \\n- In addition, a quick literature search on my end popped out [5] (ICML 23), which to me seems like  extremely related work. [5] also proposes to use Beta distributions to design a novel diffusion process (and even go beyond that by extending it to a Dirichlet distribution-based diffusion model). While to be fair [5] can be deemed concurrent work to the one presented (and was uploaded to Arxiv only in May), I think that it is absolutely key to discuss this paper, outline how the presented work is different (or not) from it, and potentially even benchmark against it (in [5] they show that they outperform D3PM, which is a baseline in this paper too).\\n- There are multiple passages in the draft (e.g. line 78, 238, 346) that make it sound like KLUB-based objectives can be used for diffusion models in general, but there is no experiment backing this claim and it directly contradicts the authors themselves (lines 219-225). This seems like overclaiming to me.\\n- Experiments are not entirely convincing. While I see the value of the presented synthetic experiments, I believe that a more comprehensive evaluation is required. Some concerns that I have are: \\n    1) Both synthetic experiments seem to show to me that beta diffusion can model point masses better than Gaussian diffusion. This is great, but makes me question the value of having two synthetic toy datasets in the main paper that lead to the same conclusion, especially compared to including more challenging datasets (Cifar10 experiments are only shown in the appendix and not mentioned in the main text).  \\n   2) The lack of other convincing experiments makes it unclear how beta diffusion would perform on non-toy datasets (basically anything except for point masses and beta distributions), and it is totally nebulous in which cases, if any, beta diffusion could be a strongly performing alternative to other diffusion models (on cifar10, beta diffusion FID scores are worse than the ones from Gaussian diffusion or [2, 3]). The paper would strongly benefit from a more realistic example that showcases where beta diffusion may have an edge over other diffusion models on any relevant metric (does not need to be state-of-the-art performance). \\n   3) The authors can do a better job of describing how and why anyone should use a beta diffusion model. For example, the hyperparameter values for the synthetic experiments are quite different from the ones used for Cifar10 (some beta diffusion-specific ones include the diffusion concentration parameter and how to bound the data) , and there is no discussion on how to choose them in practice (or even how the authors arrived at their particular choice of values).\\n   4) The synthetic datasets would seem to be a great opportunity for a detailed exploration and/or ablation of the design space for beta diffusion. However, there are only few ablative studies presented, and for the ones presented it is unclear how statistically significant they are, since no error bars are shown (esp. Figures 2,3,5 should have them) . One ablative study that would be important to include is ablating \\\\beta_max from the appendix – To my understanding, when \\\\beta_max is chosen to be too large, the end distribution (of z_1) will be just a black image, in which case there would be no stochasticity at all coming from the initial conditions during the reverse sampling process, which implies that a trade-off exists that is important to understand. Additionally, it would be valuable to ablate using ELBO vs KLUBs as beta diffusion objective on a non-toy dataset (e.g. Cifar10), as well as ablating NFE (i.e. #iterations during inference) for any trained (fixed) beta diffusion model.\\n\\n[1] https://arxiv.org/abs/2208.09392\\n\\n[2] https://research.google/pubs/pub52492/  (TMLR 23)\\n\\n[3] https://openreview.net/forum?id=OjDkC57x5sz (ICLR 23)\\n\\n[4] https://openreview.net/forum?id=4PJUBT9f2Ol  (ICLR 23)\\n\\n[5] https://arxiv.org/abs/2305.10699 (ICML 23)\\n'},\n",
       " 'review_127': {'summary': 'This paper addresses a prevalent assumption found in deep generative diffusion models, which is the Gaussian assumption in both the forward and reverse processes. In this study, the authors explore the utilization of the beta distribution in these processes and establish several key properties. Firstly, they analytically compute the marginal distribution within the beta distribution framework. Additionally, they develop an analytical computation for the conditional distribution, given both the data point and a noisy sample, in the form of a scaled and shifted beta distribution. To optimize the beta diffusion process, the authors propose a combination of two distinct KL upper bounds, which is better than using the standard ELBO. The experimental results on a synthetic setup demonstrate the ability of the beta distribution to effectively model range-bounded data distributed across disjoint regions. Furthermore, they show the efficacy of the proposed objective functions. The supplementary material also includes preliminary experiments conducted on image generation tasks.',\n",
       "  'strengths': '[Uniqueness of the methodology]\\n\\nUnlike previous works on diffusion-based generative models that heavily rely on the Gaussian assumption for both the forward and reverse processes, this work stands out as the first attempt to introduce Beta distributions into these processes. This unique approach sets it apart from existing literature. Furthermore, the authors have devised an objective function specifically tailored to optimize the beta diffusion process, further distinguishing their methodology from previous approaches.\\n\\n[Presentation]\\n\\nThe manuscript is overall well-written and exhibits clarity in its presentation. Particularly, the introduction and related works sections provide concise and comprehensive summaries of prior research, effectively highlighting the distinction between the Gaussian diffusion process and the proposed Beta distribution process. To further enhance the motivation behind this work, it would be beneficial to include a practical scenario that illustrates the necessity of constructing the Beta diffusion process. This addition would greatly strengthen the motivation behind the study.',\n",
       "  'weaknesses': '[Absence of real-world experiments] \\n\\nThe main paper primarily presents experiments conducted on a synthetic dataset. While strong theoretical analysis can support the use of synthetic experiments, including more real-world experiments would further reinforce the proposed methods. It would be beneficial to provide practical scenarios that demonstrate why the beta diffusion process should be considered over the well-established Gaussian diffusion. In the supplementary material, preliminary experiments on image generation tasks are included, indicating potential in that direction. However, it is not entirely clear why the image generation task specifically requires a beta diffusion process. One could argue that since images are typically bounded within the range [0, 1], the beta distribution is more suitable. Theoretical reasoning supports this argument. However, in practice, simply clipping the values during the reverse steps is often sufficient to remove outliers during sampling.\\n\\n[KLUB] \\n\\nI remain unconvinced about the superiority of KLUB over the negative ELBO in optimizing the beta diffusion process. Could you provide further elaboration in the rebuttal? Additionally, I am curious if this argument can be generalized to the standard Gaussian diffusion process as well.\\n'},\n",
       " 'review_128': {'summary': 'This work introduces a new type of diffusion model based on the beta distribution. The end of this is to defined a diffusion model on data that lives inside a specified range, i.e. on an interval [a,b].\\n\\nThis is achieved by first defining a forward noising process conditioned on the initial data sample $x_0$, $q(z_t, z_s | x_0)$ as a bi-variate beta distribution. The marginals of this distribution are also beta distributions, and the conditional $q(z_t | z_s, x_0)$ is also a beta distribution. The distributions are parameterised in such a way that $q(z_0 | x_0) = \\\\delta_{x_0}$ and $q(z_1 | x_0) = \\\\delta_0$. Evolving $t$ from $0 \\\\to 1$ therefore maps between the data distribution and a delta at 0. This process can be seen as a form of continuous diffusion where the noise applied is multiplicative, rather than additive like in Gaussian based diffusions.\\n\\nThey then propose to reverse this distribution by learning the distribution $p(z_s | z_t) = \\\\mathbb{E}_{x_0\\\\sim p_0}[q(z_s | z_t, x_0)] \\\\approx q(z_s | z_t, f_\\\\theta(z_t, \\\\alpha_t))$ and reversing this with small time steps. The learning of this distribution is done by matching $q(z_s | z_t, f_\\\\theta(z_t, \\\\alpha_t)) q(z_t)$ to $ \\\\mathbb{E}[q(z_t, z_s | x_0)] $. This is done via an upper bound on the KL, that can be shown to be minimised when $f_\\\\theta(z_t, \\\\alpha_t) = \\\\mathbb{E}[x_0 | z_t]$. Various other options for KL upper bounds are also proposed to minimise this distance.\\n\\nThe methodology is demonstrated on a couple of simple 1D settings that show the method works well in these cases. \\n\\nI think this is a very good paper. I would give it a higher score if the preliminary image experiments were finished and added to the main text. I think they would make the paper much stronger - not because they are images per-se but because they show the method works well in high dimension. Other high dimension tasks would be similarly convincing.\\n\\n',\n",
       "  'strengths': '- The work is cleanly presented and easy to understand.\\n- There is an extensive exploration of the options available for training these models.\\n- The work opens up a discussion for other non-additive noise diffusion models, potentially using other infinitly divisible exponential families.\\n- The experiments are sufficient to convince me that this method does indeed work, and could potentially be practically useful.\\n- The experimental set up is well explained and looks highly reproducible.',\n",
       "  'weaknesses': '- I would have liked to see evaluation on some real world data settings to demonstrate the methods utility (in the main paper).\\n- [1,2] were publicly available about a month before the submission deadline. I appreciate that is close, but I would expect to see at least a related work discussion to these works, which is not present, as they cover the same range-bound data setting as this work. Ideally we would see a comparison to some of the experimental settings in these works.\\n- I was very surprised to discover image experiments in the appendix after nearly having finished writing this review - these should certainly be mentioned in the main paper (were these completed after the submission but before the supplementary deadline?)\\n\\n[1] Lou, Aaron, and Stefano Ermon. \"Reflected diffusion models.\" arXiv preprint arXiv:2304.04740 (2023).\\n\\n[2] Fishman, Nic, et al. \"Diffusion Models for Constrained Domains.\" arXiv preprint arXiv:2304.05364 (2023).'},\n",
       " 'review_129': {'summary': 'In this submission, the authors introduce a diffusion model for range-bounded data.\\nTo do so they introduce a noising process that is multiplicative (and not additive) that leads to conditionals that are beta distributed and converges to a beta distribution which is independent of the original datapoint.\\nThey propose to approximate the reverse diffusion by learning the denoised value of $x_0$ given the noised data $z_t$ and the level of noise $\\\\alpha_t$.\\nThey then propose an upper bound on the KL divergence between the forward process and this backward process.\\nThey showcase their model on a range of synthetic 1d datasets.',\n",
       "  'strengths': '- The proposed approach enables modelling distribution of data which is supported on collection of bounded ranges.\\n- The beta diffusion process leads to closed form conditionals.\\n- Since the Kullback-Leibler divergence between Beta distributions can be available in closed-form, the training loss can be computed efficiently.',\n",
       "  'weaknesses': '- I found this submission not so easy to follow at times. For instance, why is a separate Section 2.4 needed?\\n- The need to discretised the process to get accurate samples of $q(z_t)$ is a potential drawback of the approach. Is the neural network $f_\\\\theta$ evaluated at each discretisation step during training?\\n- The experiment are limited to synthetic datasets. It would be interesting to tackle binary label data, or categorical labels via stick-breaking construction as in [Pavel et al. 2023].\\n\\nDirichlet diffusion score model for biological sequence generation, Avdeyev, Pavel and Shi, Chenlai and Tan, Yuhao and Dudnyk, Kseniia and Zhou, Jian, 2023.'},\n",
       " 'review_130': {'summary': 'In healthcare analytics, cohort constructions is one of the key steps that drives the analysis. For most problems, where the outcome of interest is a disease, the problem has asymmetrical formalism - while patients with disease are defined using string criterion and are homogenous w.r.t problem the negative set can be diverse and can have important information that is under-analyzed. The authors present a Shapley value driven approach to analyze the negative set in terms of their contribution to the predictive power of the models. Furthermore, these mappings are transformed and clustered to identify potentially clinical important patients. They have presented results and commentary from clinicians on identified clusters.',\n",
       "  'strengths': '- The authors raise an interesting hypothesis about under-analysis of the negative samples that can drive the community to develop standard methods to handle such problems \\n- It is commendable that the authors validated their findings and presented commentaries from clinicians on the identified patterns. Such efforts are increasingly important to ascertain the clinical validity of proposed AI methods\\n- Overall, the intuition behind the method is novel and somewhat defensible. The authors have also made an effort to formalize many aspects of their approach \\n- The authors have also made an effort to validate the components of the method individually (see more on this below)',\n",
       "  'weaknesses': \"- The primary weakness of the paper is a lack of comparison against baseline methods that necessitates the complexity of the proposed methods. There is also a lack of studying the correctness of the proposed cohort discovery method. It may be beneficial for the authors to support their claim on a synthetic datasets and/or provide comparisons of discovered cohorts using other standard methods such as contrastive PCA. \\n- Continuing from the above, the computational complexity of the proposed approach hasn't been acknowledged in a satisfactory manner. While Monte Carlo methods have been proposed to calculate the values, the true complexity in evaluating over the entire negative set and the subsequent calculations imposed the isotropy constraints hasn't been analyzed clearly. \\n\\nEdit: The authors have responded by providing additional baseline comparisons that alleviates some of the concerns. I have updated my review to reflect the same\"},\n",
       " 'review_131': {'summary': 'This paper describes a method to understand the set of unlabelled / negative samples in a healthcare data-set. In this setting, one typically has a set of patients with a particular label, such as indicidence of a particular disease, and a large set of unlabelled samples. Training a classifier involves selecting some subset of the unlabelled samples as the set of negative samples for training. This set is often quite heterogeneous, so methods that enable better understanding of the structure in the data and selection of negative samples can be informative. \\n\\nThe key contributions are as follows:\\n1. Definition of the Negative Shapley Value Field, which associates the Shapley Value for the the prediction task of interest with each negative sample\\n2. Illustration of a representation learning method which discovers a low-dimensional representation for the negative samples in which samples with similar Shapley Values are close to one another\\n3. A method for cohort discovery based on clustering in the low-dimensional space and interpretive analysis to demonstrate the clinical coherence and relevance of the discovered cohorts\\n4. Demonstration of improved predictive performance when selecting samples based on the negative Shapley value\\n5. Demonstration that predictive performance is maintained when the low-dimensional representations are used',\n",
       "  'strengths': 'The problem of understanding and selective negative samples for cohorts in healthcare data is an important one and methods that can be used by practitioners in this domain will be valuable. \\n\\nThe authors provide a demonstration of the utility in improved classifier performance when limiting to the set of negative samples with Shapley value > 0. This is suggested to be due to those samples which have negative Shapley value corresponding to patients who are likely to present with AKI in the future, but do not yet have this information in their medical record. This is a nice result and tackles a common problem in biomedical data science. \\n\\nMapping the unlabelled samples into a low-dimensional space where samples with similar representations are expected to have similar Shapley values is shown to enable the discovery of distinct and interpretable cohorts of samples with similar features and similar Shapley values. This result could provide a useful tool for practitioners to select or filter the set of negative samples when building classifiers on EHR data',\n",
       "  'weaknesses': '*** These weaknesses have been addressed in the author response ***\\n\\nThe \"Effectiveness of the Negative Sample Shapley Field\", described in lines 316-322, is illustrated by showing that filtering the set of unlabelled samples to exclude those which had a negative Shapley value improves the performance of the trained classifier on held-out data reminded me of co-training [1] or positive-unlabelled learning [2]. It would have been interesting to see this approach benchmarked against other methods for developing classifiers based on positive and unlabelled data, where we expect a number of the unlabelled samples to be positive rather than negative samples\\n\\nThe \"Effectiveness of Cohort Discovery\", described on lines 332-345 is a nice result but it is not clear from the experiments to what degree the isotropy constraint enabled this. This could be demonstrated by an experiment in which the same SDAE model is applied to the data  without the isotropy constraint.\\n\\n[1] Blum, A., Mitchell, T. Combining labeled and unlabeled data with co-training. COLT: Proceedings of the Workshop on Computational Learning Theory, Morgan Kaufmann, 1998, p. 92-100.\\n[2] Bekker, J., Davis, J. Learning from positive and unlabeled data: a survey. Mach Learn 109, 719–760 (2020). https://doi.org/10.1007/s10994-020-05877-5'},\n",
       " 'review_132': {'summary': 'The paper addresses the cohort discovery problem for supervised learning in the machine learning for healthcare domain. Positive examples of the cohort are easy to identify while it is not as straightforward to determine which negative examples should be admitted into a cohort.  To deal with this problem, the paper calculates the data Shapley value of the negative samples in the dataset. Then, the paper carried out representation learning using a stacked denoising autoencoder to mitigate the nonuniform changes of Shapley value in the original feature space. Finally, the paper carried out clustering in the learned representation space to identify important negative examples to create the cohort. The paper evaluated the proposed method on a clinical dataset to demonstrate the utility of the proposed method.',\n",
       "  'strengths': \"* The paper deals with the cohort discovery problem, which is an important problem in the machine learning for healthcare domain.\\n\\n* The proposed method is straightforward and makes sense to me for the most part.\\n\\n* In terms of empirical evaluation, the paper provides a detailed explanation of the cohorts discovered from a clinical perspective, although I won't be able to judge whether such findings make precise, clinical sense given that I do not have a medical background. I also appreciate the authors carried out additional experiments to study the effectiveness of each component of the proposed method.\",\n",
       "  'weaknesses': '\\n* Because the proposed method is straightforward and directly takes advantage of existing methods, I am not quite sure whether the paper has enough technical novelty from a machine-learning perspective.\\n\\n* Regarding experiments, while I think the authors dive deep into providing an analysis of the outcome of the proposed method from a clinical perspective, there are no alternative methods compared to the proposed method to understand the performance of the proposed method. It would also be interesting to see the proposed method applied to more than just one dataset as discussed in the paper. Finally, it should also be noticed that identifying relevant negative examples is not a problem that is exclusive to the healthcare domain. Many application domains will be interested in the proposed method to identify relevant negative examples for binary classification problems. As such, the authors may also consider applying their methods beyond the medical domain down the road.\\n\\n* Clarity of the paper can be improved. Some key concepts are not well explained. For example, what is the role of data Shapley value? It appears to be the contribution of a data point to the learned classifier. The authors do not seem to elaborate on this concept enough in the paper. What\\'s the intuition behind it? Why it makes sense to use Shapley value to measure contribution?  I also don\\'t think the authors explain well the phenomenon of \"the non-uniform distribution of negative samples with similar data Shapley values\". Further intuition on this point will help to better motivate the need for representation learning.\\n\\n'},\n",
       " 'review_133': {'summary': 'This paper presents a Shapley value based cohort discovery, by constructing \"Negative Sample Shapley Field\" that possesses isotropy property. By doing so, negative samples can be effectively clustered and separated with respect to the Shapley values. ',\n",
       "  'strengths': 'I think this paper points out many important problems in healthcare research. Specifically, \\n1: how to deal with pos/neg imbalance and how to make better use of vast negative samples?\\n2: how to identify negative samples that are more useful for the current research problem? \\n\\nThe use of latent variable models to deal with misssingness in EHR dataset is a promising approach too. \\n',\n",
       "  'weaknesses': \"1: Correct me if I'm wrong, but I think Eq.2 is ill-defined. For any metric M, let's say accuracy, then $s_i = s_j$ as long as both negative samples have the same predicted labels by a predictor F, right?\\n2: Many parts need justifications. For example, a) why is the defined metric in Eq.2 means high contribution to prediction task? b) why does Eq.6 help with isotropy? c) How is k-th DAE different from a normal encoder with k layers? \\n3: I don't see why DBSCAN + AE is proposed as a contribution when you can simply use VAE. \\n4: I doublt the logic between line 248 and line 249. The defined Shapley value in Eq.2 is 0 does not mean these patients are healthy. Note that you are defining M=AUROC, therefore M has a very stable value when you have sufficient samples to draw a smooth ROC curve when calculating $M(D^+ \\\\cup A)$. As a result, $s_i = E[ M(D^+ \\\\cup A \\\\cup d_i) - M(D^+ \\\\cup A)]$ is usually zero.\\n\"},\n",
       " 'review_134': {'summary': 'The paper tackles the task spatializing a mixture of speech and body sounds at different points in a sphere around a human body without explicitly recording or knowing the sound source location. Towards that goal, the paper captures a new dataset of humans speaking and making different body sounds in a very controlled and extensive setup. The paper proposes a model that takes as input the time-warped audio recorded by a VR headset and the body pose sequence, and renders the audio at different points on the sphere conditioned on the azimuth and elevation of the points. Furthermore, the paper proposes a novel and intuitloss function to accurately model both speech and short-lived body sounds. The paper compares its model with a heurisitcal baseline, evaluates different versions of the loss function, and also reports results for different microphone channel count and an ablation of the model. \\n\\n\\nPost author-reviewer discussion: I have read the rebuttal. The responses are detailed and answer my questions. I have increased my score.',\n",
       "  'strengths': '1. The proposed task is interesting.\\n\\n2. The proposed loss is intuitive and seems to be well-designed.\\n\\n3. The dataset could also be a valuable contribution for the community.',\n",
       "  'weaknesses': \"1. a) The dataset capture seems to be done in just 1 environment. There is no discussion or experiments on the model's generalization to other environments.\\n   b) The capture setup seems to be pretty complicated and could limit the applicability of the model to novel environments if training needs to be redone for new environments.\\n\\n2. a) The capture scene seem to be simple in the sense that it doesn't contain other objects, is single-room in nature, etc. How would the model fare for more complex realworld scenes?\\n\\n    b) Would the model be able to accurately render sounds at locations that don't have a path of direct sounds from the source? \\n\\n3. How is the source location in L150-1 determined?\\n\\nMinor:\\n1. The shift-l2 loss doesn't seem to perform by itself in most cases (as also pointed out by the authors) even though the design is pretty intuitive.\"},\n",
       " 'review_135': {'summary': 'This work introduces an approach for generating spatial audio from a 3D human pose and microphones placed close to the subject’s head, e.g. on a VR/AR headset, as is the case here. The authors first collect a multimodal dataset that contains 3D bodies and audio, recorded using multiple Kinects for body tracking and 345 microphones for audio acquisition. The dataset contains multiple participants in different outfits and poses, generating different sounds following a pre-defined script. To generate spatial audio, the authors propose a model that receives as input the audio recorded from the headset microphones and the 3D body pose and predicts the audio signal recorded at a microphone of the spherical capture array. Using the audio at each microphone and the locations of each microphone, the authors compute harmonic sound field coefficients that best represent the sound field. ',\n",
       "  'strengths': '- Important problem with large impact: The authors tackle an important problem for AR/VR applications that has not yet received a lot of attention. Generating accurate sound fields promises to increase immersion and the realism of virtual experiences. The proposed dataset will be an important benchmark for the community and open up new and exciting avenues of research.\\n- Novelty: The proposed dataset is an important contribution with unique data that are not publicly available. \\n- A loss that is well-motivated by prior-work and adapted to the problem structure that leads to clear benefits.\\n- A simple model that merges different types of information, using well-proven components.\\n- Writing: The paper is well-written and easy to follow.\\n- Experiments: The experimental analysis is clear, highlights the effects of each design choice and provides insights into what makes the method work. \\n',\n",
       "  'weaknesses': '- The related work section lacks a discussion of recent methods that model sound fields using neural network fields, such as:\\n  - [Learning Neural Acoustic Fields](https://www.andrew.cmu.edu/user/afluo/Neural_Acoustic_Fields/).\\n  - [INRAS: Implicit Neural Representation for Audio Scenes](https://openreview.net/forum?id=7KBzV5IL7W)\\n\\nThese could also be useful baselines for the model, both in terms of accuracy and in terms of computation compared to the proposed method. Furthermore, the following datasets could be a useful discussion point for the related work section:\\n  - SoundSpaces: Audio-Visual Navigation in 3D Environments: A discussion of whether a similar dataset as the one proposed in this work could be constructed by simulating audio propagation from artificial bodies.\\n  - Talking With Hands 16.2M: A Large-Scale Dataset of Synchronized Body-Finger Motion and Audio for Conversational Motion Analysis and Synthesis: I believe the related work section could benefit from a comparison with this paper in terms of granularity of pose representation and sound field, number of persons and type of conversations.\\n'},\n",
       " 'review_136': {'summary': 'The paper introduces a novel model for a novel task to render a 3D spatial sound from human body motion and audio collected by headset microphones. The authors also present a novel dataset containing human body motion and audio for this task. The model takes encoded audio, pose features, and target microphone position to render the corresponding spatial sound. A novel shifted-l2 loss is also proposed to address the issue of big spikes in l2 error due to the small shifts of impulsive signals. Experiments and results demonstrate the effectiveness of the proposed method.',\n",
       "  'strengths': '1. The motivation and objectives are clear. To my best knowledge, it is indeed the first paper that aims to render 3D spatial sound from a human body pose.\\n\\n2. The dataset itself is valuable. It could unlock various interesting research projects in the future.\\n\\n3. The system is simple but effective. The proposed shifted-l2 loss is interesting and could be useful in other audio applications as well.\\n\\n4. Analyses of the roles of body pose and head-mounted microphones are well-done in the ablation studies.\\n\\n5. The phase is important and I am glad that the authors consider it in the optimization.',\n",
       "  'weaknesses': '1. While extensive quantitative evaluations and analyses are done, it is often challenging to understand the gap in the perceptual level. It would be great if there is a subjective evaluation to demonstrate both the importance of the proposed task/approach and the contribution of the technical components.\\n\\n2. It would also be nice to have more samples in the supplementary material for a subjective evaluation of the proposed approach.\\n\\n3. I wonder whether any failure cases are appearing in the current exploration stage.\\n\\n4. audio and visual data time synchronization is often challenging but the details to achieve that are missing.\\n\\n5. As the authors mentioned in the limitation, the current approach could not handle spatial sound for human-object interaction, mainly for far-field modeling, and require intensive computation resources.'},\n",
       " 'review_137': {'summary': 'This paper deals with the problem of predicting sound fields around human bodies and proposes a method that exploits binaural audio signals and human body motions. The proposed method first encodes binaural audio signals and human poses and then decodes them into audio signals that are supposed to be captured by surrounding microphones. Finally, the proposed method renders the predicted signals into sound fields. The proposed method also introduces a loss function that is robust against small time shifts of time-domain audio signals. Experimental evaluations with originally collected datasets demonstrate that the proposed method captured the ground-truth sound fields reasonably well and it requires full body poses instead of only head poses for obtaining good predictions.',\n",
       "  'strengths': '1. The problem dealt with in this paper is novel as far as I know. Although sound field prediction is one of the standard tasks in audio signal processing, sound field prediction with blindly moving microphones would be novel and challenging. This paper solves this problem by (1) assuming that sound is emitted from a human and the human wears microphones and (2) integrating pose estimation of the target human.\\n\\n2. The proposed method is technically sound. Since the current problem setting is sensitive to time shifts, the proposed method handles audio signals in the time domain, which is not so popular in multi-modal and cross-modal analysis with deep learning. The proposed method achieves time-domain processing by incorporating WaveNet-like decoders.\\n\\n3. The newly introduced loss function is also technically sound. Time-domain signals are more sensitive to time shifts than frequency-domain ones. The proposed loss function named the shift-\\\\ell_2 loss effectively mitigates this problem while maintaining its discriminability.\\n\\n4. The experimental evaluations demonstrate that\\n(1) the proposed method reasonably worked well,\\n(2) full-body poses contributed to the performance improvement of sound source localization compared with head poses, and\\n(3) the proposed loss function was effective for non-speech sounds.',\n",
       "  'weaknesses': '1. The current experimental evaluations do not contain comparisons with other existing methods. I understand that the current problem setting is novel and thus there are no existing methods that can be directly applied to this problem. However, several previous methods for sound field prediction have already been known, and experimental comparisons with one of those methods will be informative for readers.\\n\\n2. The problem setting seems to be too extreme. Sound field prediction and reconstruction are one of significant problems in audio signal processing. However, the current problem setting requires (1) humans as sound sources, (2) microphones worn by humans, and (3) external video cameras. In particular, the first constraint seems to be too strict. Some justifications and potential applications will be required.'},\n",
       " 'review_138': {'summary': 'This paper presents an optimized covariance design for A/B tests on social networks with interference. The authors address the challenge of accurately estimating the global average treatment effect (GATE) in the presence of network interference. They propose a method to balance bias and variance in experimental design by optimizing the covariance matrix of the treatment assignment vector. The paper derives the bias and variance of the estimator and proposes an algorithm to implement the desired randomization scheme. Simulation studies demonstrate the advantages of their method over existing methods in various settings. Overall, the paper contributes an approach to improve the estimation of treatment effects in social network experiments by optimizing the covariance design.',\n",
       "  'strengths': 'This paper presents a approach to optimize the covariance design for A/B tests on social networks with interference, which improves the estimation of treatment effects and enables more accurate decision making based on experimental results. The paper is well-written and clearly explains the problem formulation, assumptions, and the proposed method. The authors provide a thorough analysis of the bias and variance of the estimator, a upper bound for the MSE of the HT estimator, and a projected gradient descent algorithm to solve the optimization problem. The simulation studies demonstrate the effectiveness and robustness of the proposed method in various settings. ',\n",
       "  'weaknesses': \"1.\\tThe paper briefly mentions assumptions about the direct treatment effect and interference effect. However, a more thorough discussion on the validity and generalizability of these assumptions would be valuable. Additionally, discussing the limitations of the proposed method, such as its sensitivity to certain parameter values or potential biases introduced by the assumptions, would provide a more comprehensive understanding of the method's applicability and potential drawbacks.\\n2.\\tIn the experimental results presented in Tables 2, 5, 6, 7, 10, 11, 14, 15, 19, 22, and 23 in the appendix, it is observed that the proposed algorithm’s performance in terms of MSE is significantly weaker compared to other benchmark algorithms such as ReAR, IBR-p, and PSR. This suggests that further improvements may be necessary for the proposed algorithm to achieve competitive performance\\n3.\\tThe paper could benefit from a more detailed introduction and explanation of the motivation behind balancing bias and variance. Providing additional context and background information on this topic would help to strengthen the overall argument and improve the clarity of the paper.\\n\"},\n",
       " 'review_139': {'summary': 'In this paper, the authors propose a new algorithm for A/B test design under network effect with cluster level randomization. By derivation of an upper MSE upper bound with bias-variance trade-off, the authors reparameterize to directly optimize the covariance of the treatment vector. An efficient PGD algorithm is proposed for efficient optimization. Simulation study on a real-world network demonstrates the effectiveness of the proposed method.',\n",
       "  'strengths': '1. The authors study a very important and practical problem in A/B test design with reasonable assumptions on cluster level randomization.\\n2. The paper is well written and the proposed method is both explained clearly, with reasonable assumptions  and well justified with detailed derivations.\\n3. The proposed reparameterization and the PGD optimization algorithm makes  the algorithm practical and easy to implement.\\n',\n",
       "  'weaknesses': '1. It seems that the clustering algorithm plays a very important role in the quality of the A/B experiment design. From the covariate matrix formulation, maybe in some cases it would be better to directly merge two clusters instead of using the treatment vector to guarantee the same treatment. It would be very interesting to see how the proposed method performs under different cluster methods /parameters besides the number of clusters.\\n2. As A/B experiments are usually used in real large-scale networks, it would be interesting to see scalability results in terms of number of clusters for different methods under comparison.\\n3. As the authors point out in the future work, it would also be interesting to see some empirical evaluation on the tightness of the proposed upper bound on the MSE. It may provide some insight on whether further tightening the bound can bring additional benefits.   \\n'},\n",
       " 'review_140': {'summary': 'In this paper, authors present a novel experimental design to be used for randomized experiments under network interference.\\nAuthors begin by considering a baseline adjusted Horvitz--Thompson estimator (which crucially requires knowledge of $Y_i(\\\\mathbf{0})$) and a pre-specified clusterings.\\nGiven these two things, authors derive a bound on the mean squared error of the estimator under an arbitrary cluster design.\\nMotivated by a Grothendeick identity, authors propose an experimental design where a normal vector is sampled from a fixed covariance matrix $\\\\Sigma$ and the signs of the vector become treatment assignment.\\nAuthors propose to select an experimental design by (essentially) using the normal covariance matrix $\\\\Sigma$ as a decision variable and the upper bound on the mean squared error as an objective.\\nFinally, simulations are run to investigate the performance of the method under various types of model-mispecification.',\n",
       "  'strengths': 'The main strength of the paper is a novel method for designing randomized experiments under network interference. The novelty of the method comes from developing an objective function whose decision variables are continuous, (essentially) representing the covariance matrix of assignments. This stands in contrast to previous methods which focus on selecting clusters for independent cluster randomization designs. An additional strength of the paper is that the objective considers both bias and variance, which is uncommon: most approaches attempt to \"fix\" one of these two things, but typically not both.\\n\\nOne of the most exciting technical connections is the use of Grothendieck\\'s identity, which (to the best of my knowledge) has not been used in causal inference. This offers a new tool in the design of experiments, which I suspect will be useful beyond the specific design used in this paper.\\n\\nMoreover, the simulations are very well formulated and executed.\\nIn particular, the authors investigate the effectiveness of their design under various forms of model misspecification, which speaks to the robustness of the design.\\nThis is important to investigate via simulations, as formal theory seems difficult given the black-box nature of the experimental design.',\n",
       "  'weaknesses': 'There are several weaknesses of the current method.\\n\\n1. **Assumed Knowledge**: The paper makes some strong assumptions as to what the experimenter knows. For example, authors assume that the coefficients $\\\\alpha_i$ are known by the experimenter. I think most experimenters will find that knowledge of each individual $\\\\alpha_i$ is too strong of an assumption to be practical -- in the SUTVA setting, this implies that all individual treatment effects can be estimated perfectly without any randomization. In order to be transparent, authors should state this assumption and estimator earlier in the paper, perhaps replacing the HT estimator in (eq 5).\\n2. **Pre-specified Clusters**: The paper assumes that clusters are pre-specified and little advice is given to practicioners on how to select the clusters in order to minimize MSE.\\n3. **Understanding of the Variance**: In order to run power calculations, experimenters should have at least a rough understanding (e.g. asymptotic rates) of how the variance of the experimental design depends on sample size $n$ and network parameters. Because this method is based on a black-box optimization procedure, it seems hard to analyze the variance (i.e. optimal value).\\n4. **Confidence Intervals**: In practice, experimenters value interval estimators (i.e. confidence intervals) more than point estimators, as they provide a method for uncertainty quantification. The necessary tools for uncertainty quantification (e.g. Central Limit Theorem, variance estimation) are not presented in this paper.\\n\\nWhile authors should make certain minor changes to address the above, I think that these weaknesses actually constitute further research directions on this exciting method.\\nOverall, it is my opinion that the strengths of the paper outweigh the weaknesses.\\n\\nIn the two sections below, I discuss minor weakenesses in the technical discussions and literature review which should be addressed by authors before publication.\\n\\n## Technical Remarks\\n\\nBelow are some minor remarks on technical aspects of the paper.\\nI think there are a few technical issues in the discussions, but I believe these can be easily fixed and will strengthen the technical contribution of the paper.\\n\\n1. (Line 137) authors write \"without loss of generaltiy, we consider the balanced cluster-level randomization scheme satisfying...$E[z_i] = 1/2$.\" I think that this restriction is perfectly fine, but I would say it is not technically correct to describe it as \"without loss of generality\". Consider the usual SUTVA setting: if the outcomes under treatment have more variation than outcomes under control, then the Horvitz--Thompson estimator can be made to have smaller variance by setting $p$ so that treatment is assigned more frequently. I think the phrase \"without loss of generality\" is not warranted and a simple fix is to just remove it.\\n2. (Line 152) The word \"overparametrized\" is not quite standard in this literature so I\\'d recommend either informally defining it, or just saying that \"there are more unknown potential outcomes than observations\". This is true even under SUTVA.\\n3. (Line 208): Authors introduce what they call \"Assumption 2\". I would refer to this as a \"condition\" rather than an assumption. The reason is that Assumption 2 only plays a role in choosing the design -- using standard techniques (CLT + variance estimator), Assumption 2 would not be necessary for, say, the validity of confidence intervals. Some readers might misinterpret the use of the word \"Assumption\" to think \"if this condition does not hold, then the estimates are no longer statistically valid in some sense\".\\n4. (Line 254) Authors write \"This lemma enables us to sample from bivariates Bernoulli distribution with mean (1/2, 1/2) and any valid covariance\". While this is true for $n=2$ variables, I do not believe it to be true for general $n$ variables. It is sort of implied in the Section that this \"Grotendeick mapping\" can recover any covariance matrix of $\\\\pm 1$ variables. If authors have a proof of this, they should provide it; otherwise, they should clearly state that this \"Groethendeick mapping\" cannot generate all $\\\\pm 1$ covariance matrices. I think that clarifying this will increase understanding and appreciation of the method.\\n5. (Line 294): The Monte Carlo simulation is only performed 200 times. In my experience, this is quite low. Can you increase to 10,000 Monte Carlo runs before camera ready submission? This will increase the reader\\'s confidence in you results.\\n\\n## Literature Review + References\\n\\nThe authors have missed a few important references in the causal inference literature.\\nI believe these should be easily fixable and would increase the relevancy of the paper by better situating it within the causal inference literature.\\n\\n1. (Line 36-37) In reference to cluster designs, authors write: \"This technique is originally developed in [31] and becomes a prevalent paradigm for network experiment design\". I completely agree that [31] was an influential paper for introducing cluster designs to the computer science community. [35] works the exposure mapping framework for interference [1] which allows for this arbitrary network interfernece. However, the so-called \"partial interference\" assumption has been used since at least Hudgens & Halloran (2008) and cluster designs were advocated for here. So, I\\'d at least reference some of this early work on clustering in the context of partial interference. I think this will also tie your contributions back to the vien of causal inference in the statistics literature in a stronger way.\\n2. (Line 38) Authors write that \"sharing same treatment within cluster is usually necessary for characterizing the GATE\". I would remove or substantially weaken this statement. The proliferation of cluster designs is *not* because they are necessary; but rather, a conceptually simple yet effective type of experimental design.\\n3. (Line 64) Authors write \"In this paper, we propose to treat the covariance matrix of treatment vector as a decision variable in optimization\". The following paper seems especially relevant and authors should draw a comparison: Harshaw et al (2019) \"Balancing Covariates in Randomized Experiments using the Gram--Schmdit Walk Design\". This paper studies experimental designs that directly control the covariance matrix Cov(z) (via discrepancy theory) to bound the variance of Horvitz--Thompson estimator by an implicit ridge regression of outcomes on covariates. A key idea in that paper is to use the operator norm as a measure of worst-case variance, which seems like an alternative to your Assumption 2. Given the similarity in the spirit of the two papers, this paper would benefit from a brief comparison discussion.\\n4. (Line 94) Authors cite several papers on bipartite experiments. It seems that [15] and [16] are duplicates. To the best of my knowledge, the paper of Zigler & Papadogeorgou (2021) was the first paper to propose bipartite experiments (it has been a working paper since 2019), so a citation is warranted in that discussion.\\n5. (Line 104): Authors write \"Along the same direction, [32] tries to provide...\" I recommend revising this language. The word \"tries\" gives the indication that \"[32] tries and fails\".\\n6. (Line 108): In the discussion of partial interference, early work like Hudgens and Halloran (2008) is missing.\\n7. (Line 116): A citation of several papers with more general forms of interference is listed. The recent paper Harshaw, Sävje, Wang (2022) \"A design-based riesz representation framework for randomized experiments\" is worth citing, as it proposes a deisgn-based framework which captures and extends previous types of interference.\\n8. (Line 251): I haven\\'t read [19], but it was my understanding that Grothendieck\\'s identity is typically a different type of statement, where there are two fixed vectors $x$ and $y$ and the random variables are $\\\\textrm{sign}(\\\\langle z , x \\\\rangle)$ and $\\\\textrm{sign}(\\\\langle z , y \\\\rangle)$, where $z$ is uniform from the $\\\\ell_2$ ball. In fact, I have only seen Lemma 1 in certain course notes on Sums-of-Squares (though I\\'m sure it\\'s appeared in other places). If Lemma 1 does not directly appear in [19] then authors should cite a relevant paper that derives it. In fact, this would probably be helpful to tie your work back to theoretical computer science\\'s use of the technique.\\n\\n## References\\n\\n- Harshaw, C., Sävje, F., Spielman, D., & Zhang, P. (2019). \"Balancing covariates in randomized experiments with the Gram-Schmidt Walk design\". (arXiv:1911.03071)\\n- Harshaw, C., Sävje, F., & Wang, Y. (2022). \"A design-based riesz representation framework for randomized experiments\". (arXiv:2210.08698)\\n- Hudgens, M. G., & Halloran, M. E. (2008). \"Toward causal inference with interference\". Journal of the American Statistical Association, 103(482), 832–842.\\n- Zigler, C. M. and Papadogeorgou, G. (2021). \"Bipartite causal inference with interference\". Statist. Sci., 36(1):109–123.'},\n",
       " 'review_141': {'summary': 'This paper focused on designing a randomization scheme at the cluster level for the A/B test. It proposed and derived an upper bound for the MSE of the HT estimator, which was targeted to be minimized to optimize the experiment design. This article treated the covariance matrix of the treatment vector as the decision variable in optimization to represent a class of design. Besides, it proposed to adopt projected gradient descent to guarantee the validity of the optimized covariance matrix in order to generate a randomization scheme that supports legitimate sampling. Also, it stressed the significance of boas and attempted to balance bias and variance better. Systematic simulations on a real-time social network were conducted. Experiment outcomes were analyzed and different methods were compared to show the effectiveness of the newly proposed method in this article.',\n",
       "  'strengths': '1. This paper is generally easy to follow.\\n2. The problem is well formulated in a new perspective, with detailed analysis and deduction.\\n3. The effectiveness of the proposed method is verified in the experiment. Horizontal comparisons with existing methods are sufficient and effective.',\n",
       "  'weaknesses': '1. Insufficient background introduction. Different concepts in the area should be introduced more specifically and it is better to point out their connections. \\n2. Unclear notation definitions and explanations, leading to confusion in understanding.\\n3. Experiments were not comprehensive, or at least not comprehensively expressed.'},\n",
       " 'review_142': {'summary': 'This work aims to improve robustness-accuracy tradeoff in image classifiers, using the recent smoothing ideas. The authors propose two techniques for improving adversarial robustness without loss of accuracy. One is to fine-tune the prepended denoiser with a regularized loss, to reduce miss-classification of smoothed images. Second is to use a cascade of denoisers trained on different levels of noise to pick the highest level robustness radius. They test their method on CIFAR10 and ImageNet datasets. \\n\\n',\n",
       "  'strengths': '1) Focusing on important topic of robustness of classifiers. \\n2) Interesting method in cascading models from high noise to low noise. \\n3) Good empirical results compared to recent state of the art models ',\n",
       "  'weaknesses': 'The writing can be improved a lot both in terms of coherence and clarity. I found the paper lacking in a good flow and hard to read, because of redundant repetition, lack of a coarse to fine description of the goal and the result, redundant undefined notation. The authors The same amount of content can be written such that the reader can take the message with much less effort. \\n\\nWhenever a new notation is introduced, please describe what it is defining. The reader should not have to infer what symbol is refering to what. They should be mentioned explicitly in the text. Examples: $\\\\mathbb{P}, \\\\epsilon, x\\', \\\\underline{R}, \\\\underline{p} \\n,\\\\overline{p}, R^-$ ... This makes the paper more time consuming to read which is very unnecessary. As an example Theorem 3.1 is  unreadable due to undefined notation. \\n\\nI find the use of \"diffusion\" in the title somewhat misleading. I suggest diffusion be replaced with denoising since that is what has been used in the work as opposed to a diffusion process in the context of generative models. \\n\\nIn line 109 it is mentioned that the ideal denoiser should return the original image for any noisy image. This statement is incorrect and hold only for very small levels of noise. The error in denoising is inherent in ideal denoisers as well and hence the iteration.\\n\\nIn order to reduce misclassification, the authors suggest fine-tuning the denoiser instead of the classifier to make the training less cumbersome. Although this resulted in better accuracy, it is not clear if it makes sense in theory. The cause of unrobustness is the random or incorrect boundaries set by the classifier. The denoiser is optimal with respect to denoising loss, whereas the classifier is not optimal with respect to classifying smoothed images (it has never been trained to do so). So in theory, the network that should be fine-tuned is the classifier not the denoiser. '},\n",
       " 'review_143': {'summary': 'This paper builds on diffusion based denoised randomized smoothing. It analyzes two scenarios of model errors which are over-smoothing and over-confidence. To alleviate these issues, the authors proposed deploying cascaded randomized smoothing where samples are first smoothed with large variance that gradually decreases if the model abstains from prediction. Further, the diffusion model (denoiser) is calibrated to overcome the over-confidence problem.',\n",
       "  'strengths': 'This work has the following strengths:\\n\\n1- The problem this work is tackling is important. Building reliable and robust models are necessary for deploying such models.\\n\\n2- The paper reads smoothly in most parts. Section 3.1 introduces two problems in randomized smoothing and Sections 3.2 and 3.3 propose the two components of the proposed approach.\\n\\n3- The experiments conducted in this work covered the standard datasets and 3 related baselines.\\n',\n",
       "  'weaknesses': 'Despite the strengths of this work, there are few weaknesses that I would like to be resolved before getting this paper accepted:\\n\\n1- The experimental results are missing important strong baselines such as [1, 36] (from the main paper) and [12] from the appendix. Since the method of this work results in a different smoothing parameters for (potentially) different inputs, a comparison with data-dependent smoothing approaches is necessary.\\n\\n2- The proposed approach seems to provide very limited performance gains in the small certified accuracy regimes. For instance, comparing the certified accuracy in Table 1 at $\\\\sigma \\\\in [0.25, 1.0]$ and $\\\\epsilon =0.5$: The proposed method attains 40.5% while [8] attains a 59.8 using $\\\\sigma = 0.25$. Shouldn\\'t a fair comparison be comparing the proposed method to the envelop curve of each baseline across the three $\\\\sigma$ values?\\n\\n3- One ablation experiment that can potentially showcases the diversity of the obtained $\\\\sigma$ via cascaded smoothing is to plot a histogram of $\\\\sigma_x$ for when $\\\\sigma \\\\in [0.25, 1.0]$.\\n\\n4- Another experimental analysis is to show the number of samples that were suffering from over-smoothing or over-confidence before employing the cascaded approach and after.\\n\\n5- In terms of writing, I have the following minor comments/suggestions:\\n- The preliminary part about diffusion models in lines 116-128 is not used afterwards, especially the notation. Consider moving it to the appendix.\\n- $n$ was defined twice in the \"Evaluation metrics\" paragraph (line 285 and line 290) with two different values. Please consider modifying the second one.\\n- It is confusing to have more than one bold number per column in each table. Consider highlighting only one (perhaps the combined cascading + calibration).\\n'},\n",
       " 'review_144': {'summary': 'This paper identifies the accuracy-robustness trade-off in randomized smoothing and the over-smoothing and over-confidence issues in diffusion denoised smoothing. It then proposes a to finetune diffusion models to mitigate these issues by first passing a datapoint through a cascaded smoothing pipeline to obtain class label and then minimizing Brier loss and Anti-consistency losses. This allows the framework to achieve higher empirical accuracy and robustness.',\n",
       "  'strengths': '- The paper is clearly written and well motivated. \\n- The cascaded pipeline is novel and the explanations of the problems at hand are clear.\\n- Empirical evidence for improvement is strong.\\n- Ablation study and analysis is performed to investigate the effect of each proposed loss.',\n",
       "  'weaknesses': \"There are several places in the exposition that may require more clarification.\\n\\n- Why do we not update classifier? Line 218 - 220 state that finetinung classifier is more computationally intensive than finetuning denoiser. Isn't backpropogating through an entire trajectory of denoising process more prohibitively expensive than finetuning classifier, especially when the starting noise-level is high?\\n\\n- Can the classifier itself cause any of the two over-smoothing or over-confidence issues? In this case, do we wan to finetune classifiers? In so, how do we decide which model to finetune, or both?\\n\\n- There lack some empirical investigation on the runtime issue with denoising, as is more apparent for such a long sequence of denoising iterations. The cascaded smoothing starts at a high noise-level, so denoising should take longer time. What's the trade-off between the accuracy/robustness increase with runtime?\"},\n",
       " 'review_145': {'summary': 'This paper presents a practical method to address the issues of over-smoothing and over-confidence in randomized smoothing, thereby enhancing our understanding of the trade-off between accuracy and robustness. For over-smoothing, the author introduces a multi-stage approach for computing collective certified robustness without the need to specify noise scales. This novel process provides a more precise evaluation of the certified radius. Additionally, to address over-confidence, this study incorporates two proposed loss functions, namely Brier loss and Anti-consistency loss, to fine-tune the denoiser model. By integrating these two methods into Diffusion Denoised Smoothing, significant improvements in both clean and certified accuracy can be achieved.',\n",
       "  'strengths': '1. Cascaded randomized smoothing is a specifically designed method for more accurate certified radius evaluation for Diffusion Denoised Smoothing because with diffusion models, we do not need to train smoothed classifiers for each noise scale.\\n\\n2. Evaluate both empirical accuracy and certified accuracy for the robustness of the proposed method.',\n",
       "  'weaknesses': \"1. I don't think the cascaded randomized smoothing can overcome the trade-off between accuracy and certified robustness. Cascaded randomized smoothing is only a tricky strategy to make a better computation of the certified radius. It cannot improve certified robustness intrinsically.\\n\\n2. For calibrating diffusion models, I don't see an advantage compared with classifier fine-tuning in Carlini et al. And Table 2 in Carlini et al. shows a better performance than yours with classifier finetuning. Besides, normally speaking, fine-tuning classifiers is much simpler than fine-tuning diffusion models.\"},\n",
       " 'review_146': {'summary': 'This paper proposed a new technique for certified adversarial robustness based on randomized smoothing. Two certification schemes are proposed in the paper: first is cascaded randomized smoothing where multiple smoothed classifiers of different smoothing factors are aggregated together in an efficient way; the second part is a new fine-tuning method called diffusion calibration to address the overconfidence issue in the original randomized smoothing approach. Experimental results show that the proposed method improved upon the previous baseline approach of Diffusion Denoised Smoothing.',\n",
       "  'strengths': '1. Clarity: This paper is well-written. The method is clearly described and introduced. The results are presented in a concise and clear fashion.\\n2. Originality: The method is novel in two aspects. First, the proposed scheme of cascading smoothed classifiers of multiple smoothing factors is novel and promising as an approach for combining multiple smoothed classifiers. Second, two losses are proposed for calibrating the diffusion model in Diffusion Denoised Smoothing.\\n3. Significance: Randomized smoothing and its variant, for example, diffusion denoised smoothing are known to have practical limitations as they require huge certification samples to compute the certification bound. The proposed method for more efficient certification could pave the way for practical applications of randomized smoothing and diffusion denoised smoothing.',\n",
       "  'weaknesses': '1. While the proposed method delivers improvement of certification accuracies upon the standard diffusion denoised smoothing, the paper does not discuss the computational requirements. It would be good to discuss the computational overhead from running a cascading smoothed classifier and fine-tuning the diffusion denoiser, in the main paper. \\n2. It seems from the description of cascaded randomized smoothing in section 3.2, the prediction of the cascaded smoothed classifier is defined, different from what the original randomized smoothing proposed. Then i think there should be a subsection or paragraph defining the certification bounds from the cascaded smoothed classifier. Theorem 1 does not seem to point to which one is the new certification bound. I would suggest the authors to add a pseudocode in the main text or appendix describing how the prediction and certification is done for the proposed method, in a similar way to what the original randomized smoothing paper [1] did.\\n3. Section 3.1 discussed some of the limitations of randomized smoothing. It is not clear whether this is a contribution of this work or has been observed before. From the way it is described, these limitations seems like well-recognized in the research community. If that’s the case, it would be better to put this part in the background section to avoid confusion about the novelty. \\n4. Regarding the specific limitations of randomized smoothing discussed in Section 3.1, is there evidence that supports these arguments? It would be good to show empirical evidence of overconfidence or point to a previous work that has looked into this matter.\\n5. The Brier loss and Anti-consistency loss are proposed to address the overconfidence issue in randomized smoothing. The experiments could benefit from adding an evaluation confirming that the overconfidence issue is tackled via the proposed fine-tuning process, thus further supporting the validity and effectiveness of the approach.\\n6. The main contributions of the work are two parts: cascaded randomized smoothing and diffusion calibration. However, the title “multi-scale diffusion denoised smoothing” seems to only focus on the first part of the contribution. I would recommend a more proper title to reveal the true contributions of this work, which are not limited to cascaded randomized smoothing.\\n\\n[1] Certified adversarial robustness via randomized smoothing. Cohen et al, 2019.\\n\\n==================================================================   \\nI have read the rebuttal and i will remain my score.'},\n",
       " 'review_147': {'summary': 'This paper aims to provide asymptotically valid conformal prediction (CP) regions for the time series prediction problem. Similar to the adaptive conformal inference (ACI) framework [11], the main idea is to choose the appropriate quantile of the non-conformity scores (or equivalently tuning the miscoverage rate $\\\\alpha$) at each time step to fulfill the required error rate. The framework performs an online quantile update while taking into account the sum of coverage errors overtime to stabilize the coverage better. They provided theoretical analysis that guarantees the asymptotic coverage of the predictions made by their framework. Numerical experiments on real datasets show that their method brings more stable and efficient prediction sets than ACI. ',\n",
       "  'strengths': 'In general, I liked the idea of designing a PID-like framework. Thanks to this structure, the prediction regions turn out to be more stable and efficient. Moreover, it ensures that their framework never outputs infinite size prediction sets, which is a big advantage over ACI. Also, they provided many numerical experiments in the paper and the Appendix to illustrate the power of their proposed framework highlighting the effect of each block and different choices of hyperparameters. ',\n",
       "  'weaknesses': \"1. The related work section is not well-written in general. Also, it does not represent the works in the intersection of conformal prediction and time series prediction in a fair manner. Indeed many good papers are missing, such as \\n\\t- Foygel Barber, R., Candes, E. J., Ramdas, A., and Tibshirani, R. J. Conformal prediction beyond exchangeability. arXiv preprint arXiv:2202.13415, 2022,\\n\\t- Sun, S. and Yu, R. Copula conformal prediction for multi-step time series forecasting. ArXiv, abs/2212.03281, 2022,\\nto mention a few. \\n\\n2. The comparisons are limited to ACI. Though it is a natural baseline to compare with, many other CP frameworks are designed for the time series prediction problem. It is interesting to see how they behave compared to the methods proposed in this paper. \\n\\n3. The scorecasting block seems unnecessary and, to some extent, redundant. Accounting for a wrong choice of learning model (e.g., a model that does not account for the seasonality effect) can not be a part of the design of a CP framework. This point is also mentioned in the paper in lines 286-288. However, it seems that the authors tried to put this block to force the similarity of their framework and the (well-known) PID controller.  \\n\\n4. There are numerous design choices (such as the saturation function) and hyperparameters in the framework, and it's worth noting that several of them may not be immediately intuitive for people in the Machine Learning or Conformal Prediction community when it comes to making appropriate choices.\\n\\n5. Generally speaking, I am still unsure to what extent it is worth exploring frameworks with an asymptotic coverage property, while the popularity of conformal prediction lies in its ability to provide a finite-sample guarantee.\\n\\n6. Minor Comments:\\n\\t- There are some typos in Equation 5. \\n\\n\\t- Line115: There is a typo in the definition of the pinball loss (\\\\tau should be replaced with \\\\alpha). \\n\\n\\t- Line 178: The equation reference should be (10) instead of (11).  \\n\\n\\t- In the proof of Proposition 2., the capital C has to be replaced with the small c. \\n\\n\\t- Bringing the extensions of the proposed method (e.g., conformal risk control and Proposition 3. or conditional coverage) into the discussion section is unappealing.\\n\\t- In order to facilitate the comparisons for the readers,  it is a good idea to report the Avg. size of the prediction sets and Avg. coverage in the figures like what you have in the Appendix figures. \"},\n",
       " 'review_148': {'summary': 'This paper examines the issue of how to parameterize conformal prediction in the time series setting. It argues that standard conformal inference methods would not provide valid inferences in the sequential setting, which lacks exchangeability. To resolve this, the paper suggests using online quantile tracking, integrating errors for stabilizing coverage, and utilizing scorecasting in the presence of systematic trends. The authors establish the corresponding theoretical properties, such as asymptotic coverage and conduct several experiments to justify their approach.',\n",
       "  'strengths': '1. A new method for conformal prediction in the in the time series setting with a clear presentation of the details and background.\\n2. The authors show the proposed method has a major practical benefit, that unlike ACI (Gibbs and Candes, 2021), no infinite sets are produced.\\n3. The authors demonstrate the practical utility of their methods with an extensive series of experiments on a wide range of real-time series data sets.',\n",
       "  'weaknesses': '1. Although this paper present a general theorem that their method achieves asymptotic coverage, there is insufficient discussion on the coverage guarantees such as the lower bounds and upper bounds on coverage.\\n2. The authors also explicitly avoid addressing the choice of automatic algorithms for the\\ntwo parameter $C_{sat}$ and $K_I$ in the nonlinear saturation function.\\n3. In the sequential setting (7), the authors didn’t show how to select the learning rate\\n$\\\\eta$, what factors might affect the selection of the learning rate $\\\\eta$, and what impact this\\nselection have on the performance of the method.'},\n",
       " 'review_149': {'summary': 'The paper tackles the problem of conformal UQ under distribution shifts. This is a very realistic setting where the upstream prediction model cannot be frequently updated, and we still want to certify some level of safety. The paper cleverly fames the problem as a PID control problem, and provides a practical algorithm that they show is effective on synthetic and real datasets.',\n",
       "  'strengths': '- The setting addressed is impactful and practical. A major hindrance of using CP in ML systems deployment is that the exchangeability assumption is often violated. This work provides a practical adaptation while still maintaining some guarantees of the method. \\n\\n- The PID framing of the problem & solution is clever and insightful. (very Big Brain, if i may use gen-z lingo.) The two Gibbs & Candes paper from 2021 and 2022 for CP under distribution shifts was able to circumvent the exchangeability assumption and achieve some guarantees by transforming the distribution shift into a online optimization problem for a single parameter $\\\\alpha^*$, which they prove is similar to a P controller.  This work takes the idea a step further, and introduces the integrater (I) and forecasting (D) algorithms, completing the picture (fig 2 <- such a nice figure). \\n\\n- The method can utilize time-series modeling approaches to adapt to seasonality. \\n\\n- The experiment section is well-presented. It walks you through part-by-part of the PID controller and shows the impact of each. The examples chosen are clear and convincing. \\n\\n ',\n",
       "  'weaknesses': '1. The paper did not define some concepts it used in its writing. For example: \\n- line 29, exchangeability \\n- line 25, sharpest\\n- line 83, burn-in period\\n- line 137 (not really a definition just... what are you trying to say here?) \"the quantile tracker proceeds agnostically and performs the same updates in any case.\"\\n\\nI think explaining them, even just in the appendix, will help with clarity. \\n\\n2. The paper only compared to ACI & ablations of its own method. A common choice of algorithm for the scenario introduced by the authors would be Enbpi and SPCI from Xu & Xie (references 29 and 30 in the paper).'},\n",
       " 'review_150': {'summary': 'The paper proposes an adaptation to existing adaptive conformal prediction in two novel ways: (i) by tracking the quantile via online regression over the running sum of the errors; and (ii) by incorporating a second model to anticipate the quantile in the next instant (\"scorecasting\"). The authors include theoretical guarantees for the resulting method, as well as comparisons against a benchmark in the field (ACI, which is shown to be a a special case of the proposed algorithm) over many different datasets. ',\n",
       "  'strengths': \"- Clear: the paper is well-written and very clear regarding its contributions.\\n- Limitations: the discussions on the method's limitations are very helpful.\\n- Theoretical results: the mathematical proofs are easy to follow and the notation is clear.\\n- Empirical results: the empirical studies are extensive and cover several different datasets. The experiments in the supplementary material are also very thorough.\\n- Code: the code is well-organized and readable (but please include the `environments.yml` file, all the necessary datasets, and instructions on how to reproduce figures in the paper! See below).\",\n",
       "  'weaknesses': '- Theoretical guarantees: the guarantees of the proposed method are only asymptotic. Unfortunately, no finite-sample results are included. None of the theoretical developments in the paper showcase advantages that the proposed method has over leading alternatives. \\n- Baselines: there are many recent proposals in the field (even in your related works section), but the only baseline is ACI. SPCI (Xu and Xie, 2022) also obtained asymptotic longitudinal coverage of time series without creating infinitely-wide intervals; can you underline in what ways your proposal is better? \\n- Experimental results: Can you include more details on how the hyperparameters were chosen for the examples in the main paper (for example, $r_t$)? Having too many hyper parameters can be overwhelming to the end-user (I appreciate the discussion in appendices C and D!). It would be great to include at least one example of adaptive learning in the proposed algorithm. \\n- Scalability: all the time series considered, both in the main text and in the supplementary material (SM), are small, with the largest ones comprising around 3000 data points. In scenarios where new data arrives every second, for example, it is not clear if the method would work as-is or if any modifications would be needed. A discussion about this and an experiment with a very long time series would be great.\\n- References: the authors point out the field of online calibration, and mention connections to game theory and online learning, but never explicitly discuss the connection to their work. It would be nice to better understand what tools from the field you are using or building upon.\\n- Relationship to control theory: seems slightly out-of-place. Either explain the connection better (perhaps in the SM) or develop it in another paper? As it is, it\\'s hard for the CP audience understand what the PID is, or why this connection is relevant.\\n- Reproducibility: adding the proposed method\\'s pseudocode would help a lot, either to the main text or to the SM if space is lacking. Trying to reproduce the results following the README.md, I was instructed to install the dependencies listed on `environment.yml`, but no such file was provided and I had to track them down one by one. There also seems to be a dataset missing (`datasets/preds_cases.csv`) and not all plots from the paper were generated.\\n- Minor writing suggestion: on one hand, the relation to control theory seems currently very incipient and more of a curiosity, but it is presented prominently in a section of its own. On the other hand, the interesting Proposition 3 is cramped in the final section. You might consider adding an independent section for extensions and incorporate the control theory analogy into the final discussion section.\\n- Other minor suggestions: I don\\'t see the point of including the zoom in the figures; it oftentimes hides parts of the figure and the underlying patterns are clear from the whole graph. Besides the many plots, adding a table with a summary of the results among all datasets could help a reader to draw conclusions faster. The meaning of sublinear function is given in line 164, but the term is used before in lines 55 and 67, so we suggest bringing the definition up. Display (5) has a floating \\\\cdot in the last inequality and inconsistent usage (c \\\\cdot h(t) vs -ch(t)). Figure 1 caption says prediction sets are in purple, but it is actually in orange.\\n- Typos: line 115: $(1-\\\\alpha)$ should be $\\\\tau$; line 139: the em-dash is confusing.; line 151: \"an particular\" should be \"a particular; proof of proposition 2: $C$ should be $c$; display under line 192: the second $\\\\text{err}_i$ should be $\\\\text{err}_t$; line 201: \"can made\" should be \"can be made\"; line 295: \"saturation function as in 2\" should be \"saturation function that satisfies (5)\" or \"saturation function as in Proposition 2\"line 301: missing \\\\mathrm for err_i.; the bibliography is not printed in the SM and the references do not match the main text, so it ca be confusing.'},\n",
       " 'review_151': {'summary': 'This paper investigates the ResNet architecture, a popular deep-learning model known for its improved performance through skip connections. The authors aim to uncover the underlying mechanisms behind its success. They conduct an empirical study by linearizing the residual blocks of ResNet using Residual Jacobians and analyzing their singular value decompositions. The measurements and analysis conducted in the study reveal a phenomenon called Residual Alignment (RA), which is characterized by four fundamental properties. First, intermediate representations of a given input are evenly distributed on an embedded line in the space. Second, the top left and right singular vectors of Residual Jacobians align with each other and across different depths. Third, Residual Jacobians are at most rank C for fully-connected ResNets, where C represents the number of classes. Lastly, the top singular values of Residual Jacobians decrease inversely with depth. The study consistently demonstrates the occurrence of RA in ResNet models that generalize well. This phenomenon holds for both fully-connected and convolutional architectures across various depths and widths and different numbers of classes on benchmark datasets. However, RA ceases to occur when skip connections are removed. The authors also propose a novel mathematical model where RA is present. The findings suggest a strong alignment between residual branches in ResNet, imparting a rigid geometric structure to the intermediate representations as they progress linearly through the network until they reach the final layer, where Neural Collapse occurs.',\n",
       "  'strengths': \"Originality: Using the idea of linearization of the Residual Jacobian is commonly known for exploring the behavior of Residual Networks during the training and even pre-training. The authors use the idea of the Unconstrained Jacobian Model, which is interesting but also limited to a binary classification task. Still, it is novel to the best of my knowledge. \\n\\nQuality: The motivation and idea are clearly defined, and experiments support the RA phenomena.\\n\\nClarity: The paper would benefit from improved organization, such as relocating the related work section from section 5 to section 3 or 2. Additionally, the appendix appears disorganized, with figures located randomly. Other than these, it is written very well and easy to follow.\\n\\nSignificance: The study's results demonstrate the presence of the Residual Alignment (RA) phenomenon in the singular value decomposition (SVD) of the linearized Residual Jacobian. The mathematical analysis further confirms the occurrence of RA in binary classification. However, the paper lacks a deeper exploration of RA (2-4) and other potential insights.\\n\",\n",
       "  'weaknesses': 'Linearization of the Residual Jacobian and analysis of its SVD decomposition: Despite being a valid idea, is not novel. The authors could also potentially investigate the distribution of singular values with the help of random matrix theory. These singular values depend on the input feature vectors (or hidden representations), but this dependency is not explored.\\n\\nLimited applicability to binary classification: The use of Unconstrained Jacobian Models, while interesting, is deemed limited in the context of binary classification tasks. The paper does not explore its potential beyond this specific task.\\n\\nOrganization and clarity: The paper would benefit from improved organization, particularly in the placement of the related work section, which could be better situated in an earlier section. The appendix also lacks clear structure and organization, with figures placed randomly throughout.\\n'},\n",
       " 'review_152': {'summary': 'The paper tries to analyze the remarkable performance of ResNet architecture and they find the residual alignment phenomenon. The phenomenon is general and they also proposed a mathematical model call the Unconstrained Jacobian Models to theoretically analyze it.',\n",
       "  'strengths': 'The authors find an interesting phenomenon for residual networks called residual alignments. I think it can guide future exploration for module designing, model compression, and regularization techniques.',\n",
       "  'weaknesses': 'I think the weaknesses of this paper have they only discussed such a phenomenon. It will be great if they can utilize such phenomenon to design some useful techniques.'},\n",
       " 'review_153': {'summary': 'The paper \"Residual Alignment: Uncovering the Mechanisms of Residual Networks\" explores the underlying mechanisms and success factors of the ResNet architecture, which has gained significant popularity in deep learning. The authors conduct an empirical study by linearizing the residual blocks of ResNet using Residual Jacobians and measuring their singular value decompositions. \\n\\nThey introduce the concept of Residual Alignment (RA) characterized by four properties: equispaced intermediate representations, alignment of singular vectors, low rank of Residual Jacobians, and inverse scaling of singular values. The phenomenon of RA is observed in well-generalizing models and is absent when skip connections are removed. The authors also propose a mathematical model that demonstrates the occurrence of RA. \\n\\n*Contribution & significance:* The paper identifies an interesting and seemingly novel phenomenon which they term residual alignment. They show that this observation is on solid theoretical grounds by studying the binary classification problem with cross entropy loss.  This sheds new light on an the role of residual connections in neural nets and will contribute to our overall understanding of this importance architectural component. \\n\\n*Major writing issues* The main drawback of this paper is its writing quality which is very low at the moment. While I grasped the main ideas by going through the appendix, several of critical pieces of information, such as definition of residual alignment Jacobians ($J_i$\\'s), are missing from the main text. This will make it very difficult to understand this paper just by reading the main text (which should be the default assumption for a reader). This is quite unfortunate given that the contributions are technically strong & very interesting. Thus, a significant overhaul of the writing seems to be necessary to make this work publishable.\\n\\n*Clarity about novelty* It would be helpful if authors clarify the new insights and novelty of this work, in contrast to the paper that they numerously cite \"A Mathematical Principle of Deep Learning: Learn the Geodesic Curve in the Wasserstein Space\". Also adding more related literature will also be helpful to the readers.',\n",
       "  'strengths': \"- Identification of Residual Alignment: The paper identifies and characterizes an interesting and seemingly novel phenomenon of Residual Alignment (RA), and highlights its four key properties. The properties of RA are logically interrelated and consistently observed across various architectures. The authors present evidence to support the existence of RA.\\n\\n- The authors conducted a comprehensive empirical study of the ResNet architecture, linearizing residual blocks using Residual Jacobians and analyzing their singular value decompositions. This approach provides valuable insights into the underlying mechanisms of ResNet models.\\n\\n- Theoretical Proofs and Abstraction: One of the strongest points of this paper seems to be the theoretical proofs for the emergence of RA in the setting of binary classification with cross-entropy loss. The introduction of the Unconstrained Jacobians Model as a mathematical abstraction adds further depth to the analysis and strengthens the paper's theoretical foundations.\\n\\n- The proof the main theorem in the appendix is interesting in its own right. They authors first linearize the loss function and then approximate it as a product of $(I+J_i)$ terms where $J_i$'s are the Jacobians. They go on to argue that the loss of a general configurtion (non-aligned singular vectors) is surprisingly bounded by a term that is equivalent to the aligned Jacobians. This is mainly done by invoking an interesting mathematical theorem. While I did not go into full detail of the proof and there might be details/flaws that I missed, the overall proof strategy makes sense and is very interesting, as it breaks down a very intricate problem to a tractable one. (As a side point, I recommend authors to conduct a few more detailed experimentation on the details of these steps, namely by directly. testing the inequalities they arrive at). \\n\",\n",
       "  'weaknesses': '\\n# Major issues with writing & presentation of results\\n\\nOne of the main drawbacks of the current manuscript is its presentation. There are major problems with the flow and writing which hinder my understanding of some details. Another major issues is the lack of enough related works and connection to the existing machine learning & statistics literature. Overall, I would recommend authors to do a major revision of this manuscript to make it publishable and readable. \\n\\n I tried to compile a list of minor issues with the writing to help with this.\\n\\n- Fig 1 caption: “s true label and connected to form a trajectory” every connected line goes from input to output? Shouldn’t it have 34 layers (it looks like fewer dots than 34) \\n\\n- Equation line 34-35: what is $I$? \\n- Equation between 57 & 58, what’s the dimensionality of $ \\\\sigma’(…) $ in this equation? \\n- Non capitalised sentences (examples 68, 70, 74, 92, 93, several more ) \\n- Jacobians are input-dependent, how are the Figures 2 & 3 made? Do the figures correspond to a single sample input? or averaged across multiple inputs? \\n- What does index $i$ in $J_i$ stand for?  This seems to be defined in the appendix but in the main text?\\n- line 59 “excluding the contribution from the skip connection.” What does this mean? \\n\\n'},\n",
       " 'review_154': {'summary': 'This work discovers the phenomenon of Residual Alignment (RA) in ResNets, whereby the top left and right singular vectors of residual Jacobians align with each other and in between different residual blocks. Through extensive experimental verification as well as novel theoretical frameworks and derivations, the paper shows that RA naturally emerges in ResNets but does not emerge in non-residual networks. By directly linking RA to ResNets, this work sheds new light on the broad success of these architectures.',\n",
       "  'strengths': \"I believe this paper can have a significant impact.\\n- *Significance*: This work provides novel insights that have wide ramifications in a broad range of topics (deep learning theory, regularization, architecture design, model compression). Indeed, the precise mechanisms underpinning the success of ResNets remains a hot topic of research with high stakes. I believe this work makes a rare breakthrough in that direction.\\n- *Novelty*: To my knowledge, the discovery of RA and its precise mechanisms is novel. There is also novelty in both the experimental protocols and the theoretical frameworks. These protocols and frameworks might prove useful for the community.\\n- *Quality*: The analysis is highly convincing. I feel the experimental and theoretical evidences supporting the analysis are undebatable.\\n   - The experimental protocols are innovative and strongly convey the paper's claim, demonstrating both the presence of RA in residual networks and its absence in non-residual networks. \\n   - The theoretical analysis is equally innovative and excellent.\\n- *Contextualization*: The context of the work is appropriately provided (aside from minor points detailed below), with connections made to previous works, including to the latest developments on layer-wise Neural Collapse. The paper also details potential ramifications of the discovery of RA.\\n- *Clarity*: The paper is well-structured, concise, clear. The writing is good. The plots and figures are striking, providing the required evidence to support the claims.\\n- *Soundness*: The theoretical proofs are sound (aside from very minor points detailed below).\\n- *Reproducibility*: The authors released their code for reproducibility. The code is neat and clean, with high quality standards.\",\n",
       "  'weaknesses': 'I see *no real weaknesses*, only minor points that can be easily addressed.\\n\\nMinor points:\\n- Restriction to the context of classification. RA1 and RA3 are specific to classification, and all the tasks considered fall within such a context. If the findings are restricted to classification, I think this restriction should be clearly stated.\\n- I understand that the class-wise equi-spacing on a line of intermediate representations is a consequence of RA (in particular the scaling of top singular values inversely with depth), combined with the increased magnitude of $h_i$ due to the aggregated summation in ResNets. If this reasoning is correct, perhaps it would be worthwhile detailing it?\\n- The authors missed some previous works that studied ResNets vs non-residual networks at initialization, notably [1], [2] and [3].\\n- There seem to be typos on lines 160, 239, 243. Also shouldn\\'t \"these values\" be replaced by \"the top-1 singular values\" in the caption of Figure 5?\\n- It seems Theorem 3.1 is only proved in the context of binary classification. Perhaps this should be stated. Also, I believe there is a term missing in the Equation following line 11 in the Appendix. That term relates to $h_1 - U_{k,1} U_{k,1}^T h_1$ (as can be seen e.g. in the case where all $S_i$ would be equal to zero).\\n- Perhaps Theorem 2 in the Appendix should state the convention of positive singular values, meaning that inequality on the $\\\\sup$ of the trace would always be guaranteed, with equality obtained if the determinant\\'s sign equals 1. Also shouldn\\'t $L+1$ be replaced by $L$ on line 68?\\n\\nReferences:\\n\\n[1] The Shattered Gradients Problem: If ResNets are the answer, then what is the question?, D. Balduzzi et al., ICML 2017 \\n\\n[2] Gradients Explode - Deep Networks Are Shallow - ResNet Explained , G. Philipp et al., ICLR Workshop 2018\\n\\n[3] Characterizing Well-Behaved vs. Pathological Deep Neural Networks, A. Labatie, ICML 2019'},\n",
       " 'review_155': {'summary': 'The authors of this paper proposed to augment neural ODEs with an additional stabilization term that is derived from the pseudo-inverse of a Jacobian matrix to learn dynamics of a system from data. The authors provided theoretical grantees to show that their augmented version is still capable of learning the original dynamics despite having an additional term and that the additional term actually stabilizes the learned dynamics. Experimental results were shown and compared with a vanilla NODE across a variety of dynamical systems with different characteristics. ',\n",
       "  'strengths': 'The overall paper, description and explanations of the work is very well written and relatively accessible even to a reader who is not very familiar to the topic. I also appreciate the simplicity of the idea, in that the proposed stabilization term could potentially be easily combined with other variations of neural ODE methods to achieve potentially more accurate predictions. The experimental results were presented in a wide variety of scenarios and the benefits of the proposed method does seem significant when compared to Vanilla ODEs. ',\n",
       "  'weaknesses': \"The following are the two improvements that I believe could improve the paper.\\n\\n1. The idea behind this paper seems simple and the results seems promising, which given it's simplicity, could really be an impactful contribution. Hence, if the authors could also demonstrate the gains of this method on another variation of vanilla NODE and also perhaps an actual application, I believe this paper will be significantly stronger. \\n\\n2. The overall paper is relatively accessible to readers not familiar with the field from a conceptual point of view, however, it'll be more informative if the authors could more candidly explain the connection between certain parts of the paper. For example, it is not very clear from an initial pass how does the manifold relates to the loss function and training of the NDE and the additional stabilization term. \"},\n",
       " 'review_156': {'summary': 'This paper aims to learn ODE dynamics where the dynamics has some extra equation constraint. For example, a double pendulum with energy conservation. In the problem setting, a neural network is used to learn the time derivative of the system, the dynamics is then rolled out with a classical solver. To ensure the rollout respects the conservation laws, the authors propose to add a stabilizing term to the time derivative, which can be proven to make the rollout asymptotically converge to the manifold defined by the conservation law. The stabilizing term is implemented with peudo-inverse of the Jacobin of the conservation function. Experiments show that the proposed method can stabilize the rollout w.r.t. the conservation law, compared to the method without stabilization.',\n",
       "  'strengths': '- The paper has good theoretical analysis and the practical implementation is based on the theories.\\n- The experimental results are improved.',\n",
       "  'weaknesses': '- The baseline method involves no stabilization. Is there other simple method that can ensure the stabilization? For example, since the conservation equation is known explicitly, can one use one degree of freedom only to satisfy the constraints? I.e., if the output is $m$-dimensional, the network can only predict $m-1$ dimensions and use the conservation equation to compute the last dimension directly.'},\n",
       " 'review_157': {'summary': \"The authors propose a new method called stabilized neural differential equations (SNDEs) that enforce arbitrary manifold constraints for neural differential equations. The proposed method is applicable to any type of ODE, hybrid models (UDEs), and can incorporate any type of manifold constraints. The authors' showcase their work on first- and second-order systems including non-chaotic and chaotic, non-autonomous and autonomous examples. \",\n",
       "  'strengths': \"Originality: \\nThe related work is nicely covered with a specific focus on Hamiltonian/Lagrangian and other constrained neural differential equation methods. It has been made clear out of the related work, which previous approach is most similar to the work presented and how the current work differs/builds upon it. \\nThe proposed work is a novel perspective/approach on the existing work on constrained neural DE methods. It is largely based on earlier PhD thesis by Chin (1995) on stabilization methods for simulations of constrained multi-body dynamics. \\n\\nQuality: \\nThe submission is technically sound. I have not analyzed Proof 2 in depth, but based on the information that the authors' have provided, it seems supported. \\n\\nClarity: \\nThe submission is very clearly written making it enjoyable to read as it is clear and understandable for the reader. The submission is well organized, the notation is clear, the function input/output dimensions are clarified, as well as matrices are defined. \\n\\n\",\n",
       "  'weaknesses': 'Quality:\\nDespite providing a thorough overview of related work that also incorporate constraints, experimentally the authors only compare to NODE and SONODE which are known not to extrapolate well beyond the training regime due to the limited constrains/bias for the differential function/vector field. If the authors would have included comparisons to some of the other works mentioned in the related works section, such as Finzi et al., or other method that include a Hamiltonian constraint (SymODEN etc), it would put the present work in a better comparison to the related work in the field, as it provides an alternative to it. \\nAs such an explicit comparison has not been made, it is hard to evaluate the present method in context of other, constraint based Neural ODE type, methods. \\n\\nClarity:\\nEq (3). I assume there is a missing $\\\\in \\\\mathbb{R}^n$\\n\\nSignificance: \\nThe proposed method is a relevant contribution to the field, however, I miss a better empirical comparison to other recent constrained neural ODE methods, this would make the submission a lot stronger and a better contribution to the existing work in the field.  '},\n",
       " 'review_158': {'summary': 'This paper proposes a general framework to stabilize NODE models. By introducing a new stabilization term, it can learn vector fields that satisfy various conditions. The authors evaluate the effectiveness of the proposed method on several physical systems represented by ODEs.',\n",
       "  'strengths': '- This paper proposes a new stabilization term that makes it possible to learn vector fields that satisfy various types of conditions.\\n- The proposed method has been theoretically and experimentally evaluated, and the results are valid.\\n- The paper is well written.',\n",
       "  'weaknesses': '- Lack of clarity on how the problem setup differs from HNN and LNN.\\n- Insufficient discussion of applicability to PDEs.'},\n",
       " 'review_159': {'summary': 'Neural ODEs which learn a particularly dynamics can be unstable during evolution of the learned dynamics. This papers studies instabilities which take solutions outside of the constraint space of a given evolution. The authors show that a simple added control term to the learned evolution can improve stability noticeably. This added term, intuitively, projects part of the flow onto the tangent space of the constraint manifold. This stability term has the benefit that it is not complicated to implement, has some theoretical guarantees of stability, and works well in the models they consider.',\n",
       "  'strengths': \"As mentioned in the summary, I see a few benefits to the authors' proposed techniques:\\n- The method is rather simple and easy to follow. The reason why it enhances stability is readily apparent and experiments back this up.\\n- The authors raise an important point about neural ODEs in the context of constraints. As someone not completely familiar with the field, I appreciated how they setup the problem and discussed it.\\n- There are some simple theoretical guarantees of the stability of the approach. The experiments back up these theoretical guarantees, though the experiments appear to be focused on mostly toy models.\",\n",
       "  'weaknesses': 'Main comments:\\n- There are a host of tools in the Riemannian optimization literature that are relevant here and not discussed. For example, there exists many algorithms for learning flows or vector fields on manifolds (e.g. [1], [2]) and performing transport on those manifolds. There are also simpler methods such as projected gradient descent or riemannian descent via retractions of the exponential map which can easily stay on a manifold and could be adapted to this setting. I suppose the authors would argue that their idea is simpler, but I would not be convinced unless these are compared to at least empirically or theoretically.\\n- The authors\\' main contribution is addressing a control problem and not really a learning problem. The paper includes an additional term to the ODE evolution to better control the trajectory, but this parameter is not learned in any way. Thus, the problem they address is really one of control and not learning. This problem of stable control is well studied in control theory as far as I understand. I raise this point for two reasons. First, I worry the problem the paper addresses is a bit outside of the scope of this conference. Second, as I am not an expert here, it is not clear to me how effective their particular controller is. Perhaps the authors can expand on this point and address comparisons to methods in the control literature. \\n- The theoretical guarantees and experiments, I think, could be expanded. Related to my previous comments, the theorems are two straightforward statements about the added stability of the control term. There are no theorems relating to how much better this is for specifically learning tasks (e.g., some proofs about generalization error). On the experiments side, all experiments seem to be on toy models of small dimensional systems. It is difficult to see how much better this will work in higher dimensional or more complex systems. \\n\\n\\n\\nSmaller comments:\\n- Eq. 3 missing $u \\\\in \\\\mathbb{R}^n$\\n- A number of references have no journal or indication of where it was published (even an arXiv indicator)\\n- The pseudo-inverse can be expensive to calculate in high dimensions with large numbers of constraints. Is this an issue in practice? Have you considered faster approximations to this?\\n- Some portions of the text use $f_\\\\theta(u)$ and others $f_\\\\theta(u,t)$. I would stick with one notation and express whether or not the setting the authors study depends on $t$ explicitly throughout the work.\\n- All of the experiments seem to be on low dimensional systems. Is there a reason why the authors did not go to higher dimensional examples?\\n- Many of the problems people care about are on continuous spaces (e.g., fluid flow in Navier stokes). Does the method here extend to that setting in an obvious way?\\n\\n\\nReferences:\\n\\n[1] Lou, Aaron, et al. \"Neural manifold ordinary differential equations.\" Advances in Neural Information Processing Systems33 (2020): 17548-17558.\\n\\n[2] Ben-Hamu, Heli, et al. \"Matching normalizing flows and probability paths on manifolds.\" arXiv preprint arXiv:2207.04711 (2022).'},\n",
       " 'review_160': {'summary': 'The paper proposes a zero-shot TTS model, P-Flow, which combines a speech-prompted text encoder and a flow-matching generative decoder. The encoder generates a speaker-conditional text representation using the target speech prompt and text, while the decoder utilizes conditional flow matching to model the conditional distribution of mel-spec.  The evaluation shows that P-Flow achieves comparable speaker adaptation performance to the large-scale autoregressive models (e.g., VALL-E) with significantly fewer training data and more than 20x faster sampling speed. Subjective testing also shows human listeners prefer the audios generated by P-Flow compared to VALL-E due to its better pronunciation accuracy and naturalness.  ',\n",
       "  'strengths': \"1. The paper challenges the recent trend that using LM-similar training approach for speech synthesis, instead, it argues that non-autoregressive formulation using the cheaper traditional representations such as mel-spectrograms can make speech synthesis both fast and high-quality.\\n2. The paper proposed a novel speech-prompted text encoder. Combining the text and speech prompt, this encoder tries extracting speaker information from the prompt and generating a speaker-conditional text representation. Specifically, the MAS algorithm is utilized to align the text encoder output with the mel-spectrogram, and the training target of the encoder is set to minimize the distance between the text encoder representation and the mel-spec. It not only distills speaker information to the encoder representation but also provides a way for end-to-end training for the whole system.\\n3. The paper argues that it is sufficient to use the first-order Euler's method to solve the ODE during inference, instead of depending on the off-the-shelf numerical ODE solvers.\\n4. The paper proposes to guide the sampling trajectory away from the average feature vector computed from h.\\n5. The paper explains well why masked loss is necessary, i.e., preventing the model from collapsing to a trivial copy-pasting. Other works such as voicebox also utilizes masked loss but they do not provide a good explanation.   \\n6. The paper conducts extensive experiments to evaluate the performance of P-Flow in terms of objective metrics (WER, SECS, inference latency) and subjective metrics (CMOS, SMOS). The paper also provides an ablation study to show the effectiveness of speech prompting and guidance methods. \\n7. Both the experiment results and demo audios show that P-Flow achieves lower WER, competitive SECS, much smaller inference latency, and much higher human preference scores, compared with VALL-E.\",\n",
       "  'weaknesses': '1. LM-similar training approach, i.e., modeling the sequential discrete tokens in autogressive way, is supper good at long sequences, which has been demonstrated by the success of ChatGPT with very long input tokens. Since the paper is trying to argue that using non-autoregressive method with mel-spectrum representation is at least as good as the modeling metrology proposed in VALL-E, a very important experiment is to show the model\\'s performance in terms of the very long prompt text, which is missing from this paper.\\n2. The paper shows that P-Flow generated audios are preferred by human listeners compared to VALL-E, and it also points out that the difference is not only attributed to the model but also the performance degradation introduced by the neural codec. A very important experiment is to show compared to Encodec, what is performance gain can be achieved by the hifi-gan vocoder. This can help the readers to get a better insight regarding the potential of the model itself.\\n3. duration predictor is very important in P-Flow, however the paper does not provide the experiment results of the duration predictor, at least it should be included in the supplemental materials. \\n4. The paper uses the first-order Euler\\'s method to solve the ODE during interference. How this simple inference comparing to the off-the-shelf ODE solvers? \\n4. There are still some important things which are not clarified well. \\n   1) \\\\hat_{h} is not well explained, how to calculate \\\\hat_{h}? \\n   2) In table 1, the GT achieves higher WER comparing to P-Flow, why?\\n   3) during inference, \\\\hat_{d} is used to expand h_c to h. How about training, do you use d or \\\\hat_d?\\n   4) In table 2, the inference latency of VALL-E is approximated using the size of the transformer. The readers cannot tell how accurate the approximation is and I would suggest the authors to give more details regarding the approximation in the supplemental materials.\\n5. There are some typos: Line 147, \"it also serves encourages the\" should be \"it also encourages\"; L176, \"objective (L_{dur})is to minimized\" should be \"objective (L_{dur}) is to minimize\"'},\n",
       " 'review_161': {'summary': 'The paper introduces P-Flow, a novel zero-shot text-to-speech (TTS) model that addresses the limitations of existing large-scale neural codec language models. P-Flow utilizes speech prompts for speaker adaptation and consists of a speech-prompted text encoder and a flow-matching generative decoder. The text encoder generates a speaker-conditional text representation using speech prompts and text input, while the generative decoder synthesizes high-quality personalized speech at a significantly faster speed than real-time. P-Flow is trained on the LibriTTS dataset using continuous mel-representation and achieves comparable speaker similarity performance to large-scale zero-shot TTS models but with significantly less training data and more than 20 times faster sampling speed. The results demonstrate that P-Flow offers improved pronunciation and is preferred in terms of human likeness and speaker similarity compared to state-of-the-art alternatives.',\n",
       "  'strengths': '- Novel approach: P-Flow introduces a unique methodology for zero-shot TTS that combines speech prompts and text input for speaker adaptation, resulting in improved speech synthesis quality and faster synthesis speed.\\n- Data efficiency: P-Flow achieves comparable speaker similarity performance to large-scale models but with only a fraction of the training data, making it more data-efficient.\\n- Improved sampling speed: P-Flow demonstrates a significant improvement in sampling speed compared to previous autoregressive TTS methods and large-scale neural codec language models, enabling real-time or near-real-time synthesis.\\n- High-quality synthesis: The flow-matching generative decoder in P-Flow produces high-quality personalized speech, enhancing the naturalness and human-likeness of the synthesized audio.\\n- Preference over state-of-the-art: P-Flow is preferred over recent state-of-the-art counterparts in terms of pronunciation, human likeness, and speaker similarity, making it an attractive alternative for zero-shot TTS.',\n",
       "  'weaknesses': '- The motivation of using the flow-matching-based decoder is not very clear. This mask and prediction training schema can be applied to other generative models such as GAN and DDPM/DDIM. What makes you believe that the flow-matching model is the most appropriate choice?\\n- The evaluation of zero-shot performance in real scenarios is not verified. Although this paper assures no overlap exists with our training data, as Libri-TTS (the training set) is derived from LibriSpeech (the test set), the current results are not yet sufficiently convincing to demonstrate its ability and performance in real zero-shot scenarios.'},\n",
       " 'review_162': {'summary': 'This work propose a flow-matching zero-shot TTS model called P-Flow. It is fast and data-efficient in comparison with Vall-E.',\n",
       "  'strengths': 'I like the idea of flow matching, and it seems a new fashion for generative tasks. I do believe flow-matching will benefit the speech generation community.\\nThe idea of prompting speaker encoder is novel and potentially effective.\\nI believe the clarity and quality of the presentation are good and easy to follow.\\nThe samples in the demo page are promising.\\nThe major claims are supported with in-depth ablation studies.\\n',\n",
       "  'weaknesses': 'The overall novelty is limited. The main architecture of this model is very similar to recent NAR TTS models such as Glow-TTS, Grad-TTS. For example, all these models leverages MAS to compute alignments, and all these models have a powerful probabilistic decoder that\\nallows to learn complex distribution from known latent prior, such as normalizing flow (Glow-TTS), DDPM (Grad-TTS), and flow matching (P-Flow).\\n\\nFrom my side, the experimentation is far from sufficient. As I said, this work is very similar to NAR TTS models like Glow-TTS and Grad-TTS. A direct comparison of P-Flow with Glow-TTS and Grad-TTS in the high quality TTS synthesis is essential, or the authors could report\\nthe comparison of P-Flow with the promoting version of Glow-TTS or Grad-TTS in zero-shot scenarios.\\n\\nThe vocoder is trained separately.'},\n",
       " 'review_163': {'summary': 'The paper proposes P-Flow that can achieve high speaker similarity performance and fast inference speed on the zero-shot TTS Task. To improve the speaker similarity score, P-Flow uses  a speech prompted text encoder to generate speaker-conditional text representation for speaker adaptation. To achieve fast inference speed and high audio quality, P-Flow incorporates the flow matching generative decoder with the speaker-conditional text representation. Experimental results demonstrates that P-Flow trained on a relatively small dataset matches the speaker similarity performance of the large-scale zero-shot TTS models and has more than 20× faster sampling speed.',\n",
       "  'strengths': '1. The proposed speech prompt approach for the non-autoregressive zero-shot TTS model is interesting, which surpasses the speaker embedding approach and provides in-context learning capabilities for speaker adaptation.\\n2. In experiments, P-Flow shows comparable speaker adaptation performance to the large-scale autoregressive baseline using significantly fewer training data and a small transformer-based encoder.\\n3. The flow matching generative decoder enjoys a faster sampling speed than previous neural codec language models while maintaining a good audio quality.',\n",
       "  'weaknesses': 'After listening to the audio samples in the demo page, my main concerns are mainly related to the unstable timbre issue. Please refer to the following Questions section for details.'},\n",
       " 'review_164': {'summary': 'This paper proposed a novel multi-task optimization method aimed at mitigating conflict between task gradients without inducing the substantial time slowdown that typically comes with specialized multi-task optimizers.\\nThe proposed method, called FAMO, aims at improving the worst-case rate of improvement across all tasks at each step.\\nAt a high level, it does this by setting the weights of each task to minimize the gradient norm of the log task loss (similar to how MGDA sets weights by minimizing the gradient norm of the task loss). They show that finding these weights is the dual of finding the direction that maximizes the minimum rate of improvement across tasks. In practice however, these weights are learned over time via SGD updates after each optimization step of the main model, rather than optimized in full at each model update step.\\n\\nThe authors then demonstrate their method on a toy 2D loss landscape (used in prior work), showing that their method reaches the Pareto frontier of this problem, like other optimization methods (and unliked naive Adam), but has the closest overall compute time to Adam. Next, the authors compare their method to 11 other optimization methods for MTL on 4 supervised MTL and 1 RL setting finding that FAMO compares competitively (it is consistently in the top 2 or 3 performing methods) in all settings.  Finally, the authors demonstrate the performance efficiency of their method in the supervised learning settings showing that FAMO is slightly faster than comparable methods on settings with 2 or 3 tasks, and orders of magnitude faster as the number of tasks increases to 10 and 60.',\n",
       "  'strengths': '- The method being proposed has clear benefits in terms of speed / efficiency, especially as the number of tasks scales, which is very important in many MTL settings.\\n- The method is compared to a broad and representative set of optimization methods, and performs competitively on all benchmarks proposed even outperforming slower methods consistently.\\n- Moreover, the experimental methodology seems sound; all experiments consider multiple random seeds and 2 sensible metrics to compare methods are considered.\\n- The paper is well written, with good figures, clear descriptions, and the motivation is straightforward. Moreover, I find the proposed method to be explained well.',\n",
       "  'weaknesses': '- The primary contribution of FAMO (in my view) is the decision to maximize minimum task rate of improvement, by focusing on the gradient of the log loss, rather than maximizing the minimum total improvement (i.e. MGDA). However, this is not the “fast” part. The fast part of the method comes from optimizing the task-weights slowly, via gradient updates, throughout the optimization process. The authors do well to point this out in the appendix, but the effects of these contributions should be analyzed separately. In a deep neural network it is possible that the generalization benefits come from the amortized optimization of task weights, rather than the specific weight objectives. This could easily be addressed by, for instance, comparing amortized MGDA to FAMO, which is perhaps the most comparable setting.\\n- I feel as though GradNorm is also natural comparison to this method, given that it also learns task weights during training (in an amortized fashion), with the goal of balancing the average rate of improvement across tasks.\\n- [21] is referenced as suggesting that current optimization methods aren’t worth the tradeoff in computation time, but iirc their conclusion was that optimization methods actually don’t help performance over the baseline, which appears to not be true in this papers experiments. This discrepancy should likely be commented on.'},\n",
       " 'review_165': {'summary': 'This paper proposes a dynamic convex combination multi-task learning losses reweighting so that it can decrease different task losses more balancedly while having little computational overhead than simple task loss average. Specifically, they formulate an optimization problem to find a new “gradient” direction that can achieve sufficient relative-to-magnitude decrease for the worst task loss. Instead of solving this optimization exactly every update, the authors amortize the optimization by keeping dual variables on the probability simplex across updates and update them through one-step gradient descent after every primal variable (learnable parameter) update. Experimentally, the authors show that their proposed method FAMO can achieve comparable/superior on 4 multitask supervised learning benchmarks and 1 multi-task RL benchmark, while being more time-saving compared to other gradient manipulation methods.',\n",
       "  'strengths': '1. The paper is in general well-written, with a nice discussion about different multi-task gradient manipulation technique in Appendix A.\\n2. The proposed method FAMO empirically is competitive with other methods on multiple benchmarks.',\n",
       "  'weaknesses': '\\n**[Lack of proof for significant contribution]**\\n\\nIn terms of methodology, as the authors mention themselves, FAMO’s motivation formulation is basically applying MGDA to the logarithm of all task losses. Thus the formulation is practical but not very novel. What distinguishes FAMO from MGDA fundamentally is FAMO’s amortized optimization of the dual variable. I will raise additional question later in this section about solidifying this contribution. In terms of experiment results, the authors claim FAMO can perform better/equal to other baseline methods in terms of (1) final performance, and (2) wall-clock time. For final performance, it is not convincing enough that FAMO can always match/outperform other MTL methods. On CityScapes and CelebA, it seems to fall behind some other methods. On QM-9, it’s also not clear to me what’s the value of multi-task learning — it seems single task learning (STL) is better (with lower MAE values) than almost all MTL methods  (including FAMO) (please do correct me if I’m misunderstanding this). I would appreciate authors to provide further clarifications about these points. In terms of wall-clock time, the authors only show the wall clock time for each epoch for different methods. However, this neglects the fact that different methods might require different number of epochs to converge. It is conceivable that a non-optimization-amortized method could take longer per epoch but converge in fewer epochs than FAMO and thus could use less total time. I think the authors should also report the total time as it should be final metric to judge the wall-clock savings.\\n\\n**[Understanding the impact of amortizing the optimization]** A primary contribution of the paper is to propose to amortize the optimization to find the update direction instead of solving it exactly each update. Hence I believe it is important and useful that the authors provide experiment results on the non-amortized version of FAMO, where the optimization in equation (5) is solved exactly in each iteration. With this non-amortized result, it would provide the context of whether the amortization deteriorates the performance, allowing the readers to understand the room of improvement with amortization. Besides, it would also be interesting to see the amortized vs non-amortized comparison for MGDA to further understand this point.\\n\\n**[Potentially incorrect proof for proposition 3.1]** In the proof for proposition 3.1, the authors use the Lagrangian of the dual by adding $cz^\\\\top \\\\mathbf{1}$ to the objective to get rid of the simplex constraint. However, the simplex constraint is not only about sum of the variables being 1, but also about having nonnegative individual values. Thus, I believe these nonnegative constraint should also be reflected in the Lagrangian. Otherwise it needs to be specifically argued that the optimal solution cannot occur on the edges of the simplex.'},\n",
       " 'review_166': {'summary': 'This paper proposes a new multi-task balancing method with claimed O(1) efficiency, which is much more efficient than previous gradient manipulation methods.\\n\\nThe core idea is to let the multiple losses decrease at roughly the same speed.\\n\\n',\n",
       "  'strengths': 'The method is more efficient than previous gradient manipulation methods.\\nAuthors conducted lots of experiments on several datasets and show that the method is performing well on them.',\n",
       "  'weaknesses': '1. I think the contribution is little bit over-stated. When I read the title, abstract and introduction, I thought authors will present a novel method to manipulate task gradients with O(1) time and space complexity, which is awesome. Why I thought that? For example, in Figure 1, they compare FAMO with other gradient balancing methods like PCGrad and CAGrad, which balance task gradients with O(K) time and space complexity.\\n\\nHowever, authors actually do not manipulate gradients but weight losses. Losses weighting are not novel path with previous methods DWA and UW. If you balance losses rather gradients, of course you can have O(1) time and space complexity since you do not touch parameter gradients w.r.t to K losses. \\nIn Question [highlight in the introduction], authors want to design an MTL optimizer, which should handle the gradients of parameters. I am not sure if the algorithm proposed in the paper can be called a new optimizer?\\nMy suggestion is that authors can re-factory the story [title, abs, intro] as an efficient loss balancing methods, which seems more suitable to their contributions.\\n\\n2.  The method part is not presented very clearly, see the questions.'},\n",
       " 'review_167': {'summary': 'The paper addresses an important issue with (most) prior MTL optimization techniques which requires the computation of all per-task gradients, during training, for obtaining the update direction. This results in a $\\\\mathcal{O}(K)$ requirement in space and time where $K$ is the number of tasks. The authors propose a novel approach for dynamically weighting tasks using $\\\\mathcal{O}(1)$ space and time.',\n",
       "  'strengths': '1. The paper proposes a novel approach for addressing a known pain point with (most) SoTA multi-task optimization methods.\\n2. The paper provides strong empirical evidence which indicates the method performs on par with SoTA MTL methods (e.g., NashMTL, IMTL-G, CAGrad) while significantly reducing the optimization time.\\n3. The paper is well-written and well-structured. Connection to prior works in MTL literature is well established (Appendix A-B).\\n',\n",
       "  'weaknesses': '1. While the division of the proposed method follows a different trajectory, the proposed algorithm is fairly similar to MGDA. Hence, more discussion is needed on the connection between the proposed method and MGDA.\\n2. Please provide additional details on the experimental sections (data split sizes, HPs, etc.).\\n3. Hyperparameter (HP) optimization:\\n    - Previous papers on MTL (e.g., CAGrad) did not include a validation split for NYU/Cityscapes. If the authors follow the same settings, how did you tune FAMO’s specific HPs? \\n    - Missing details on the tuning of the lr for the task weights.\\n4. From section 5.4 (and as stated by the authors), it appears the method is highly sensitive to the choice of HPs.\\n5. It would be beneficial to include figures of the losses throughout the optimization process and some metric to verify that the losses decrease in an (approximately) equal rate.\\n6. It would be beneficial if you could provide a figure of the task weights throughout the optimization process.\\n\\nMinor: \\nTable 2, MR column missing indication for best-performing method.\\n'},\n",
       " 'review_168': {'summary': 'This work analyzes the learning dynamics of non-contrastive SSL approaches such as BYOL and Simsiam. Based on the proposed theory, the authors analyze the how the stop-grad and predictor module affect the learning dynamics. Importantly, the authors design a theoretically inspired loss and gain improvement on classification tasks.',\n",
       "  'strengths': '1. This work provides solid analysis and discussion on the learning dynamics of non-contrastive SSL algorithm, which contributes to our understanding of the algorithm. Especially, they consider the widely used cosine similarity loss, while existing works only discuss Euclidean loss. They also propose an isotropic loss which is inspired by the theory.\\n2. The simulation experiments helps understanding the proposed theory.',\n",
       "  'weaknesses': '1. Lack of basic introduction to the used techniques, e.g., the neural tangent kernal (NTK).\\n\\n2. Lack of awareness of dividing the article into paragraphs. The preliminary, theoretical analysis and the simulation experiment are all mixed in chapter 2, which might be confusing for readers.\\n\\n3. The accuracy for the baseline model (BYOL) is too low. In the well-known SSL repository, solo-learn [1], the top-1 accuracy of BYOL (R-18, 1000ep) is 92.58 on CIFAR-10, and 70.46 on CIFAR-100. However, in this paper the baseline is only 89.4 and 61.1. I am afraid that this experiment cannot justify the effectiveness of the proposed isotropic loss. \\n\\n4. This paper mainly provides theory to understand how non-contrastive SSL algorithms work (4 pages), and the design of the isotropic loss is inspired by the theory (only half a page). I think the title of this paper is not accurate enough.'},\n",
       " 'review_169': {'summary': 'The learning dynamics of non-contrastive self-supervised learning is an important problem to understand how these methods avoid collapse without using negative samples. In this paper, the authors provide a rigorous analysis of this problem on a simple linear network with Gaussian inputs, especially the difference between Euclidean and cosine loss functions. It is demonstrated that both losses have implicit regularization effects on the variance of representation, and the role of predictor and stop-grad operations are thoroughly investigated. Based on these insights, the authors propose an isotropic loss to equalize the convergence rate and lead to a better performance in various settings.  ',\n",
       "  'strengths': 'The theoretical analysis in this paper is novel and clearly improves the understanding of how loss function, stop grad and projector affect the performance of non-contrastive self-supervise learning. Based on the mathematical understanding, the authors propose a new loss function that could beat the baseline method on different datasets, which illustrates the validity and power of the proposed theory in practice.',\n",
       "  'weaknesses': 'The major weakness of this paper is the strong assumptions that require the network to be linear and the input to be iid Gaussian. For real-world datasets and practical network structures, it is not clear if those insights are still valid.  '},\n",
       " 'review_170': {'summary': 'This article builds on the theory of non-constrastive (nc) self-supervised learning (SSL), with methods such as BYOL or SimSiam. Contrary to the existing litterature, they study directly the cosine similarity loss used rather than a Euclidian loss on the eigenspace, using NTK dynamics. They show that collapse is avoided in this case with implicit variance reduction. With their analysis, they find an undesirable anisotropy which they fix with a new family of losses that outperforms the state-of-the-art, especially without needing an Exponiential Moving Average (EMA) target network.',\n",
       "  'strengths': 'The theory provides strong results in the linear framework, explaining the eigenvalues dynamics of both euclidian and cosine losses with and without projectors and stop gradients. The use of the NTK dynamics and the analysis of the cosine similarity is novel to me.\\n\\nThe findings that the eigenvalues affect learning as a learning rate provide a good justification for the new IsoLosses, which gives state-of-the-art results. In particular, the removal of the EMA and the increased dimensionality of the losses ensures their consistency.',\n",
       "  'weaknesses': 'One of the main claims of the article is the analysis of the cosine similarity loss. However in that case, if the dynamics are quite different as claimed by the authors, I find the use of the result of Tian et al. that the predictor eigenspace aligns with the one of the correlation matrix of the representations surprising since it was established with a Euclidian loss. I would have hoped atleast a comment on this, if not an analysis of the alignment as done in Tian et al.\\n\\nI was awaiting an analysis of the eigenvalues similar to Figure 2 for a real network, and not only a comparison with other losses. As such, the analysis of the IsoLoss feels a bit disconnected from the theoretical analysis. Why do the dimensionality increase? Is it because small eigenvalues do not collapse due to their low learning rates ? Do the eigenvalues evolve during training similarly to the linear case, for BYOL/SimSiam and IsoLoss ? (and their euclidian counterparts)\\n\\nTwo important notions in the theory of NC-SSL are the EMA and the weight decay. Since an important improvement of the method is the removal of the need of the EMA of the target network, I would find natural to mention the effect of the EMA in the dynamic. \\nSimilarly, the results of Wang et al. indicate the importance of the role of weight decay to collapse unwanted eigenvalues. I am surprised that the role of weight decay is not mentioned anywhere, especially despite its use in the implementation.\\n\\nThe formulation of the Isoloss (in particular the cosine similarity one) is very hard to interpret. However, it is logical due to the way it was found.\\n\\nThis is an interesting theoretical article despite some flaws and questions raised, and I am ready to raise my score if my questions are answered.'},\n",
       " 'review_171': {'summary': '\\nThis paper studies algorithmic fairness in multiclass classification setting. The fairness notion considered is parity of true positive rates (TPR) which is the multi class analog to equalized odds. The paper gives a post-processing algorithm which, given a score function, outputs a fair classifier. The paper then gives sample and time complexity guarantees and experimental evaluation on benchmark datasets. \\n\\nThis paper furthers work studied Alghmadi et al., which according to the authors, is the only other post-processing method available for multi-class TPR parity. \\n\\nThe paper gives a general post-processing algorithm that takes as input a score function and outputs a classifier that satisfies approx TPR party. The authors show that if you begin with the Bayes score function, their post-processing returns an optimal, fair classifier. They also give results showing that if the initial score function is not Bayes optimal but instead satisfies a decision calibration condition, then the post-processing is optimal among all classifiers that can be derived from the initial score function. \\n\\nThe post-processing method consists of two parts. The first part of the process estimates the feasible region of TPRs and then finds the utility-maximizing TPRs that satisfy fairness constraints (either exactly via search if we know the distribution, or via a linear program if we are estimating the TPRs from data). The second step involves finding the hypothesis that achieves these TPRs, which either corresponds to a tilting - essentially a threshold - of the score function without randomization or a mixture of two models that lie on the boundary. \\n\\nFinally, the paper gives some experimental evaluation on three benchmark datasets that serves as a proof of concept of the post-processing and showed that it is competitive with other standard techniques (notably reductions). ',\n",
       "  'strengths': 'Fairness via post-processing in multiclass classification settings is not a focus on most prior work on algorithmic fairness, which makes this an interesting and novel contribution. \\n\\nAlthough restricted to TPR parity, the paper does a complete analysis of the topic under this fairness definition. The paper addresses both not knowing the underlying distribution and so possibly starting from a non-Bayes score function and also discuss estimating the parameters from finite samples. ',\n",
       "  'weaknesses': 'The paper gets a little notationally and technically dense in Section 3. While the presentation is still fairly clear, I think additional higher level exposition to describe in particular Step 2 of the algorithm could be beneficial to readers - maybe including additional description of a tilting. \\n'},\n",
       " 'review_172': {'summary': 'The work proposes a post-processing algorithm to achieve the equal opportunity constraint in multi class classification. The proposed algorithm takes arbitrary Bayes rule estimate and only requires additional unlabelled data. The authors derive finite-sample guarantees and perform empirical evaluation to support their claims.\\n\\nI did not check the math, but, having prior experience in this area it looks believable.',\n",
       "  'strengths': 'The paper is well written and the proposed methodology is sound. It extends a rather long line of works on post-processing with unlabelled data.',\n",
       "  'weaknesses': 'In the context of the paper, I do not see major weaknesses from the methodological side, but rather remarks that are presented in the next part. \\n\\nFrom the theoretical part, I could mention that the devision by p_{a, y} with large number of protected attribute and classes can make the bound non-informative. \\n\\nI think that the expectation in the fairness guarantee is not well placed, I expected to have  $E[\\\\Delta(h)]$. '},\n",
       " 'review_173': {'summary': 'This paper proposes a novel post-processing approach to reduce the true positive rate parity for multi-class classification problems. It is shown on two real world data to outperform an existing baseline in terms of accuracy and true positive rate parity.',\n",
       "  'strengths': '1. The proposed approach is novel and technically sound.\\n\\n2. The proposed approach guarantees fairness by a sample complexity bound.\\n\\n3. The proposed approach outperforms an existing baseline post-processing approach in terms of reducing TPR parity.\\n\\n4. The presentation is clear.',\n",
       "  'weaknesses': '1. Some related work, such as [45], is mentioned in the paper but not compared in the experiments.\\n\\n2. Fairness in multi-class problems seems to be a rather trivial/incremental problem when there are plenty of approaches solving the fairness problems in binary classification and regression problems. Approaches from fairness in regression (e.g. Narasimhan et al., \"Pairwise fairness for ranking and regression\", 2020) should be easily applied to solve the fairness problems in multi-class classification. Please justify more for why Fairness in multi-class classification is a problem worth studying. Some approaches from fairness in binary-classification (e.g. Kamiran and Calders, \"Data preprocessing techniques for classification without discrimination\", 2012; Yu et al., \"FairBalance: How to Achieve Equalized Odds With Data Pre-processing\", 2023) can also be easily adapted to multi-class problems.'},\n",
       " 'review_174': {'summary': 'This paper considers fairness in multi-class classification under the notion of parity of true positive rates - an extension of binary class equalized odds - which ensures equal opportunity to qualified individuals regardless of their demographics. We focus on algorithm design and provide a post-processing method that derives fair classifiers from pretrained score functions. ',\n",
       "  'strengths': '- paper deals with an interesting problem\\n- paper is technically sound',\n",
       "  'weaknesses': '- paper does not properly compare w.r.t. the state of the art \\n- novelty of the proposal is not clear\\n- paper is hard to read and follow'},\n",
       " 'review_175': {'summary': 'In this submission, the authors advocate an inference attack composed of two stages for practical FR models. The first stage analyzes the distances between the intermediate features and batch normalization parameters. The second stage reconstructs data using a pre-trained generative adversarial network (GAN) guided by the attack model in the first stage.',\n",
       "  'strengths': '1.The writing and presentation are good and easy to follow.\\n\\n2.The experimental results also demonstrate some effectiveness of the proposed method.',\n",
       "  'weaknesses': '1.The overall technical contributions are somewhat limited, firstly, the way of using BN to perform membership inference attack has been explored for a long time. And secondly, the inversed training data are from a pretrain GAN, which is heavily depending on the strength of the pretrain GAN. And optimizing the synthesized face data is too weak only by the single supervision from the first stage. \\n\\n2.And from the Figure 3, I don’t think the recovered face data is visually close to the original data for some of the pairs. Therefore, I doubt that whether the authors really achieve the initial goal, recovering the similar enough or effective enough face training data, by their proposed method or not.\\n\\n3.The experimental comparisons are too simple and rough, lacking some important state-of-art related competitors. '},\n",
       " 'review_176': {'summary': 'The paper presents a novel method for inference attacks against face recognition method. In particular, it advocates two-stage inference attack, where the first stage identify the membership and the second stage involves model inversion attack that recover the input from embedding. Experimental evaluation shows that the proposed method can largely identify the correct membership and the model inversion sees good as well.',\n",
       "  'strengths': '1. It proposes a novel two-stage method for inference attack of face recognition systems.\\n\\n2. Experimental evaluation shows the proposed method has promising results.',\n",
       "  'weaknesses': '1. The evaluation is not thorough. It only conduct some ablation study with comparing to the existing attack methods.\\n\\n2. The paper does not cover some import topic for inference attack of face recognition, such as the black box attacks for face recognition.'},\n",
       " 'review_177': {'summary': 'The authors propose a membership inference attack against face recognition (FR) models in the white-box scenario where membership information is known for some records and white-box model access is available, but without access to a classification layer. The attack utilizes information stored in batch-norm statistics and using a meta-classifier, the authors demonstrate the effectiveness of the proposed attack. They also extend the attack to improve model inversion attacks by utilizing their membership-classifier to \"reject\" generated samples that fall below a certain threshold.',\n",
       "  'strengths': '- The utilization of an attack meant for one kind of privacy leakage (MI) in another scenario (model inversion) is interesting.\\n\\n- The paper is well written, and proposed techniques/motivation are explained properly.',\n",
       "  'weaknesses': '- L16: \"..very first....without a classification layer.\" This is not the first work to explore FR models that do not use a classification layers. Please refer to [1, 2]. Similar claims appear on L39 about necessarily requiring logit access for good model performance. The authors in [1] report near-perfect detection for 3 different kinds of learning algorithms/models, none of which require classification logits.\\n\\n- L25: \"attribute attacks (also known as property inference attacks)\" - these two are not the same at all. Similarly, L31-32 claim that all inference attacks on ML can be categorized into membership and model inversion attacks. Please refer to [3] for a detailed explanation and to better understand these differences.\\n\\n- L188: \"If it is from the training data set, then the attack model should output 1, otherwise we expect it to output 0\" -how is this membership information obtained? As also outlined in Algorithm 1, the attack very clearly assumes access to not only batch-normalization parameters (which can only realistically come from full-model white-box access), but also knowledge of $m$ members and $n$ non-members. While the latter is reasonable, assuming knowledge of members is a very strong assumption (on top of an already-strong access model).\\n\\n- L292 says \"...theoretically analyze..\" but nowhere in the paper did I see any theoretical analysis?\\n\\n# Minor comments\\n- Figure 2: Why is Stage 2 on the left? It seems counter-intuitive.\\n\\n## References\\n\\n[1] Chen, Min, et al. \"FACE-AUDITOR: Data Auditing in Facial Recognition Systems.\" USENIX, 2023\\n\\n[2] Li, G., S. Rezaei, and X. Liu. \"User-Level Membership Inference Attack against Metric Embedding Learning.\" ICLR 2022 Workshop on PAIR2Struct 2022.\\n\\n[3] Salem, Ahmed, et al. \"SoK: Let the Privacy Games Begin! A Unified Treatment of Data Inference Privacy in Machine Learning.\" 2023 IEEE S&P, 2023.'},\n",
       " 'review_178': {'summary': 'This paper introduces a novel inference attack algorithm for face recognition models that do not have classification layers. The proposed attack consists of two stages: membership inference and model inversion. The membership inference attack analyzes the distances between intermediate features and batch normalization parameters to determine if a face image belongs to the training dataset. The model inversion attack reconstructs sensitive private data using a pre-trained generative adversarial network (GAN) guided by the attack model.',\n",
       "  'strengths': '1) The paper introduces a novel two-stage attack algorithm for face recognition models without classification layers. \\n2) The proposed method outperforms state-of-the-art similar works and can recover the identities of some training members. \\n3) This research has implications for the development of more robust and privacy-preserving face recognition models.',\n",
       "  'weaknesses': '1) This paper would be beneficial to compare the proposed method with more state-of-the-art techniques to demonstrate its superiority.\\n2) This paper does not provide any code implementation.\\n3) The model performance used in the experiment is relatively low, and we hope to conduct experiments with models at a higher level of accuracy. (For example, ResNet200/VIT-Large on WebFace260M).'},\n",
       " 'review_179': {'summary': 'This paper investigates the theoretical complexity of finding the global optimal solution of ReLU networks and linear networks. Specifically, it first considers a specially designed neural network, each hidden neuron of which has only one outgoing edge. By using the homogeneity of the ReLU function, it reparameterizes this network such that all the weights (except the first layer ones) are either -1 or +1 (i.e., moves the absolute values into the first layer weights). In this way, it shows that it is possible to find the global optimal by enumerating the partitions of the data space, with time complexity that is polynomial in the dataset size (but not polynomial in network size). It also shows that a normal fully-connected neural network can be “blown up” to one with the above special design (out-degree = 1 for each neuron), by replicating hidden neurons that have multiple out-going edges.',\n",
       "  'strengths': 'The obtained time complexity of finding the global optimal is polynomial in the dataset size. \\n\\nThis paper handles multi-layer ReLU/linear neural networks, while prior works only obtain similar results on one-hidden layer networks.',\n",
       "  'weaknesses': 'The main trick of this paper is to consider those variables (e.g., network width, depth, input dimension etc) in which the time complexity is exponential or greater as constants, so that the time complexity can be *stated as* polynomial – in the remaining variable (i.e., dataset size). I don’t think this is a clever trick, as it does not solve the problem at all. Note that the complexity is far greater than polynomial (or even than exponential) in the other variables, for width $w$ it is $|D|^{w2^w}$, and for depth it is larger than $|D|^{2^{\\\\lambda^l}}$. \\n\\nGiven this large complexity in width and depth, the result of time complexity has little to no usefulness for practice. \\n\\nThe paper only focuses on the time complexity, while ignoring the space complexity – memory costs. Note that the blowing up procedure requires much more space complexity, which is exponential in depth. Recall that a neural network without blowing-up only requires space which is linear in depth. This huge memory cost is a drawback of the analyzed training algorithm, and should be considered and analyzed.'},\n",
       " 'review_180': {'summary': 'This paper studies the computational complexity of training linear and ReLU neural networks. Under assumptions such as the squared loss and the out-degree of every hidden neuron being exactly one, the authors prove that there exists an algorithm such that the global optimal solution can be computed in polynomial time for the linear and ReLU networks when the input dimension and the number of hidden neurons are fixed. To better understand the tractability of training linear networks, the idea of untangling is proposed and used to develop the existence of a polynomial-time algorithm for training linear networks. Although deciding whether a given architecture has an untangling is NP-hard in general, the authors prove that the complexity of determining this property for linear networks is linear time. They also provide a complexity result for computing an untangling of an architecture of bounded treewidth.',\n",
       "  'strengths': 'The novelty of this paper is clear. First, it ensures the existence of a training algorithm for linear and ReLU networks that achieves global optimal solutions in polynomial time under a different assumption compared to previous work. Second, the idea of untangling is proposed as a new assumption for studying these networks. These contributions could open up a new angle for studying the training complexity of ReLU and linear networks. The paper is well-written, and I enjoy reading the paper.',\n",
       "  'weaknesses': 'In my view, the assumptions are the main weaknesses of this work. The out-degree being 1 and the untangling of architecture are unrealistic assumptions. Deep neural network models in practice do not satisfy these assumptions. Second, finding the global optimal solution seems to be unnecessary. Usually, we would avoid getting to the global optimal solution because of overfitting. Third, when a machine problem is given, we only have the dataset so the number of hidden neurons $w$ is unknown. Based on these reasons, it seems hard to apply the results in this paper to applications.'},\n",
       " 'review_181': {'summary': 'The paper studies algorithms for exact minimization of quadratic loss over ReLU and linear neural networks when the total number of neurons is a fixed constant. The results can be divided into two parts:\\n\\n* A polynomial time algorithm for a fixed size ReLU/linear network, when it has the following structure: 1) One layer of neurons with arbitrary edges between inputs and those neurons. 2) A tree of neurons (i.e., every neuron has out-degree one) on top of that. More precisely, the algorithm runs in time $|D|^{O(nw 2^w)}$, where $|D|$ is size of the dataset, $n$ number of inputs, and $w$ total number of hidden and output neurons.\\n\\n* A polynomial time algorithm for a (possibly large) linear network whenever all hidden neurons can be collapsed (like in a graph minor) onto inputs and outputs such that the resulting bipartite graph is equal to the connectivity graph between inputs and outputs. So, it\\'s some sort of condition that says that the graph has a \"simple\" connectivity structure. This pattern of connectivity needs to be known to the algorithm, the authors prove that it is in general NP-hard to find it.\\n\\nIn both of these settings polynomial-time algorithms are already known for the most natural subcases (for example, one fully connected layer in the ReLU case).',\n",
       "  'strengths': '* The topic is interesting and relevant. As the authors point out, we know surprisingly little even about simple cases of this basic problem.\\n\\n* The paper is clearly written, including the context and exhaustive discussion of related work. It was a pleasure to read.\\n\\n* A lot of attention was paid to careful and correct explanations in the proofs.',\n",
       "  'weaknesses': 'It is not clear how many interesting new cases these theorems cover. I did not feel the results and proofs were particularly surprising. For example, the ReLU proof quite heavily (but skillfully) relies on previously used enumeration of hyperplane partitions. And the tree structure in the ReLU theorem does not look very relevant to practical architectures.'},\n",
       " 'review_182': {'summary': 'This paper studies the computational complexity of empirical risk minimization (ERM) for neural networks, that is, given an architecture and training data points, find weights and biases of a global minimum of the training error. The problem is well-known to be NP-/ER-/W[1]-hard already in very easy special cases. This paper identifies a bunch of cases in which it can still be solved in polynomial time, namely in each of the following cases:\\n- for ReLU networks with all hidden neurons having out-degree one, if the size of the NN is regarded as a fixed constant,\\n- for an improper ReLU learning setting, leading essentially to the case of the first bullet point by blowing up the architecture,\\n- for linearly activated NNs if they fulfill a certain structural property.\\n\\nMoreover, the authors analyze the computational complexity of determining whether a linearly activated NN satisfies the structural property mentioned in the third bullet point.',\n",
       "  'strengths': '- Given the significance and hardness of the problem, finding tractable special cases is a very important contribution to the theory of machine learning. This paper provides a decent starting point (building upon Arora et al. (2018)) and hopefully initiates further research towards this goal.\\n- The paper is mathematically very well-written. It even cleans up with some vagueness in previous work (see Remark after Lem. 3).\\n- The paper also is very precise in surveying the previous literature on computational complexity of ERM for NNs.',\n",
       "  'weaknesses': '- The obtained algorithms are only of theoretical interest because (i) the tractable special cases are rather unrealistic, (ii) the running times have still high dependencies on \"fixed\" constants, and (iii) this work focusses purely on minimizing the training error and neglects learning / generalization. So the paper should really be seen as fundamental theoretical research rather than pushing the frontiers of what we can do in practice. As such, I think it is of significant value.\\n\\nApart from this, I have many minor comments as below. None of them is a reason to downvote for me, but I urge the authors to carefully work on them for the next version:\\n\\n- My impression is that the abstract is not very informative. Instead of spending too much effort on motivating the results there (see also my next comment), it would be better to be more precise of what this paper actually proves (why not simply state the main results?).\\n- While I believe the paper makes important contributions (as outlined above), I am quite unhappy with the way the results are pitched, e.g. already in the abstract, and in lines 17-20, and other places where the authors claim that so little is known about the complexity of NN training. Yes, it is true that not many positive results have been achieved for pure empirical risk minimization, but this is for a good reason: the problem simply IS really hard in the worst-case, and this has been studied thoroughly. While I do agree that finding tractable special cases is an important research contribution, I believe that this will always only be possible for very special cases and therefore disagree with staging this as such a \"huge\" gap in the literature.\\n- a recent preprint you might not be aware of is: Froese, Hertrich: \"Training Neural Networks is NP-Hard in Fixed Dimension\" (https://arxiv.org/abs/2303.17045). This includes a multitude of new stronger hardness results for both ReLU (and linear threshold) networks. I think you should cite this in line with other negative complexity results you already cite, like (Arora et al., 2018; Abrahamsen et al., 2021; Goel et al., 2021; Froese et al., 2022; Bertschinger et al., 2022). In particular in line 52, for the constant n case, the Bertschinger et al. (2022) result relies on multi-dimensional outputs. The new preprint suggested above shows that NP-hardness can already be achived with a single-dimensional output (and still only 2-dimensional input).\\n- line 65: \"it is not difficult to show that LIN-NNT is poly-time tractable for any network of bounded size\": why is this the case? can you please elaborate? And does it depend on whether the NNs are fully-connected or not?\\n- lines 68-69: are you referring to arbitrary n but constant w here? If so, please make the arbitrary dependence on n more explicit.\\n- lines 90 and beyond: are you still talking about fixed size?\\n- line 278: \"save\" -> \"except\"?? (or I completely misunderstand this sentence)\\n- line 282: the ellipsoid method is NOT polynomial in the number of variables and constraints. In fact, its time complexity depends on the bit-length of the encoding of the input. It is what people call \"weakly polynomial\" and there is no strongly polynomial time algorithm known, even for the special case of linear programming. This also affects the running time of the overall algorithm. It should be something like $|D|^{\\\\mathcal{O}(nw2^w)}\\\\cdot\\\\mathrm{poly}(L)$, where $L$ is the bit-length of the encoding of all data points. Please fix this everywhere in the paper where you state running times involving a quadratic program (for example, this also applies to Thm. 12).\\n- line 297: in addition to the cited thesis, you should probably also cite the paper the thesis is based on (Hertrich, C., Basu, A., Di Summa, M., & Skutella, M. Towards lower bounds on the depth of ReLU neural networks. NeurIPS 2021.) and additionally the following paper making significant progress towards proving the conjecture: Haase, C. A., Hertrich, C., & Loho, G. Lower Bounds on the Depth of Integral ReLU Neural Networks via Lattice Polytopes. ICLR 2023.\\n- line 305: point (2): \"polynomial-time training\" is very misleading here, this is only true if the architecture size is regarded as a fixed constant!\\n- general comment about Section 5: what you are doing here is known as improper learning in the learning theory community. You should probably mention the term and compare to the respective literature. In particular, while you prove that your blow-up procedure does not increase the training error, such a move might heavily increase the generalization error of empirical risk minimization in learning settings. You should mention this!\\n- line 348: Are you a \"such that\" missing at the end of this line?\\n- line 379: d3 -> d_3'},\n",
       " 'review_183': {'summary': 'The paper studies the neural network training problem for ReLU and linear networks. They show new settings where the problem can be solved in polynomial time. They provide two main contributions: \\n- For ReLU networks, they give a polynomial-time algorithm for training constant-size networks where the out-degree of all hidden neurons is $1$. This extends similar previous results for depth-$2$ networks. They observe that every constant-size network can be transformed into a network with the above structure. \\n- For linear networks, they identify a condition, called untangling, that allows for efficient learning if the untangling is given. Finding an untangling is NP-hard in general, but if the network has a constant number of hidden neurons or a constant treewidth, then it can be found in linear time.',\n",
       "  'strengths': 'The neural network training problem is a natural question that has been studied in several prior works. This paper makes a further step towards understanding when this problem can be solved efficiently, for both linear and ReLU networks.\\nAlso, the paper is well-written.  ',\n",
       "  'weaknesses': 'My comments are regarding the result on ReLU networks:\\n- The result requires out-degree of exactly $1$ for all hidden neurons. It is indeed more general than the results of Arora et al. 2018 and Boob et al. 2022, but the family of networks covered by the new result and not by the previous ones is somewhat restricted. The authors show that every constant-size network can be transformed into a network with the above structure, but it is not clear to me what the implications of the ability to solve the problem for the transformed network are. It would be helpful if the authors elaborated further on the motivation for this transformation.\\n- I am trying to understand what are the main technical differences between the current result and Arora et al. 2018, and what are the main non-trivial steps. I would be happy if the authors elaborate more on this issue. Below I provide some comments in this respect: \\n    - Regarding Lemmas 1 and 2: The idea of “pushing the weights backward” in ReLU networks with out-degree $1$ of each neuron (i.e., making all weights in {-1,0,1} in all layers except for the first layer) is not new. It was done, e.g., in [1].\\n    - Regarding Lemma 3: The authors compare it to Arora et al. in the Remark, and claim that both the bound on the number of partitions and the efficient enumeration method are essentially new. I actually believe that the $|D|^{O(n)}$ bound on the number of partitions follows immediately from the Sauer–Shelah lemma (do you agree?). I don’t know whether an efficient enumeration algorithm was previously known. Is it the main technical contribution in this result?\\n    - Regarding Lemma 4: I believe that the Sauer–Shelah lemma can give a tighter bound here (namely, $|D|^{O(n \\\\cdot \\\\text{poly}(x))}$). Again, I don’t know regarding efficient enumeration.\\n    - Given Lemmas 1-4, the proof of Theorem 5 becomes similar to the result from Arora et al., right?\\n    - The result in Section 5, namely, transforming networks to larger ones with out-degree $1$, is a trick that was also used in prior works. As far as I understand, this is exactly Remark 2.2. from [1]. \\n- Typo in line 215: should be $a_{u,w}^*$.\\n\\n[1] Maass, Wolfgang. \"Bounds for the computational power and learning complexity of analog neural nets.\"\\xa0Proceedings of the twenty-fifth annual ACM symposium on Theory of computing. 1993.\\n'},\n",
       " 'review_184': {'summary': 'Most estimation methods for individualized treatment rules (ITRs) assume no unmeasured confounders for valid causal inference. However, such an assumption can be unreasonable, such as when estimating ITRs from observational data. Previous work has applied proximal causal inference to estimate ITRs when this assumption is violated, but is restricted to policy classes that either exclude treatment-inducing confounding proxies or exclude outcome-inducing confounding proxies [1]. To this end, the authors propose estimating a stochastic mixture of both policy classes from [1] to yield a more flexible ITR. Theoretical and simulation results demonstrate the superiority of the proposed method. ',\n",
       "  'strengths': 'The assumption of no unmeasured confounders is nearly ubiquitous across ITR estimation methods, despite frequent violations when dealing with observational data. This makes the problem the authors are trying to solve - estimating ITRs when this assumption is violated - very significant. Moreover, the theoretical and simulation results are of sufficient quality to convince me that the method outperforms [1], the existing state-of-the-art in proximal learning.\\n',\n",
       "  'weaknesses': 'While I believe the merits and potential contribution of the paper outweigh its limitations, the theoretical and empirical results of the paper are weaker than that of previous work, and the clarity of the paper can be improved. I go into more detail below:\\n\\n1. **Theoretical guarantees are much weaker than those of previous methods.** Convergence rates, finite-sample error bounds or asymptotic normality is often derived for ITR methods [2-5], including the method this work seeks to improve over [1]. However, while the authors prove that the proposed method will converge to a policy with better value than that of [1] asymptotically, they do not derive a rate of convergence or establish any finite-sample error bounds. Moreover, the asymptotic analysis from Appendix G assumes convergence of several estimators in $L\\\\_\\\\infty$ space. This is a much stronger assumption than the assumptions made in previous work, which only assumes convergence of estimators in $L\\\\_2$ space (e.g. see Assumption 12 from [1] or Condition B5 from [3]).\\n\\n2. **The real data analysis does not strengthen the validity of the proposed method.** When applying ITR estimators to real datasets, it is common practice to assess performance by using either (1) an estimator of the value [2-6] or (2) arguments based on domain knowledge that support the validity of the proposed method [1,6]. For example, in [1], the authors argue that the estimated policy is accurate by demonstrating that the estimated coefficients and interpretation of the policy is consistent with findings from previous literature. In contrast, the only conclusions that these authors draw from their real data analysis is that the proposed estimator gives different results than previously proposed methods. Such a conclusion says little about the validity or superiority of the proposed method. One way this analysis could be greatly improved is to look at the patients from Figure 3 where the recommended treatment differs between the proposed method and that of [1], and use domain knowledge or previous literature to argue that the recommendations given by the proposed method is more sound. Alternatively, the authors could make this conclusion by comparing the coefficients of the proposed policy with that of [1]. \\n\\n3. **Empirical comparisons were relatively limited.** The authors only benchmark the proposed method against those of a single previous work, [1]. To conclude that the proposed method achieves state-of-the-art performance, the authors should benchmark the proposed method against additional baselines as well. For example, there are many methods that assume no unmeasured confounders which the authors could evaluate to demonstrate the utility of using a proximal causal inference framework (e.g. [7,8]). There are also other methods that relax the no unmeasured confounders assumption or have shown robustness when such assumptions are violated, such as instrument variable (IV) methods [3,9] and M-learning [4]. How are the assumptions made by proximal learning less restrictive than those made by IV approaches, and can such methods be applied to the simulated datasets? If so, the authors should benchmark the proposed method against these method. And if these methods are not applicable, the authors should explain why in the paper. In addition to the number of competing baselines being limited, the simulated datasets from this work all have the same sample size and behavior policy. When deriving new ITR methods, it is common practice to evaluate the method on datasets of different sample sizes (and if observational data is of interest, varying behavior policies) so as to demonstrate robust performance [2-5,7-11]. \\n\\n4. **The implementation uses very simple estimators.** In theory, $d_z,d_w$ and $\\\\delta$ could be estimated by any weighted classification and regression algorithm. However, in their empirical experiments, the authors only explore estimating $d_z$ and $d_w$ with linear policies and estimating $\\\\delta$ with a Nadaraya-Watson estimator where the bandwidth is chosen based on a heuristic. Moreover, while $h$ and $g$ were estimated using neural networks, the architecture and number of training iterations was fixed a priori. This contrasts to previous works which use more cutting-edge machine learning approaches to estimate the ITR, such as kernel machines, random forests or neural networks, and adopts hyperparameters to the data at-hand using cross-validation [8]. Such works are especially prevalent in top-tier ML conferences [10,11], and better demonstrate broad applicability and flexibility of the proposed method. \\n\\n5. **Many parts of the paper need to be better written to avoid confusion and address some open questions.** For example, for the real data analysis, it is not clear what assumptions proximal learning is making and how it is useful for the analyzed dataset. It is mentioned that patients were arranged in a \"control group\" on line 289. Were patients randomized to receive a treatment? If so, wouldn\\'t the no unmeasured confounders assumption hold, as treatment assignment is not being affected by any unmeasured covariates? Also, what is the logic behind the choice of $Z$ and $W$ on line 296 (e.g. why are the variables in $Z$ expected to affect treatment but not outcome), and what specifically are the unmeasured confounders $U$ that we are trying to adjust for? Finally, it is stated that the outcome is censored. Does this mean that 30-day survival rate is censored for some of the patients? It is well-known that optimizing censored outcomes without adjusting for the censoring mechanism can yield bias [5]. \\n\\n>> Here are some other suggestions to reduce points of confusion and improve readability:  \\na. The explanation of how the proposed method improves upon [1] in the Introduction section (lines 56-65) is confusing. For example, it is stated on line 69-61 that [7] maps an ITR with domain $\\\\mathcal X\\\\times\\\\mathcal W\\\\times\\\\mathcal Z$ with the domain being restricted to $\\\\mathcal X\\\\times\\\\mathcal W$ to $\\\\mathcal X\\\\times\\\\mathcal Z$. While this makes more sense after reading section 2.2, these statements initially appear contradictory. Also on lines 59 and 63 \"two optimal in-class ITRs\" should be changed to \"these two optimal in-class ITRs\" to clarify that the authors are referring to the classes mentioned on line 57.  \\nb. The paper has many typos. For example, \"Tchetgen Tchetgen et al\" in line 34 should include the year and a link to the reference, \"netwrok\" on line 73 should read \"network\", and on line 169 the authors should add $V(d_{z\\\\cup w})$ to the argmax.  \\nc. On line 142-143 the authors state that Assumption 3 assumes \"Z has sufficient variability with respect to the variability of U\". But isn\\'t assumption 3 actually assuming that U has sufficient variability with respect to the variability of Z?  \\nd. On line 173 it is stated that $\\\\mathbb E[Y(a)|X,U]$ may not be identifiable under proximal causal inference. But doesn\\'t assumptions 1-5 allow for such identifiability?  \\ne. Remark 1 is not true. For example if $\\\\pi(X)=0.5$ then $\\\\pi$ is constant but the policy class will not be in $\\\\mathcal D_{\\\\mathcal Z}\\\\cup \\\\mathcal D_{\\\\mathcal W}$.   We actually need the restriction that $\\\\pi$ is both constant and in the set $\\\\\\\\{0,1\\\\\\\\}$.  \\nf. The results of Appendices E and G should appear in the main paper as propositions, theorems or corollaries.  \\ng. For sections where over 10 references are cited back-to-back, I think readability would be improved if these citations appeared in chronological order.  \\nh. The authors should add a Discussion section that summarizes the results of the paper and proposes important avenues for future work (also see my comments on the Limitations section).\\n\\n\\n\\n\\nReferences:\\n\\n1. Qi Z, Miao R and Zhang X. Proximal Learning for Individualized Treatment Regimes Under Unmeasured Confounding. JASA. 2023.\\n\\n2. Zhao Y, Zeng D, Rush AJ and Kosorok MR. Estimating Individualized Treatment Rules Using Outcome Weighted Learning. JASA 107 (499): 1106-1118. 2012. \\n\\n3. Qiu H et al. Optimal Individualized Decision Rules Using Instrumental Variable Methods. JASA 116 (533): 174-191. 2021.\\n\\n4. Wu P, Zeng D and Wang Y. Matched Learning for Optimizing Individualized Treatment Strategies Using Electronic Health Records. JASA 115 (529): 380-392. 2020.\\n\\n5. Zhao YQ, Zeng D, Laber EB, Song R, Yuan M and Kosorok MR. Doubly robust learning for estimating individualized treatment with censored data. Biometrika 102 (1): 151-168. 2015. \\n\\n6. Raghu et. al. Continuous State-Space Models for Optimal Sepsis Treatment: a Deep Reinforcement Learning Approach. MLHC 2017.\\n\\n7. Zhao YQ, Laber EB, Ning Y, Saha S and Sands BE. Efficient Augmentation and Relaxation Learning for Individualized Treatment Rules using Observational Data. JMLR 20: 1-23. 2019.\\n\\n8. Zhou X, Mayer-Hamblett N, Khan U and Kosorok MR. Residual Weighted Learning for Estimating Individualized Treatment Rules. JASA 112 (517): 169-187. 2017.\\n\\n9. Pu H and Zhang B. Estimating optimal treatment rules with an instrumental variable: A partial identification learning approach. JRSS-B 83 (2): 318-345. 2021. \\n\\n10. Yoon J, Jordon J and van der Shaar M. GANITE: Estimation of Individualized Treatment Effects using Generative Adversarial Nets. ICLR 2018. \\n\\n11. Chen Y, Zeng D, Xu T and Wang Y. Representation Learning for Integrating Multi-domain Outcomes to Optimize Individualized Treatment. NeurIPS 2020.'},\n",
       " 'review_185': {'summary': 'The paper discusses the optimization of treatment rules in the context of observational data and under assumptions of proximal inference. Various theorems are introduced, and a real data analysis performed using a healthcare example.',\n",
       "  'strengths': 'Below is a list of perceived weaknesses. \\n\\nThe paper is overall sound and the topic of importance. I appreciate the presence of the real data application. Assumptions and results clearly stated.',\n",
       "  'weaknesses': \"Below is a list of perceived weaknesses. \\n\\nIt was not clear to me how the empirical results compare to competing methodological baselines from other approaches (I don't believe the different values presented in the figure represent different algorithmic approaches). \\n\\nThe paper is quite heavy on notation and, at least to me, light on intuitive explanation for findings as they are discussed, limiting insight into the inner workings of why the method works.\\n\\nI don't know the proximal causal inference literature well so am not well-positioned to discuss the contribution in that subfield of causal inference. \\n\\nI don't see a discussion of uncertainty estimation in the theoretical or empirical results. Uncertainty estimation in optimized treatment effect regimes can be difficult (e.g., the bootstrap may not be appropriate or may have poor coverage) but may be important to usefulness in practice.\"},\n",
       " 'review_186': {'summary': 'The goal is to learn an optimal individual treatment rule (ITR) where the data suffer from unobserved confounding but where the researcher has a treatment proxy and an outcome proxy. \\n\\nWhile the general problem has been studied before by Qi et al (JASA 2023), this paper’s contribution is to broaden the class of ITRs. For a broader class of ITRs, the authors identify the value function and show that it exceeds the value function of the narrower class.\\n',\n",
       "  'strengths': 'My comments are brief because this is a strong paper.\\n\\nOriginality: The essence of the improvement is that, for different covariate values x, one may either use the “outcome” ITR or the “treatment” ITR. This departs from previous work, where either the “outcome” ITR or the “treatment” ITR is used across covariate values.\\n\\nQuality: The proofs look correct, and the results are easy to interpret. Rates for the objects in Proposition 1 would be an improvement; see the question below.\\n\\nClarity: The paper is well written and well referenced.\\n\\nSignificance: The paper contributes to two popular literatures: proxies and ITRs. While its theoretical contribution is modest, it does appear to have practical relevance.',\n",
       "  'weaknesses': 'The theoretical contribution is somewhat incremental.\\n\\nTake a pass to fix typos, e.g. “netwrok” on line 73.\\n\\nAn extra sentence in Remark 1 would be welcome, that explains the point summarized as “originality” above.\\n'},\n",
       " 'review_187': {'summary': 'The authors present a new optimal individual treatment regime (ITR) within the proximal causal inference framework, which avoids the strong assumption of no unmeasured confounding. Instead, one assumes the effect of the unmeasured confounders flows exclusively through proxy variables, as defined through outcome-inducing and treatment-inducing confounding bridges. Compared to prior work, this optimal ITR that is defined with respect to a more flexible function class that depends on known confounders X, treatment-inducing confounding proxies Z, and outcome-inducing confounding proxies W.',\n",
       "  'strengths': 'The proposed ITR is a natural extension of existing ITRs by using a function \\\\pi(x) that selectively chooses between two existing ITRs based on known confounders x. Under the proximal causal inference frameowrk, the proposed ITR is proven to be superior to existing ITRs in the literature. (Existing ITRs from Qi 2023 can be viewed as special cases of the proposed ITR.) The authors introduce a simple plugin estimator for the proposed ITR and show that the value of the resulting estimator is determined by approximation error of \\\\pi and the gain from using \\\\pi. Simulation studies show that the proposed ITR is either superior or comparable to existing ITRs. The manuscript is clearly written. The authors provide a nice review of prior work in this area and clearly describe how their work builds on existing work.',\n",
       "  'weaknesses': '1. The proposed extension of the ITR function class appears quite incremental. The value of the proposed ITR follows directly from application of the tower rule. The paper would be greatly strengthened if the authors can show that this is the best one can do, e.g. showing that the value of a more complex ITR function class would be unidentifiable without much stronger assumptions.\\n\\n2. In the simulation studies, the improvement in mean value when using the proposed optimal ITR over existing ITRs is large only in scenario 2. In all other scenarios, the improvement is small. Can the authors explain the behavior in this simulation study? Also, can the authors explain settings in which the proposed ITR is expected to substantially improve over existing ITRs? My guess is that the gain is biggest when (i) there are large differences between expected value at each X for the ITR with domain (X,W) and the ITR with domain (X,Z) and (ii) the optimal pi function has high variance (e.g. pi(X) is equal to 1 half of the time). Does this correspond to scenario 2?\\n\\n3. The authors perform a real-data analysis in Section 5, which illustrates how the proposed ITR is different from existing ITRs. However, the authors do not calculate the values of the estimated ITR, so readers cannot compare the performance of the proposed ITR against existing ITRs. Do the authors have estimates of the values of the estimated ITRs?\\n\\n4. The number of treatment-inducing confounding proxies and outcome-inducing confounding proxies were small in both the simulation studies and real-world data analysis. However, the practical appeal of the proximal causal inference framework is its use of proxies for unmeasured confounders, which would suggest the use of many variables as potential proxies. Can the authors include simulations that reflect more realistic settings where more proxy variables are used? How does the proposed method perform as the number of these proxies increases?'},\n",
       " 'review_188': {'summary': 'The following results are given in the paper: \\n1. A tighter analysis of the local search algorithm of Lattanzi and Sohler. The paper shows a constant approximation guarantee for their algorithm.\\n2. The paper extends the approach of Lattanzi and Sohler to multi-swap local search (where more than one point is swapped in every iteration). Using this approach, an approximation guarantee of 10.48 is obtained.\\n3. The paper also gives a (9+\\\\eps) approximation. Such a 9-approximation algorithm using local search is already known (https://www.sciencedirect.com/science/article/pii/S0925772104000215). The algorithm given in this paper has a slight running time advantage.\\n\\nThe algorithm is a local search algorithm. The justification of the title is that the swap-in points in the local search strategy are obtained by D^2 sampling (i.e., the sampling strategy used in k-means++).',\n",
       "  'strengths': \"1. Knowing a better analysis for an already published algorithm is good.\\n2. Extension to multi-swap and its analysis giving better approximation guarantee is interesting.\\n3. Matching the best possible approximation (possible using local search) using a slightly better running time is also interesting.\\n4. The experimental section shows that the local search iterations do better than Lloyd's. This is interesting and can be of practical use. It would have been better if the running time comparison was also given to make the tradeoffs more visible.\",\n",
       "  'weaknesses': '1. The paper looks good from the point of view of extensions to the Lattanzi and Sohler work. However, from the point of view of developments in local search algorithms (which is essentially what the paper is), the improvement over (https://www.sciencedirect.com/science/article/pii/S0925772104000215) seems incremental. Even the proof techniques are similar.\\n2. There are some discrepancies in the experimental section. For example, Figure 2 says \"first row...\", but there is none. I did not find the running time for the local search iterations (even MSLS-G).'},\n",
       " 'review_189': {'summary': 'This paper proposes a new k-means algorithm: multi-swap local search (MSLS) which combines local search and k-means++, to achieve a constant approximation guarantee with efficient time complexity. Specifically, the local search framework includes a step that selects alternative centers for optimizing the cost function, and this paper selects those centers using the $ D^2 $-sample from k-means++  (without updating costs). \\n\\nThe authors prove that the random candidate centers obtained in this way lead to an improvement over the cost. By iterating on this step, MSLS will return a constant approximation result.\\n\\nThe author also leverage ideas from coreset and  dimensionality reducion to propose a more efficent $ 9+\\\\varepsilon $-approximation algorithm within the local search framework.',\n",
       "  'strengths': '- The paper is well written. All sources of motivations and techniques involved in this work are clearly presented, making it easy to follow the key ideas of the algoirthm and the related works. It does make a novel contribution to the classic problem.\\n- The idea behind the MSLS algorithm is natural and the proofs are very clear. Although the author refer techniques from the previous work, the approximation analysis is non-trivial and results in very tight ratios.\\n- The MSLS algorithm is simple and easy to implement. The experiments are comprehensive. This work is valuable in both theory and practice.',\n",
       "  'weaknesses': '- the time complexity is $ \\\\tilde{O} (nd k^p) $, which grows exponentially w.r.t. $p$.'},\n",
       " 'review_190': {'summary': 'This paper studies the standard $k$-means problem. Given a $k$-means instance $(P,k)$, the goal is to find a set $C$ of centers with size at most $k$ such that the sum of the squared  distances from $P$ to $C$ is minimized. For the $k$-means problem, Lattanzi and Sohler (ICML 2019) proposed an elegant combination of the local search and the $k$-means++ seeding methods. Instead of enumerating all the swap pairs constructed between the data points and the current centers, they showed that $k$-means++ sampling can be used for sampling a data point to serve as the candidate center for swapping in such that a $509$-approximation can be achieved in expectation in time $O(ndk^2loglogk)$. This paper extends the single-swap strategy to multi-swap strategy. In a single local search step, this paper shows that using $k$-means++ to sample $t$ data points induces a good $t$-swap for the local search process such that the clustering cost can be reduced significantly by at least a $\\\\Omega(1-1/k)$ fraction with certain probability. After $O(k^{t-1})$ local search steps, an improved approximation can be achieved related to the swap size $t$, where the total running time can be bounded by $\\\\tilde{O}(ndk^{2t})$. When $t$ is large enough, the approximation could be smaller than 10.48. By combining the techniques from Cohen Addad et al. (NeurIPS 2021), the papers shows that by using more local search steps (with exponential dependence on $\\\\epsilon$), the approximation guarantee can nearly match the lower bound of the $9+\\\\epsilon$ of the standard multi-swap local search method.',\n",
       "  'strengths': 'The strengths of this paper can be summarized as follows:\\n1. This paper proposes a fast multi-swap local search method for solving the standard $k$-means problem, which runs in linear time in the data size. The approximation ratio significantly improves the previous one with linear running time in the data size (i.e., 509-approximation)\\n2. This paper gives another multi-swap local search method which better approximates the optimal clustering centers during the local search swaps using a subroutine called APX-CENTERS, where an improved approximation guarantee, i.e., $9+\\\\epsilon$, can be obtained with running time exponentially dependent on $poly(\\\\epsilon^{-1})$. The approximation ratio matches the approximation lower bound of local search methods for the $k$-means problem and significantly improves the running time of previous work based on direct enumeration of swap pairs constructed between the whole dataset and the current centers opened.\\n3. In experiments, this paper proposes a heuristic method which avoids the exhaustive searching process for determining which subset of the sampled set of data points should be swapped in. The experiments show that the multi-swap local search method achieves better performance on clustering quality with fixed local search iterations compared with single-swap local search methods.',\n",
       "  'weaknesses': '1. Although the authors show that sampling-based multi-swap local search can improve the approximation to a very small constant and even matches the lower bound of local search methods, the core idea behind is to use the successive $k$-means++ sampling strategy to construct candidate set of centers for swapping in, which is an extension of the sampling-based local search method (denoted as LS++ method )proposed by Lattanzi and Sohler. The claimed improvement in ratio seems to be minor as LS++ already guarantees constant approximation (in [1] the authors claimed that they did not attempt to optimize the constants and this paper verifies that LS++ can yield approximation ratio smaller than 26.4). The key idea behind the analysis for multi-swap local search method is as follows: (1) the authors further divide the optimal clusters into different groups according to their current clustering cost (i.e., $cost(P_h^*,C) \\\\ge \\\\delta ALG/k$ or $cost(P_h^*,C) < \\\\delta ALG/k$) (2) the authors give weights for swap pairs such that each current center can be used for at most $(1+1/t)$ times when performing a summation of all bad swap pairs. The analysis for probability lower bound that induces a good swap is similar to that of LS++ method.\\n\\n2. Some theoretical details is unclear to me. During the construction of ideal weighted multi-swaps, this paper partitions the optimal clustering centers and current clustering centers based on $\\\\tilde{O}=${\\n$o_i \\\\ | \\\\ cost(O_i^*,C) \\\\ge \\\\delta ALG/k$} and $\\\\tilde{C}=$ $C\\\\backslash$ {$C[o_i] \\\\ | \\\\ o_i \\\\in O^* \\\\backslash \\\\tilde{O}$}. Then, in the construction of ideal multi-swaps, each swap is consist of $In$ and $Out$ such that $In \\\\subseteq \\\\tilde{O}$ and $Out \\\\subseteq \\\\tilde{C}$. If my understanding is not wrong, some of the optimal centers in $\\\\tilde{O}$ is not used for construction of ideal multi-swaps. If not all optimal centers is used at least once for constructing ideal multi-swaps, then the bound for summation of clustering cost for all \"bad\\'\" optimal clusters may not hold in Lemma 11. The ideal multi-swaps construction considers the two caes: (1) for each center $c_i \\\\in \\\\tilde{C}$ that is neither busy nor lonely, form $In$ with the optimal centers captured by $c_i$ (multi-swap) and borrow $|In|-1$ lonely centers from $L$ (2) for each center in $\\\\tilde{C}$ that is busy, form single swap using each of optimal centers captured by $c_i$ and the lonely centers in $L$. However, there may exist some case that for some optimal clusering center $o_i^* \\\\in \\\\tilde{O}$, the current center $c_j$ that captures $o_i^*$ is not in $\\\\tilde{C}$ and hence $o_i^*$ will no longer be used for constructing ideal multi-swaps. Here is an example where $o_i^*, o_2^*, o_3^*$ is the optimal clustering centers, and $c_1$, $c_2$, $c_3$ is the current centers with swap size $p=2$. In this instances, it holds that $c_1$ captures $o_1^*$ and $o_2^*$, $c_3$ captures $o_3^*$, $cost(O_1^*,C) \\\\ge \\\\delta ALG/k$, $cost(O_2^*,C)<\\\\delta ALG/k$ and $cost(O_3^*,C) \\\\ge \\\\delta ALG/k$. Hence, we have $\\\\tilde{O}=${$o_1^*,o_3^*$} and  $\\\\tilde{C} =${$c_2,c_3$}. During the construction of ideal multi-swaps, since $c_1$ is not in $\\\\tilde{C}$, $o_1^*$ will never be used during the construction. \\n\\n3. Another main weakness of this paper is the experiments. (1) As a local search algorithm, it’s important to validate the performance of the proposed algorithm within a certain time limitation, which is not presented in the experimental results. This paper mainly compares the experimental performances with fixed local search steps. It is unfair since multi-swap local search method takes more time than single-swap local search methods (i.e., the LS++ method). (2) In experiments, the maximum local search step is set to be 50, which is much smaller than the theoretical bounds (100000kloglogk) for obtaining good performance for LS++ algorithm. For this setting, even single-swap local search method may not converge to a good local optimal solution. The authors should present more evaluation for larger local search steps (i.e., several hundreds or thousands of local search steps) and fixed running time that is large enough for each algorithm to reach the convergence. (3) The size of the tested datasets is rather small (i.e., no larger than 500,000). However, in the recent results for clustering algorithms, instances of size over 1 million [1] or even 100 million [2] have been considered. Since multi-swap local search is much slower than the single-swap local search method (even with heuristic acceleration by avoiding the enumeration of all subsets of data points for swapping in), it is unclear that whether the proposed algorithm can scale well on large-scale datasets compared with single-swap local search method.\\n\\n[1] Ren J, Hua K, Cao Y. Global Optimal K-Medoids Clustering of One Million Samples[J]. Advances in Neural Information Processing Systems, 2022, 35: 982-994.\\n[2] Matsui Y, Ogaki K, Yamasaki T, et al. Pqk-means: Billion-scale clustering for product-quantized codes[C]//Proceedings of the 25th ACM international conference on Multimedia. 2017: 1725-1733.'},\n",
       " 'review_191': {'summary': 'This paper studies local-search algorithms for k-means clustering. The goal here is to obtain a local-search algorithm which (1) give a close to 9-approximation ratio (which is best possible for local search algorithms) and (2) is practical. In the past literature, there has been many local search algorithms developed for the k-means problem, but all of them either have a relatively big approximation ratio or have a prohibitive running time in practice due to the complexity of the local moves at each step. \\n\\nIn this paper, the authors give a simple local search algorithm which is practical and guarantees a 10.48-approximation. They also give a more complex local search which matches the approximation lower bound of 9, but with a significantly faster running time than in Kanungo et al. [2004]. However, this algorithm is significantly more complex and is unlikely to be used in practice. They also give experiments that show that their first algorithm and a slight variant of it perform well in practice.\\n',\n",
       "  'strengths': 'In my opinion, the strengths are as follows.\\n1) The paper is clearly written.\\n2) The first algorithm is a nice result since it combines practicality with an almost best possible theoretical guarantee. As far as I know (not being an expert), this is the first time the D^2-sampling is used and analyzed in combination with multi-swap local search. Overall, the techniques in the paper are nice.',\n",
       "  'weaknesses': 'I do not see an obvious weakness in this work, the results are tight or close. Overall, I think this is a nice paper that fits well in the context of NeurIPS. '},\n",
       " 'review_192': {'summary': 'The paper proposes an automatic error classification pipeline for ImageNet models. In particular, they categorize mistakes into overlapping classes, multi-object images, fine-grained and fine-grained with out-of-vocabulary (OOV), non-prototypical, the examples influenced by spurious correlations and unexplained mistakes. To detect fine-grained OOV errors the authors used WordNet and an open world CLIP classifier. They evaluated 121 models and showed that better performing models (in terms top-1 accuracy or multi-label accuracy) have a lower _portion_ of unexplained errors, and higher portions of errors which are explained by class ambiguity and fine-grained cases. They analyzed error portion trends separately for objects and organisms ImageNet classes, and analyzed the effect of training dataset and model architecture.',\n",
       "  'strengths': 'While prior works studied questions similar to this paper such as [1] analyzed error types of one or a few high performing ImageNet classifiers such as ViT-3B, and [2] looked at how multi-label accuracy improves with model scale, this paper studies a more detailed question of how the error type distribution changes as we scale up the models in terms of the architecture size and pre-training dataset.\\nThey also propose an automatic way to identify fine-rained out-of-vocabulary mistakes which relies on an external open world classifier model CLIP (assuming that we filtered out overlapping and fine-grained classes).\\n\\n**References**\\n\\n[1] Vasudevan, Vijay, et al. \"When does dough become a bagel? analyzing the remaining mistakes on imagenet.\" \\n\\n[2] Beyer, Lucas, et al. \"Are we done with imagenet?.\"',\n",
       "  'weaknesses': '1. **Limited novelty.**\\n\\nGiven the results from the prior works that study label mistakes and ambiguity in ImageNet dataset like [1] and [2], the novel insights from this paper seem limited.\\nI would suggest that the authors explicitly emphasize that the error categorization and definitions as in Figure 1 and most subsections in Section 3 (except for novel approach for fine-grained OOV) were proposed in prior works, and that they separate the background and results from prior works and their novel approaches and insights. \\n\\nIn particular, both [1] and [2] categorize mistakes in a similar fashion, and the categorization in [2] is the one this paper relies on. [1] focus on analyzing mistakes of a few large-scale models like ViT-3B and report the percentage of different error types and their severity in their Section 4.1 Table 2. Similarly to this paper they report mistakes separately for objects and organisms classes from ImageNet. They also propose ImageNet-M — a subset of only 68 examples where high-performing models still consistently make major mistakes.\\n[2] also discuss a similar error categorization but they focus on analyzing how scaling up models affects top-1 and multi-label accuracy. \\nThis paper combines two types of analysis from [1] and [2] and studies how scaling up models affects the error types distribution, and concludes that for stronger performing models the percentage of major mistakes significantly decreases. While this experiment and analysis is new, the conclusions are somewhat straightforward given the results from [1] and [2]? \\n\\nCould the authors please list the new observations and conclusions that were made in their analysis and that were not known in prior work?\\n\\n\\n\\n2. **The extent to which the pipeline of error type classification is automatic seems to be overclaimed.**\\nThe introduction and abstract of the work make an impression that the paper proposes a fully automatic way to classify model’s mistakes, without relying on manual annotation unlike prior works [1, 2].\\nHowever, after reading Section 3 it turns out that class overlap (Sec 3.1), multi-object cases (Sec 3.2), and spurious correlations (Sec 3.6) rely on manually obtained labels from [1] and [2], the definition of non-prototypical examples (Sec 3.5) relies on the ViT model’s mistakes which were analyzed in [1], and fine-grained errors (Sec 3.3) rely on manual grouping of classes into super-classes (see another comment re this case in Questions).\\nThe only case of automatic error categorization is the fine-grained out-of-vocabulary error in Section 3.4 which involves WordNet tree and open world CLIP classifier. \\n I suggest that the authors adjust their claims accordingly since such a pipeline can’t be called automatic.\\n\\nIn particular, if the proposed error classification pipeline was indeed automatic and didn’t have limitations discussed in lines 45-47 in terms of relying on human labellers, how would one apply the proposed pipeline to another large-scale dataset where we don’t have these labels from [1] and [2]? If it is possible, it would be helpful to see the application of such error classification to another dataset.\\n\\n\\n3. **The design choices for detection of fine-grained out-of-vocabulary mistakes is not fully clear.**\\nThe only automatic and novel part of the error classification pipeline is detection of fine-grained OOV mistakes: (1) first we find 10 most visually similar images in ImageNet train set in terms of the CLIP embedding, (2) check that at least one label belongs to the same superclass as model’s prediction, and (3) measure CLIP similarity with the correct class and WordNet in-vocabulary and OOV sibling classes related to both correct class and model\\'s prediction.\\n\\nFirst, for the last step the description of the label proposal set is a bit confusing, and it would be helpful if the authors could clarify the exact set of proposals they are considering.\\nSecond, it would be helpful to have more examples like in Figure 10 to illustrate step-by-step fine-grained OOV mistakes identification and show for each example what were the 10 closest images in embeddings space and which labels they had, and then which label proposal set CLIP scored (in particular, where those proposals were taken from and what were the CLIP scores exactly). It would be helpful to have more intuition for each step of this process.  \\n\\n4. [Minor] While the paper is generally easy to follow, I highlight a few points below which were not as clear:\\n\\n-  For Figures like 3, 5 and other trends, please clearly define what exactly is shown on y axis. I am assuming it is (# of mistakes of type X ) / (# of all mistakes) for each model.\\n- On the same Figures, does each marker correspond to one model? Is it correct that each model is shown twice: once for objects and once for organisms?\\n\\n- Please fix captions for Figures 7, 12 and 14.\\n\\n\\nTypos:\\n\\n- Line 54: and -> an\\n- Line 99: find\\n- Line 113: need to\\n- Line 189: the\\n\\n**References**\\n\\n[1] Vasudevan, Vijay, et al. \"When does dough become a bagel? analyzing the remaining mistakes on imagenet.\" \\n\\n[2] Beyer, Lucas, et al. \"Are we done with imagenet?.\"'},\n",
       " 'review_193': {'summary': 'This paper aims to create an automated pipeline for defining the types of errors made by ML models on ImageNet. Error categories are from previous work, and the paper compares the results between the previous human based pipeline and the newly automated version. The authors use the pipeline to evaluate over 100 models, and provide some analysis on the findings.',\n",
       "  'strengths': '- Paper structure is clear\\n- Design decisions for automating each step of the pipeline make sense\\n- Results are validated and put in context with prior work',\n",
       "  'weaknesses': '- Analysis of results seems limited. I would like to see additional analysis that builds upon the benefits of such pipelines. For example, if we can now easily get to severe model errors, can we do human analysis on these to create categories or better understand them?\\n- I would like to better understand the motivation behind this work, such as potential use cases for the pipeline to improve machine learning research'},\n",
       " 'review_194': {'summary': \"The paper introduces an automated pipeline to classify ImageNet's errors from 4 categories: (i) fine-grained categories; (ii) fine-grained OOV; (iii) Non-prototypical instances; and (iv) Spurious correlations. The main contribution of the paper is this automated pipeline with which various errors can be categorized.  While there exists a plethora of recent works in classifying ImageNet errors, the paper does a good job of summarizing all these errors and also designing an automated pipeline to detect them for ImageNet. \\n\",\n",
       "  'strengths': '- Good overview of ImageNet errors and a simple, but effective automated pipeline for error detection.\\n- A wide-range of models are tested which is a strong point for the paper. ',\n",
       "  'weaknesses': '- The analysis is restricted to only analysing ImageNet errors. While it is a good direction to inform vision research -- it will be beneficial to extend the framework to understand error types in other ImageNet variants such as ImageNet-A. What are the error distributions in such sets? The current analysis though good, is restrictive.\\n- The paper does not discuss recent works such as ImageNet-X (https://facebookresearch.github.io/imagenetx/site/home)  which also looks at understanding model failures. While the categories considered in this paper is a subset of ImageNet-X error types, can the authors compute an overlap metric between some of the error types detected in this paper and ImageNet-X? \\n- While a range of models are tested, can the authors distinguish between the pre-training strategies more in the plots? E.g., highlight SSL methods, Vision-Language pre-training methods and Supervised Pre-training methods using different colors / notations. This would make the paper stronger.\\n- Can the authors give some intuitions on the unexplained failures? What are the potential causes? \\nHow can the error analysis learnings be useful in improving model training? Can the authors provide some intuition on this? '},\n",
       " 'review_195': {'summary': 'The paper introduces an automated analysis on the model errors in ImageNet.\\nThe analysis sequentially categorizes into six types of errors with increasing\\ncriticality, unveiling the true model failures. The results are contextualized\\nwith previous work.',\n",
       "  'strengths': \"- This work is of high interest to the computer vision and machine learning\\n  community, given the extensive use of ImageNet as a benchmark.\\n\\n- The quality and presentation of the analysis is excellent.\\n\\n- The full code to conduct the pipeline presented in the paper is provided with\\n  the paper, which is extremely value considering the reproducability under the\\n  complexity of the analysis (wrt. the number of models, etc.). Although the\\n  analysis may seem very large-scale, it is surprisingly affordable and, with\\n  the code, is very easily reproducable.\\n\\n- The analysis builds upon and refines the previous NeurIPS's work by Vasudevan\\n  et al..\\n\\n- The sequential categorization, starting with the least critical category of\\n  error, is a very good idea.\",\n",
       "  'weaknesses': '- I could not find any major weakness of the paper that would\\n  impede its acceptance in the current state.'},\n",
       " 'review_196': {'summary': 'This paper proposes a pipeline to automatically categorize ImageNet classification misclassifications. Previous work [1] defined and categorized those misclassifications into 4 types manually and this is the main motivation of automating the process. The results show that their pipeline has an accuracy of 60% based on human annotations of model misclassifications.\\n\\n\\n[1] analyzing the remaining mistakes on imagenet\\n\\nI have read the author’s rebuttal and adjust the rating accordingly!',\n",
       "  'strengths': 'The paper is easy to follow as they mostly based on the previous work [1].',\n",
       "  'weaknesses': '- The novelty of this paper is minimal and the motivation is not strongly supported. For example, the definitions and categorization of misclassifications have been done before in [1]. In writing, I do not see the reason why we need such categorization of misclassifications (i.e. the motivation). In Related work where I expect to see the motivation, the authors did not contrast their work with the literature then it is hard for me to see the contribution. I believe Related work can be greatly improved. Automating [1] is not considered novel at NeurIPS standard in my opinion.\\n- The authors only tested on 1 model and 1 dataset. It does not make the findings generalize. Another problem is the number of samples being examined. Based on Table 1, only 378 were tested!!!\\n- It looks like the authors are trying to do 4-way classification. In this case, it makes more sense to build a model to do that rather than having different methods for different misclassifications. The four types of misclassifications can be easily collected or synthesized.\\n- The authors only compared with [1]. The reviewer encourage them to extend the comparisons to others (e.g. [2]) and with other datasets and classifiers.\\n\\n[2] ImageNet-Hard: The Hardest Images Remaining from a Study of the Power of Zoom and Spatial Biases in Image Classification'},\n",
       " 'review_197': {'summary': 'The paper studies the problem of how to optimize the Matrix factorization (MF) mechanisms so that the effect of random noise can be minimized. The MF mechanisms can be applied in addition to the well-known DP-FTRL or similar online DP algorithms in machine learning training. This technique decomposes the query matrix A (e.g., a matrix encoding the prefix sum) into two matrices and adds noise to the intermediate matrix multiplicative result of the data and one of the decomposed matrices. It can potentially introduce less variance to the final results. The key idea of the paper is formulating the MF problem into an optimization problem. The authors show the sensitivity of the mechanism under some constraints of the participation schema and discuss how to derive the best decomposition in terms of minimizing the error profile because of the decomposition. Some experimental results are provided to demonstrate that the proposed mechanism is at least as good as the classic DP-SGD mechanism.',\n",
       "  'strengths': 'Generally speaking, this paper provides some in-depth results on the MF mechanism that can be interesting to the community.\\n1. The authors provide an insightful analysis angle on how to optimize the MF mechanism.\\n2. The authors derive the sensitivity of the MF mechanism under some additional assumptions about the participation schema of the users and the property of the original query matrix.\\n3. The authors show how one should optimize the MF mechanism via decomposition and how the mechanism can enjoy privacy amplification via sub-sampling.\\n',\n",
       "  'weaknesses': '1. While the technical contributions are sufficient for building a good paper, the presentation in this paper makes readers somehow hard to follow. \\n\\n- MF mechanism is relatively new compared with the other DP mechanisms. So MF may be ambiguous if a reader is not familiar with the ancestors of this work (i.e., [14, 16]), as some readers may be confused DP MF problems (e.g. [1*, 2*]) with the MF mechanism at the first glance. Introducing problem formulation in (the beginning of) the introduction section may help readers evaluate and understand the value of the paper.\\n- The explanation of why the MF mechanism can help and how the proposed methods are derived in this paper is not easy to follow. \\n- It is unclear what are benefits one can get by following the participation schema and decomposition method proposed methods. There may be some discussion scattered around the paper, but a summary (via a table) comparing the results of this paper to the existing ones may deliver the results more directly to the readers.\\n- The key algorithms are most deferred to the appendix. So main text itself is not self-contained and reader-friendly (readers have to jump between the main text and the appendix). At least some algorithms closely related to the main contribution of the paper, like the sampling scheme, should be stated in the main text, not just the theoretical results using this algorithm.\\n\\n2. Some experimental results may need further explanation. \\n- Why the BANDMF and  MULTI-EPOCH MF tends to introduce a similar level of noise as DP-SGD when the number of epoch increases?\\n- What is the exact RMSE for BANDMF, MULTI-EPOCH MF and DP-SGD in Figure 4? Also, how should one understand the relationship between RMSE and accuracy (From Table 5 in appendix, smaller noise in DP-SGD can have worse performance than ampl MF)?\\n\\n\\n[1*]Hyejin Shin, Sungwook Kim, Junbum Shin, and Xiaokui Xiao. 2018. Privacy-enhanced matrix factorization for recommendation with local diferential privacy. IEEE Transactions on Knowledge and Data Engineering 30, 9 (2018), 1770–1782.\\n\\n[2*] Zitao Li, Bolin Ding, Ce Zhang, Ninghui Li, and Jingren Zhou. Federated Matrix Factorization with Privacy Guarantee. PVLDB, 15(4): 900 - 913, 2022'},\n",
       " 'review_198': {'summary': 'The authors present a novel mechanism explicitly designed for differentially private training. The mechanism considers the sensitivity of different participation schemes in the context of fixed datasets during differentially private training. The key contributions of this work can be summarised as follows:\\n1. By accounting for the sensitivity of multistep participation schemes, the proposed mechanism eliminates the need for composition.\\n2. The authors illustrate how matrix factorisation can benefit from privacy amplification through subsampling and shuffling.\\n3. They propose a computationally efficient and precise implementation utilising b-banded matrices to compute sensitivity.\\n4. Additionally, they introduce an optimisation technique to craft these b-banded matrices.\\n\\nThe authors provide theoretical proofs and compelling experimental results to support their claim that their approach outperforms DP-SGD accounting.\\n',\n",
       "  'strengths': '* The paper effectively presents the problem, the proposed solution has a nice and clear structure, and the arguments flow in a natural way.\\n* The related work is well-presented, providing context and the existing related work gap, namely if the matrix factorization can benefit from the same privacy amplification techniques as DP-SGD.\\n* The experimental section is detailed, offering thorough explanations and interpretations of the results.\\n* The paper elegantly recovers privacy amplification bounds from DP-SGD by carefully constructing the proposed linear operator.',\n",
       "  'weaknesses': '* the current presentation is not self-contained, as it has plenty of references to the appendix/other related work. It is not ideal, as the main statements of the paper are a bit hard to fully understand without them. I know that space is a limiting issue, especially for well-detailed works like this, but please reconsider restructuring so that the main results (Theorem 2. and Theorem 4.) are possibly more easily to grasp without relying on the appendix this much.\\n'},\n",
       " 'review_199': {'summary': 'This paper proposes banded matrix factorization for differential privacy. It shows this new mechanism can be effectively applied to centralized and federated-learning settings (where individuals can choose when and how many times to participate in training). The main technical part is the $b$-minsep-participation schema that generalizes the $(k, b)$-participation proposed in Choquette-Choo et al. \\n',\n",
       "  'strengths': 'The experiments in Sec 6 demonstrate that banded MF exhibits a very good improvement over multi-epoch MF and DP-SGD in the centralized settings, and almost coincides with (or improves modestly) the state-of-the-art performance in the federated learning.  ',\n",
       "  'weaknesses': 'While the presentation of the paper is good for the most part, there are some issues that can be improved. For instance, the notation $\\\\hat b$-banded matrices were used several times in the Abstract, Introduction, and Sec 2 without a precise (or even intuitive) definition [It was defined on Page 5!]. Also, $\\\\hat b$ and $b$ seem to be interchanged arbitrarily (which is really confusing); see for instance lines 62, 188, 189. (I understand that $\\\\hat b$ is taken to be equal to $b$ only in Sec 5, but not necessarily in the first 4 sections)\\nAlso, Theorem 1 is rather cryptic: Do the \"equal-sized subsets\" mean batches of the same size? Does the partition change for each iteration (like typical SGD)? Is it not the case that $B b = m$? \\n\\nThis sentence (line 89-90) \"The connection between DP empirical risk minimization [3, 4, 5, 7, 8, 9, 13, 15, 21, 23, 30, 34, 36,90 40, 45, 46, 47, 49] and DP online regret minimization [2, 4, 5, 24, 31, 33] has been studied for a long time.\" is awkward. What is the point of this sentence? Why not directly citing some of those works that studied this connection!!\\n\\nWhat is SGDM in lines 95 and 101?\\n\\nThe argument in line 213 is not clear: How does Theorem 2 imply that $\\\\text{diag}(X) = 1$ and bandedness mean the squared sensitivity is equal to $k$? \\n\\n'},\n",
       " 'review_200': {'summary': 'In this paper, the authors show how Matrix Factorization (MF) can subsume prior\\nstate-of-the-art algorithms in both federated and centralized training settings, across all privacy\\nbudgets. They apply the key technique: MF mechanisms with banded matrices. For both the\\ncross-device federated learning setting and the centralized setting, the result in this paper\\nimproves or generalizes previous results. In addition, the $\\\\hat{b}$-banded matrices\\nsubstantially improve the memory and time complexity.',\n",
       "  'strengths': '1. The problem of Matrix Factorization for Differential privacy is well-motivated.\\n2. This paper is solid, the results look correct.\\n3. The result improves or generalizes previous results.',\n",
       "  'weaknesses': 'The main result for the centralized setting is summarized in Section 5. However, it seems the\\nresult for federated learning setting is not stated clearly. Is there a summary of the result for FL\\nsetting?'},\n",
       " 'review_201': {'summary': 'Applying matrix factorization mechanism and balancing tradeoffs of the mechanism in differential privacy is a long living issue. This work constructs MF mechanism with banded matrices for both centralized and federated training setting across all privacy budgets. For federated setting, this work is compatible with real world federated learning devices. For centralized setting, banded matrices are on par with the same privacy amplification results of DP-SGD algorithm.',\n",
       "  'strengths': '1. Banded matrix factorization with amplification can outperform DP-SGD with amplification for centralized setting, and well-balance privacy-utility tradeoffs.\\n2. With b-min-sep-participation, banded MF can optimize (k,b)-participation, and reduce linear memory/time complexity for per-iteration noise generation to a constant.',\n",
       "  'weaknesses': '1. The bound of sensitivity of MF mechanism looks confusing although the first part looks tight (sup for C*x and C*x_tilde). See Question 5.\\n2. Although this work considers FL in the practice, the dataset like CIFAR 10 seems quite outdated and the scale of CIFAR10 is too small, which is not enough to convince the community.\\n3. Probably authors need to clarify questions I stated in the next sections.'},\n",
       " 'review_202': {'summary': 'The submission investigates whether LLMs are able to create PDDL domains and problems description in three domains, two standard planning benchmarks, and one more challenging domain. The paper considers two related to the title: a) direct construction of the PDDL with an LLM, b) correcting errors in PDDLs. The paper also considers extracting plans with the obtained PDDL domains. The baseline is using a classical planner, that succeeds if the PDDL is correct. In c), they compare using the LLM as a planner, or using a ReAct style idea, but obtaining the prompts from the PDDL. This middle-ground scenario might be appealing for cases where the planning domain might not capture some elements of the problem, but an LLM can have additional insights.   The experiments are performed using GPT-4.',\n",
       "  'strengths': '- The benchmarks used for experiments are relevant and not trivial. The household domain illustrates might be convincing for those not familiar with the planning literature.\\n- Using the symbolic models as targets instead of solving the task using an LLM can help to bring the gap between LLM and symbolic models.\\n- Producing a PDDL is harder than the typical implementation of LLMs plug-in. For instance, an LLM producing simple SQL might be inspected immediately, while isolated actions are not so easy to check.',\n",
       "  'weaknesses': '- As the submission says, producing more complex PDDLs might be challenging.\\n- Both the planning benchmarks and the household domain might actually be easy for an LLM than domains in practical applications. That should be discussed further in the paper.\\n- The results of the manual evaluation might not extrapolate to other domains, and verification by a simulator might not be available. The submission should elaborate on the issue of explainability that is largely ignored in the document. The literature on explainability for planning should be discussed, including issues like model reconciliation.\\n'},\n",
       " 'review_203': {'summary': \"There's been a fair amount of recent work on using LLMs to directly write plans for planning problems. In contrast, this work divides the planning process into two stages where first an LLM is used to translate natural language descriptions of actions to formal PDDL actions, then goals can be planned towards using a classic PDDL planner like FastDownward. Alternatively, the formal model can be used to validate and propose feedback on plans proposed by an LLM planner. They also explore using feedback from an automated PDDL validator (VAL) to correct things like syntax errors, as well as human feedback, both of which are ingested by the LLM which is prompted to repair the model.\",\n",
       "  'strengths': '- The two stage process proposed here (first translating to a PDDL representation, then planning) is a nice setup. Unsurprisingly, when the PDDL model is correctly specified (e.g. after rounds of human feedback), the performance is much better than a setup that lacks this PDDL model construction step.\\n- The paper flows very nicely, giving a good overview of the problem and concise summary of the method in the intro, and a nice related work and PDDL/planning background section.\\n- The inclusion of detailed descriptions of the prompts is essential and much appreciated (and the full prompts given in the appendix) for fully understanding what the LLM is seeing. The authors do a great job of this. This kind of extensive appendix is invaluable for both replicating LLM work and understanding precisely what the inputs/outputs of the LLM are and its various failure modes.\\n- I found a lot of the analyses / results commentary throughout the paper to be quite interesting and informative, such as the comparison between GPT-3.5-Turbo and GPT-4, or the aside about how LLMs do more \"reasonable\" things in their plans with respect to a human-like prior, for example leaving a knife on the counter instead of placing it on top of a toaster as the symbolic planner sometimes did. These little asides gave me a better feel for the strengths/weaknesses of LLMs in the context of planning, world model construction, etc.\\n- The idea of translating the formal model *back* into natural language when presenting the user with errors is also a nice touch.',\n",
       "  'weaknesses': \"- The human feedback seems necessary given the errors GPT-4 introduces, and presumably this method wouldn't work well at all without that step of human correction. That means the method can't be fully automated (i.e. with just VAL feedback and no human feedback), or if this is the case then it isn't discussed or evaluated in the paper. Still, this is not a huge weakness in my view – methods involving humans are good too, and perhaps this could be a first work on which future work could be built that is more automated than just humans looking through a whole PDDL model trying to spot bugs. The authors discuss this a bit in section 4.2 and appendix A.4 which are quite nicely written.\\n- Seeing an evaluation on more domains would have been nice, but I'm not super familiar with the norms in the planning literature. What they have is enough for me to get a reasonable feel for things, so this is not a big weakness.\\n\\n**Overall**, this seems like a good paper that I would weakly support acceptance on. Given the heavy involvement of humans in correcting the model I don't see this as an extremely groundbreaking result, but I think it's still a moderate to high impact well written piece of research that deserves to be published and would be appreciated by a NeurIPS audience. My opinion is definitely open to revision, and I may be missing some points as discussed in Questions below.\"},\n",
       " 'review_204': {'summary': 'This paper proposes a translation approach to using LLMs for planning. Instead of relying on LLM prompt completion to generate plans, this approach parses a written description of the domain into a valid PDDL domain description. The user can then opt to use the PDDL domain description with an automated PDDL planner, or use the domain description along with prompting to force an LLM to generate a plan that can be parsed by a plan validator. \\n\\nThe evaluations were based upon International planning competition domains that are produced to push the limits of symbolic planning domains and are generally considered as challenging benchmarks within the symbolic planning community.\\n\\nThe key findings of the paper can be summarized as follows:\\n1) Allowing LLMs to generate PDDL descriptions working in conjunction with syntax validators and human experts to create a valid PDDL description. The process was still too error-prone to completely automate without human supervision.\\n2) LLMs are not capable of planning even with the restricted PDDL grammar for symbolic planning domains representative of the state-of-the-art in symbolic planning community.\\n3) External symbolic modules that validate plans are capable of improving LLM planning performance, but is still well below the performance of a purpose-built automated planning algorithm',\n",
       "  'strengths': 'The paper appropriately evaluates the capability of LLMs to plan and reason with domain sizes representative of the state-of-the-art in symbolic planning. As can be seen from table 1, the domains are significantly larger than ones seen in evaluating LLMs for planning. both in terms of number of actions and in terms of number of literals within the domain. \\n\\nThe claims of the paper are appropriately scoped, and are well supported by the experimentation. Care was taken by the authors to explicitly characterize the difficulty of the planning domain.\\n\\nThe key results of the paper are intuitive, in that it appears that LLMs are capable of translating information from one format (textual descriptions) to another (formal planning domain predicate and action description), but perform poorly at the actual task of planning and reasoning. Appending plan validator feedback to the prompt and replanning with an LLM is akin to backtracking in planning algorithms but is a very roundabout and computationally inefficient way of implementing search algorithms. It is essentially using the LLM output and context window as memory.',\n",
       "  'weaknesses': \"Reliance on the user: The LLM is forced to generate the domain description one action at a time. This pushes the workload of identifying the right number of actions and stopping criterion onto the user. understanding whether the domain description if complete and consistent is a major aspect of generating the PDDL domain, and right now it seems to be done by the user. \\n\\nExplicitly stating the contribution: I would like the authors to reflect and restate what the major contribution of this paper is. Is it a prompt structure that helps LLMs consistently translate descriptions into PDDL. Or is it the definitions of the symbolic modules used to validate the planning module developed in particular to work well with LLMs. The statement of why the paper is novel, and significant seems missing from the submission, though I appreciate the value that this work brings to the table.\\n\\nLLMs are new on the scene, and I have seen quite a few papers in the LLM + symbolic planning that are very recent and potentially close to the NeurIPS submission deadline. I would hope that if accepted, the authors acknowledge this work and rewrite the background and related work sections accordingly [1],[2]\\n\\n[1] - Liu, B., Jiang, Y., Zhang, X., Liu, Q., Zhang, S., Biswas, J. and Stone, P., 2023. Llm+ p: Empowering large language models with optimal planning proficiency. arXiv preprint arXiv:2304.11477.\\n[2] - Valmeekam, K., Olmo, A., Sreedharan, S. and Kambhampati, S., 2022. Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning and Reasoning about Change). arXiv preprint arXiv:2206.10498.\"},\n",
       " 'review_205': {'summary': 'This paper proposed to apply GPT LLMs to perform PDDL model construction from natural language description and correction with feedbacks, and then use classic planners or LLM planners to construct plans from the PDDL models. Experiments were conducted in the synthetic domains to verify the proposal and found that GPT-4 can construct PPDL models with less errors and classic PDDL planner outperforms LLM planners with the constructed PPDL models.',\n",
       "  'strengths': '1. This is a new exploration of using LLMs to construct PDDL models (or symbolic world models for AI planning)\\n2. Experiments are conducted to compare the performance of LLM planner and classic PDDL planner on the constructed PDDL models, and find that classic planner works better on PDDL model extracted by LLMs.',\n",
       "  'weaknesses': '1. No theoretical framework is proposed to link the underlying probability models of token sequences of  LLMs to the domain and action models described by formal action description languages and its formal handling (e.g. planning, validation, correction and son). Without such a theoretical formal characterization, it is difficult to evaluate the validity and applicability/boundary of this kind of approach built on top of the LLMs, prompt-engineering, chains of feedback correction and planning and so on. \\n2. A few experiments are given but without a systematic handling of metrics and the underlying hypotheses to be verified, and explanation to guide the application of the proposal and future research. The experimental methodology is ad-hoc.'},\n",
       " 'review_206': {'summary': 'This paper presents a novel framework for analyzing and understanding policy optimization based on mirror descent that can leverage any general parameterizations of the policy class. The new framework induces a new update rule based on mirror descent, and the authors proved the new framework enjoys sublinear and linear convergence for general policy parameterization. \\n\\n',\n",
       "  'strengths': \"- The authors did a great job presenting the problem's background and motivation, and the differences between the new proposed novel framework and previous related literature, which is quite intuitive and easy to understand. \\n- The authors provided solutions (Sec. 3.1) to solve the new proposed update rule (Line 1 in Algorithm 1) by introducing a new mirror map, which is novel and easy to follow. \\n- The theoretical analysis for convergence and sample complexity are provided, which makes the whole framework novel and complete. \",\n",
       "  'weaknesses': '- Not necessarily a weak point, but it would be good to provide some empirical examples to explain the motivation or the algorithm.\\n\\n- Not sure if the current framework can be extended to other settings such as online or offline RL. '},\n",
       " 'review_207': {'summary': 'This is a theoretical work and the main claim is the proof of linear convergence rate for policy mirror descent (PMD) algorithms with general policy parametrization. This contrasts with previous results (Lan 2022, Xiao 2022, Cen et al 2021, Zhan et al. 2021,  Cayci et al. 2021, etc.) that proved convergence rates for either tabular or other specific policy parametrizations. The work develops the proof by creating a framework that incorporates general policy parameterization into PMD: Approximate Mirror Policy Optimization (AMPO). The analysis performs a non-trivial extension of the three-point descent lemma (Chen and Teboulle, 1993, Lemma 3.2) and uses the proof techniques of Xiao et al. (2022) for PMD.\\n\\n**Post rebuttal update**\\n\\nThe authors did several changes to answer my review, e.g., they implemented their algorithm and ran some experiments.\\nI raised my score by 1 point due to including an implementation of the algorithm. The experiments did not fully convince me, so I did not raise my score further (see my discussion with the reviewers for more details). My impression is that the contribution is mainly theoretical, and it fits into the literature on theoretical works in this topic. Looking at the constants, and discussing with the authors, I also had the impression that there is a gap in the theory and practice in this domain. It seems that none of the previous works performed experiments to validate the theory either, and replacing the constants in the bounds with reasonable values makes the bounds vacuous. This is not really a problem of the current work, as previous theoretical works in this domain seemed similar. I would encourage the authors to critically consider these points, and discuss limitations of the theory, unless the experiments strongly support the theory.',\n",
       "  'strengths': \"- The paper is well-written and explains how the contributions relate to previous work.\\n- It appears rigorous.\\n- Previous proofs had quite restrictive settings, whereas the submitted paper's theorems allow for neural network parameterizations of the policies, so this is quite important for more realistic theory, and seems like a substantial contribution to this line of work.\",\n",
       "  'weaknesses': '- There are no experiments. It may be good to have to some illustrative experiments that allow understanding the contribution at a glance.\\n- The paper is dense and all of the proofs are in the appendix. Given that reviewers are not obligated to read the appendix, and that no evidence or intuitively clear reasons for why the theory is true is provided in the main paper, it is difficult to judge the correctness of the work without reviewers going beyond what is expected of them (although the work does recover the best known rates in the tabular setting as well as several other previous restricted settings, which is promising). The main related past works were all published at journals, so I wonder whether submitting to a journal may be a better option. I think that conference theory papers benefit from intuitive examples and experiments in the main part of the paper.'},\n",
       " 'review_208': {'summary': 'This paper extends the recently introduced policy mirror descent method of tabular setting to function approximation setting. The essential development seems to reside in exploiting the mirror descent update in the dual space and projecting the dual representation of the policy into a \"realizable\" representation that is consistent with the function approximation used. The author recovers both sublinear and linear convergence when such projection error can be controlled. The resulting method is thus implementable with general parameterization of the policy.',\n",
       "  'strengths': '1. I enjoy the simplicity of this idea. It is well known that when using general function approximation of the policy it becomes unclear how basic three-point lemma holds as we are performing descent in the parameter space, not the policy space. This paper uses the well-known interpretation of the mirror descent method and suggests to first project the dual representation of the updated policy into the one that is representable by the function approximator. Consequently, one is directly doing approximate descent directly in the policy space and the existing framework of policy mirror descent can be adapted. \\n\\n2. I also appreciate discussions on the potential choices of distance-generating functions. Example 3.5 and 3.6 appears to be new to me. Theorem 4.5 on how to control the policy projection error with neural network parameterization seems to be useful. \\n\\n3. Minor comment: using Tsallis divergence as the distance-generating function has been discussed explicitly in arXiv preprint arXiv:2303.04386, 2023. ',\n",
       "  'weaknesses': '1. It appears to me that Lemma 4.1 can be understood as using the projected dual variables $f^{\\\\theta}_s - \\\\nabla h(\\\\overline{\\\\pi}_s)/\\\\eta$ instead of $Q_s$ when doing the policy mirror descent update, especially in the analysis $\\\\overline{\\\\pi}$ is set to be the last policy.  In this sense, Lemma 4.1 seems to be a fairly standard result. This can be seen from \\n\\\\begin{align}\\n \\\\tilde{\\\\pi}_s =  \\\\mathrm{argmin}  <- \\\\eta f^{\\\\theta}_s + \\\\nabla h(\\\\overline{\\\\pi}_s), \\\\pi> + h(\\\\pi) - <\\\\nabla h(\\\\overline{\\\\pi}_s),\\\\pi>\\n\\\\end{align}\\nand consequently \\n\\\\begin{align}\\n \\\\tilde{\\\\pi}_s =  \\\\mathrm{argmin}  <- \\\\eta f^{\\\\theta}_s + \\\\nabla h(\\\\overline{\\\\pi}_s), \\\\pi> + D(\\\\pi, \\\\overline{\\\\pi}_s).\\n\\\\end{align}\\nGiven the above observation standard descent lemma can be applied and yields Lemma 4.1.\\n\\n2. I personally would much appreciate the perspective of this paper -- the projection step of the policy -- instead of the technicality/importance of Lemma 4.1 that the paper is currently promoting. Kindly correct me if I have missed anything.\\n\\n'},\n",
       " 'review_209': {'summary': 'While policy mirror descent methods have been theoretically analyzed in many past works to establish strong convergence guarantees, questions remain regarding the implementation of function approximation in this class of algorithms. The work analyzes general approximators with PMD, obtaining linear convergence guarantees up to standard approximation error. The theoretical approach also yields past algorithms as special cases, and the authors analyze the neural network approximation case as a corollary of their result. The theory also incorporates slightly weaker assumptions/constants in the bounds compared to past work.',\n",
       "  'strengths': 'I think the theoretical contributions of the paper are interesting.\\n\\n- The paper contributes to understanding how theoretically sound function approximation could be used in the case of policy mirror descent based methods, which already admit strong linear convergence guarantees.\\n- The paper is well-written, and the main statements are rigorous and well-defined.\\n- The theory unifies many past policy-based approaches under a framework, which is a meaningful contribution to RL theory.\\n- AMPO, while having theoretical guarantees, seems to be practically relevant and straightforward to implement.\\n- The authors provide a comprehensive comparison with existing results, and their algorithm is well-motivated with examples. The assumptions they introduce seem to be weaker than certain previous results,',\n",
       "  'weaknesses': '- Certain parts of the theoretical results (Sections 3.1, 4.2) are adaptations of existing results, and in the case of Section 4.2, it is not clear how the paper uses certain assumptions/quantities in the referred work in their context.\\n- The particular assumption (A1) and the final result incorporating a $\\\\mathcal{O}(\\\\sqrt{\\\\varepsilon_{approx}})$ bias could be compared to existing results on approximate PMD, see Q4 below.\\n- No experimental results: I think this is a minor weakness. As the main contribution of the paper is theoretical, benchmarking scores with well-tuned existing algorithms could be in my opinion irrelevant. However, since the starting point of the paper was the practical success of PO with function approximation, at least the practical implementation of Algorithm 1 could be demonstrated in some cases.'},\n",
       " 'review_210': {'summary': 'This paper proposes a policy update scheme based on mirror descent for general function approximation. The paper also provides corresponding theoretical analysis on the sub-optimality gap and computation cost. Overall, the reviewer find the theory part not strong enough to prove the advantage of the proposed new algorithm or contribute any new insight to the community.',\n",
       "  'strengths': '-',\n",
       "  'weaknesses': '1. The main results in Theorem 4.3 is not really a meaningful upper bound of the sub-optimality gap of the learned policy since, for a general function approximation class, we do not know how large the term involving $\\\\epsilon_{approx}$, $v_\\\\mu$, and $C_v$ is. More detailed characterization of their scales (how fast do they converge to zero) is necessary to make the current analysis meaningful.\\n2. It is weird to make assumptions on $\\\\pi^t$ in A1, A2, A3 when you are exactly analyzing the convergence of $\\\\{\\\\pi^t\\\\}$, since we do not know where the policy iterate $\\\\pi^t$ will go to. A more natural way to do this is to assume the conditions hold for all policies in the policy class. (But then the authors need to be more cautious about the assumptions.)\\n3. No new insights found in the current framework. The main techniques (mirror decent for policy optimization) are already widely used in previous reinforcement learning theory studies. The proposed algorithm seems another form or a very close variant of proximal policy gradient (PPO).'},\n",
       " 'review_211': {'summary': \"The paper introduces a method for graph random features (GRFs). Graph random features is the graph equivalent (i.e. kernels defined on graphs) of kernel matrix approximation using Random Features (Rahimi & Recht). Recently Chromanski et al. had proposed a method for GRF which uses a series of random walks. \\n\\nIn the Euclidean setting, the quasi-Monte Carlo variants of the Random Features methods have been developed since they provide better convergence properties. So the goal of this paper is to devise an algorithm for the quasi-Monte Carlo GRFs setting. \\n\\nThe idea is to correlates the length of the random walks by imposing 'antithetic termination' which is effectively a procedure to obtain a more diverse ensemble of graph random walks. \\n\\nThe paper provides several theoretic results related to the error guarantees as well as a brief empirical study.\",\n",
       "  'strengths': '+ Original idea with strong practical impact and wide ranging downstream applications as time-efficient approximation of the graph diffusion process is used in many scientific fields. \\n+ The paper is of very high quality: Well written and clear.  \\n+ Good literature review and problem justification, as well as empirical analysis. \\n\\n',\n",
       "  'weaknesses': '- Some typos/grammatical mistakes (esp. definite/indefinite articles), please proof read before publishing\\n- Some questions below as well.'},\n",
       " 'review_212': {'summary': 'This work proposes an efficient random-walk sampling approach that accelerates the estimation of the feature mapping for 2-regularized Laplacian kernels. The random walk sampling is based on antithetic termination, which is a variance reduction technique and sounds novel  when being applied to the estimation of graph random features. The technique sounds solid. The authors also conducted experiments from different angles to verify the effectiveness of the proposed approach in practice. ',\n",
       "  'strengths': '1. Using random walk with antithetic termination to estimate graph random features is novel, to the best knowledge of me. \\n2. Although I did not check the appendix, the technique and the benefits it may bring look reasonable to me.\\n3. The authors did a great job to explain the key insights behind. The paper is very well written. \\n4. The experiments are extensive. The benefits of the proposed approach is justified from various angles. ',\n",
       "  'weaknesses': '1. The biggest weakness of the work is the limited scope of this work. It is unclear why the 2-regularized Laplacian kernel is important and why we need to compute it. It seems that 1-regularized Lap kernel can be efficient computed by Pagerank algorithms, why we may need 2-regularized Lap kernel. \\n2. It is unclear how much the estimation of the 2-regularized Laplacian kernel relies on the random walk with antithetic termination. Can this random walk approach be only applied to 2-regularized Laplacian kernels or a broader range of graph kernels? This question is kind of related to whether the paper has over-claimed the contributions. Neither the title nor the introduction reflect that the improvement is only for  2-regularized Laplacian kernels, and they claim a broader range of contributions. I expect the authors to make the actual contributions more clear in the revised version.  '},\n",
       " 'review_213': {'summary': 'The author(s) extend the work of Choromanski [2023] and introduce quasi monte carlo graph random features.\\nTo estimate the 2-regularized Laplacian kernel, they now use random walk features for each node which have coupled probabilities of terminating after a certain number of steps.\\nThis increases diversity in the features and interestingly leads to provable reduction of variance of the global estimates.\\nAn empirical evaluation supports the theoretical findings by improved practical variance, as well as in a clustering and supervised node learning scenario.\\n',\n",
       "  'strengths': '\\nThe paper is well-written and mostly easy to follow. \\nWhile proofs are moved to the appendix, a sketch of proof of the main result is included in the paper. I like that.\\n\\nThe introduced way of increasing diversity in random walks is (up to my knowledge) novel and very easy to implement. While it is evaluated in the context of estimating the 2-regularized laplacian of a graph, I agree with the authors that this method is of independent interest. \\nAn interesting question is if this kind of sampling improves results of other random walk based approaches, as well, or if the parctical impact is restricted to just a few scenarios (GRF being one of them).\\nAs a result, I see potential impact for further research beyond this immediate application.\\n\\n',\n",
       "  'weaknesses': \"The introduction is structurally very similar to that of Choromanski [2023]. I'm assuming now that I know one of the authors of this submission. Otherwise, I would recommend the authors to revise the introduction to decrease similarity. \\n\"},\n",
       " 'review_214': {'summary': 'Kernel methods are important in many ML applications, but they suffer from scalability issues. In the Euclidean setting, random features methods (Rahimi & Recht NeurIPS 2017) can be used to \"sketch\" the kernel matrices and speed up computations. In the graph setting, however, no such random feature seems to have been available until a 2023 preprint by Choromanski. \\n\\nThe present paper present an improvement over Choromanski\\'s method. To explain it, note that the basic idea in the 2023 preprint is to consider random features for the regularized graph Laplacian, and to obtain an approximation of an operator of the form $(I-U)^{-d}$ via importance-weighted random walks. These random walks have geometrically distributed lengths. \\n \\nThe main theoretical contribution of the present paper can now be explained: a simple modification of Choromanski\\'s method, where the the geometrics of pairs of random walks become correlated, has the same zero bias and a smaller variance than the above method. \\nThis requires an elementary, but long proof with a long case analysis.\\n\\nExperimentally, the gains observed were:\\n\\n* visible, but not too big for approximation of the kernel;\\n* impressive for graph diffusions (which is natural because this requires exponentiating the Laplacian);\\n* fairly significant for clustering and node attribute prediction methods.',\n",
       "  'strengths': 'The paper is clear and seemingly original. In general it is fairly well-written. Moreover, the \"anthitetic\" coupling is a simple little idea that could be applicable more broadly.\\n\\n',\n",
       "  'weaknesses': 'The present paper has been submitted before Choromanski\\'s preprint appeared. As a result, applications of graph kernel random sketches are quite incipient still. It is hard to say whether the present paper will have a significant direct impact. _[Edit on 08/11: this was partly addressed in the rebuttal.]_\\n\\nThe proof of variance reduction is very long and difficult to check. (Though I believe it.)  (An \"actionable version\" of this point is that it would pay off to make this paper a bit less dependent on Chorumovski\\'s preprint by eg. adding more experiments or theory.)  \\n\\n\\n_Less important comments_\\n\\nThe notation $t_{1,2}$ is a bit weird as it represents a pair of RVs. Moreover, if I understand correctly, these r.v.s are resampled at each step of the walk. \\n\\nIn terms of exposition, it seems that all the authors need to do is to correlate the coin flips for the two walks at each step. Could you write their joint distribution purely in terms of the probabilities of 00, 01, 10 and 11?  '},\n",
       " 'review_215': {'summary': 'The paper proposes a idea to borrow one of the strengths of score-based DMs, which is the ability to perform accurate density estimation in low-density regions and to address manifold overfitting by means of data mollification. We connect data mollification through the addition of Gaussian noise to Gaussian homotopy, which is a well-known technique to improve optimization. Data mollification can be implemented by adding one line of code in the optimization loop, and the authors demonstrate that this provides a boost in generation quality of likelihood-based GMs, without computational overheads.',\n",
       "  'strengths': 'The paper presents a fairly easy to use data mollification techniques to help vae and flow model to generate better samples, especially for low data density region.',\n",
       "  'weaknesses': '1.The first concern of this paper is its novelty and it is very critical for conference like Neurips. It basically states the same thing as in \"Generative modeling by estimating gradients of the data distribution\", a NeurIPS 2019 oral paper. Due to the identical proposition and analysis of generative model, the novel element in this paper is very limited. The difference is instead of inference the score, the paper just let the generative networks to train under the mollified data.\\n\\n2. The description of the model is vague, except for algorithm1, there is no clear presentation of how to use the model. Although in line 235, it says \"This process uses the solution from one level of mollification as a means to guiding optimization for the next.\", do the authors suggest, in a generative task (lets say image generation) a sample is generated from white noise by following the gradient of each gaussian level? The connection between langevine dynamics, SDE, diffusion models are very strong to this kind of sampling.\\n'},\n",
       " 'review_216': {'summary': 'The paper proposes an optimization method that improves the training of likelihood-based generative models. The central idea is that in the early phases of the optimization, the learner tries to model a smoothed version of the likelihood function. As the optimization proceeds, the smoothening decreases (and the difficulty of the optimization problem increases) with the end goal of learning the likelihood of the true distribution. The authors show that this simple idea (inspired by the diffusion models literature) gives consistent improvements in the performance of likelihood-based generative models.',\n",
       "  'strengths': 'The authors borrow an idea from the diffusion literature (the mollification of the data distribution at many levels) and they apply it in an interesting way to likelihood-based models such as VAEs and Normalizing Flows. Interestingly, the modeling target changes during the optimization (starting from easy distributions and slowly going to harder ones). Instead, diffusion models try to model all the distributions simultaneously. As far as I know, this method has not been proposed in previous works and it seems to be effective in improving likelihood-based models.\\n\\nThe paper is clearly written and the experimental methodology seems valid. \\n\\nThe authors showcase the effectiveness of their method starting from informative toy examples and moving to real datasets (CIFAR-10 and CelebA). The boost in performance is consistent across the experiments.\\n',\n",
       "  'weaknesses': 'Even though the method increases the effectiveness of likelihood-based models, the performance is still very weak. The authors acknowledge this limitation. This is not necessarily an important weakness since future work might further improve the performance of likelihood-based models to the point they become competitive with diffusion models. However, I do not see how this particular optimization method could be improved to achieve these results.\\n\\nI do not see why the noise schedule has to be similar to the noise schedule diffusion models use. In the design process of a diffusion model, we typically select the corruption scheduling such that the difficulty of transitioning from one corruption level to the next one during sampling is roughly the same across all corruption levels. Why does this intuition transfer here on how we select the scheduling?\\n\\nI am also puzzled why there is no catastrophic forgetting happening. The authors mention that for the last 50% of the optimization, they stop using their method of mollification and they train for the true distribution.\\n\\n\\n\\n\\n\\n\\n'},\n",
       " 'review_217': {'summary': 'In this paper, the authors address the limitation of likelihood-based Generative Models (GMs) in achieving high-quality samples compared to state-of-the-art score-based Diffusion Models (DMs). They propose a novel approach to enhance the generation quality of GMs by incorporating data mollification, a technique used in score-based DMs for accurate density estimation in low-density regions and to mitigate manifold overfitting.\\n\\nThe authors connect data mollification with Gaussian homotopy, a well-known optimization technique, by adding Gaussian noise to the data. This simple addition can be implemented with just one line of code in the optimization loop of likelihood-based GMs. Through experiments on popular image datasets using various likelihood-based GMs, such as variational autoencoders and normalizing flows, the authors demonstrate improvements in generation quality, as measured by the FID score.\\n\\nNotably, this approach provides a boost in generation quality without incurring additional computational overheads. This work could potentially be a step towards bridging the gap between likelihood-based GMs and score-based DMs, offering new possibilities for generating high-quality samples in various domains.',\n",
       "  'strengths': 'The approach presented is both straightforward and seamlessly integrable into the training process of various generative models. The authors provide lucid instructions and accompanying pseudo code for its implementation. Notably, the results displayed in table 1 exhibit a remarkable enhancement compared to the baseline performance.',\n",
       "  'weaknesses': 'The approach described in the paper lacks explicit discussion regarding its relationship to noise augmentation. However, towards the end of section 3, it appears that the authors have chosen a temperature factor of 0.7, which leads to a substantial mollification towards the end of the training process. Additionally, their results are comparable to what is typically observed with conventional data augmentation techniques.\\n\\nGiven that the evaluation of the presented method in this paper is entirely based on empirical analysis, it is crucial for the authors to empirically demonstrate that their approach surpasses alternative methods. Replacing the sigmoid noise schedule with a uniform/constant function would be the equivalent to simple data augmentation with Gaussian noise. Since data augmentation using Gaussian noise is a common practice in the training of many generative models, it becomes essential to provide empirical evidence showcasing that the proposed noise schedule yields results that go beyond what can be achieved with a uniform noise schedule. The authors should provide results from experiments with different amounts of noise and show that their noise schedule outperforms all of these.\\n\\nThe authors present little theoretical evidence for the choice of noise function. They justify their choice of the sigmoid function by referencing Jabri et al., who demonstrated improved stability with the sigmoid function compared to the cosine function through empirical results. However, the empirical findings displayed in table 2 contradict this justification, indicating that a cosine noise schedule performs better than the sigmoid noise schedule in all cases except GLOW.'},\n",
       " 'review_218': {'summary': 'This paper proposes the use of data mollification to improve sample quality from likelihood-based generative models. The authors observe that likelihood-based models are worse-performing than score-based models due to manifold overfitting (i.e., learning the manifold but not the distribution on it), and poor density estimation in low-density regions (demonstrated with toy examples). Data mollification is proposed as a solution to these issues and demonstrated visually with toy mathematical constructions. On CIFAR10 and CelebA (64x64), the methodology is shown to improve FID scores and there is a visible qualitative improvement in the model samples. Different choices of mollification processes and annealing schedules are explored and compared.',\n",
       "  'strengths': '- Main results show significant improvements in FID score on multiple image datasets by introducing a technique that entails no additional computational cost. These hold across different image datasets. Samples are not cherrypicked.\\n- Results are positive on two families of generative models, normalizing flows and variational autoencoders.\\n- The considered hypotheses suggesting why likelihood-based models suffer from sample quality are backed with theoretical work and experiments with toy examples, where visualization of these phenomena can be confirmed.\\n- Various hyperparameters (e.g., the choices of mollification process and schedule) are compared, and the main results are ablated against the same model without the proposed methodology. This gives confidence in their methodology truly demonstrating improvement on the datasets and models considered.\\n- The paper is very well written, has clear and easy-to-follow language, and the literature review is more than satisfactory. There are a few issues on presentation (see questions section in my review).',\n",
       "  'weaknesses': '- My biggest concern is that the image datasets considered might be too simple to conclude that these techniques will materialize into improvement for larger-scale datasets and models. One potential way to do this is to study, e.g., ImageNet 64x64; usually, positive results there are much more likely to hold in larger scales due to the large scale and difficulty of ImageNet itself. Conversely, results in datasets with very narrow distributions (low entropy) like CIFAR10 and CelebA might not transfer to very diverse, more challenging datasets in practice. Studying the effect of the methodology on more challenging datasets will make the results much more valuable and significant.\\n\\n- The methodology is not very substantial due to its extreme simplicity, nor is mollification new to the literature as acknowledged by the authors themselves. Arguably, however, applying mollification to the data in a schedule for generative models is not something done in practice for generative models, and contrary to score-based models, it does not require learning all noise levels, so it could be seen as a clever and creative way of applying similar ideas from the literature. Simplicity can be positive, and perception of novelty can be extremely subjective, so I am not too concerned about this. Still, due to how short the contribution is, exploring more models would been very welcome since the paper is generally about likelihood-based generative models.\\n\\n- Minor: while there is enough visual and empirical evidence, there is little discussion for *why* data mollification alleviates the problems of manifold overfitting and accurate density estimation in low-density regions. Since there is a lot of discussion and even theorems from prior work in the body of the paper, a theoretical lens, or at least hypotheses or discussion around this question feel lacking and would be very welcome.'},\n",
       " 'review_219': {'summary': 'The paper proposes using different generative models (transformer or diffusion) rather than the same model (like in trajectory transformer/decision diffuser) for observation prediction, reward estimation, and action prediction in “model-based” offline RL. They demonstrate that this flexibility improves performance in offline RL in a POMDP setting where two dimensions of the state vector are removed for each environment.',\n",
       "  'strengths': '1. The paper is well written and easy to read.\\n2. The consistent increase on POMDPs is encouraging. And the ablation with different modules is very interesting.',\n",
       "  'weaknesses': '1. Similar performance to DD on D4RL Gym tasks.\\n\\n2. Major similarities to previous work (trajectory transformer, decision diffuser) and the authors acknowledge this and highlight the reward modeling as novel. While it is interesting, a (temporal difference) variant already exists in the trajectory transformer paper [Janner et al 2021].  Namely, the trajectory transformer with Q function (a form of reward modeling) guided planning which can be found in Section 4.2 of [Janner et al 2021], under “Combining with Q functions”. \\n\\n3. Does it matter which two observation dimensions are removed? An explanation of which dimensions were removed and why is missing and a sensitivity analysis to the dimensions removed are missing as well.\\n\\n4. Is there any intuition for why the conditioning in Equations (4), (5), (6) were chosen? \\n\\n5. Is there heuristic that could be used to choose the different modules with any online interaction? Such a heuristic would be necessary in offline RL.'},\n",
       " 'review_220': {'summary': \"This paper proposes to disentangle the different modalities (reward, observations, and actions) utilized in offline goal-conditioned reinforcement learning instead of the standard temporal single-module structure. The paper contributes three independent generative modules that have the benefit of parallelizable training. The paper includes empirical results showing the proposed algorithm's comparable or superior performance to baselines on several MDP and POMDP environments. \",\n",
       "  'strengths': '1. The core idea to utilize a different decomposition of tokens to enable independent training of generative models appears interesting and novel. I enjoyed the simplicity of the approach, accompanied by the good empirical results. \\n\\n2. Overall, I found the paper to be well-written and clear. I liked that the authors are clearly familiar with the relevant related literature and used diagrams throughout to help illustrate concepts. \\n\\n3. Given the good empirical results, the idea of semantic decomposition (noted in strength 1) could be generally impactful for communities interested in transformers + RL.\\n\\n4. I appreciate the extensive experiments performed to support the claims of flexibility and performance.  ',\n",
       "  'weaknesses': 'In general, I liked this paper. A few things that I think could improve it:\\n\\n1. I would have liked to see the training cost comparison to the other algorithms. \\n\\n2. In general, I would also like to see a more extensive discussion of the experimental results, as noted in questions 4-6 in the Questions section below. \\n\\n3. I feel like some of the claims are a bit strong. For example, how does the work \"guarantee\" expressivity and flexibility? This language is often used when we have an assured property of the system or algorithm, but I don\\'t see any rigorous theoretical evaluation of this claim. \\n\\nMore minor:\\n\\n1. Missing some references, including work in compositional offline RL (as mentioned in the introduction, first paragraph) [Mendez et al., 2022] and a reference to the POMDP formalism [Kaelbling, Littman, and Cassandra, 1998]. \\n\\n2. The focus on MDP and POMDP environments was somewhat unclear to me. I think including some motivation or intuition in the Introduction as to why this approach would work better than previous works in both types of environments would make this more clear.\\n\\n-----------------------------------------------------------------------------\\n\\n[Mendez et al., 2022] Mendez, Jorge A., Harm van Seijen, and Eric Eaton. \"Modular lifelong reinforcement learning via neural composition.\" arXiv preprint arXiv:2207.00429 (2022).\\n\\n[Kaelbling, Littman, and Cassandra, 1998] Kaelbling, Leslie Pack, Michael L. Littman, and Anthony R. Cassandra. \"Planning and acting in partially observable stochastic domains.\" Artificial intelligence 101.1-2 (1998): 99-134.'},\n",
       " 'review_221': {'summary': 'This paper proposes to tackle the problem decision making using a stack of different generative models. The first generative model constructs a conditional distribution over observations. A subsequent generative model constructs a conditional distribution over rewards, with a final generative model constructs a distribution over actions. The authors illustrate the efficacy of this decomposed approach across a suite of different tasks.',\n",
       "  'strengths': '- I enjoyed reading the paper -- it was quite clear and easy to read. The motivation of the paper to decompose the generative modeling objective into a set of component modules is sound. \\n- The paper follows a formulation of offline reinforcement learning as probabilistic inference that is likely to relevant to a large audience at NeurIPS with the increasing popularity of generative models\\n- The approach performs well across a set of different environments, outperforming existing baselines across 3 separate tasks.',\n",
       "  'weaknesses': \"- The results illustrated in the approach are a bit toy -- with the largest gains in the Maze2D environment. The Mujoco control environment has somewhat limited gains and the constructed POMDP environment seems a bit artificial. It may be that the Mujoco control environments have already saturated in performance and it may be interesting to try more complex planning tasks such as RLBench or other robotic manipulation environments.\\n- While I understand the motivation to decompose trajectory synthesis into a set of modular components, I'm not sure I completely understand the particular decomposition of first observations, then rewards, and then actions. It seems like decomposing rewards first may be more natural then observations.\\n- It might also be interesting to explore the extent to which decomposed submodules can enable compositional generalization or more efficient multitask learning by encoding structure in the greneration procedure. For instance -- perhaps the observation model can be used across a set of different tasks.\\n\\n\\nThere are a couple of typos in the paper listed below:\\n\\n- L133 typo auotregressive -> autoregressive\\n- In L303  Dai et al should be Du et al. The method does not use a state model as a pretrained text2image model but rather a learned text2video model.\\n- The table before section 4.2 is misformatted and extends to the margin of the paper\"},\n",
       " 'review_222': {'summary': 'This paper highlights a drawback in prior frameworks, such as Decision Transformer and Diffuser, where the absence of modular hierarchies among different tokens results in limited expressivity and flexibility. To overcome this issue, the paper introduces Decision Stacks (DS), a modular algorithm designed for learning goal-conditioned policies using offline datasets. The proposed method parameterizes three generative model-based modules for future observation prediction, reward estimation, and action generation, respectively. Through various offline evaluations in both MDP and POMDP environments, this paper demonstrates that DS outperforms previous approaches by generating superior plans.',\n",
       "  'strengths': 'This paper presents a modular probabilistic framework, utilizing deep generative models to establish token-level hierarchies in trajectory generation. The proposed algorithm, Decision Stacks (DS), incorporates independent generative models for simulating the temporal evolution of observations, rewards, and actions, allowing for parallel learning and enabling flexible generative decision making. The algorithm is both straightforward and effective, particularly in the POMDP setting, where DS surpasses other baseline methods by a significant margin. Additionally, the experiments are conducted meticulously, and the visualizations of example rollouts in the Maze2D-medium-v1 environment are clear.',\n",
       "  'weaknesses': 'One major concern regarding the proposed algorithm DS is the high complexity of the model, as it requires training three generative models. However, in most experiments such as offline RL with an MDP setting, the performance improvement compared to other baselines that use only one generative model is not significant. Furthermore, the paper lacks an explanation of the specific dimensions that were excluded to construct the POMDP setting. Additionally, as depicted in Figure 1, the generation of observation, reward, and action sequences follows a sequential order, and there exist dependencies among the three generative models. However, the paper does not provide clear explanations on how training can be parallelized and how the choice of generative models affects performance.\\n'},\n",
       " 'review_223': {'summary': 'This paper focuses on solving offline RL with generative models. Concretely, it proposes a method to modularize the joint distribution of time-induced trajectories and use separate generative models to represent observation module, reward module, and action module. Evaluations are conducted on D4RL benchmark with MDP and POMDP environments. Extensive comparisons against prior works are included.',\n",
       "  'strengths': '- The paper is fairly well presented and easy to follow. \\n\\n- The proposed method is extensively evaluated against multiple related approaches.',\n",
       "  'weaknesses': '- Novelty of the proposed method is limited. The improved performance can also be attributed to other confounding factors, such as larger models due to reward and action modules being factored out.\\n\\n- It is counter-intuitive to ignore the canonical time-induced casual ordering in favor of different token types. More intuitions and theoretical analysis (if applicable) are encouraged to provide.\\n\\n- Lack of evidences to support the claims on modular expressivity (L145). Are there any experiments showing it can transfer to new environments?\\n\\n- The empirical results, especially those on D4RL locomotion tasks, are not significant enough to justify the extra compute introduced.\\n\\n- Just swapping each module with different model architectures/modeling strategies is not enough to gain insights of the proposed method. More ablations and analysis are necessary.'},\n",
       " 'review_224': {'summary': 'This paper explores the behavior and performance of neural operator models on multiple partial differential equation (PDE) systems in the transfer learning setting. The authors investigate the impact of various factors on the performance of neural operator models, including model size, downstream dataset size, underlying physics of the downstream tasks in relation to pre-training, and distributional shifts.\\n\\nThe study employs the \"pre-train and fine-tune\" paradigm for SciML (Scientific Machine Learning) problems. The authors show that it is possible and beneficial to develop more general SciML models capable of solving multiple tasks with the same set of weights, even when downstream tasks involve small-to-moderate distribution shifts relative to the pre-training data. The research demonstrates the potential of neural operator models for transfer learning, paving the way towards building foundation models for SciML.',\n",
       "  'strengths': 'Originality: \\n\\nThe paper demonstrates a high level of originality in several aspects. Firstly, it explores the use of neural operator models for solving multiple partial differential equation (PDE) systems, a novel approach that combines the power of neural networks with physics-informed learning. The authors investigate the behavior of these models under various conditions, including model size and downstream dataset size, providing valuable insights into their scalability and transferability. Secondly, the study applies the \"pre-train and fine-tune\" paradigm to SciML problems, showing the potential of developing more general SciML foundation models. This approach is innovative and opens up possibilities for efficiently addressing diverse downstream tasks with a single pre-trained model. Furthermore, the paper explores the impact of distributional shifts in downstream tasks relative to the pre-training data, contributing to the understanding of transfer learning behavior in the context of PDEs. The inclusion of multiple downstream PDE systems and the analysis of various performance metrics demonstrate a comprehensive and original investigation.\\n\\nClarity: \\n\\nThe paper is well-written and presents its findings in a clear and organized manner. The subsection is organized logically following the order of the posted questions.\\n\\nSignificance:\\n\\nThe significance of the paper lies in its contribution to the field of SciML and transfer learning for PDEs. By characterizing the behavior of neural operator models under different conditions and exploring transferability across multiple downstream PDE systems, the paper provides valuable insights for researchers working in the area of computational physics and scientific modeling. The findings have practical implications, as they suggest the potential for developing more versatile and efficient foundation models for SciML tasks. The \"pre-train and fine-tune\" approach demonstrated in the paper can be leveraged to achieve better generalization and performance in solving PDEs across a wide range of scenarios.',\n",
       "  'weaknesses': 'Motivation: \\n\\nWhile the paper extensively analyzes the performance of neural operator models under different conditions, it lacks direct motivation of understanding the transfer learning for PDEs problem in SciML, as these different conditions have been well-explored in the LLM and CV community.\\n\\nPotential Overfitting in Transfer Learning Settings: \\n\\nThe paper briefly mentions that few-shot transfer learning outperforms training from scratch, but it does not thoroughly address the possibility of overfitting to the specific downstream tasks during fine-tuning. An investigation into potential overfitting issues and strategies to mitigate them would be valuable.'},\n",
       " 'review_225': {'summary': 'This paper analyzes the transfer performance of the pre-trained foundation model for scientific machine learning applications described by PDEs. A wide range of settings is considered: various sizes of downstream datasets, pretrained model, out-of-distribution data, as well as multi-tasks and applications. Conclusions, though not necessarily surprising, are drawn under these settings. ',\n",
       "  'strengths': \"- To the best of the reviewer's knowledge, this is a relatively comprehensive analysis of pre-training and transfer learning regimes over a diverse set of physical systems. \\n\\n- The presentation is clear and easy to follow, and the experiments are comprehensive and convincing. \",\n",
       "  'weaknesses': '- For the experiments, more network architectures can be considered.\\n\\n- The findings provided by the paper are more or less consistent with NLP and cv tasks. This is not necessarily a drawback, but the paper would be stronger if it provides some findings that make Scientific Machine Learning different from other well-explored AI tasks.'},\n",
       " 'review_226': {'summary': 'This paper investigates the finetunability, transfer, and generalization properties of a foundational model applied to the field of scientific machine learning, as functions of finetuning dataset size, pretrained model size, and value of physics parameters governing the equations of the system. ',\n",
       "  'strengths': 'The paper is well-written and well-organized, easy to follow and understand. The authors present their method clearly, and they provide a detailed evaluation of their method, with findings clearly highlighted and supported by strong empirical evidence. The experimental hypothesis are clearly stated up front and verified throughout the paper, with sound methodology and experiment design.',\n",
       "  'weaknesses': \"A weakness, also acknowledged by the authors at the end of Section 3 -- but without much contextualization --, is that they only explore the questions raised in the paper in the Fourier Neural Operator (FNO) architecture, and present it as a prototypical SciML architecture. Section 3 explains that this is a good choice for problems with periodic boundary conditions like the ones explored in this paper. However, it's unclear whether any of these results would hold for other types of OOD problems or other types of architectures. Therefore, without more contextualization, it's unclear whether these findings are generalizable and would allow the community to build on top of these findings, or whether they are anecdotal, and would only hold for the architecture and type of problems explored in this work.\\n\\nAnother weakness is that some of the findings, as currently present, merely seem to provide additional experimental evidence for notions that are already widely accepted in the community, such as the fact that, in the low downstream data regime, pretraining a model and then finetuning it on this data is preferable (and yields higher performance) than training a model on this data from scratch, or that finetuning small capacity models plateaus to a certain irreducible error even if data continues to increase. \\n\\nFinally, while the authors acknowledge that a concurrent paper covers the alternative approach of in-context learning (as opposed to finetuning), I would have expected the authors of this paper to compare against that alternative, as opposed to simply benchmarking against training from scratch, which is a much less tight comparison. I think this paper would benefit from the inclusion of that baseline.\"},\n",
       " 'review_227': {'summary': 'This work explores and demonstrates how a \"pretraining+finetuning\" paradigm may be leveraged for neural networks applied to PDEs. Specifically, for three different systems governed by distinct PDEs, the authors study how different factors influence performance: (1) downstream dataset scale; (2) model scale; (3) OOD-ness of the downstream data; (4) pretraining on systems governed by different physics. The authors find that pretraining systematically improves performance, delivering significant performance gains in limited downstream data settings -- which are particularly relevant to SciML, which is often more data-constrained than NLP. ',\n",
       "  'strengths': '* **S1.** This work could be very significant for the community: it explores important topics for SciML, presents extensive strong results, and is easy-to-follow, well-structured, and pleasant to read. The paper is also extensively detailed (regarding data setup, architectures, etc.).\\n\\n* **S2.** The authors study a variety of scenarios (OOD-ness, downstream dataset size, etc.) and perform appropriate comparisons with a \"from scratch\" baseline. The identified strength of the approach (in the low downstream data regime) answer particularly well challenges in the field.\\n\\n* **S3.** The authors open-source their code, which will help with propagating their work, increasing its impact, and enabling better reproducibility. ',\n",
       "  'weaknesses': '* **W1. The experiments could be more systematic across the three systems proposed.** \\n    * **W1.1.** The SYS-3 setup is not featured for downstream dataset scaling & model scaling; it would be valuable to see it in these scenarios to further validate the method, especially since it is described as the most challenging setting.\\n    * **W1.2.** The behaviour over multiple operator could be better explored: it is lacking a comparison with SYS-2, and is done only on a very \"in-domain\" case (while Figure 1 for instance is done with disjoints domains) thus causing the n-shot behaviour to be flat. \\n   * **W1.3.** (minor) In Figure 4d) (with extreme OOD on SYS-1), the from scratch behaviour is different, never catching-up with the TL case. This diverges from the trend and warrants some explanations. \\n\\n* **W2. Some of the framing around large language models is inaccurate.**\\n   * **W2.1.** l25 \"An important aspect of the trained foundation model is the notion of emergence—the model is able to perform tasks seemingly different than those for which it was trained by leveraging shared features across the training tasks.\" It is misleading to characterise emergence with this sentence. As discussed in Wei et al., 2022 emergence is more accurately described by \"abilities that are not present in smaller-scale models but are present in large-scale models\".\\n   * **W2.2.** The few-shot terminology can be confusing in some cases. For large language models, zero/few-shot is synonymous with in-context learning. Mentioning few-shot alone simply means prompting the model. Here, in this work, it systematically means finetuning the model on these few shots. \\n   * **W2.3.** l227 \"This is motivated by observations in NLP that after a critical model size, we can expect significantly better adaptation performance\" it\\'s unclear what the authors refer to here, as finetuning efficiency in NLP is closely related to sample efficiency and is known to increase smoothly with model size (Kaplan et al., 2020). \\n   * **W2.4.** (minor) l145 the focus on GPT models is a bit odd: finetuning applies to all classes of modern language model, and in fact the GPT (i.e., causal decoder-only) models are somewhat unique in their ability to not require finetuning. Conversely, they do not perform as well for fine-tuned tasks as other models: see What Language Model Architecture and Pretraining Objective Work Best for Zero-Shot Generalization? Wang et al., 2022. \\n   * **W2.5.** (minor) l25 the references to scaling laws are missing a citation for Hoffmann et al., 2022, which is the reference work at this time and which highlighted the need for joint scaling of data and model size instead of model size alone predominantly. \\n\\n* **W3.** Smaller nits: l44 \"TL\" to refer to transfer learning as not been introduced as an acronym. \\n '},\n",
       " 'review_228': {'summary': 'This paper introduces cycle consistency in diffusion models to achieve regularization in image manipulation. It allows out of domain image generation with text prompt modification, and can be trained with very little data (~2K) with minimal computational requirements (1GPU). When we apply pre-trained DM models on I2I tasks, it is difficult or unpredictable to control the mask and attention maps to achieve the desired results. Cyclic consistency regularization allows us to address this. Experiments are conducted on many datasets such as Yosemiti summer-winter, horse-zebra, etc. On standard metrics such as CLIP, FID, and LPIPS, the proposed method outperforms other baselines such as CycleGAN, TEX2LIVE, etc. ',\n",
       "  'strengths': '1) There has not been much regularization in diffusion models except for guidance driven by the conditional text. It is nice to see the celebrated Cycle-Consistency loss developed for diffusion models. \\n\\n2) The paper clearly motivates and states the problem. It is nice to see that the proposed method nicely inherits the controlnet architecture to incorporate the cycle-consistency loss function during training. \\n',\n",
       "  'weaknesses': '1) While enforcing cyclic consistency we are feeding the actual input image as the conditional input. This seems a bit strong and it appears that the diffusion model may be overfitting to the conditional input. \\n\\n2) It is not clear how one obtains the negative prompt c^{-1}. The method takes a prompt c_{text}=(c^{+}, c^{-}), where c^{+} is the prompt that drives the diffusion process towards the images that are associated with it, and the negative prompt c^{-} drives the process away from these images. The paper only mentions this once without sufficient details on how this is done. \\n\\n3) The proposed method heavily relies on controlNet and uses the original image to impose the Cyclic-Consistency loss. It may be worth just testing with standard ControlNet with canny edge-map as conditional input and appropriate text prompt. \\n\\n'},\n",
       " 'review_229': {'summary': 'This paper presents a method that tackles the challenge of consistent image-to-image (I2I) translation using diffusion models (DMs) and unpaired image conditioning and text prompts. The proposed approach incorporates Cycle Consistency Regularization to ensure cycle consistency and Self-Regularization to generate images that align with the target domain. Furthermore, the paper introduces a multi-domain I2I translation dataset that encompasses object state changes.',\n",
       "  'strengths': 'a)\\tFrom the visual results, the proposed CycleNet can well preserving the structures of the input image.\\n\\nb)\\tThe author introduces a multi-domain I2I translation dataset for object state changes.',\n",
       "  'weaknesses': \"a)\\tThe experimental results are quite strange. \\n\\ni.\\tIn Figure 2, Figure 3, Figure 5, and many images in the supplementary materials, The results of CycleNet show severe hue shifting. This is a serious issue, and I suggest the author analyze and address this problem.\\n\\nb)\\tThe author's comparison methods are not comprehensive. Many editing methods based on diffusion have been proposed, such as pix2pix-zero, masactrl, etc. I suggest the author compare these methods.\\n\\nc)\\tAlthough CycleNet aims to handle unpaired I2I translation tasks, it still requires paired datasets for training. So, how well does CycleNet generalize to unseen domains (such as variations of other unseen species, etc.)?\"},\n",
       " 'review_230': {'summary': 'This work aims at addressing the task of unpaired I2I translation with pre-trained diffusion models. Inspired by CycleGAN, authors incorporate cycle consistency into diffusion model to regularize process of image translation and proposed CycleNet. In addition it also contributes a multi-domain I2I translation dataset with object state change. Extensive experiments demonstrate that the proposed method can produce high-quality translation results with good consistency and is able to generalize to out-of-domain generation tasks by changing text prompts.',\n",
       "  'strengths': '1. It is interesting and reasonable to introduce cycle consistency into diffusion models for training unpaired I2I translation models.\\n2. A new multi-domain I2I translation dataset for object state change with text prompt is collected.\\n3. Extensive experiments demonstrate the effectiveness of the proposed method.\\n4. Capbility to generalize to out-of-domain data by simply changing text prompt.',\n",
       "  'weaknesses': '1. I wonder how CycleNet compares with CycleGAN. More comparison between CylceNet and CycleGAN should be provided. If their performance is similar, then why use a diffusion-based method instead of GAN-based for unpaired I2I translation task?\\n2. Authors are suggested to experiment with more diffusion models such as T2I Adapter to show its generalization on models.\\n3. Any explanation on why FastCycleNet perform better in several metrics? The coffee-to-empty translation result does not seem good, not only changing the color but also failing to become empty.'},\n",
       " 'review_231': {'summary': 'The paper introduces CycleNet, a new method that enhances image manipulation by incorporating cycle consistency into diffusion models. The paper addresses the challenge of unpaired image-to-image translation and aims to provide a consistent and intuitive interface for this task.',\n",
       "  'strengths': \"1.Originality: The paper introduces CycleNet, a new method that incorporates cycle consistency into diffusion models for image manipulation. This approach combines the concept of cycle consistency with text-guided diffusion models. \\n\\n2. Quality: The paper provides a comprehensive evaluation of CycleNet's performance using various quantitative metrics such as FID, CLIP Score, LPIPS, PSNR, SSIM, and L2.  The results also support the claims of the paper.\\n\\n3. Clarity: The paper is well-written and presents the concepts, methodology, and findings. \",\n",
       "  'weaknesses': '1.Novelty is limited. The concept of combing cycle-consistency constraint and diffusion model for image-to-image translation has been widely explored by other works, such as UNIT-DDPM, Dual Diffusion Implicit Bridges (DDIBs), cyclediffusion and so on.\\n\\n2.Lack of Comparative Analysis between the proposed method with other existing cycle-consistency based diffusion models. The part of 6.3 is not sufficient to illustrate the key difference and novelty of the proposed method.\\n\\n3.The results are low-quality and far from satisfaction. For the classic image-to-image translation tasks, i.e., winter-to-summer and horse-to-zebra, I do not find any improvement over existing ui2i methods. In addition, the results of CUT aand CycleGAN are questionable, especially for winter-to-summer task, they are too bad compared with the results from their original papers.\\n\\n4.The results of coffee-to-empty also do not convince me as it seems to only transfer the rgb image to gray image. Similar results also happen in the horse-to-zebra.'},\n",
       " 'review_232': {'summary': 'The paper proposes CycleNet, a method for unpaired image-to-image translation using pretrained diffusion models. The main idea is to reconstruct the conditional images through a reverse process. The idea seems reasonable, and the paper is well-organized, with sufficient experimental results.',\n",
       "  'strengths': 'The idea seems reasonable, and the paper is well-organized, with sufficient experimental results.',\n",
       "  'weaknesses': '1. The concept of cycle construction has been extensively studied in the field, and this work follows a similar idea, which weakens its contribution.\\n2. In CycleGAN, the reconstruction constraint $L_{x \\\\rightarrow y  \\\\rightarrow x}$ plays a vital role. However, in FastCycleNet, this constraint is omitted, yet the performance does not show significant drops. It would be helpful if the authors could provide an explanation for this observation.\\n3. For some variable notation (such as ($\\\\bar{x}_o$), authors had better provide their definitions, It would be beneficial for readers to quickly understand these notations.'},\n",
       " 'review_233': {'summary': 'This paper introduces a novel framework called Maximum MDP to address the problem of state-wise constrained policy optimization, namely the authors considers limiting the expected maximum state-wise cost rather than the cost for each state. Similar to the TRPO/CPO framework, the authors derived a worse-case constraint violation guarantee and practical algorithm which were shown in be effective in a set of robotic locomotive tasks.',\n",
       "  'strengths': '- I really like the simplicity of the idea proposed by the authors, state-wise safe RL is a much more common requirement for real-world safety critical problems but most literature on safe RL focus on constraining the cumulative cost. Reformulating the problem as constraining expected maximum state-wise cost eliminates the scalability issues associated with state-wise safe RL and effectively transforms the problem into a cumulative cost problem.\\n- Furthermore, this formulation allows the authors to easily adapt existing algorithms for cumulative constraints (CPO) with little modifications.\\n- Experiment section is well-structured and answers key practical questions associated with the proposed algorithms.',\n",
       "  'weaknesses': \"- Theorem 1 doesn't really depend on the specific formulation of MMDP and is really a finite-horizon variant of the policy improvement theorem from TRPO/CPO (which I think is a nice contribution in itself), I think the authors should try to convey this\\n- There is a major error in the proof in the appendix, note that equation 20 is not correct since $I - P$ is not invertible\"},\n",
       " 'review_234': {'summary': 'This paper introduces a novel approach to solve safe RL tasks. This approach is based on a new method SCPO and corresponding MMDP framework. Authors show the efficacy of this method by providing mathematical guarantees. Additionally, authors give useful practical implementation tips to improve reproducibility of their work.',\n",
       "  'strengths': \"originality\\n  - This paper extends CMDP framework to account for state-wise safety guarantees. It's a fairly natural extension, and authors did a great job of explaining the shortcomings of existing methods and how theirs addresses the gaps. \\n\\nquality\\n  - The paper is well-written and includes thorough mathematical analysis and practical tips for implementation. \\n  - Experimental section includes fair comparison with existing SOTA methods.\\n\\nclarity\\n  - The paper uses consistent notation with previous papers (i.e. TRPO).\\n  - Including pseudocode (in appendix) is useful.\\n \\nsignificance.\\n  - The paper has a good significant impact on safe RL. The presented method is novel and beats existing methods on the selected benchmarks. Authors also provided concrete future direction for this work.\",\n",
       "  'weaknesses': \"- Not necessarily a weakness, but including intuitive explanation of proposition 1 and 2 would be helpful to increase overall readability of the paper.\\n- Paper heavily relied on concepts TRPO, but didn't give explanations about them in the background section. \"},\n",
       " 'review_235': {'summary': 'This work tackles the problem of state-wise safety in the reinforcement learning problem. To this end it introduces the framework of Maximum Markov Decision Process and an algorithm State-wise Constrained Policy Optimization (SCPO) to solve the problem. Numerical results illustrate the performance of the authors algorithm.',\n",
       "  'strengths': 'The paper is well written and supported by extensive numerical results.\\n',\n",
       "  'weaknesses': 'Novelty is slightly limited. Similar state augmentation mechanisms have been studied before. The algorithm developed here arises from a somewhat straightforward application of trust region methods to such state augmentation mechanisms.\\n'},\n",
       " 'review_236': {'summary': 'This paper discusses an important topic about safe reinforcement learning, which explores the state-wise issue. It is a significant problem because, in the real world, state-wise constraints are one of the most common and challenging constraints in safety-critical applications. Most safe RL methods focus on cumulative safety, which may need to be improved to ensure safety during deploying RL in real-robot applications. ',\n",
       "  'strengths': '1. The writing quality is good.\\n2. Theoretical results sound good to me.\\n3. The code is provided in this study.\\n',\n",
       "  'weaknesses': \"1. The experimental results are very weird, especially for the reward performance. For example, in Figure 1, all the baselines’ reward values are almost the same; please check the environments' reward settings. This is also shown in Figure 4.\\n2. The method cannot ensure safety while deploying the method in real-world applications; demos that the authors provided also confirm this point, that is, sometimes the agent will violate safety constraints and crash into obstacles.\\n\"},\n",
       " 'review_237': {'summary': 'This paper proposed a cGAN (conditional generative adversarial network) method for general image inverse problems (IR). Conventional cGAN methods for IR usually suffer from mode collapse that the generators learned to ignore latent inputs and are unable to generate diverse image reconstruction samples. Motivated by existing work, this work proposes to incorporate multiple latent input to the GAN model during training to mitigate the mode collapse effect. Accordingly, a sophisticated designed supervised training loss function is also presented in this work. The numerical results show that the proposed method generates comparable or even better results to cGAN and score-based baseline methods on compressive MRI and image inpainting.',\n",
       "  'strengths': '1, The paper is overall well motivated, clearly written and easy to follow. \\n\\n2, The proposed posterior sampling-based method is effective for generating multiple samples compared to some score-based methods. The multiple sampling can also be applied for model uncertainty estimation, which is important for many medical imaging problems.\\n\\n3, The theoretical interpretation on the mean and covariance of predicted posterior distribution is informative, though it is sometimes unrealistic for most real-world imaging problems.\\n',\n",
       "  'weaknesses': '1, One contribution of this paper seems still to be based on the idea of Adler & Oktem [9], where multiple latent vectors are as inputs to the discriminator and generator module instead of only one input. In the meantime, as pointed out by the author as well, adding extra regularization term in the adversarial GAN loss during training is not completely new. \\n\\n2, This proposal ignores a body of work for posterior sampling based on Bayesian deep learning such as Monte Carlo dropout, deep ensembles, etc. There’s also a lack of numerical comparisons with these methods, making the baseline methods not sufficient enough. \\n\\n3, While some ablation studies provided in its original submission, the effects of regularization parameter $\\\\beta_{SD}$ and number $P$ on the final imaging reconstruction are still not comprehensive and could be improved. For example, a visual illustration or numerical comparison of several proposed sampling results due to different settings of $\\\\beta_{SD}$ is preferable.\\n\\n4, The assumption for proposition 3.1 that samples $\\\\widehat x_i$ and $x$ are independent Gaussian conditioned on y is not true for imaging applications, weekend the theoretical contribution. \\n\\n5, Some technical details and notations are confusing and could be improved in their current state.\\n'},\n",
       " 'review_238': {'summary': \"The paper presents a new method based on conditional GANs (cGANs) for generating posterior samples for solutions of inverse problems. The motivation comes from the fact that standard approaches to inverse problems typically use point estimates, which due to the perception-distortion tradeoff will lead to blurry images. Conversely, reconstruction via sampling can be used to navigate the perception-distortion tradeoff by either sampling small counts to have sharp images, or averaging many samples to approximate the point estimate reconstruction.\\n\\nAll of the above is known from the previous literature. The present paper's specific contributions largely center on the loss function and regularization design for cGANs to avoid posterior collapse and increase sample quality. The regularizer design is based on matching the means and covariances of the samples to the means and covariances of the true distribution. The manuscript chooses to compute these statistics over the $\\\\ell_1$ norm rather than the $\\\\ell_2$ norm, and the paper shows that $\\\\ell_2$ norm can in fact lead to collapse.\\n\\nIn numerical experiments the paper demonstrates superior FID and conditional FID performance for the proposed method, indicating that it is superior at distribution matching than the previous methods considered. For distortion metrics, the experiments demonstrate that superior distortion performance can be achieved by averaging over samples.\",\n",
       "  'strengths': \"**Originality**\\n- Interesting new regularization method for training cGANs for image restoration tasks.\\n\\n**Quality**\\n- The paper's quantitative results indicate SotA performance across a variety of tasks for both MRI reconstruction and image inpainting.\\n- Principled use of VGG weights instead of Inception weights for FID calculation and correlations to radiologist perception.\\n- A derivation motivating the use of both the supervised standard deviation reward and the application of this award over $\\\\ell_1$ norms.\\n\\n**Clarity**\\n- Excellent presentation of perception-distortion tradeoff and its relevance to imaging inverse problems.\\n- Detailed outline of the proposed method with the appendices, as well as relevant mathematics concerning the various tasks in the results.\\n\\n**Significance**\\n- There is substantial interest in the image reconstruction/restoration community now, much of which has focused on conditional diffusion models. The establishment of competitive performance in this space with cGANs (as well as the superior performance to past cGAN methods) will be of interest.\",\n",
       "  'weaknesses': '**Quality**\\n- The MRI images still demonstrate substantial artifacts from all methods at 8X acceleration. It is possible to find a number of features and fine details that are missing, so I doubt these would be accepted for clinical use.\\n- Although VGG may correlate better with radiologist scores, it is still an ImageNet feature backbone and contains nullspaces that may be poor for the tasks under consideration (Kynkäänniemi, 2023).\\n- There is a literature dedicated to so-called \"plug-and-play\" methods that are relevant to the present work, but was not considered. See (Venkatakrishnan, 2013) and follow-up papers.\\n- The U-Net is used as a surrogate for point-estimate methods in the MRI example, but it is known in the MRI community that the U-Net is a poor reconstructor. A more standard comparison would be to use the End-to-End Variational Network (Sriram 2020), which is available from the fastMRI GitHub repository. This comparison was included in the cited paper of (Jalal 2021).\\n- The competing methods for inpainting seem out of date. Dozens of methods based on conditional probabilistic diffusion have emerged over the last year (e.g., DDRM (Kawar 2022) and follow-ups), so I do not find these experiments as strong as the MRI ones.\\n\\n1. Kynkäänniemi, Tuomas, et al. \"The Role of ImageNet Classes in Frechet Inception Distance.\" ICLR (2023).\\n2. Venkatakrishnan, Singanallur V., Charles A. Bouman, and Brendt Wohlberg. \"Plug-and-play priors for model based reconstruction.\" 2013 IEEE global conference on signal and information processing. IEEE, 2013.\\n3. Sriram, Anuroop, et al. \"End-to-end variational networks for accelerated MRI reconstruction.\" Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part II 23. Springer International Publishing, 2020.\\n4. Kawar, Bahjat, et al. \"Denoising diffusion restoration models.\" Advances in Neural Information Processing Systems 35 (2022): 23593-23606.'},\n",
       " 'review_239': {'summary': 'This work uses conditional GANs for solving image recovery problems including face-inpainting and accelerated MRI. In particular, a regularization scheme is proposed that tackles the lack-of-diversity issue related to posterior sampling from cGANs. The authors show that the proposed regularization allows sampling from the true posterior under the assumption of a Gaussian signal prior. Empirically the method outperforms a U-Net trained end-to-end, existing cGANs and two score/diffusion/Langevin approaches in terms of accuracy and the latter also significantly in terms of speed.',\n",
       "  'strengths': '1. The paper is written very clearly and is well organized.\\n2. The proposed regularization significantly improves over existing cGAN approaches and hence will be of interest for the community.\\n3. The theoretical discussion of a toy example with Gaussian signal prior is insightful and contributes to the understanding of the proposed regularization.',\n",
       "  'weaknesses': '1. The authors argue that sampling from the posterior distribution alleviates any concerns about fairness and facilitates uncertainty quantification and further that uncertainty quantification in MRI, and fairness in face-generation, are both of paramount importance. In Appendix A they show that a classifier trained on images from the prior distribution maintains its performance when averaged over many samples from the posterior but not when evaluated on a point estimate.\\nHowever, the empirical experiments in Section 4 do not evaluate these points in detail. Regarding uncertainty quantification for MRI Figure 4 shows one example of the pixel-wise standard deviation (SD) but a discussion on the usefulness and practical applicability is missing. To me it seems that in the depicted SD map the model is equally uncertain about every edge in the image making me wonder about the usefulness of this map to a radiologist.\\nRegarding fairness in face-generation 5 different reconstructions of one image are shown and the authors argue that the fact that some samples show almond-shaped eyes demonstrates fairness. \\n    Here, a more detailed evaluation would strengthen the contribution although I acknowledge that this might be out the scope for a single paper.\\n\\n2. In terms of reconstruction accuracy the U-Net is shown to be outperformed but I would assume that a stronger baseline trained end-to-end like a Var-Net https://arxiv.org/abs/1704.00447 would perform significantly better in terms of PSNR and SSIM. Further, the conditioning makes the model lose the advantage of unconditioned generative models for solving inverse problems to be independent from the forward map. \\n    Since the authors also do not convincingly demonstrate cGANs to be superior in terms of fairness and uncertainty estimation (see previous pont), I wonder about the general usefulness of cGANs as proposed in this work.\\n    However, I acknowledge that this work significantly outperforms previous cGAN based approaches and thus is a valuable contribution to the field of generative models for solving inverse problems. Also the authors discuss the dependence on a specific forward model as a limitation and refer to ongoing work that removes this constraint.'},\n",
       " 'review_240': {'summary': 'This paper introduces a regularization term, comprising an L1 penalty and a standard-deviation reward, for the conditional GAN with Wasserstein loss. The objective is to ensure the generation of high-quality samples for a specific input observation y. The proposed approach is evaluated on two image recovery tasks: MRI reconstruction and face image inpainting. The numerical results illustrate its effectiveness in comparison to alternative methods.',\n",
       "  'strengths': '1) The proposed regularization term is simple and easy to implement and be added to GAN models;\\n2) Discussed different regularization options and demonstrated why they did not work in this case;\\n3) It includes theoretical analysis and empirical results;\\n4) The overall writing and presentation are good and easy to follow.',\n",
       "  'weaknesses': '1) The novelty of this paper sounds a little bit limited. The supervision-L1 to regularize conditional GAN is proposed by previous work. So it looks like it only added a new reward term on top of previous work.\\n\\n2) The two experimental tasks are all linear image restoration tasks. However, it is curious how the proposed method would work on nonlinear tasks.\\n\\n3) It would also be interesting to see whether the proposed method would work on a more complicated real-world dataset for the inpainting task.\\n\\n4) The current experimental image datasets are low resolution. Will it still outperform other models in terms of quality and computational cost on higher-resolution image datasets?\\n\\n5) How to determine the hyper-parameter: belta_adv for different datasets?\\n\\n6) Minor issue: there are some writing inconsistencies (e.g., the capitalization of the headline of 4.2 /4.3 is different from the headline of 3.1/3.2).\\n\\n\\n#------------------------------------------------------------------------------------------------#\\n\\n#------------------------------------------------------------------------------------------------#\\n\\nMost of my previous concerns have been addressed by the authors during the rebuttal, thus I have increased my rating accordingly. However, it would be great if the authors could add some experiments about non-linear image inverse problems.'},\n",
       " 'review_241': {'summary': 'This papers considers the graph OOD generalization problem with given environment information. It proposes a novel invariant learning method based on adversarial loss which is derived from independence conditions of the causal graph. Experimental results show the proposed method is very effective.\\n',\n",
       "  'strengths': '- Compared with previous work, this work proposes a more graph-specific environmental exploitation algorithm, which includes a subgraph selector.\\n\\n- The proposed method comes with theoretical results to show that the derived optimal paramteres can lead to learning causal subgraph only for invariant prediction.\\n\\n- The proposed method outperforms existing methods on various benchmarks by a large margin. Ablation studies show the proposed method is benefiting from each component.\\n',\n",
       "  'weaknesses': '- In fact, the proposed method can also be not that graph specific. We only need to replace the subgraph selector f_{\\\\theta} with a feature selector, then we can apply the method to invariant rationalization [1]. So, the claim may not be 100% true.\\n\\n- The theorems only provide equivalence between optimal paramters and learning causal subgraphs, but they did not mention what can be guaranteed if we cannot achieve optimal parameters (e.g., due to hidden variables).\\n\\n[1] https://arxiv.org/abs/2003.09772\\n'},\n",
       " 'review_242': {'summary': 'This paper proposes a new graph learning model to incorporate label and environment causal independence (LECI) for solving the graph OOD generalization problem. The authors first introduce two causal independence properties to distinguish causal and spurious subgraphs. Enforcing environment causal independence properties and utilizing the environment label information, LECI is able to identify causal subgraphs for invariant predictions. The authors further leverage an adversarial learning strategy to learn the label and environment casual independence. In contrast to the previous graph OOD methods which commonly assume non-existence of the environment information, LECI instead fully utilizes environment information and introduces a graph-specific environmental exploitation algorithm. Extensive experiments on GOOD and DrugOOD benchmark datasets demonstrate the superiority of LECI among other baseline methods.\\n',\n",
       "  'strengths': '1. The illustration of graph OOD generalization from a causal perspective is clear and easy to understand, and the derived two causal independence properties could be used to distinguish between causal subgraphs and spurious subgraphs for graph OOD future works.\\n2. The adversarial learning implementation of LECI is technically sound, and the derivation of the adversarial objective is rigorous.\\n3. The theoretical results are convincing.\\n4. Extensive experiments on GOOD and DrugOOD benchmark datasets demonstrate that LECI significantly outperforms baselines, and the authors also conducted comprehensive experiments for sensitivity analysis and ablation studies.\\n',\n",
       "  'weaknesses': '1. LECI assumes the environment information is known, which is a tight requirement. The authors argue that the environment labels can be accessed by applying simple groupings or deterministic algorithms, but in this case, the obtained labels are not accurate. From my perspective, these labels can be served as auxiliary information or as a proxy for ground-truth environment labels, but directly regarding them as environment labels may be not appropriate. However, I do believe LECI can be combined with the existing environment inference methods. I wonder if the authors have made some attempts. \\n2. The authors did not discuss the computational complexity of LECI in the paper.\\n'},\n",
       " 'review_243': {'summary': 'The paper proposed a novel learning strategy to incorporate label and environment causal independence (LECI) for tackling the graph OOD problem. Enforcing such independence properties can help exploit environment information and alleviate the challenging issue of graph topology shifts. With good empirical results on several datasets and related theoretical analyses, the paper justifies the effectiveness of the proposed LECI.',\n",
       "  'strengths': '1.\\tThe paper proposed an effective method for tackling the graph OOD problem. The author proposes to solve the problem by introducing label and environment causal independence, which is a good idea.\\n2.\\tThe logic is clear and solid, including the well-defined research problem and challenges, the proposed solutions, and theoretical analysis.\\n3.\\tThe gained empirical improvement is quite significant with the proposed LECI framework. Several ablation studies are shown.\\n',\n",
       "  'weaknesses': '1.\\tI am puzzled for \"graph-specific and \"distribution shift on graph topology\". Compared with other graph-specific OOD baselines, why LECI can solve the problem, as the author mentioned on line 19 and line 20.\\n2.\\tIt would be better to perform analysis on the complexity analysis, and some details are not explained so clearly of the two discriminators.\\n3. Due to the adversarial mechanism, the proposed method cannot scale to large-scale datasets and also it is very hard to train.\\n'},\n",
       " 'review_244': {'summary': 'This paper proposes a novel adversarial approach called LECI, for OOD generalization. The paper leverages label and environment information to identify the causal and invariant graph, thereby enhancing the accuracy and reliability of causal and invariant subgraph identification. The authors conduct extensive experiments on various real-world datasets under different distribution shift and demonstrate the effectiveness of the proposed approach. ',\n",
       "  'strengths': '(1) The paper proposes an effective learning strategy to incorporate label and environment causal independence for tackling the graph OOD problem.\\n\\n(2) Detailed theoretical guarantees for casual subgraph discovery are provided.\\n\\n(3) Extensive experiments on synthetic and real-world datasets, which provide insightful empirical findings.\\n \\n',\n",
       "  'weaknesses': '1. Limited novelty. Since environment inference and environment exploitation are often combined, and previous methods have used environment-based approaches specifically for graphs[1-2], it is puzzling why the author propose that previous methods did not explicitly mention graph-specific designs in line 26. Moreover, if representations are obtained by both structural and feature information using message passing, it begs the question of whether invariant learning on such representations has already addressed by previous works. The novelty of the article requires more presentation.\\n\\n2. Tables 1 and 2 do not include a comparison with GIL[2] as mentioned in line 266. Furthermore, based on my limited knowledge, GIL also involves capturing and optimizing invariant subgraphs, utilizing invariant learning for optimization. It is recommended to provide an explanation regarding the explainability of subgraphs between LECI and GIL. It appears that the paper requires additional elaboration on its novelty.\\n\\n3.Does the presence of three relatively independent adversarial training criteria in the main model pose significant challenges to the model training, such as difficulties in convergence similar to DANN? From Figure 4 on the left, a similar trend can be observed. It seems that this model requires dedicated hyper-parameters such as learning rate and number of epochs in order to achieve better results.\\n\\n[1] Chen, Yongqiang, et al. \"Learning causally invariant representations for out-of-distribution generalization on graphs.\"  NIPS, 2022.\\n\\n[2] Li, Haoyang, et al. \"Learning invariant graph representations for out-of-distribution generalization.\" NIPS, 2022.\\n\\n'},\n",
       " 'review_245': {'summary': \"This work addresses the issue of graph out-of-distribution (OOD) generalization by considering the data generation assumption of the presence of a causal subgraph and a spurious subgraph within each graph, and the assumption of label and environment causal independence. The paper proposes an adversarial training approach that leverages accessible environment information in the dataset. By jointly optimizing over these properties, the method aims to discover causal subgraphs for invariant prediction. Experimental evaluations on synthetic and real-world datasets demonstrate the method's superior performance compared to existing approaches.\",\n",
       "  'strengths': \"1. The paper is well-written, organized, and effectively conveys its ideas. A notable distinction from prior work is the assumption of access to environmental information, but the authors provide a thorough evaluation of this assumption's fairness compared to existing methods.\\n2. This paper introduces a novel approach to address the graph OOD problem by integrating environment and label independence, allowing for the comprehensive utilization of environmental information. The proposed method is accompanied by theoretical guarantees, enhancing its credibility.\\n3. The empirical evaluation is carefully designed, incorporating diverse datasets, relevant baselines, and comprehensive sanity checks. The authors further enhance their study with sensitivity analysis and ablation studies, providing a robust evaluation framework.\\n\",\n",
       "  'weaknesses': \"1. The paper introduces assumptions about the data generation process but lacks a formal definition of the OOD task within the paper. It would be beneficial to clarify details such as the training data distribution, test data distribution, and the specific differences between them. Specifically, is the difference solely attributed to the environment variable E, and are new E values observed in the test distribution? Additionally, it would be helpful to address whether the support for $P^\\\\text{tr}(E)$ and $P^\\\\text{te}(E)$ should be the same.\\n2. Although the paper has theoretical analysis of the proposed approach, it does not directly connect to the OOD generalization error. It is not explicitly stated how the proposed model's performance will be in various OOD settings theoretically. \\n3. The paper explores three different distribution shift assumptions, but it appears to place more emphasis on the Covariate SCM assumption. In the experimental section, it would be advantageous to clarify the specific SCM that the data satisfy and provide further details regarding how the data satisfy the SCM.\\n\"},\n",
       " 'review_246': {'summary': 'The paper considers the online list labelling problem: A set of $n$ elements arrive online and have to be inserted into an $c\\\\cdot n, c>1$ constant, large array while the array must at all times be sorted. Every time an already inserted element is \"shifted\" in order to maintain the order, it incurs a cost of $1$ and the goal is to minimize the total cost. The variant of the problem studied here, is the one where alongside the arrival of each element the algorithm obtains a possibly erroneous prediction on the rank of that element.\\n\\nThe paper presents an algorithm, that if the total error $\\\\eta$ is defined as the maximum error in the predictions, has an amortised cost of $O(\\\\log^2 \\\\eta)$ and thus only constant cost when $\\\\eta$ is almost zero. This bound is tight for any deterministic algorithm. These results are complemented with empirical evaluation.',\n",
       "  'strengths': 'It is an interesting problem and data structures with predictions are indeed not as developed as online problems with predictions.',\n",
       "  'weaknesses': '- The writing is at places not very precise and can be misleading. To give an example saying that the data structure is \"optimal for any prediction error\" is not true. For one I think the authors use \"optimal\" to mean \"best possible\" which differs from the convention that optimal refers to the offline optimal algorithm which knows the whole input in advance. Furthermore even \"best possible\" would not be completely accurate since it  can be up to a constant factor worse than the best previously known result with predictions. Perhaps \"tight up to a constant factor\" would be accurate? See also L80 \"improvement at no cost\", or L79 where \"proportionally\" I think is meant to be \"linearly\" etc.\\n\\n- The prediction error is not very natural: Consider the scenario where one prediction is off by a lot and all others are perfect. Considering the maximum error in the predictions over all elements is heavily unfair against such a scenario where the predictions are arguably quite good and one could easily obtain an optimal insertion of all elements without (or with barely) any shifting.'},\n",
       " 'review_247': {'summary': 'Author study a fundamental online problem which is also important\\nin practice: online list labeling.\\nThe introduce rank predictions for this problem and define prediction error\\nin a natural way. They achieve O(1) consistency and a robustness comparable\\nwith the best possible classical online algorithm.\\nThey show that the dependence of their competitive ratio on prediction error\\nis the best possible. They also analyze the case where the prediction\\nerror comes from some unknown distribution.\\nGiven the importance of the problem and soundness of the results, I recommend\\nthis paper to be accepted.\\n',\n",
       "  'strengths': '* important problem\\n* tight bounds, complete analysis',\n",
       "  'weaknesses': '* consistency is O(1) but not really close to 1.'},\n",
       " 'review_248': {'summary': 'The author presented a novel learning-augmented algorithm for the online list labeling problem, providing solid theoretical guarantees in terms of the error in the predictions. They also investigated the stochastic error model and bound the performance in terms of the expectation and variance of the error. Finally, they carried out an experimental evaluation of the proposed methods.\\n',\n",
       "  'strengths': 'Although the problem studied, online list labeling, might be considered quite peculiar for this conference, I believe it can be a seminal work for learning augmented data structures. I like this work very much because they provide solid performance guarantees, showing that our algorithm utilizes predictions optimally because their cost upper bound matches a lower bound shown in Section 3.3 for any prediction error. They also show that their algorithm is optimal in the case of entirely erroneous predictions and that for deterministic LLAs, the learned LLA is optimal for all prediction errors.\\nI also appreciated the study of the case in which the error for each element x is sampled independently from an unknown probability distribution with a given average and variance error.',\n",
       "  'weaknesses': 'The main weakness of this work is that the problem studied, online list labeling, is quite specific. It would be interesting to apply this methodology to other data structures to solve problems that are more common and known. '},\n",
       " 'review_249': {'summary': 'This paper is about the classic Online List Labeling problem in the recent model of algorithms with predictions (a.k.a. learning-augmented algorithms).\\n\\nIn this problem n orderable items (say, integers) arrive over time. We need to keep them in the sorted order in an array of size c*n, for some constant c. When the i-th item arrives, we know its relative ordering only with respect to the i-1 items that arrived before, so we do not know where to put it, and we might need to reinsert it later at a different location (in order to have space for future items while maintaining the sorted order). Our goal is to minimize the number of such reinsertions.\\n\\nThere is already known a deterministic data structure with amortized cost O(log^2 n) per insert, and a randomized one with cost O(log^3/2 n).\\n\\nIn this paper the authors propose a data structure that together with each new item receives a prediction on what would be the final rank of that item among all n items.\\n\\nThe data structure uses internally as a black-box a classic (prediction-less) data structure for the problem. Denoting by f(n) the cost of this internal black-box data structure – so, f(n) = O(log^2 n) if we want a deterministic solution, and f(n) = O(log^3/2 n) if we are fine with a randomized one – and assuming all predicted ranks are within eta from the true ranks, the amortized cost of the new algorithm is O(f(eta)). Moreover, if prediction errors are distributed according to a Gaussian distribution with mean mu and variance var, the cost is O(f((mu + var)^2)).\\n\\nThe main idea of the data structure is to maintain a tree-like structure over the inserted items, and delegate maintaining items in non-overlapping subtrees of different sizes to instances of a classic data structure for the problem. Locations of items in the tree are guided by their predicted ranks. If a data structure corresponding to a subtree becomes overfull because of prediction errors, it gets merged with neighboring subtrees. This general idea was already present in the literature around the problem, but the details of implementation and analysis are very novel.\\n\\nThe authors also provide results of some simple experiments. What is nice (and always present in learning-augmented literature) is that the predictions are actually learned from training data, so the experiments can be considered end-to-end. The cost improvements observed over classic data structures are roughly 50%.',\n",
       "  'strengths': \"1) The main algorithm is nontrivial, yet simple and with a clearly visible main idea.\\n\\n2) I like the additional analysis of the algorithm's performance under prediction errors coming from a Gaussian distribution (on top of the more standard analysis in terms of the maximum prediction error).\\n\\n3) The algorithm uses existing classic data structures in a black-box manner, so it should be easy to implement and can leverage already optimized implementations of these data structures.\\n\\n4) The authors provide a matching lower bound (albeit only for deterministic algorithms).\\n\\n5) The paper is well written and easy to follow.\\n\\nSimply speaking, it is one of the most interesting recent papers that I have read in this area.\",\n",
       "  'weaknesses': '1) The studied problem seems relevant in practice, but I am not sure how important it really is – however, even if it is not, I find the paper sufficiently appealing on purely theoretical grounds to merit acceptance.\\n\\n2) The experiments are of a proof-of-concept style – e.g., datasets are adapted from benchmarks for other problems that have not much to do with this one – but it is a common thing for papers in this area.'},\n",
       " 'review_250': {'summary': 'The paper presents a new deep Gaussian process (DGP) model, the thin and deep GP (TDGP), which does not suffer from a diminishing signal as the number of layers increases. The crux of the TDGP model is the covariance function that, for each layer $\\\\ell$, acts on a linear combination of a (non-linear) transformation of the outputs of the previous layer and the inputs $\\\\mathbf{x}$, $\\\\mathbf{h}^\\\\ell(\\\\mathbf{x}) = \\\\mathbf{W}^\\\\ell(\\\\mathbf{h}^{\\\\ell-1}(\\\\mathbf{x})) \\\\mathbf{x}$. This hierarchical construction is shown to cover the usual DGP models while not suffering from diminishing signals as the depth increases. To perform inference in this model, the authors adopt a mean-field VI scheme, which is demonstrated to be effective through a number of experiments on both synthetic and real-world data.',\n",
       "  'strengths': '1. The paper presents an interesting and original approach to DGPs, an important field that should interest the NeurIPS community.\\n2. The paper is of high overall quality and very well-written.\\n3. The presented model has the potential to be of considerable significance, given that it generalises previous DGP models while not suffering from the same pathologies.',\n",
       "  'weaknesses': '1. While I think the paper presents a great idea with lots of potential, my main concern is the lack of a deeper analysis of the model. Given that the proposed model is essentially just a particular transformation of the inputs at each layer and a rather straightforward mean-field VI scheme, I would expect some insights into the behaviour of the model, even if these were just empirical. The current experiments do present some interesting insights, but, say, what happens to the model\\'s performance as we increase the depth of the model? What if we change the width of the layers? What if we use different covariance functions than the squared exponential? How does the induced covariance matrix look at different layers of the model compared to, say, DNSGP? Why does the model encourage low-dimensional latent spaces, and does this happen too for models deeper than just two layers? A Gaussian prior shouldn\\'t encourage sparsity, so this aspect of the model is particularly puzzling.\\n2. As mentioned, a standard mean-field VI scheme seems very rough given that this is known to perform poorly for many models, including DGPs. To my knowledge, the current state-of-the-art is still the doubly stochastic VI scheme by Salimbeni & Deisenroth (2017), so it would make sense to try something similar (and unless I misunderstand something, it seems fairly straightforward to do this for the proposed model). \\n3. One clarity issue (perhaps the only one) I find with the paper is that it is unclear to me which DGP model the authors refer to as \"CDGP\". Deep GPs have evolved dramatically from the original formulation of Damianou & Lawrence (2013), and the mentioned pathologies are not as pronounced anymore (to my knowledge). It is great that the authors compare against DNSGP, but comparing against the doubly stochastic DGP rather than the original formulation makes much more sense. As it is unclear if the authors actually compare to the current state-of-the-art, it is also unclear if the proposed model addresses actual problems.\\n4. Experimentally, the model seems to work well, but the authors use only two layers for all models. This is particularly strange as a key selling point of the proposed model is that it doesn\\'t degenerate as the number of layers increases. But it is also an odd choice since deeper models should work better (and DNSGP demonstrably does for two of the UCI datasets). It is also strange that MRAE statistics are only reported for the GEBCO dataset; these should also be reported for the UCI experiments.\\n5. The model is claimed to be \"interpretable\", but this only seems to be the case for a two-layer model (i.e., one with a single latent space). For deeper models, the distance matrix is still a highly non-linear function of the inputs, which I don\\'t think will be particularly interpretable.\\n\\n\\nReferences:\\n\\n- Andreas Damianou & Neil Lawrence, \"Deep Gaussian processes\", AISTATS 2013.\\n- Hugh Salimbeni & Marc Peter Deisenroth. \"Doubly Stochastic Variational Inference for Deep Gaussian Processes\", NeurIPS 2017.'},\n",
       " 'review_251': {'summary': 'This paper considers the problem of non-stationary kernel design for Gaussian processes. Two main approaches for this problem are deformation kernels and length-scale mixture kernels. On one hand, deformation kernels, eg deep GPs, have found great success while trading off expressivity and the ability to learn latent manifolds in intermediate layers, for lack of interpretability and being prone to pathologies. On the other, length-scale mixture kernels retain interpretability but typically break the triangle inequality in the induced latent space, precluding a manifold structure. The authors propose thin and deep GPs, which aim to combine the benefits of both these approaches, while mitigating their drawbacks. The approach learns a position-dependent matrix, parameterized by a GP, which learns a pointwise linear transformation of the data. The output of such a layer can then be composed to learn a new matrix acting on the original data, enabling a deep learning structure. Numerical examples are provided which appear competitive with existing techniques.',\n",
       "  'strengths': 'This paper is clearly presented and combines existing ideas in a novel way. The numerical examples seem well selected, with a mixture of synthetic/analytic examples that demonstrate the utility of the method, with standard benchmark datasets allowing for meaningful comparisons on real data. A case study is also provided that is geared towards the strengths of the technique.',\n",
       "  'weaknesses': \"The main weakness of the paper in my view is Theorem 3.1. It appears that the proof that the CDGP is a generalization of deep GPs hinges upon the introduction of a new variable that plays the role of the deep GP, and then turning off their method's parameters by concentrating their priors around zero. This seems highly misleading unless the method is introduced in a way that uses the augmented space as default, or some numerical evidence is given that it should be turned off if appropriate. In this case, presumably the deep GP should also be tested with and without an augmented space for fair comparison. It seems that the augmented space is not used in any of the experiments in any of the models presented, since the local linearity leaving the data unchanged around zero is listed as a limitation.\"},\n",
       " 'review_252': {'summary': 'This paper extends the CDGP to address two weaknesses in deep Gaussian processes. The solution is similar intuitively to a residual connection. Instead of letting each layer depend only on the last layer, they let each layer depend on the last layer and the input. This allows the model to induce a manifold and use a lengthscale field.',\n",
       "  'strengths': 'This seems like an important problem, and the solution seems principled.',\n",
       "  'weaknesses': 'There should be more discussion of what it means to not induce a manifold, why violating the triangle inequality leads to that, and why not inducing a manifold is a drawback. I think inducing a manifold implies that one can make the latent space plots: why are these valuable? Why do they require the triangle inequality?\\n\\nThere should be more discussion of how a lengthscale field leads to interpretability.\\n\\nIn both the latent space and the inverse lengthscale plots, there should be some discussion about why we want to see these plots: for instance, in figure 7, we have the two sets of plots: what can we glean from them about the data/problem/etc? Figure 8 has a little bit (the zone of high correlation extends into the mountains), but this is not obvious for a non-expert application reader. You could have a short tutorial perhaps of how to read these plots in the supplement.'},\n",
       " 'review_253': {'summary': 'Techniques such as Deep Kernel Learning and extensions such as Deep GPs have been proposed in order to overcome the flexibility constraints associated with standard shallow GPs. However, although these techniques are better suited to model non-stationary data, they are still susceptible to issues such as pathologies when extended to more than a few layers, as well as overfitting. These techniques also lack the interpretability of the latent space and associated length-scales that make standard GPs so appealing. In order to mitigate these limitations, the authors propose a novel approach that generalises over the more widely-used compositional DGPs via a hierarchical model that incorporates locally linear deformations of stationary kernels. A synthetic example is crafted in order to showcase how TDGP improves over competing methods for problems exhibiting heavy non-stationarity. This is further complemented by an analysis on a real-world dataset, as well as 4 benchmark datasets from the UCI repository.',\n",
       "  'strengths': '- The paper is very well-written and a pleasure to read. I commend the authors for structuring the paper in a manner that clearly shows connections to related models, while also showcasing the key contributions of this work.\\n- I particularly appreciated Sections 4.1 and 4.2, which capture the various dimensions along which TDGP can lead to improvements over other methods (predictive performance, uncertainty quantification, and interpretability).\\n- The problem statement tackled in this paper is well-motivated, and the limitations of other techniques are clearly pointed out both verbally and visually in the experiments section. One possible improvement to this could be highlighting application domains where TDGP is expected to be most impactful – i.e., which application domains tend to non-stationary data where well-calibrated uncertainty is especially useful. While fairly minor, this could help clarify the significance of this work earlier on the paper.  ',\n",
       "  'weaknesses': '- The authors comment in the *Limitations* section that the increase in the number of variational parameters could slow down optimisation – it could be worth supporting this statement by specifying the computational complexity, and maybe an analysis reporting wall clock time for one of the experiments in Section 4. \\n- I would also be interested in whether the increased parametrisation of the model results in models that are less stable or difficult to consistently converge. This has implications on the practical utility of the model.\\n- The paper focuses heavily on using the SE kernel throughout – can this be extended to other kernels or is the value-add of this extension not considered to be worthwhile for the paper?'},\n",
       " 'review_254': {'summary': 'The paper proposes two novel modifications to the Pre-Layer Normalization (Pre-LN) Transformers, introducing the Pre-Root Mean Square Normalization (Pre-RMSNorm) and Pre-Compressed Root Mean Square Normalization (Pre-CRMSNorm) Transformers. The authors aim to improve computational efficiency by simplifying LayerNorm to RMSNorm and introducing a lossless compression technique for zero-mean vectors. They claim these changes maintain the arithmetic functionality of the original models, reducing training and inference time by up to 10%. The paper includes extensive mathematical proofs and technical diagrams to support their claims. Experiments using Vision Transformer (ViT) and GPT models demonstrate the improvements in speed.',\n",
       "  'strengths': \"The paper presents novel ideas in Transformer optimization, leading to improved computational efficiency. The use of compression in the Pre-CRMSNorm Transformer is particularly inventive. The detailed mathematical proofs and the experimental results provide a strong basis for the claims made, enhancing the paper's quality and clarity. Also, the potential for the method's applicability in various domains enhances the paper's significance.\",\n",
       "  'weaknesses': \"Although the paper presents comprehensive mathematical proofs, the practical effectiveness of the proposed model is not extensively demonstrated. More empirical results across different domains and data types would further substantiate the authors' claims. The authors acknowledge that the proposed modifications might slightly increase the training workload, which could be a limitation for some applications. Lastly, the handling of vectors in $\\\\mathbb{R}^{d-1}$ by accelerators is assumed, which might not hold true in all scenarios.\"},\n",
       " 'review_255': {'summary': \"This paper proposes modifications to the popular transformer architecture's normalization mechanism in order to improve efficiency without sacrificing performance. It starts out with the baseline architecture Pre-LN (LayerNorm), and derives two new architectures: Pre-RMSNorm and Pre-CRMSNorm, which are inspired by the use of RMSNorm instead of LayerNorm mechanism in certain transformers in the literature to improve efficiency without noticeably affecting performance.\\n\\nThe paper formally proves the arithmetic equivalence of all three architectures. It also evaluates the two proposed architectures over the baseline by conducting experiments on ViT and GPT3.  It reports modest improvements in training time (around 2%) and slightly bigger improvements in inference time (1-9%) for a variety of different hyperparameter settings.\\n\",\n",
       "  'strengths': 'The paper sheds light on normalization mechanisms in transformer architectures by relating two of the most popular such mechanisms: LayerNorm and RMSNorm.\\n\\nBy starting out with the empirical observation in the literature that RMSNorm is more efficient than LayerNorm, it derives two new architectures based on RMSNorm and proves them to be arithmetically equivalent to the LayerNorm architecture.\\n\\nThe empirical evaluation is quite thorough, using both ViT and GPT settings, and demonstrates modest improvements in both training and inference times across a wide range of hyperparameter settings.\\n\\nFinally, the presentation is crystal clear: the paper is extremely well written even for an informed outsider to follow.\\n',\n",
       "  'weaknesses': 'The single major weakness is that the savings in training and inference time is not too significant (around 1-3% in training time and about the same or slightly more in inference time, depending on the setting).\\n\\nThe authors acknowledge this by noting that normalization is not the elephant in the room, and that attention and MLP dominate the computation especially as the model size grows.  They even show an empirical upper bound on the speedup (which is the time taken by the normalization mechanism as a fraction of the overall time -- around 12-18%).\\n\\nA minor nit: The last sentence of the abstract \"Experiments demonstrate that we can reduce the training and inference time of Pre-LN Transformers by up to 10%\" is a bit misleading.  I would appreciate it if you paraphrase this sentence, by 1) separating out the training and inference time numbers, and 2) providing both lower and upper bounds instead of just the 10% upper bound.'},\n",
       " 'review_256': {'summary': 'This study explores the relationship between Pre-RMSNorm and Pre-LN Transformers, demonstrating that these two variants can be theoretically reparameterized into one another. Additionally, the authors introduce a novel Transformer variant called Pre-CRMSNorm, which reduces one hidden dimension while maintaining the same representation power as Pre-LN and Pre-RMSNorm. Experimental evaluations on ViT and GPT models reveal that the proposed approach significantly improves computation efficiency during both model training and inference stages.',\n",
       "  'strengths': 'The findings are interesting and reasonable. The proposed approach is novel and demonstrates a new direction to improve model efficiency via parameterization. The authors conduct experiments on both image data (i.e., ViT) and natural language (i.e., GPT). ',\n",
       "  'weaknesses': '1. The study would benefit from additional evaluations of the proposed method beyond computation efficiency. While the comparisons conducted on computation efficiency are useful, it is crucial to include discussions on the effectiveness of the resulting model. The absence of such results makes it challenging to assess the proposed method and its claims, particularly regarding training speedup. For example, it remains unclear whether the proposed reparameterization yields comparable training performance and stability when compared to Pre-LN Transformers.\\n\\n2. The efficiency gain diminishes as the model size scales larger, which affects the empirical contribution of the proposed method. Additionally, without sufficient discussions on model performance, it is unclear whether the proposed method is compatible with low-precision data for model inference and training, which plays an important role in making deep learning efficient. Incorporating experiments with fp16 and bf16, as well as exploring the use of quantized models, would significantly enhance the paper and provide valuable insights.\\n\\n3. The main finding of the study fails to provide a very deep insight beyond the reparameterization connection. Also, I feel the equivalent claim is a bit ambiguous, and would recommend the author phrase the claim as reparameterization. This is crucial because different reparameterizations for the same network can lead to substantial variations in training stability, training performance, and even inference performance. Emphasizing the reparameterization aspect would address this ambiguity.'},\n",
       " 'review_257': {'summary': 'The paper analyses the two common types of normalization layers in Transformers: LayerNorm and RMSNorm (root-mean-square-norm). LayerNorm scales all vectors to be of the same norm, while changing the vectors\\' \"directions\". RMSNorm, in contrast, keeps the same direction, but just rescales the vectors to the same constant norm.\\nThe authors \"unify\" both approaches, by showing how to force LayerNorm to act like RMSNorm. Then, since RMSNorm is faster to compute, the authors argue that this conversion (LayerNorm -> RMSNorm) can get the expressivity benefits of LayerNorm with the speed of RMSNorm.\\nFinally, the authors propose C-RMSNorm, which saves 1 dimension. For example, if the model hidden size is 1024, C-RMSNorm allows reducing it to 1023 while calculating the norm. \\nOverall, the authors argue that these changes can reduce the training and inference time of LayerNorm transformers by 10% (although without discussing whether there\\'s a reduction in performance/accuracy).',\n",
       "  'strengths': \"## Strengths\\n+ The authors provide a thorough explanation of LayerNorm vs. RMSNorm.\\n+ The authors show the relation between LayerNorm vs. RMSNorm, which I haven't seen in any other paper.\\n+ The proposed approaches can sometimes reduce inference and training time, which is an important problem that solving can save millions and save carbon emmission.\",\n",
       "  'weaknesses': '## Weaknesses\\n- I\\'m not sure about the soundness of some of the claims. The authors argue that LayerNorm is **equivalent** to RMSNorm and even write explicitly `PreLN Trasnformer = Pre-RMSNorm Transformer` (Eq 4). However, they only show one direction of this equality: the authors show how to take a Pre-LayerNorm transformer, and by imposing specific values to weights and enforcing constraints it can be equivalent to RMSNorm. That is, by constraining LayerNorm you can achieve RMSNorm. To my understanding, this means that Pre-LayerNorm is **at least** as expressive as Pre-RMSNorm. But what about the other direction? Maybe Pre-LayerNorm is more expressive if we do not impose these constraints? Can we take a Pre-RMSNorm and make it a Pre-LayerNorm?\\n- Similarly, I am not sure that the authors prove both directions when claiming in Section 3.2 that `Pre-RMSNorm = Pre-C-RMSNorm`.\\n- Novelty - The authors claim to \"propose Pre-RMSNorm\". Is this proposal novel? aren\\'t models such as LLaMA already using Pre-RMSNorm?\\n- Another issue with soundness: the authors write multiple times that these conversions are \"free efficiency improvement\" and \"free lunch\". However, in Line 228 they write: \"We have to pay the extra cost for training for the parameter change\". So, what exactly do the authors mean by \"free lunch\" if there is an extra training cost, and the accuracy is not guaranteed to be the same?\\n- Many evaluation details are missing. \\n    - On which datasets do the authors perform the experiments? \\n    - How can the authors perform training and inference with **GPT-3**? As far as I know, GPT-3 is not open-sourced. Further, the authors mention they used \"**GPT3 XL and 2.7B**\". What exactly do they mean here? What is \"**GPT3 XL**\"? and what is \"**GPT3 2.7B**\", Is there such a model? The sizes of GPT-3 that I know about are much bigger than 2.7B. Where exactly this model was taken from and what exactly do the authors mean?'},\n",
       " 'review_258': {'summary': 'This paper proposes SparseProp, an event-based algorithm for efficient simulation and training of sparse Spiking Neural Networks (SNNs). By leveraging the sparsity of the network, SparseProp reduces the computational costs of operations from O(N) to O(log(N)) per network spike. This method avoids iterating through all neurons with each spike and adopts efficient state updates. Demonstrations include a simulation of a sparse SNN with one million LIF neurons, achieving speeds surpassing prior models by over four orders of magnitude. This innovation offers the potential for more sophisticated brain-inspired models.',\n",
       "  'strengths': '1. The proposed method decreases the computational cost of conventional event-based SNN simulation from O(n) to O(log(n)) per network spike. The cost decrease mainly comes from using efficient data structures for spike searching and change of reference frame for state evolution.\\n\\n2. The authors demonstrate the potential to use the event-based simulator for training SNN. This can be a handy tool for SNN training combined with the EventDrop algorithm. It could decrease the training cost of the SNN when number of events is low. However, the authors performed no experiments on this matter, making the contribution vague.',\n",
       "  'weaknesses': 'The main concern of the reviewer is the usefulness of the proposed approach in real-world applications. Thus, the proposed method may better serve as a neuroscience tool than be used in real applications, as advertised by the authors in the introduction. Here is a list of weaknesses of the paper the reviewer summarized:\\n\\n1. The paper lacks experiments with SNN algorithms for real-world tasks. The experiments done in the paper concentrate on analytical modeling and non-realistic neural network architecture. However, SOTA SNN algorithms have different architectures and may generate different results. The authors need to perform experiments on real tasks to make a convincing statement on the applicability of real applications.\\n\\n2. Event-based computation typically suffers from parallelization problems and scalability problems. The problem becomes more apparent when the number of spikes increases in the SNN compared to sparse networks. On the other hand, GPUs and typical deep-learning accelerators use vector computation which is very easy to parallel and can generate much lower latency compared with the event-based approach. The authors must discuss and compare the two approaches using actual workload and show under what conditions the event-based approach may have an advantage.\\n\\n3. It is hard to say that the proposed method will have an advantage compared with the significant amount of SOTA SNN algorithms that use the Euler method to simulate the activity of spiking neurons. The step-based simulation method demonstrates its effectiveness in many complex tasks and efficiency in many neuromorphic hardware. Therefore, the significance of the proposed approach can be limited.'},\n",
       " 'review_259': {'summary': 'This paper presents an efficient event-based algorithm named *SparseProp* for both inference and learning of sparse SNNs. It gets rid of the discretized simulation of ODEs in neuronal dynamics and utilizes phase representation for those neuron models with closed-form solutions between spike times. A priority queue is employed for recording and evolving the states of related neurons when a spike is triggered, which reduces the amortized time complexity to O(K log N) per spike.',\n",
       "  'strengths': 'This work manages to perform a lazy update of neuron states. Phase representation rather than membrane potential is a brilliant idea since all neurons now share an identical magnitude of update in internal states, which makes it feasible to update $\\\\phi^{reset},\\\\phi^{th}$ alone as an alternative to the O(N) polling all neurons\\' potentials. The priority queue ensures the incoming spike always happens in the neuron at the top of the heap. The experimental results also show significantly improved simulation efficiency. Although there exists earlier work [1] applying priority queue to the simulation of event-based SNNs, the algorithm presented here for sparse SNNs is definitely not trivial.\\n\\n[1] Eduardo Ros, et al. \"Event-driven simulation scheme for spiking neural networks using lookup tables to characterize neuronal dynamics.\" Neural computation, 2006',\n",
       "  'weaknesses': \"There are still some major concerns to be resolved\\n\\n1. The whole study seems to assume a positive external input, i.e. $I^{ext}>0$ in Line 155/544 and a special setting $V_{th}=0, V_{reset}=-1$ in Line 134. In such a case, we expect a spontaneous spike dynamic for those integrate-and-fire models. We have a well-defined unperturbed interspike interval $T^{free}$ and can deduce the phase $\\\\phi$ accordingly. However, a popular setting in many recent SNN studies, such as ref.6 and ref.17, is $V_{th}>0, V_{reset}=0$, and $I^{ext}=0$. Under this assumption, a neuron won't fire if the incoming excitatory spike is not strong enough. There will be no spontaneous spike and thus no unperturbed interspike interval $T^{free}$ or valid phase representation, and the whole thing seems to fall back to polling of neuron states. In fact, any $I^{ext}\\\\in[V_{reset}, V_{th}]$ lead to an invalid $T^{free}$ for the LIF model as Eq.7 shows. All in all, I don't think we can assume those parameters without losing generality as Lines 133-134 reads.\\n2. For an excitatory-dominated network, it might be possible that two neurons become postsynaptic neurons of each other. *SparseProp* may find that any firing of one will trigger a spike of the other, and it implies an endless loop of updating the priority queue.\\n3. The training algorithm coupled with *SparseProp* is more like a draft since no experimental results are really attached here. There might be many details to be considered when designing a backpropagation algorithm for *SparseProp*.\"},\n",
       " 'review_260': {'summary': 'Simulation of RSNN (recurrent spiking neural network) is a difficult task, whose limits prevent large scale (say 1e.9 neurons) simulations. Often, in practice, one neuron is connected to only a few others, the sparsity. The present paper leverages this sparsity to upscale the simulations limits of RSNN. Sparsity is often leveraged to increase performance and scalibity but SparseProp (algo. presented in this paper) seems to be a newcomer for event-based simulations of RSNN.',\n",
       "  'strengths': '-The authors present a new and efficient algorithm for event-based simulations of RSNN. In its structure, the algorithm is fairly similar to classical ones, \\nwhile taking advantage of the sparsity structure, it presents a very good ratio (high) efficiency / complexity. Practically, it mainly forces the practitionner to have a better data structure.\\n-The exposition and background are in general clear and the algorithm seems natural to derive in the history-flaw of the paper (great!). Algorithms for non-sparse and sparse simulations\\nare cleary written and can be easily compared by the reader.\\n-Simulations are given, for SparseProp and classical algo, giving a good sense on how performant their method is (performant!).\\n-The flow of the paper Abstract / General -> Particular / Practical, is smooth.\\n-Examples on classical RSNN are given, which are good toy examples for the reader to play with.\\n-Simulations are available in Julia.',\n",
       "  'weaknesses': '-General comment on citations: the authors could give more references, for example:\\n\\t-line 59: several classical papers showing the origin of the differential equation, would be appreciated.\\n\\t-figure 1: a reference paper, explaining the role and subtilities of the phase representation, would be appreciated (especially since its of crucial importance for this paper).\\n-The claim of efficient simulation is for general univariate RSNN but the paper nearly entirely focuses on homogeneous ones. I understand that this can be generalized, \\nas explained in Section 6, but no numerical results (as in Figure 3) are given and the algorithm is only explained (Section 2.1) for homogeneous networks. For pedagological purpose, \\nits great, but it leaves with a taste of unfinished. It feels like the most interesting and difficult part is \"left for the reader\". I would suggest claiming a weaker result or \\ngiving more material for the understanding of heterogeneous networks (eventually in the appendix). This is the main reason why Soundness grade is only at 2.\\n-Since the pulse-coupled phase oscillators (and constant phase velocity) is an important and simplifying assumption, the paper lacks a discussion on it or a reference that discuss it (is it a strong assumptions: yes, no, why - how is it linked to Eq. 1...).\\n-Section 7 is simulation-less so the reader can not know if the proposed algorithm is efficient. Moreover it is mentionned \"training of RSNN\" in the title, which seems a bit of an overstatement since there is only a 20 line, simulation-less, section about it. I know that this is because the authors of EventProp did not make their algo available but this also should not be a problem for the reader. I would suggest removing the \"training\" in the title and keeping this section either in an appendix or as a \"bonus\" section. '},\n",
       " 'review_261': {'summary': 'This paper introduces an efficient Spike-based recurrent network learning simulation method based on an event-driven implementation.\\n\\nThe method is based on two main contributions. The first consists in a change of temporal reference frame that uses the phase of a neuron rather than its absolute time, the second contribution consists in finding an efficient data representation corresponding to the parsimonious structure of neural connectivity. This method is applied to different neuron models, from a linear LIF model to more complex models such as the quadratic LIF neuron.',\n",
       "  'strengths': 'This paper clearly presents an original method for simulating and training a spiking neural network. The motivation for the paper is very well set out, and the methods are clearly explained both in terms of the definition of the mathematical equations and the path that leads to its numerical implementation. The results look very promising, and the preliminary results set out in the appendix are very promising indeed. In particular, the experimental results show that this method can be used to implement very large networks on computational architectures of reasonable size, which is a game changer for the SNN community.\\n\\nMinor:\\ncaption of Fig 4 : repetition of «\\xa0higher densities\\xa0» ',\n",
       "  'weaknesses': 'Although Figure 3 already presents a comparison between the proposed method and a conventional method, it would have been desirable to have a comparison between these two methods in terms of the quality of the obtained results. It would have also been beneficial to isolate the improvements achieved by the two contributions independently (the first contribution being the change in temporal reference, and the second being the sparse representation of data). Some improvements in the presentation can be made... For example, the \"peek\" function is not defined.'},\n",
       " 'review_262': {'summary': 'This paper explores the issue of data poisoning attacks on machine learning models, focusing on linear models. The authors find that the effectiveness of state-of-the-art poisoning strategies varies across different datasets. They introduce definitions of optimal poisoning attacks for finite-sample and distributional settings and prove performance convergence under certain conditions. They also characterize optimal poisoning attacks under a theoretical Gaussian mixture model and find that a larger projected constraint size is linked with higher vulnerability, while larger separability and smaller standard deviation provide less vulnerability. These findings explain the performance differences of indiscriminate poisoning attacks on linear models across various datasets and suggest ways to improve robustness against poisoning.',\n",
       "  'strengths': \"- The observation that the performance of state-of-the-art poisoning strategies significantly varies across different datasets is indeed insightful. It not only challenges the common understanding of indiscriminate poisoning attacks but also opens up new lines of inquiry into why these differences occur.\\n- The theoretical analysis under specific data distributions is a major strength of this paper. It's robust, reliable, and underpins a comprehensive understanding of how and why different datasets might be more or less vulnerable to poisoning attacks. By tying the theoretical analysis back to empirical attack performance, the authors effectively bridge the gap between theory and practice, enhancing the practical relevance of their findings.\",\n",
       "  'weaknesses': '- It\\'s not explicitly clear from the paper whether the observation that \"linear learners on some datasets are able to resist the best-known attacks even without any defenses\" is novel or previously reported. The authors could benefit from addressing this explicitly. \\n\\n- The authors\\' focus on linear classifiers is indeed a limitation. While the paper provides valuable insights into data poisoning attacks on linear models, these findings cannot be directly extrapolated to non-linear classifiers such as neural networks. Moreover, the paper does not provide enough information to definitively conclude whether linear classifiers are more robust than non-linear classifiers without additional defense strategies.\\n\\n-  The paper doesn\\'t sufficiently distinguish its analysis from existing works on data poisoning that also provided theoretical analysis on Gaussian mixture distributions and linear classifiers, such as [1]. Could you elaborate on this?\\n\\n\\n\\n[1] Tao, Lue, et al. \"Can Adversarial Training Be Manipulated By Non-Robust Features?.\" Advances in Neural Information Processing Systems 35 (2022): 26504-26518.'},\n",
       " 'review_263': {'summary': 'Inspired by the variant performance of indiscriminate data poisoning attacks against different datasets, this paper studies the inherent robustness of datasets against them. Using an optimal attack designed for a binary Gaussian dataset, the authors discover three properties, namely class separability, variation, and constraint size are important factors to determine the robustness of a dataset. Experiments further validate the theory on several datasets. ',\n",
       "  'strengths': '(1) This paper studies an important problem, namely the dataset robustness against indiscriminate data poisoning attacks.\\n\\n(2) The authors provide initial but valuable evidence on understanding the vulnerability of datasets by explicating the three properties. Although these characteristics match our intuitive understanding of the problem, they have not been systematically analyzed or studied.\\n\\n(3) The empirical findings, especially the results in Section D, are nicely presented and very comprehensive. Moreover, I can find answers to most of my initial questions when reading the main paper in the appendix.',\n",
       "  'weaknesses': \"(1) I don't find the title a nice summarization of the entire paper as it is probably too general. I would suggest mentioning the dataset robustness in the title.\\n\\n(2) I don't think comparing with LDC is necessary as I clearly see the drastic difference. I suggest the authors move this part to the appendix and present some more valuable content in the main paper, e.g., some experiments in Appendix D.\\n\\n(3) Although it has been mentioned in the appendix, I think it is important to mention what attacks you use to generate Table 1. The authors should at least provide a pointer to the appendix.\\n\"},\n",
       " 'review_264': {'summary': 'This paper delves into the impact and effectiveness of indiscriminate data poisoning attacks on machine learning models, particularly linear ones. It highlights significant variations in attack effectiveness across different datasets and seeks to understand whether this is due to inherent dataset robustness or shortcomings in current attack strategies. The paper presents optimal poisoning definitions, characterizes these attacks under a theoretical Gaussian mixture model, and identifies learning task properties that affect attack performance. It concludes with suggestions for designing better defenses against such attacks.',\n",
       "  'strengths': '- The question the paper is trying to answer, of whether some datasets are inherently robust to poisoning attacks or just resilient to state-of-the-art attacks, is original and interesting.\\n- The paper flows smoothly and is decently written, but contains some grammatical mistakes and typos (some of which I mention below). A careful proofread can increase the quality of writing quite a bit.\\n- The paper is sound, and the claims are proved on 1D toy Gaussian mixture model then extended to more complex data distributions. \\n- The empirical results support the theoretical results. Specifically, on various datasets, the results show that the datasets that are less vulnerable to poisoning have higher values for metrics defined by the paper (Sep/SD and Sep/Size).\\n',\n",
       "  'weaknesses': '- The contributions of the paper is not very significant as there is no clear practical implication of the findings of the paper. However, the paper investigates an interesting phenomenon of \"inherent robustness\" of some datasets which might inspire further investigations of this sort.\\n- The paper analysis is restricted to linear models.'},\n",
       " 'review_265': {'summary': 'This paper explores poisoning attacks on linear classifiers.  Specifically, the authors explore why poisoning attacks may have high efficacy on one dataset but low efficacy on another.  The authors relate this phenomenon to two potential factors: (1) (projected) constraint set size and separability. The authors theoretically characterize an optimal poisoning attack w.r.t. Gaussian mixture data.',\n",
       "  'strengths': 'Previous work has repeatedly shown that poisoning attacks represent a real and serious threat to machine learning models.  Most work in the field focuses on how to design better attacks or better defenses.  An improved theoretical understanding of what mechanisms allow an attack to work could accelerate research for both attacks and defenses.  In my view, this represents a challenging, under-explored research topic. This paper makes an incremental step into improving understanding in this area.',\n",
       "  'weaknesses': 'I rate the paper as borderline reject and explain my rationale below. I want to make clear that with a thoughtful rebuttal and changes to different aspects, I could definitely see my score increasing.\\n\\nWhile the paper has many things I like, it is my view that the paper still needs work.  Perhaps the biggest problem is that the writing tends to overclaim results or draw conclusions that, as written, are not well supported.  I discuss a couple of cases below under \"Experimental Results.\" I also ask multiple questions about points I had concerns with in the \"Questions\" section below.\\n\\n* A more harmless example of what I perceived as overclaiming is on lines 42-43, which state, \"we consider indiscriminate poisoning attacks for linear models, *the most commonly studied victim models in the literature* (emphasis added). It is not my assessment that linear models are the most commonly studied victim model, particularly recently. Reading this sentence, it felt to me that the authors were stretching to over-justify the paper\\'s restriction to linear models. This is despite the subsequent sentences being more than adequate to justify the choice, e.g., \"linear models are still not well understood\" and \"high interpretability.\"\\n\\n* A second example is on lines 35-36, which state \"the reasons why attacks are sometimes ineffective have not been previously studied.\"  I do not know this statement to be true and expect given other work (e.g., the lethal dose conjecture) that this is not true.\\n\\n**Experimental Results**\\n\\nMy biggest concerns are around the experimental results and the conclusions drawn from them. \\n\\n* Lines 343-344 state, \"Table 1 summarizes the results show that Sep/SD and Sep/Size can *largely* explain why datasets...are harder to poison than others.\" In my view, this statement is making primarily a causation claim. However, the results in the table provide primarily correlation results.  To make a causation claim (which I think is the appropriate type of claim for this paper to try to make), the experiments should externally vary the separability and measure how the performance changes.  I realize that is non-trivial, but I believe it is the right type of experiment here.  \\n\\n* Lines 390-392 state, \"Although limited in effectiveness, the defense still mitigates the poisoning to some degree *mostly by shrinking the projected constraint size*\" I do not see how the empirical results as presented can support such a strong claim.  As written, the text may barely support the claim that smaller projected constraint size *partially* helps (a weak, not that meaningful claim). To justify *mostly* a lot more is needed.\\n\\n* Section 7 Better Feature Representation: Lines 363-364 state, \"We train LeNet and ResNet18 on the CIFAR10 dataset...\" From this sentence, it is my understanding that your pretraining was done on all 10 classes.  If so, your feature encoder goes beyond the transfer learning setting, and I believe this approach does *not* correspond with \"the practical scenario where the victim has access to some *small number* of clean samples...\"\\n\\n* On lines 360-361, we present two ideas -- using better features might improve separability and using data filtering might reduce the projected constraint size.\" I would expect data filtering would both improve separability and reduce the constraint size.  The paper should explain how you are ensuring filtering is only affecting one criteria and not the other.  \\n\\n* I understand why the authors chose to lay out Figure 1 as they did.  However, I did not find the overlapping bars were the best format.  I was initially confused by the formatting, and it took me some time to figure out exactly what was being visualized since I expected multiple attacks, but only saw two bars.\\n\\n**Miscellaneous Comments**\\n\\n* Overall, I found section 5.1 notationally cumbersome and lacking a clear structure and flow. I had to re-read it twice to extract all the main points.  One possible fix is to provide more intuition about why each is being proposed and how the pieces relate.  It felt as though you gave a lot of disparate pieces of information to the reader without walking them through how they fit together as you went alone\\n\\n* Lines 40-41 state, \"An attack is considered ineffective if the increased risk from poisoning is roughly equal to or smaller than the injected poisoning rate.\"  This perspective makes sense, but it took me a minute to understand the definition as stated. I think this sentence could be written more intuitively.'},\n",
       " 'review_266': {'summary': 'This work studies the problem of fairness in the context of distillation of adversarially robust models. Specifically, it is shown that the accuracy disparity between classes (leading to “unfairness”) is _further exacerbated_ for student models, attributed to the a) capacity gap between the student and teacher model and b) equal importance given to classes during the distillation process. \\nThis essentially leads to the need for fair adversarial distillation. This is achieved via modelling the “difficulty of learning a class” via the Least PDG Steps (LPS) measure to model the ease by which a sample can cross the decision boundary. Based on this, a flexible and general reweighting scheme is proposed which can be applied “post-hoc” on top of any distillation mechanisms by allowing for the reweighting. A thorough empirical evaluation is presented showing consistent improvements in the average and worst-group accuracy over existing methods as well as superiority over other fair adversarial training methods. ',\n",
       "  'strengths': 'This paper studies an important and relevant problem of the fairness-robustness trade-off in the relevant setting of knowledge distillation. I like the motivation behind the need to study the \"fine-grained\" effect of adversarial distillation w.r.t accuracy gap between different classes. The approach to analyse the problem is concise and well motivated: and has important implications in both the \"inductive bias\" of adversarial robustness towards different classes as well as the generality of reweighting via class difficulty. Further, the empirical evaluation is thorough and comparisons are made with comprehensive baselines, both w.r.t original robust-distillation methods as well as different \"reweighting\" / fairness methods. \\n\\n',\n",
       "  'weaknesses': 'Following are some questions which I believe should be addressed:\\n1. An essential baseline assumption is that _all classes are balanced_ i.e. equally represented in the training data. How do you foresee the generality of your method in the scenario where we not only consider class difficulty but also the class-imbalance? It looks like the estimator on Eq(6) would now be biased.\\n2. The results seem to be evaluated only on the CIFAR datasets, it would be interesting to see how this observation holds beyond CIFAR. \\n'},\n",
       " 'review_267': {'summary': \"This paper deals with the issue of fairness in adversarial training in image classification with distillation. The idea is that due to model capacity gap between the teacher and the student model, not all classes are equally capable of retaining the teacher model's robustness and thus the distilled student model shows a larger variation among different classes in terms of adversarial robustness which is not desired.\\nThe proposed solution is a simple class-wise re-weighting of the training objective which increases the importance of such difficult classes and reduces that of the easier classes. The proposed weights are heuristically motivated according to the (inverse) of the number of PGD steps needed to find an adversarial example averaged over each class (weighted with hyper-parameter beta).\\n\\nNumerical results on CIFAR 10 and CIFAR100 show empirical improvements of the average and worst-class robustness.\",\n",
       "  'strengths': 'The problem is interesting and well-motivated. The paper is written well and easy to follow. The proposed solution is intuitive and simple.\\n\\nEmpirical results show improvement in terms of average and worst-class adversarial robustness against state-of-the-art on cifar 10 and cifar 100.',\n",
       "  'weaknesses': 'The paper proposed a simple re-weighting approach, and lacks any foundational contribution to the problem. The performance is thus heavily judged by empirical tests.\\n\\nMy concern on this issue is the following:\\n\\n1- Due to lack of theoretical grounding, how reliable are the experimental results? This is specially important in CIFAR100 results given the low robustness (<5%). One could for instance report the standard deviation across different training runs to show such sensitivity.\\n\\n2- The formulation is heuristic, especially as the proposed class weights are not predetermined and change according to the latest model obtained in the last iteration. This means the objective changes in each epoch. How stable is this approach? Also, what are these weights calculated over (training set or validation set)? As one of the differences with GAIRAT it is mentioned that least PGD steps (LPS) is calculated over the validation set in there. How important is this choice and how much difference does it make?\\n\\n3- The metric to measure class difficulty is borrowed from GAIRAT, with some modifications. What is the sensitivity to the pgd parameters such as the step-size.'},\n",
       " 'review_268': {'summary': \"Adversarial robustness distillation transfers knowledge from a teacher model to a student model and improves the overall robustness of the student in terms of resisting adversarial attacks. This work studies robust fairness in the task of adversarial robustness distillation, which focuses on the adversarial robustness of different classes. This work first makes an observation that the student may only partially inherit the teacher's robust fairness, due to the capacity gap between the teacher and student, and the varying class difficulties. To address this issue of robust fairness, this work proposes Fair-ARD, which uses a geometric perspective to quantify the per-class difficulty and adjust the weight of each class accordingly. Extensive experiments demonstrate the efficacy of Fair-ARD in improving the robust fairness in knowledge distillation.\",\n",
       "  'strengths': '1. This work, for the first time, explores how to transfer robust fairness in adversarial robustness distillation. Robust fairness can be of vital importance in ML applications with social and/or safety concerns. This research initiates an important direction for the community.\\n2. The proposed method, Fair-ARD, is a general framework that can be readily incorporated into existing ARD methods.\\n3. The experiment evaluation is thorough.\\n4. The writing and math notations are clear.',\n",
       "  'weaknesses': '1. The experiments are mostly done on CIFAR-10/100, a relatively curated and easy dataset. Following prior work like IAD [35], it is encouraged to include more realistic and challenging datasets like Tiny-ImageNet. In the sense of robust fairness, a large number of classes and/or unbalanced data distribution would introduce some more practical challenges.\\n2. The re-weighting strategy in proposed method requires re-estimating the difficulty of every sample in every epoch. This process involves multiple PGD steps. This method may introduce a large quantity of computation overhead to the distillation procedure.\\n3. Citations should be given when previous methods first appear in the paper (e.g., IAD, RSLAD, and MTARD in Line 75).'},\n",
       " 'review_269': {'summary': 'This paper focuses on the issue of robust fairness in adversarial robustness distillation. This paper proposes the Fair Adversarial Robustness Distillation (Fair-ARD) framework, which utilizes a more refined difficulty metric and an adaptive class re-weighting approach, enabling the student model to learn the knowledge about each class in a fairer way. Extensive experiments confirm that Fair-ARD can significantly improve the robust fairness of the student model and slightly improve overall robustness.',\n",
       "  'strengths': '+The main strength paper firstly investigates the issue of robust fairness in adversarial robustness distillation, and furthermore proposed a reweighting method to get a class-fair student model. \\n\\n+The paper is well-writing and easy to follow.\\n',\n",
       "  'weaknesses': '-The novelty is somewhat limited.  Robust fairness is widely studied in the adversarial training method (adversarial distillation is a type of variant to improve the robustness based on the adversarial training). In this regard, the originality of the research is limited.\\n\\n-The reweighting method toward different class is widely applied in adversarial training ([1], [2] as mentioned in article). More advanced state-of-the-art method (such as [3]) should be discussed and compared.\\n\\n-The metric to measure class difficulty is lack of theoretical basis. Directly applying the least PGD steps seem to not be a good estimate method. Different step size and steps num will lead to different results, e.g., Auto-PGD [4], and the similar idea is applied in AT (e.g. [2], [5]). If the least PGD steps is applied in reweighting and can really be helpful, a theoretical analysis is supposed to provide.\\n\\n[1] Jingfeng Zhang, Jianing Zhu, Gang Niu, Bo Han, Masashi Sugiyama, and Mohan Kankanhalli. 360 Geometry-aware instance-reweighted adversarial training. In ICLR, 2021.\\n\\n[2] Han Xu, Xiaorui Liu, Yaxin Li, Anil Jain, and Jiliang Tang. To be robust or to be fair: Towards 355 fairness in adversarial training. In ICML, 2021.\\n\\n[3] Wei, Zeming, et al. \"Cfa: Class-wise calibrated fair adversarial training.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\\n\\n[4] Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an  ensemble of diverse parameter-free attacks. In International conference on machine learning, 362 pages 2206–2216. PMLR, 2020. \\n\\n[5] Xiaojun Jia, Yong Zhang, Baoyuan Wu, Ke Ma, Jue Wang, Xiaochun Cao; Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022.'},\n",
       " 'review_270': {'summary': 'The paper addresses the issue of amplified class-imbalanced performance during adversarial robust distillation (ARD). The authors propose a fair-oriented ARD method that incorporates a class re-weighting mechanism for adversarial training. The method is applicable to various ARD techniques and consistently achieves success across different datasets.\\n',\n",
       "  'strengths': '1. The paper provides strong evidence (Fig. 1 and Tab. 1) to highlight the severity of the robust fairness (class-imbalanced adversarial robustness) issue.\\n2. The proposed method is simple yet effective, as validated through extensive experiments.\\n',\n",
       "  'weaknesses': '1. The reviewer suggests investigating whether existing fair-oriented distillation methods can mitigate the robust fairness problem with slight modifications. For example, [A] addressed biased issues in standard knowledge distillation and conducted experiments on the CIFAR-10S dataset. It would be beneficial to discuss and compare these existing methods in this submission.\\n\\n2. Prior work [17, 29] has emphasized that average accuracy can be odd to fairness in both standard and adversarial robust settings. However, the experiments presented in Tab. 2, Tab. 4 of the main paper, as well as Tab. 7 and Tab. 8 in the supplementary material, show that the proposed method consistently achieves significantly better average scores while maintaining the best fairness scores, contrary to established theories. This raises concerns about the credibility of the experiments, and the reviewer requests an explanation for this phenomenon.\\n\\n[A] Jung, Sangwon, et al. \"Fair feature distillation for visual recognition.\" Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021.\\n\\n'},\n",
       " 'review_271': {'summary': 'This paper presents a novel approach to compute optimal equilibria in multi-player extensive-form games through the use of Lagrangian relaxation as a two-player zero-sum extensive-form game. Building upon the mediator augmentation game framework, the proposed computing approach significantly contributes to the reduction of zero-sum games, thereby holding substantial implications for mechanism design and information design. Furthermore, it plays a pivotal role in fostering a well-balanced hierarchy of concepts.\\n\\n',\n",
       "  'strengths': '-- The investigation of computing minimax equilibria in extensive-form games is an interesting and well-motivated problem.\\n\\n-- Most correlation equilibrium notions pose challenges in finding optimal equilibria, whereas the framework presented in this paper offers a learning-based algorithm to compute them.\\n\\n',\n",
       "  'weaknesses': \"-- The paper lies heavily on notation that lacks intuitive explanations. To enhance reader understanding, a schematic representation of the mediator-augmented game framework should be included in the main body. \\n\\n-- The approach proposed in this paper resembles a transformation of the original game into a mediator-led Stackerberg game. It would be beneficial to discuss and compare existing research on equilibrium solutions for zero-sum games in Stackelberg games to provide a contextual background for the paper's contribution. Lack controlled experiments involving additional algorithms for equilibrium solutions in Stackelberg games.\\n\"},\n",
       " 'review_272': {'summary': 'This paper studies the computation of optimal equilibria in multi-player extensive-form games via no-regret learning algorithms. The key idea is to take the constrained LP formulation of the optimal equilibrium problem proposed by Zhang and Sandholm and consider the saddle point formulation, which can then be solved using no-regret learning algorithms. In order to alleviate the large $\\\\lambda^*$, a binary-search based algorithm is proposed. Finally, the algorithms are compared with a LP-based method on several tabular games as well as for an auction-design problem.',\n",
       "  'strengths': '- The paper is well-written. The results presented clearly and the writing is easy to follow.\\n\\n- The experimental results seem compelling as it has an order of magnitude advantage in wall-clock time over the LP-based method. This advantage is consistent across a set of diverse instances.',\n",
       "  'weaknesses': '- I have some concerns about the LP formulation (G). Consider a $N$ player normal form game with $A$ actions per player for instance; it seems that for the correlated equilibrium in such a game, the $\\\\mu$ in (G) would need to have dimension $A^N$. However, no swap-regret algorithms can find an approximate correlated equilibrium with $\\\\tilde{O}(NA^2/\\\\epsilon^2)$ samples. It seems that the LP formulation (G) can lead to suboptimal dependence on the number of players.\\n\\n- Perhaps related the previous point, while in Line 79 the authors claim that \"Our algorithm significantly outperforms existing LP-based methods\", in the experiments it is only compared against the LP based solution to (G) proposed by Zhagn and Sandholm. Is (G) the only known LP formulation of the optimal equilibrium problem? If not, wouldn\\'t it make sense to compare against those as well?'},\n",
       " 'review_273': {'summary': 'The paper focuses on addressing the challenge of computing optimal equilibria in extensive-form games. The authors introduce the revelation principle, which transforms the problem into a linear programming (LP) task. \\n\\nThey propose using Lagrange relaxations to solve the LP, treating the resulting saddle-point problem as a Nash equilibrium in a zero-sum two-player game. The authors explicitly construct such zero-sum game. To efficiently find the solution, the authors employ regret minimization over conic hulls. Additionally, they highlight the flexibility of their approach by showing that other algorithms for zero-sum two-player games can be utilized, offering different convergence rate guarantees or achieving last-iteration convergence. \\n\\nThe paper concludes with thorough experimental evaluations, demonstrating the effectiveness and scalability of their proposed methods across various simple games.',\n",
       "  'strengths': '- The paper addresses the significant problem of computing optimal equilibria in game theory. By reducing this problem to zero-sum games, the authors provide a framework for finding optimal equilibria. The key contribution lies in the fact that existing algorithms for zero-sum extensive form games can be directly applied to this problem. This reduction greatly enhances the understanding and applicability of the proposed approach.\\n\\n- The experimental evaluation conducted by the authors is robust and contributes to the strength of their work. They provide evidence of the scalability of their methods through preliminary experiments. This not only showcases the effectiveness of the proposed techniques but also demonstrates their potential for real-world applications. The inclusion of experimental results further reinforces the practical relevance of the research and adds value to the overall paper.',\n",
       "  'weaknesses': 'My only concern is about the revelation principle. The reduction in the paper relies on the revelation principle, which is a fundamental concept. However, it is not clear regarding the specific conditions under which a fixed pure strategy d_i exists for different players and within which games and equilibria this concept applies.  Additionally, how to effectively find such d_i strategies is also a problem.'},\n",
       " 'review_274': {'summary': 'The authors proposed a learning-based framework to solve for optimal equilibria in n-player general-sum extensive-form games. The key idea is to leverage Lagrangian relaxation and convert such games to 2-player zero-sum extensive-form games which can then be solved using known learning methods that solve for minimax equilibria. ',\n",
       "  'strengths': '* significance\\nI believe this work could be a significant contribution to the field as it proposes a computationally practical method that solves for optimal equilibria in n-player general-sum games. This is significant as it offers a language to speak about optimality of equilibria in addition to stability and could make game theoretic methods attractive in wider classes of practical applications. \\n\\n* originality\\nI believe the proposed method is novel. \\n\\n* clarity\\nThe paper is well written and relatively easy to follow. \\n\\n* quality\\nThe theoretical derivation of the method appears sound; the empirical results seem extensive though it would be interesting to understanding additional details which I have commented below.  ',\n",
       "  'weaknesses': 'The presentation of the empirical results seems to be primarily focused on the efficiency and feasibility of converting the problem of solving for optimal equilibria in n-player general-sum EFGs to solving minimax equilibria in two-player zero-sum games. For instance Table 1 presented runtime results of the learning-based method compared to solving LP directly. \\n\\nWould it be possible to provide additional details on optimality as well especially in general-sum games such as Sheriff where we know the value of max-welfare equilibria (e.g. https://www.cs.cmu.edu/~gfarina/2020/efcce-aaai20/coarse-correlation.aaai20.pdf)? Would the proposed method scale up to these instances of sheriff game? '},\n",
       " 'review_275': {'summary': 'This paper presents family of algorithms namely Counterfactual Contribution Analysis (COCOA), which is based on measuring contribution of an action by asking counterfactual question. The new measure of contribution performs better than existing methods such as HCA in terms of lower variance. They define rewarding outcome as function of state, action and reward. They compute contribution coefficients which can be used to learn a policy with COCOA policy gradient estimator. ',\n",
       "  'strengths': '1. The authors show that the presented COCOA policy gradient estimator can result in lower variance than existing method such as HCA, which suffers from spurious contributions which can be alleviated by using less informative encodings.\\n2. The authors demonstrate demonstrate the performance of COCOA compared to standard baselines in key-to-door environment. They further present improvement in sample efficiency due to favorable bias-variance trade off\\n3. The way COCOA is learning the correct distanglement enables long-term credit assignment better than existing methods.',\n",
       "  'weaknesses': 'Compared to policy gradient methods like REINFORCE and Advantage, the COCOA estimators seem to be very computationally expensive.'},\n",
       " 'review_276': {'summary': 'This paper proposes Counterfactual Contribution Analysis (COCOA) to improve credit assignment in the reinforcement learning problem by building upon Hindsight Credit Assignment.',\n",
       "  'strengths': 'This paper is written in a clear manner and allows non-expert audiences to understand its difference and contribution in contrast to previous work.',\n",
       "  'weaknesses': 'I do not feel that I understand enough about this field to critique this paper.'},\n",
       " 'review_277': {'summary': 'The paper introduces a novel credit assignment algorithm for reinforcement learning known as COCOA (Counterfactual Contribution Analysis). The proposed method extends the concept of Hindsight Credit Assignment (HCA) and aims at making the learning process more sample efficient. By leveraging counterfactual reasoning, COCOA measures the contribution of actions upon obtaining subsequent reward, thereby achieving improved credit assignment. The paper provides an extensive theoretical analysis of COCOA while addressing its potential advantages and limitations.',\n",
       "  'strengths': '- The proposal of a novel approach to credit assignment in RL.\\n- Comprehensive theoretical derivations and analysis that support the argument.\\n- Improvement in policy gradient estimators and progression in long-term credit assignment by distinguishing rewarding outcomes.\\n',\n",
       "  'weaknesses': '- The absence of empirical comparisons with related methods, particularly RUDDER which is cited in the paper.\\n- Unclear scalability of the proposed method in more complex environments and restricted quality of the inverse dynamics model.\\n- Limited empirical evaluation and ablation studies, i.e. examining the influence of the dynamics model on performance.\\n'},\n",
       " 'review_278': {'summary': 'The paper presents a policy gradient estimator using credit assignment measure on influence of specific actions toward future rewards. The paper offers theoretical analysis on resulting algorithm such as (1) policy gradient estimator is unbiased, (2) variance of the estimator in relation to some existing methods, and so on. The authors also include numerical studies using a simple but specifically designed example to highlight the benefits of the proposed algorithm.',\n",
       "  'strengths': '1. With some assumptions, the paper provides analytical guarantees on a range of desirable aspects of the algorithm. ',\n",
       "  'weaknesses': '1. Given HCA, contribution seems marginal. \\n2. Claims are either straightforward or require strong assumptions (quarantees in extreme cases such as Prop 2, Theorem 3)\\n3. Experiments too simple '},\n",
       " 'review_279': {'summary': 'This paper introduces COCOA, a new family of hindsight credit assignment methods that build on HCA, which uses hindsight importance weights for the policy gradient estimator to reduce its variance. HCA uses state-conditioned importance weights, i.e., the ratio of $p(a_t|s_t, s_{t+k})$ to $\\\\pi(a_t|s_t)$. COCOA generalizes HCA by replacing $s_{t+k}$ with $u_{t+k} = f(s_{t+k}, a_{t+k}, r_{t+k})$ with a general function $f$. Specifically, the authors suggest using either $f(s, a, r) = r$ or $f(s, a, r) = g(s, a)$ where $g(s, a)$ is a function that can fully determine the reward. These variants lead to a lower variance compared to vanilla HCA by conditioning only on information that is related to the reward function. They evaluate COCOA on synthetic domains, showing that COCOA outperforms HCA with improved credit assignment.\\n',\n",
       "  'strengths': '- The authors generalize HCA in an important direction, and the theoretical benefits of COCOA are significant and clear.\\n- The paper contains informative discussions about various aspects of hindsight gradient estimators, which provides further insights into hindsight credit assignment in general.\\n- The paper is well-written and easy to follow. ',\n",
       "  'weaknesses': '- The paper lacks discussion regarding return-conditioned HCA. While the authors argue that (state-conditioned) HCA suffers from high variance, the original HCA paper also proposes a return-conditioned variant (Sec 3.2 and Theorem 5 in Appendix B), which can enjoy similar benefits to COCOA. Also, when referring to HCA, the authors only mention its state-conditioned variant throughout the paper. Discussing and comparing with the return-conditioned variant of HCA would be more relevant given its similarity to COCOA-reward.\\n- The novelty of the method is a bit limited, as the original HCA paper also proposes a general version of HCA that is conditioned on any function of the future trajectory (Sec 3 in the HCA paper). Nonetheless, the paper further discusses sufficient conditions of this function to make the policy gradient estimator unbiased.\\n- The experiments are conducted only on toy, synthetic environments. It is questionable how COCOA works in more realistic domains.'},\n",
       " 'review_280': {'summary': 'This paper proposes Counterfactual Contribution Analysis (COCOA), an RL credit assignment approach inspired by the Hindsight Credit Assignment (HCA) family of algorithms. \\n\\nThe paper notes that in some instances, the previously proposed State-HCA approach can degrade to as high a variance as REINFORCE due to using the future state for obtaining hindsight weights. \\n\\nInstead of estimating hindsight contributions of actions based on future states (as in State-HCA), this paper introduces the idea of a rewarding outcome which is a function of a future state, action, and reward (s’, a’, r’) tuple. The paper proposes two choices for the rewarding outcome– the reward itself or the reward predictive features of the state-action pair (COCOA-reward and COCOA-feature). The paper provides intuitions on how the COCOA approaches should lead to lower-variance policy gradients compared to State-HCA due to reduced encoding of state information. \\n\\nExperiments in a key-to-door environment shows that the COCOA approaches perform much better than State-HCA, REINFORCE (with and without baseline), and all-actions policy gradient on Q-values.\\n',\n",
       "  'strengths': '**S1.** Hindsight-based approaches are a promising solution to the credit assignment problem in RL, which is of great interest to the research community. \\n\\n**S2.** While identifying the high-variance failure case of State-HCA may not be a novel contribution (see W2), the proposed solution to use rewards or reward predictive features instead of states is novel. The solution idea is simple, well-motivated with examples (e.g., Figure 2 and text below proposition 2), and fits the HCA family of approaches well. Focusing on features that can be useful for HCA is an interesting direction and opens a way to improve previous HCA approaches.\\n\\n**S3.** The paper is well-written and easy to follow.\\n',\n",
       "  'weaknesses': \"**W1.** The paper's claims would be more accurate with the clarification that HCA refers to the State-HCA algorithm from the HCA paper. The claim that this approach generalizes HCA (e.g., line 103) is inaccurate. HCA generally proposes any function of the future trajectory to estimate contributions, and future states are simply one instance in the proposed family.\\n\\n**W2.** The observation that State-HCA-based approaches can suffer from high-variance or spurious contributions (even in comparison to Monte-Carlo approaches) is not a novel finding, as it has also been noted in previous work [1,2]. Could the authors clarify the similarities and differences to the observation made in the papers above? \\n\\n**W3.** A crucial weakness is that it is hard to judge the applicability of the proposed approach based on evaluation in a single environment (linear key-to-door). While linear key-to-door is a challenging problem from the perspective of credit assignment, an evaluation in Atari games (along the lines of Deep HCA [3]) could be more informative in guiding intuitions of how this approach scales to complex settings.\\n\\n**W4.** The paper also needs to include evaluation against other hindsight baselines, for instance, return-conditioned HCA, which was concretely proposed in the HCA paper. An even more interesting comparison would be to Counterfactual Credit Assignment [4], which learns features for hindsight contribution. \\n\\n\\nOverall, I appreciate the direction the authors took to address the limitation of State-HCA. Should these weaknesses be adequately clarified/addressed, I would happily increase my score.\\n\\n\\n—------------------—------------------—------------------—------------------—------------------\\n\\n### References\\n\\n[1] Young, K. (2019). Variance Reduced Advantage Estimation with $\\\\delta$ Hindsight Credit Assignment. arXiv preprint arXiv:1911.08362.\\n\\n[2] Zhang, P., Zhao, L., Liu, G., Bian, J., Huang, M., Qin, T., & Liu, T. Y. (2019). Independence-aware advantage estimation.\\n\\n[3] Alipov, V., Simmons-Edler, R., Putintsev, N., Kalinin, P., & Vetrov, D. (2021). Towards practical credit assignment for deep reinforcement learning. arXiv preprint arXiv:2106.04499.\\n\\n[4] Mesnard, T., Weber, T., Viola, F., Thakoor, S., Saade, A., Harutyunyan, A., ... & Munos, R. (2020). Counterfactual credit assignment in model-free reinforcement learning. arXiv preprint arXiv:2011.09464.\\n\"},\n",
       " 'review_281': {'summary': 'This paper lays out a goal of addressing a weakness in HCA that HCA can confuse the contributions of actions to reaching a state, increasing the variance of gradient estimation. Instead, the COCOA method proposed in this paper generalizes HCA to use any feature that is predictive of rewards, such as the reward or reward-predicting features. Thus, it allows for selecting an appropriate rewarding outcome to disentangle the contributions of each action from the observed rewards. The paper derives a new unbiased gradient estimator (given the exact hindsight model). Experiments are then conducted to show that when these models are known, they can reduce variance in cases not handled by standard control variates. ',\n",
       "  'strengths': \"The biggest strength of this paper is thorough experimentation to illustrate when COCOA reduces variance when the hindsight models are known. \\n\\nThe experiments and environment clearly show the COCOA method's impact in the cases: when distractor rewards are encountered during the episode and when the distractor rewards are of the same magnitude as the main reward. These experiments show clear evidence that selecting the appropriate disentangling factor is essential to reducing variance. \\n\\nThe experiments to show the SNR as a function of credit assignment distance highlights how each gradient estimator degrades as the episode length and distance between action and rewarding stimulus increases. However, this should be evaluated at longer distances as the slopes and shapes of the curves are difficult to observe in this range. \",\n",
       "  'weaknesses': 'The biggest weakness of this paper is that there is no investigation into how accurate the estimates of hindsight models need to be to reduce variance. Past variance reduction techniques for policy gradients have proven useless in practice (Tucker et al. 2018). So it is crucial to understand the practical limitations when developing a new method. \\n\\n\\nThe comparison to q critic, when q is known, is odd. Because if q is known, then the natural gradient will be known (Kakade, 2001). It should be made precise what sources of variance these experiments are measuring. \\n\\nThe bias can be much higher for COCOA methods than other methods (Figure 3 (D)), and it needs to be clearly discussed since this method is supposed to be unbiased. \\n \\nA more relevant baseline instead of the Advantage method would be the doubly robust control variate for policy gradient methods (Huang and Jiang, 2020). This has a significant variance reduction compared to standard baselines in policy gradient. The comparison would also better highlight the limits of information between the two approaches. \\n\\nThe success/failure of an algorithm depends greatly on hyperparameter choices. It needs to be clear how each method\\'s hyperparameters were chosen. Since this paper is trying to argue that COCOA has better sample efficiency, it should be made clear in what exact context this claim is being made. Furthermore, if one wants to say that COCOA has better information utilization through measuring performance, then the hyperparameters for the baseline methods need to be tuned to their absolute maximum. As the paper currently stands, the experiment design is insufficient to make this argument, even if it is likely true. \\n\\nThough not poor, the writing in the paper has room for improvement. One of the best ways for this paper to have a bigger impact is to make it written so that most RL people can easily understand the lessons. So I recommend that the authors spend time revising the writing for a future or camera-ready version of the paper. \\n\\n___minor comments__\\nwhat are the decibel units? This is nonstandard in ML, so it is worth specifying. \\n\\nTable1: In the Advantage method, $v^\\\\pi$ should just be $v$ because the baseline can be any state-dependent function\\n\\nAlthough common in the ML community $\\\\nabla_\\\\theta$ is a mathematical symbol for a directional derivative. However, it is used in this work as a partial derivative. Further, since the gradient is a function that takes a derivative with respect to all inputs and partial derivates are the quantities of interest, it makes mathematical sense to use mathematical symbols for partial differentiation, not gradients. \\n\\nLine 100: \"it has a failure mode of practical importance\" —say what this is. \\n\\nSection 3.1 Define reward outcomes first. It is unclear what they mean, making it hard to interpret. It also needs to be made clear when or why one would use different choices of f. Giving a few motivating examples would help here. \\n\\nLine 133: Eq 1. Check the JMLR guidelines for standard practice for referencing equations. It should be just (1) not Eq, and equation blocks should only be numbered if they are referenced. \\n\\nLine 146: missing for all k?\\n\\nDefinition 1. Remark on definition 1 to clarify what is needed to satisfy this property in practice. \\n\\nTheorem 1: It is important to remark that the gradient estimator is unbiased only if the counterfactual term is known precisely, which is unlikely in practice. This would be like saying the DDPG is unbiased, which is misleading because it is only true if Q is known. \\n\\nTheorem 4. \"equals\" should be changed because the expression is not a statement of equality but proportionality. \\n\\nLine 246: \"SNR indicates… fewer trajectories…\" This is not universally true. It can require an exponential number of trajectories to get a gradient estimate, and lower variance estimates will not help this. \\n\\n\\n\\nREFERENCES\\nHuang, Jiawei, and Nan Jiang. \"From importance sampling to doubly robust policy gradient.\" International Conference on Machine Learning. PMLR, 2020.\\n\\nKakade, Sham M. \"A natural policy gradient.\" Advances in neural information processing systems 14 (2001).\\n\\nTucker, George, et al. \"The mirage of action-dependent baselines in reinforcement learning.\" International conference on machine learning. PMLR, 2018.'},\n",
       " 'review_282': {'summary': 'This paper studies the problem of learning a latent representation for data supported on a low-dimensional manifold. It proposes to promote orthogonality of the tangent vectors arising from a learned chart, on top of existing rectangular flow loss. Experiments are provided to demonstrate the effectiveness of the algorithm.',\n",
       "  'strengths': 'Promoting orthogonality of the tangent vectors from a learned chart is interesting.',\n",
       "  'weaknesses': '## Presentation:\\n1. The paper seems insufficiently prepared and proofread. In particular, there are numerous evident typos even in the first paragraph of the introduction. Consequently, they weaken the credibility of the paper.\\n    1. Lines 29, 33 the \"D\" in \"R^D\" uses a mathbb, whereas in lines 31, 32 the \"d\" or \"D\" does not.\\n    1. Line 29 “fulfil” -> “fulfill”\\n    1. In equation 1, the q_phi(x) should have been q_phi^{-1} (x)\\n    1. Section 3 talks about general manifold learning, and is almost detached from the technical sections 2 and 4.\\n2. Line 43: A line is one-dimensional. What is a two-dimension line?\\n3. If one compares equations (5) and (6), it appears that we assume the learned map q_phi is a chart of manifold M. If that is the case, this should be made explicit.\\n4. From (8), it is unclear that where the introduced G term are evaluated. I suppose it is on points x_i’s?'},\n",
       " 'review_283': {'summary': 'The authors introduce a new method for regularising manifold learning flows. Essentially, it attempts to reduce the entanglement between the dimensions of the learned manifold by encouraging non-diagonal elements of the metric tensor to be small. Leveraging the already necessary computation of $J^\\\\top J$, where $J$ is the Jacobian of the flow transformation, this is done efficiently by minimising the $\\\\ell-1$ norm of the non-diagonal entries.\\n\\nExperiments on synthetic and real data show how this is effectively achieved, especially when compared to similar models that do not employ the regularisation scheme. Beyond achieving the desired effect, the proposed method achieves lower FID-like scores on real tabular data.',\n",
       "  'strengths': 'The paper is very well written and the presented ideas are easy to follow. Experimentally, the authors confirm both in intuitive, synthetic examples and real data. The proposed regularisation scheme is also simple and computationally efficient, which is also a desirable feature. Overall, I consider it a strong contribution and see high potential of being widely adopted as a mechanism for regularising manifold learning flows.\\n\\nI also appreciate the limitations raised and discussed by the authors, indicating maturity in their analysis and raising important considerations related to the use of their work.',\n",
       "  'weaknesses': 'Although I see the potential mentioned above, I do consider it could be viewed more widely as a weak point, given the relatively niche application. Although it does not affect the merit of the work, the principle might be too specific to manifold learning flows.\\n\\nI would consider more tabular data experiments are needed, with additional data sets, given the mixed results attained. More concretely, some analysis of what specifically differentiates the data sets enough to cause the difference in performance.'},\n",
       " 'review_284': {'summary': \"The paper studies the current manifold learning methods. It compares canonical manifold learning flow (CMF) with other manifold learning methods and demonstrates that CMF can learn the orthogonal features existing in data. From synthetic data on Moebius, the paper shows the benefits of using CMF.  Also, the paper shows the generated images from the CMF learned latent space is of higher quality than other methods' learned latent spaces. Lastly, the paper acknowledges some limitations of CMF, for example, high computation cost of the full Jacobian tranpose Jacobian.\",\n",
       "  'strengths': \"1. The paper is very clear on the advantages of CMF against other manifold learning methods. \\n2. The paper did various types of experiments to showcase the CMF's performance among the methods.\",\n",
       "  'weaknesses': '1. Although being mentioned in the limitations, the paper does not provide results about the computation costs of CMF. There is no comparison of the computation time of CMF against other methods, also how the dimension affects the computation cost. It is unclear if CMF is scalable to higher-dimensional datasets.\\n2. The paper does not compare CMF with a lot of methods, including PCA and ICA or purely deep learning methods. For example, an autoencoder can also extract feature representations from data. How does CMF compare to these approaches?'},\n",
       " 'review_285': {'summary': 'The authors address the interesting question of how to disentangle the relevant manifold directions properly in the latent space of manifold learning normalizing flows (MLF). After a comprehensive theoretical background, the main motivation is presented in form of a toy example of a simple noisy line embedded in $\\\\mathbb{R}^{2}$. When varying the latent dimension $z_{i}$ of a RNF and setting the remaining latent variables to $0$, the corresponding contour lines are partially aligned. Doing the same with the proposed method, CMF, leads to orthogonal contour lines and thus to a meaningful latent representation where one latent variable encodes the line and the other the (noisy) off-manifold direction. This intuition leads straightforwardly to enforcing the orthogonality of the flows Jacobian matrix. To do so, the authors propose a new cost function for learning manifold structures using an NF by adding a penalty term which ensures that the off-diagonal entries of the Gram matrix (Jacobian-transpose-Jacobian) are $0$ at the one hand, and are sparse at the other due to the l1-norm. The effecitiveness of the method is tested in experiments on toy-data, tabular data and 32x32x3 image data.\\n',\n",
       "  'strengths': 'The paper is overall well written. The theoretical background is exhaustive and well-explained. The example in 4.1 serves as a good illustrative motivation. The experiments are comprehensive.',\n",
       "  'weaknesses': \"The contribution is somewhat marginal. Though citing [1], they don't mention that the corresponding authors propose a very similar penalty term. To my understanding, the only differences of the penalty term in [1] are\\na) that in [1] the diagonal entries are penalized to be $1$ whereas in this work the diagonal entries are unconstrained.\\nb) [1] used the L2-norm whereas in this paper the L1-norm is used.\\n\\nGiven the great similarity, the penalty term suggested by [1] should be included in the comparison. What do we gain by not constraining the flow to be an isometry? In addition, the authors use the M-flow for benchmarking although a better method for overcoming the limitations of M-flows (namely that the log-determinant term is not considered while training) was already proposed in [2]. At least citing and ideally comparing with [2] should be part of the paper. The same is true for comparing with [3]. It would be nice to see how the contour lines differ from the method introduced in [3].\\n\\nFurthermore, I am not sure to understand the reasoning behind Definition 4.1. To my understanding, every differentiable manifold is a canonical manifold as one is free to choose the basis of the tangent space to be orthogonal. Thus, such a basis always exists which is the only requirement to be a canonical manifold. Definition 4.1. is simply an existence statement and not useful as such. I think what the authors wanted to define is a manifold equipped with a chart s.t. the chart induces an orthogonal basis of the tangent space. However, this is very much the definition of the principal component flow [3]. Please enlighten me in case I totally misunderstood something.\\n\\nI am also confused about the comparison with rectangular NF (RNF) in Figure 2. By definition for RNF we have that $d<D$. However, in Figure 2 the author uses $d=D$. This is a contradiction. If $d=D$, a standard NF can be used rather than an RNF. In addition, one claimed strength of the proposed CMF is the sparisity induced by the l1 norm. Thus, the relevant dimensions should be found automatically which elevates, in theory, the necessity to estimate $d$ a priori. Then, why not always set $d=D$ and then apply the proposed penalty term? The number of prominent latent dimensions should correspond to the true intrinsic dimensionality of the data.\\n\\nFinally, the notation for the manifold, data manifold, and learned manifold is confusing. In line 74 or line 90, $\\\\mathcal{M}$ is a lower dimensional manifold. In line 83, $\\\\mathcal{M}_{\\\\theta}$ is introduced without explaination. In line 212, $\\\\mathcal{M}$ is referred to as the learned manifold and in the same line, the data manifold is introduced without further explanation. In addition, a new notation for a canonical manifold is suggested. I find the various versions for a manifold confusing and don't see the added benefit of it (especially given that Definition 4.1. is not useful in my opinion).\\n\\n\\n[1] Eike Cramer, Felix Rauh, Alexander Mitsos, Raúl Tempone, and Manuel Dahmen. Nonlinear 350 isometric manifold learning for injective normalizing flows. arXiv preprint arXiv:2203.03934, 351 2022.\\n\\n[2] C. Horvat and J.-P. Pfister. Denoising normalizing flow. In Advances in Neural Information Processing Systems, volume 34, 2021.\\n\\n[3] Edmond Cunningham, Adam D Cobb, and Susmit Jha. Principal component flows. In Interna410 tional Conference on Machine Learning, pages 4492–4519. PMLR, 2022.\\n\"},\n",
       " 'review_286': {'summary': 'This paper explores decentralized learning algorithms with the aim of faster model convergence while comparable accuracy compared with conventional DL methods. The new proposed algorithm - epidemic learning (EL) - leverages a dynamically changing, randomized communication topology to train a machine learning model in DL environment. The paper provides theoretical analysis which shows that the EL algorithm surpasses the best-known static and randomized topologies in terms of convergence speed, w.r.t. two key properties: linear speed-up and transient iterations. The experimental results show that the proposed EL-oracle and EL-local achieve quicker convergence than baselines. ',\n",
       "  'strengths': 'This paper is studying a very interesting and important problem - DL algorithms. The paper is well written, which is easy to follow. The proposed EL algorithm is technically sound. The theoretical analysis and experimental results show its effectiveness compared to baselines. \\n',\n",
       "  'weaknesses': 'A major concern is that the proposed EL algorithm is not significantly different with semi-dynamic and time-varying and randomized topologies (they are introduced in related work section). Especially, gossip learning (GL) is like a special case of EL-local with s = 1. \\n\\nA minor comment: Figure 3 should be improved by giving label for x-axis. Also there is no full words for the first abbr \"CDF\". \\n'},\n",
       " 'review_287': {'summary': 'This paper proposes a decentralized learning algorithm in which each node\\nupdates its model from a set of s random nodes in a system with n > s\\nnodes. The authors provide a theoretical analysis of the convergence speed\\nand the number of transient iterations, i.e., the number of rounds required\\nto reach linear speedup stage. Experiments are performed for the CIFAR-10\\ndataset comparing the proposed two methods EL-Oracle and EL-Local with a\\nnumber of baselines that are static topologies. The comparison metrics are\\naccuracy, test loss, and communication volume with increasing number of\\ncommunication rounds.',\n",
       "  'strengths': 'A simple yet effective solution for decentralized learning. It is easily\\nimplementable and can be easily adopted for any decentralized learning\\ntask.\\n\\nThe theoretical analysis has some novel approach and is quite technical.\\n\\nThe paper is generally well written.',\n",
       "  'weaknesses': 'Title: Epidemic learning is a very confusing title. The reviewer is of the\\nopinion that it is an overloaded term. For example, there are many\\ninference problems in the context of contagions (like infectious diseases)\\nwhere the objective is to estimate information about an outbreak. Also, the\\nreviewer is of the opinion that this title might fail to gain the attention\\nof readers from the decentralized learning community. Thirdly, it is very\\nshort and non-informative.\\n\\nTheorem 1 mentions step size \\\\gamma, which does not feature in any\\nexpressions that appear in the statement. The expressions for \\\\gamma in\\nequations (4) and (5) should be included in the statement.\\n\\nRemark 1: The authors mention that they \"provide convergence rate directly\\nfor the local models\". But wouldn\\'t the expected convergence rate of the\\nentire global averaged model depend on the maximum of (worst case) the\\nconvergence rates among the local models? This is not addressed.\\n\\nExperiments section is weak: All the inferences are based on a single\\nlearning problem on a single dataset. The gain in accuracy is not\\nsignificant, but again the reviewer agrees that there are benefits such as\\nreduction in communication rounds and volume. Yet, the gain in accuracy is\\nlow enough to wonder what would happen if the same was used for, say a\\nclassification task on ImageNet.\\n\\nThe performance for varying s: The authors only use s=7. They mention that\\nthis is consistent with baselines. However, they could have performed a\\nseparate experiment to study how their method performs under different\\nmetrics for varying s. Suppose, they get very good performance for s=5\\nitself, wouldn\\'t it be an interesting statement?\\n\\nDisconnect between theory and experiments: \\n\\n1. The authors do not make an attempt to connect theoretical results to\\nexperiments. For example, they mention that the number of transient\\niterations is an inverse function of s. There are no experiments (like the\\none suggested above) to test the tightness of the theoretical bounds. A\\ntable analogous to Table 1 for experiments would be very helpful.\\n\\n2. Step size: From a theoretical perspective, the step size \\\\gamma in\\nequations (4) and (5) depends on s. However, in the experiments (Appendix\\nD), it is obtained by only running the fully-connected topology. Some\\nanalysis of how convergence depends on s and \\\\gamma (as a function of\\ns) would be useful.\\n\\n7-regular static: The authors consider only one instance of 7-regular\\ntopology. There are many possibilities for a 96-node graph. The authors\\ncould have considered 5-10 instances of 7-regular graphs and provided\\nresults averaged over these topologies.'},\n",
       " 'review_288': {'summary': 'This paper considers Epidemic Learning, a framework for distributed optimization where each node in a network pushes gradient-descent updates to a uniform random subset of $s$ nodes in the network. Theoretical bounds on the rate of convergence are derived as well as the number of ``transient iterations,\" showing that this scheme improves upon existing fixed and randomized topologies. These results are supplemented by some empirical evaluations that show gains in communication and iterations to convergence compared to complete or fixed sparse topologies. ',\n",
       "  'strengths': 'The technical results generalize existing convergence rates of complete graphs (i.e. centralized SGD). The analysis is fairly clean and logical, and the paper is fairly well-written. This work also provides some experimental components to support their findings.',\n",
       "  'weaknesses': 'The practical benefits of this kind of decentralized optimization could be better contextualized (see below). The analysis, while clean, does not seem particularly conceptually surprising.\\n'},\n",
       " 'review_289': {'summary': 'This paper proposes a decentralized learning algorithm based on random communication, i.e., each node sends its model to a random set (with a fixed size) of other nodes at each round. This paper theoretically shows the superiority of random communication in terms of transient iterations over other decentralized algorithms, which is further validated by experiments.',\n",
       "  'strengths': '1. This paper provides a simple yet effective scheme of communication for decentralized learning.\\n\\n2. This paper is technically sound. The technique developed for convergence analysis is interesting.',\n",
       "  'weaknesses': '1. In the proposed algorithm, each node is required to send message to a fixed number $k$ of random neighbors at each round. In practice, this may only be applied to networks with high connectivity (e.g., fully connected), and other application scenarios need to be motivated. In addition, the theoretical superiority of convergence directly depends on $k$, so it might be unfair comparing with other algorithms which conventionally works on arbitrary connected graphs. Can the restriction on $k$ or uniformly random selection be relaxed a little bit, say, allow to communicate with varying number of neighbors?\\n\\n2. Although the authors conduct an experiment to explain the imbalanced load on different nodes, I still have a concern that the balanced pattern reported in this paper may rely on the uniformly random selection. Such an assumption may not be aligned with the real cases, e.g., the degrees of different nodes vary, then some nodes may have higher load than others under random selection. This problem may arise from the non-doubly stochasticity of the mixing matrices. Could other methods handling asymmetric communication, such as push-sum, be helpful for load balancing?\\n\\n3. Figure 4 shows that EL outperforms the baseline algorithm throughout the learning process, which seems inconsistent with the theoretical statement that the superiority of convergence lies in transient iterations, i.e., the early stage. As the learning proceeds, the convergence will be dominated by the first term. So I suppose the test accuracy of the various methods may get closer with large $T$?'},\n",
       " 'review_290': {'summary': 'The authors study the benefits of using randomized communication topologies for decentralized optimization of non-convex functions. Critically, the communication protocols studied are not based on picking/sampling a communication graph that remains fixed throughout learning. Instead the authors study the case where the nodes randomize their communication patterns with the rest of the nodes in each round. Based on this premise they propose two algorithms, EL Oracle and EL local and study their convergence rate. The prosed algorithms are shown to converge asymptotically faster than state of the art. Experiments verify the theoretical advantage empirically. ',\n",
       "  'strengths': 'The paper communicates clearly and precisely its contribution. Despite extensive work on decentralized algorithms, including randomized and fixed topologies that can vary over time, to the best of my knowledge the proposed algorithms are novel. Importantly, the authors note that time varying randomized topologies have not been shown to have an advantage over their static counterparts.   ',\n",
       "  'weaknesses': 'I am not 100% sure which quantity is bounded in (3) and if it is supposed to be comparable to the rates provided in Theorem 1. The paragraphs after (3) list various ways EL Oracle and Local improve over (3) but I cannot say I follow them. For example, the first term in EL Oracle in Theorem 1 and (3) are identical but the comments mention an advantage in the first term. Clarifying this would help.\\n\\nIn its current state, the paper is not adequately explaining which part of the analysis unlocks the potential of non-static randomized communication graphs. I think highlighting which parts of the analysis are critical would help. Intuitively, I would expect that improving communication would have an effect similar to decreasing the variance $\\\\sigma$ or improving $p$ but it seems like this is not true.   '},\n",
       " 'review_291': {'summary': 'The paper proposes a novel approach to simulate state-of-the-art graph neural networks (GNNs) using standard message passing. The authors introduce graph transformations that preserve the expressivity of GNNs and allow for better code optimization and competitive predictive performance on various molecular benchmark datasets. The paper presents two types of simulation, weak and strong, and evaluates their performance empirically. ',\n",
       "  'strengths': '- The paper is highly original and presents a novel approach to simulating GNNs. \\n- The authors provide a thorough evaluation of the proposed method on 10 benchmark datasets. \\n- The paper is well-written and easy to follow, with clear explanations of the proposed method and its evaluation. \\n- The proofs in the supplementary are comprehensive. I am impressed by the detailed step-by-step illustrations\\n',\n",
       "  'weaknesses': 'Lack of Clarification. \\n- The intro is not logically coherent. For example. it lacks a formal definition of “simulation” before expanding on it (e.g. simulation is using graph transformations so that standard message passing can reach comparable performances as state-of-the-art graph neural networks? In the introduction, no formal definition of “simulation” is given before expanding on “strongly/weakly simulated” MP algorithms.\\n- Likewise, how do you define graph transformations and what are all possible types of graph transformations? Only until Section 3 were formal definition given\\n\\nThere are claims in the introduction that seem not grounded, which require justification and explanation:\\n- Line 19-20: This is due to their limited expressivity: for all MPNNs, there are 20 pairs of non-isomorphic graphs that get the same embedding\\n'},\n",
       " 'review_292': {'summary': 'This work presents a simulation theory/method for efficiently approximating non-standard GNN functions via standard MPNNs plus graph transformers. It starts from the cases that can be strongly simulated and extends to weak simulation for a comprehensive conclusion. A simulation algorithm is also proposed and verified with experimental results.\\n\\n',\n",
       "  'strengths': '   1. The problem is new (especially focused on non-standard GNNs), clearly defined and rigorously investigated. The motivation is quite practical (if I understand correctly).\\n   2. Experiments on graph classification tasks verify the effectiveness of the proposed algorithms, including performance on AUC, time cost, RMSE, etc.',\n",
       "  'weaknesses': '   1. The structure of the paragraphs dramatically reduces the readability.\\n   2. See the questions below.'},\n",
       " 'review_293': {'summary': 'The paper formally introduces the notions of MPNN simulating GNN with graph transformation. With the definitions, the authors further investigate which class of GNN can be simulated by MPNN.',\n",
       "  'strengths': 'The work presents the first systematic theoretical investigation toward understanding which GNN can be simulated by MPNN.',\n",
       "  'weaknesses': 'The simulation is based on expressiveness equivalence, so more empirical investigations may be required to understand the equivalence in practice.'},\n",
       " 'review_294': {'summary': 'The authors introduce methods for simulating certain graph neural networks (GNNs) using standard message-passing algorithms composed with graph transformations. To do so, the authors introduce a class of nonstandard message-passing algorithms they call \"augmented message passing\" (AMP) algorithms, demonstrate that many standard GNNs are composed of AMP layers, and explicitly construct graph transformations such that standard message passing on the transformed graph input is at least as expressive as a given AMP algorithm. The authors also discuss \"weak simulation,\" and consider more specifically existing techniques that can be weakly simulated via the methods introduced by the authors. Finally, the authors numerically evaluate the performance of their introduced methods.',\n",
       "  'strengths': 'The authors contribute a novel method for constructing message-passing neural networks (MPNNs) on transformed graph inputs that are at least as expressive as a wide class of GNNs with nonstandard message passing. This gives a standard way of viewing GNNs composed of AMP layers, which encompasses many state-of-the-art GNNs. This also formalizes previous work that considered graph transformations composed with MPNNs as a way to make MPNNs more expressive; simultaneously, it gives motivation for constructing GNNs that do not fit within this framework to construct more expressive GNNs This mapping between certain GNNs with nonstandard message passing and MPNNs acting on graph transformations also gives a potentially simpler framework for analyzing properties of such GNNs, though the authors are saving such study for future work.',\n",
       "  'weaknesses': 'One weakness is that it is not immediately apparent what practical advantages the introduced simulation methods yield over direct implementations of the GNNs being simulated. The authors mention one advantage being that standard libraries for implementing MPNNs can be used once a given GNN architecture has been shown to be simulable via an MPNN acting on a graph transformation, but that is a relatively minor advantage.'},\n",
       " 'review_295': {'summary': 'The paper investigates the idea of simulating (replacing) non-standard message passing networks (MPNs) using simple standard MPNs by first applying a graph transformation (new nodes and edges). The paper provides a formal construction of graphs and their generalizations in the form of relational structures that allows for describing e.g. non-pair-wise interactions and cellular complexes. The step through relation structures is important to make arrive to the main theorem of the paper, which is that many non-standard MPNs (based on higher-order relational structures) can be simulated with standard MPNs if the relational structure is converted to a graph in an appropriate way. The theoretical results are underpinned with experiments, showing that indeed simple MPNs on transformed graphs perform on-par (or even outperform) advanced non-standard MPNs.',\n",
       "  'strengths': '* The paper is precise and clear and systematically builds up to the theorems. The various formal definitions provided along the way are helpful in getting a high level picture of the graph NN field. At the same time, I must admit, that the formal approach does require quite some attention from the reader as the paper is dense with information and intuition is sometimes hard to acquire.\\n\\n* The experiments are effectively presented. Table 1 and 2 are interpretable and convincing.\\n\\n* The paper provides a novel analysis \\n\\n* The paper gives useful insights into the expressivity of various forms of graph NNs.\\n\\n* The paper seems reproducible with a link to clean (anonymous) code in the supplementary materials, and the supplementary materials are otherwise very thorough as well.\\n',\n",
       "  'weaknesses': 'The main paper has few details for practitioners. E.g., how to convert a relational structure to a graph is not explained. Details are however provided in the supplementary materials. The paper could benefit from a running example, perhaps the CWN case (fig 1) in which the struct2graph conversion is intuitively explained, as well as why one can similar CWN on this new graph. An example is given at line 248, but feels a bit too abstract for me.'},\n",
       " 'review_296': {'summary': 'The paper deals with supervised machine learning with graphs, specifically with expressive GNNs, and how to implement them efficiently. Specifically, it investigates the expressive power of graph transformations to transform an input graph such that an ordinary 1-WL-equivalent message-passing GNN can simulate, e.g., k-WL-equivalent GNNs, in a layer-wise fashion (strong simulation). To that, the authors formally define this transformation and show that an MPNN can simulate many popular, more expressive GNNs, see Corollary 3.6. \\n\\nThe authors acknowledge that such a transformation is folklore knowledge.\\n\\nMoreover, they investigate the regime (weak simulation) where the MPNN on the transformed graph needs more iterations to distinguish the same pairs of non-isomorphic graphs. Restricted to their particular definition of transformation, they show that some GNN layers cannot be strongly simulated but weakly simulated. \\n\\nEmpirically, they show that their transformations often beat standard message-passing GNNs regarding predictive performance on standard benchmarks. Somewhat surprisingly, they show that they sometimes even beat the architectures they are aiming to simulate. \\n\\n\\n',\n",
       "  'strengths': 'The paper is easy to read, and everything is formalized appropriately. The proofs seem to be correct, and the theoretical results are plausible. \\n\\nTo the best of my knowledge, Theorem 5.2 and Corollary 5.3 are new and somewhat interesting. \\n\\nThe experimental study is well conducted, and the presented results are somewhat interesting. ',\n",
       "  'weaknesses': 'Section 3 just contains more or less obvious results known within the graph learning community. (This is also clearly acknowledged by the authors in the introduction and the appendix.). However, with this in mind, it is unclear why Section 3 occupies 1/3 of the main paper.\\n\\nIt seems that the proof of Theorem 4.1 strongly exploits specific details of \"Structure-to-graph encoding\" (Def. 3.1), which makes the results somewhat narrow. The authors should be more clear about this.\\n\\nThe reasoning in lines 191 -- 195 is highly handwavey. You seem to implicitly assume that the function is continuous on a compact domain. \\n\\n\\n'},\n",
       " 'review_297': {'summary': 'This paper provides a unifying framework for the algorithm design and performance analysis of multicalibrated predictors.\\nIn this paper, the multicalibraion problems is placed in the setting of multi-objective learning.\\nUnder this interpretation, approaches based on game dynamics is proposed and analyzed.\\nIt is shown that this approach yields improved performance guarantees.',\n",
       "  'strengths': '- Bounds are improved for a variety of problems.\\n- Experimental results support the effectiveness of the proposed method.',\n",
       "  'weaknesses': '- The approach based on game dynamics does not seem very surprising as it is a common approach to transform min-max optimization into a problem of finding an equilibrium solution by interpreting it as a zero-sum game.\\n- I have concerns about whether the definition is consistent with that of existing studies. (please refer to \"Questions\")\\n\\n\\nMinor comments:\\n- When citing existing results in Table 1, etc., it would be better to indicate the theorem number or the relevant section. I had a hard time checking the corresponding part.'},\n",
       " 'review_298': {'summary': 'The authors proposed a unified framework for multicalibration learning by exploiting its connection to the game dynamics in multi-objective learning. Strong theoretical guarantees were given and its extension to address group fairness was discussed.',\n",
       "  'strengths': '1. The analysis of the game dynamics in multi-objective learning was novel and strong.\\n2. Connection between multicalibration learning and game dynamics in multi-objective learning was well exploited, unified framework was given.\\n2. The author gave a clear presentation of the key ideas of the work despite substantial material.',\n",
       "  'weaknesses': '1. The experiment parts seem to compare with algorithms within the proposed framework. Is there any comparison with existing baseline algorithms?\\n2. How does the multi-objective learning discussed in the paper related to the Pareto optimal one?\\n3. Given different learner choices shown in the empirical section, is there any learner who fits the proposed framework better?'},\n",
       " 'review_299': {'summary': 'This work exploits connections to game dynamics to propose a unifying algorithmic framework to address the multicalibration problem which has been recently used for tackling fairness concerns in machine learning. More precisely, based on the classic game dynamics approach used in learning problems, it is shown that multicalibration results can be seen as learning dynamics for two-player zero-sum games relying on no-regret algorithms or best response dynamics. Using this unifying framework, the paper recovers some guarantees for existing multicalibration algorithms with simplified proofs and results. Multi-objective learning guarantees are shown and new guarantees are also established for several multicalibration settings including in particular an exponential reduction in the complexity of k-class multicalibration over prior work. Experiments were conducted to evaluate the empirical performance of multicalibration algorithms on some real-world datasets. \\n',\n",
       "  'strengths': '-  The paper proposes a unifying approach using game dynamics which recovers prior results with simpler proofs and establishes novel guarantees improving over prior work in multiple settings. \\n- This paper is well-written, the presentation is very clear. \\n- While I am not familiar with the calibration/multicalibration literature and I did not go through the long appendix supporting the main part in details, the results are sound, quite rigorously exposed and the proofs which leverage for instance prior online learning results seem solid to the best of my knowledge. \\n- Several additional experimental results are also provided in the appendix to support the theoretical findings. ',\n",
       "  'weaknesses': 'Regarding novelty, the related work section mentions in l. 55-56 that ‘no work has established a broad connection between no-regret learning and multicalibration’. No-regret learning has been priorly used for calibrated forecasting as acknowledged by the paper. While it is mentioned that multicalibration ‘has very different challenges than calibrated forecasting’, the discussion regarding these is reduced to a single line l. 57-58 in the related work section. Given that one of the main contributions of this work is the unifying framework based on the connection with game dynamics, I would expect a more detailed discussion to further clarify the novelty with respect to prior work and calibrated forecasting regarding this particular aspect. For instance, some proofs such as the one of Theorem 3.8 follow similar lines to the proof of calibration as also mentioned in l. 246-247. Moreover, it seems that this connection to game dynamics was known for multi-objective learning and multicalibration is linked to it via the simple facts 2.5 and 2.6. '},\n",
       " 'review_300': {'summary': \"The paper provides a two-player dynamics framework that seeks to unify many strands of recent work on multicalibration and multiobjective optimization. With three possible setups considered: No regret against No regret, Best response against No regret, and Best response against Best response, efficient algorithms are provided to demonstrate that these generic setups apply in particular to (multi-)calibration-like constraints. The framework is then applied to several existing and new settings in the literature with the goal of improving some convergence bounds or, respectively, simplifying and streamlining the analysis of specific algorithms. Some experiments are given that show what happens when proposed dynamics are run with specific well-known no regret algorithms in the driver's seat. \",\n",
       "  'strengths': \"To me, the main strength of this paper is the rather clean nature of the setup, which promises that by combining, in any combination, best-responding and no-regret agents, it is possible (though not without further work) to recover existing multigroup fairness results. Previous guarantees are (with a couple exceptions) improved somewhat marginally, or greater simplicity of the framework is claimed in some other cases, but overall it is the generality of this framework --- showcased by its adaptability and ability to recover various insights about calibration (not just regret bounds, but also questions of the simplicity of the output calibrated model, amount of randomness required, etc) --- that is the paper's main forte.\\n\\nAdditionally, the conditional multicalibration setup presented in the paper (and generalizing previous conditional results in the quantile setting) looks like an interesting addition to the literature.\",\n",
       "  'weaknesses': 'No particular weaknesses, other than the relatively well-studied nature of, and relatively small gains in, some of the applications (but no big deal), as well as the somewhat terse and cramped presentation.\\n\\nFor instance, there are a few \"intuitive-sounding\" claims made about where NRNR, BRNR, BRBR may be applied to the greatest utility, but the actual applications are then scattered throughout the paper rather than recalled immediately (there is also Table 1, but I would appreciate a more intuitive dive into which dynamic was used where and why, at the point where these dynamics were actually introduced). For another example, I would be interested in further comments on potential alternative definitions of conditional multicalibration and a slightly expanded treatment of the comparison to the existing 1/sqrt(# people in group) type of guarantee. \\n\\nStill, the paper is overall solid and well-done and I enjoyed reading it.'},\n",
       " 'review_301': {'summary': 'This paper presents a novel approach to multicalibration by leveraging game dynamics and no-regret learning algorithms. The central idea is that multicalibration can be modeled as a multi-objective learning problem where an adversary and a learner play against each other, guided by no-regret dynamics.\\n\\nThe authors propose three types of dynamics: no-regret no-regret (NRNR), no-regret best-response (NRBR), and best-response no-regret (BRNR), each serving different purposes. These dynamics are used to establish the multicalibration algorithms that match or improve the fastest known sample complexity rates for multicalibration, provide deterministic multicalibrated predictors, and offer online multicalibration.\\n\\nThis work also extends the application of these dynamics to other fairness notions, specifically multi-group learning and multi-distribution learning. For the multi-group learning problem, the authors devise an optimal multi-group learning algorithm that relies on NRNR dynamics and is simpler than the existing approaches.\\n\\nThe authors validate their theoretical claims with empirical results on a few standard datasetst. The results highlight the importance of effective no-regret algorithms for better multicalibration, with the Optimistic Hedge outperforming others in the no-regret no-regret dynamics.\\n\\nOverall, this paper contributes to the field by providing a unified, game-theoretic framework for multicalibration that unites disparate existing results and offers more efficient solutions, both in theory and practice. Moreover, it highlights the broader applicability of game dynamics and no-regret algorithms to other fairness notions in machine learning.',\n",
       "  'strengths': 'The paper introduces a novel perspective by approaching multicalibration and other fairness notions using game dynamics and no-regret learning algorithms. It presents multicalibration as a multi-objective learning problem within a game-theoretic framework. However, while the application to multicalibration is new, the use of no-regret algorithms and game-theoretic models is well-established in other areas of calibration literature.\\n\\nThe paper offers a technically sound approach with rigorous mathematical derivations. The theorems are well-proved, and the proposed algorithms are clearly detailed. However, the empirical section could be expanded upon to strengthen the validation of the theoretical claims with real-world data.\\n\\nThe authors have done a reasonable job in articulating complex concepts and methodologies, with the paper being generally well-structured. The use of tables aids understanding, though more insights can be provided for the technical results.\\n\\nThe work has the potential to unify and extend prior work on multicalibration and other fairness notions. However, the impact of the work may depend heavily on how effectively these theoretical insights can be translated into practical applications. Furthermore, while the findings from the empirical results could guide the selection of no-regret algorithms in multicalibration tasks, the experimental validation is relatively limited and does not fully exploit the range of situations where these algorithms could be applied.',\n",
       "  'weaknesses': \"The paper provides a theoretically strong development of multicalibration algorithms using game dynamics. However, there seems to be a gap between the theoretical development and the empirical results. The authors could improve this aspect by designing more comprehensive experiments that test a wide range of scenarios to validate their theoretical claims. These could include different types of datasets, varying levels of complexity, and possibly real-world use cases.\\n\\nThe experimental evaluation is currently limited to only a few standard but simple dataset. This may not sufficiently test the robustness of the proposed algorithms under different conditions. More experiments with diverse datasets would provide a better understanding of the algorithms' performance and potential limitations. Additionally, it would be beneficial to compare the proposed methods with more baseline or state-of-the-art algorithms for multicalibration to understand the relative performance.\\n\\nAlso, the paper could be improved by providing more detailed descriptions of the proposed algorithms. While the authors do discuss the high-level ideas behind using game dynamics for multicalibration, it may be beneficial for readers to have more specific details about how these algorithms are implemented.\\n\\nAlthough the authors discuss several previous works, it is not entirely clear how their contributions improve upon or differ from these existing methods. Besides theoretical comparison, a clearer empirical comparison would make the authors' contributions more evident.\\n\\nThe paper could benefit from a more explicit discussion of the limitations of the proposed methods. \"},\n",
       " 'review_302': {'summary': 'The authors proposed a method for semantic correspondence using pretrained diffusion model as a feature extractor of the images. Without explicitly training on the additional data/annotations, a simple feature matching based on winner-take-all strategy with cosine distance metric surpasses the previous works on three different tasks; semantic/geometric/temporal correspondence.',\n",
       "  'strengths': '- Exploration on the usage of diffusion model for correspondence tasks\\n- Good performances just with frozen pretrained model & simple matching pipeline',\n",
       "  'weaknesses': \"1. Limited novelty\\n- Merely replacing the backbone network for feature extraction with the latest model in a straightforward manner does not captivate my interest. It also fails to provide new insights to the readers. It would be beneficial to delve deeper into why these pretrained diffusion models outperform previous backbones like DINO, CLIP, or ResNet.\\n\\n2. Limited demonstrations\\n- The paper lacks several essential ablation studies that explore architectural design choices. These studies could include comparing models with and without a decoder, evaluating different options for Q/K/V selection, and assessing the impact of finetuning on correspondence datasets.\\n- Given the relatively low originality, the paper would benefit from showcasing more diverse pixel-level prediction tasks. This could involve demonstrating the model's performance in object detection, image/ video segmentation, as well as other correspondence tasks such as depth estimation and optical flow. These additional demonstrations would significantly strengthen the paper.\"},\n",
       " 'review_303': {'summary': 'This paper introduces DIFT, a method to yield emergent correspondence from image diffusion models without training or additional fine-tuning.\\nThe method is simple - given an image (or an image pair), DIFT adds noise to the image to simulate the forward diffusion process, and pass it to the U-Net of a pretrained diffusion model to extract feature maps.\\nThe authors discover that by simply computing the cosine similarity between the emergent feature maps, one can establish strong semantic, geometric and temporal correspondences without training.',\n",
       "  'strengths': '* The discovery of emergent correspondences from image diffusion is novel. The proposed method is surprisingly simple as well, and this opens new possibilities and research directions for future work.\\n\\n* Strong performances on standard benchmarks of semantic correspondence, geometric correspondence and temporal correspondence.\\n\\n* The writing is clear and easy to follow.',\n",
       "  'weaknesses': '* Missing evaluation of PF-PASCAL for semantic correspondence. This is not a critical drawback, as results on PF-PASCAL tend to be saturated.\\n\\n* Incomplete implementation details. What was the image size / feature map size used to establish the correspondences? Image size is a critical factor in many image correspondence methods.\\n\\n* Lack of latency and computation analysis. This is crucial to identify the applicability of DIFT to real world scenarios.\\n\\n* Lack of rationale or analysis on how exactly the image diffusion models can yield such feature maps easily. While some motivation is provided in the introduction, it seems insufficient for the readers to fully understand how the correspondences are emerging from image diffusion. Analyzing some failure cases could be helpful.'},\n",
       " 'review_304': {'summary': 'The paper addresses a classical computer vision problem, ie, points correspondence. The authors show that the feature maps of the decoder of a diffusion model U-Net enable robust feature matching with a simple nearest neighbor search. Semantic or geometric correspondence can be achieved, by selecting the appropriate denoiser time step. The authors report results, quantitative analysis and comparison on several benchmarks, chosen for each specific task.',\n",
       "  'strengths': 'The authors observe empirically that the features contained in the U-Net decoder are powerful features  for image correspondence. They also show that those features embed different levels of semantic information, depending on the time step of the denoiser. \\n\\nIt is particularly relevant given the fact that diffusion models used by the authors are pretrained (the authors only add noise to the input image), and that the drawn conclusions are consistent over different DMs. \\n\\nThe set of experiments reported in the paper are thorough and results are convincing. The variety of the results, quantitative and qualitative, demonstrate the reliability and flexibility of such features.\\n\\nI particularly enjoyed reading a paper presented with such simplicity and clarity.',\n",
       "  'weaknesses': 'The drawback of the approach is probably the computational complexity that is intrinsic to any point matching approach relying on nearest neighbor search based on high dimensional features. \\n\\nIt is not clear from the paper (nor the supplementary material), if choosing the optimal time denoising time step is critical or not. A corollary of this question would be: do we expect the semantic level contained in the features to degrade smoothly from large time step to small ones?'},\n",
       " 'review_305': {'summary': \"The paper proposes to use off-the-shelf generative networks based on denoising diffusion models to find local correspondences. The paper is extremely simple: instead of generating samples purely from random noise or doing some kind of image-based conditioning, the method just adds random noise to the input image and takes some intermediate level in the denoising U-Net as a dense feature map, from which it can extract sparse features. Feature matching is done via cosine distances. Keypoints may be provided (e.g. for semantic matching) or taken with an off-the-shelf keypoint detector, such as SuperPoint. The authors show that their approach works for high-level semantics (e.g. an eye across different animals or even species) and geometric correspondences, and can also track points across time in video sequences. Parameters such as the stage in the denoising process or which intermediate layers to use are chosen per dataset. There are some tricks (e.g. featuremaps are averaged over batches with different noise inputs), but that's about it.\",\n",
       "  'strengths': \"1. Cool idea.\\n2. Very simple. The actual method section is a single paragraph and doesn't require any math. The paper is well written and easy to understand.\\n3. Very good results on multiple tasks, including semantic matching and tracking in video sequences, without training or fine-tuning.\",\n",
       "  'weaknesses': '1. My main complaint is that I find it hard to believe this approach will work well across arbitrary geometric changes. I have experience in this field and conclusions drawn from HPatches rarely translate to real scenarios. The paper gives very few results, which makes these experiments unreliable and difficult to trust (my guess is that this gap will disappear when the method is properly evaluated). For instance:\\n- What is the image size?\\n- How many points do you use? \\n- Do you use both the illumination and viewpoint splits for HPatches (the supplementary material suggests so)? If so, why not split the results by sequence type?\\n- Why not use the more standard MMA metric from D2-Net (which isn\\'t perfect but is easier to understand), instead of estimating homographies? Why not both?\\n- Why not use modern baselines? The most recent method is from 2019 (R2D2): see e.g. DISK, PoSFeat, ALIKE, or SILK (citations below). (Note: CAPS is weakly supervised and works worse than the DISK variant supervised only with epipolar geometry, as far as I know.)\\n- Could you provide a simple precision/recall curve and compare it against traditional local feature methods? My intuition is that it would be worse.\\n- What happens if you add RANSAC?\\n\\nI generally discount claims on this dataset and steer people towards evaluation benchmarks focusing on downstream tasks, such as visualocalization.net or the image matching challenge (https://image-matching-workshop.github.io/). I understand that this is likely beyond the scope of this paper, and I think it would be acceptable that it just shows these features work reasonably well for rigid matching, but if you want to claim that \"though not trained using any explicit geometry supervision, DIFT outperforms prior state-of-the-art methods that utilize explicit geometric supervision signals designed specifically for this task, such as correspondences obtained from Structure from Motion pipelines\" (L210-213), then you\\'re going to have to substantiate that much better.\\n\\n2. Given that the paper is so simple and the concept itself is very easy to explain, it would be nice to see more introspection. For instance, showing qualitative results using PCA or t-SNE to cluster the features (see for instance the videos from DINO v2) would help understand what\\'s going on.\\n\\n3. Important details are relegated to the supplementary material:\\n- The amount of noise used per dataset. It\\'s surprising that, for instance, for geometric correspondence with Stable Diffusion the best results are with t=0, which means basically no noise (if I understand the formulation correctly; I looked at the code).\\n- The fact that for semantic correspondence per-class prompts are used. I think this is a reasonable assumption, but it should be mentioned. It also suggests the method may not work so well in non-object-centric images.'},\n",
       " 'review_306': {'summary': 'The authors find that intra and cross-category correspondences are implicitly learnt by diffusion models trained self-supervised on large datasets. The paper proposes an approach to extract this knowledge as features from pre-trained Unet-based diffusion models. In particular, to compute the features of a particular image, noise is added to the image to simulate the diffusion process, and then input to the pre-trained diffusion model. The intermediate layer activations from the Unet at a particular timestep are used as features. They showcase the performance of these features on semantic-matching, outperforming other unsupervised baselines and strongly-supervised approaches specifically designed for semantic matching. They also show that without any task specific finetuning, the features can be used for geometric matching and temporal matching ( video-object-segmentation throught label propagation), with competitive performance compared to state-of-the-art. ',\n",
       "  'strengths': '- The proposed idea is simple and effective\\n\\n- The results are convincing. Having a single model applicable to many different correspondence tasks without specific architecture/training and outperform task-specific methods would be a useful contribution. The new perspectives that it opens are exciting. \\n\\n- The paper overall reads well. \\n',\n",
       "  'weaknesses': '1) The authors do not comment on the run-time of the proposed approach. I expect it will be quite slow since the image needs to go through the reverse diffusion process.  \\n\\n2) Related to the above, relying on the diffusion model at inference time makes the method impractical in many applications. To remove the reliance on diffusion models at inference, would it be possible to train a feature predictor, using as ground-truth the features extracted from a pre-trained models? Have you done any experiments in this direction?\\n'},\n",
       " 'review_307': {'summary': 'This paper tackles the problem of interactive visual navigation; i.e., an agent navigating in an enviornment where it is allowed to affect the configuration of the environment (e.g., by moving objects around or picking them up), to improve navigation performance. The key idea is to learn a hierarchical policy that factors in agent intent to propose an action that either results in navigation towards the goal, or interaction with an obstacle. A dataset based on the PROC-THOR simulation environment is also introduced, to facilitate evaluation.',\n",
       "  'strengths': \"[S1] The proposed method is sound; and for the most part, well-defined. The problem formulation is easy to follow, and the description of the method is clear.\\n\\n[S2] Interactive navigation is a challenging and relevant robotics/embodied-AI problem to the Neurips community. While a large fraction of existing approaches focues on non-interactive visual navigation, this paper explicitly considers affecting state changes by manipulating obstacles, resulting in a novel problem setting where there isn't much prior work.\\n\\n[S3] I find the positioning of this paper w.r.t. existing literature fair. The baseline methods considered for evaluation are representative of the various flavors of non-interactive visual navigation approaches that have, over the years, been proposed for PointGoal navigation.\\n\\n[S4] The paper discusses enough implementation details that a reasonable practitioner may be able to replicate the key aspects of the model architecture and the state, action, reward structures.\\n\",\n",
       "  'weaknesses': 'Meta-comment: I have one major concern with the experiment design and evaluation setup; which unfortunately results in the key claims of the paper not being substantiated. I have tried to elaborate the issue, and also the rationale behind it. I also suggest a few mitigation strategies (note: these aren\\'t the only possible ones; other strategies welcome too). While I am unsure whether these may be addressed in the short author response window, if these are adequately addressed, I would have no reservations in bumping my score up.\\n\\n\\n[W1] **[Major] Evaluation metrics and experiment design**:\\n\\nInteractive navigation is very tricky to evaluate. In (non-interactive) navigation scenarios, the path length metrics used in literature are often highly correlated to execution time. Assuming that each atomic action executed by the agent takes nearly the same time to execute, a longer path length would mean that the agent takes longer to reach the goal. However, in the interactive navigation scenario, typical path length metrics like SPL are no longer good indicators of the amount of time it would take to complete the task. This is because, the time spent in picking up or moving objects will also count towards the overall \"time-to-reach-goal-state\"; and picking up or moving objects is heavily dependent on object states, which voids the assumption that each action takes roughly the same amout of time.\\n\\nI understand the rationale behind using typical metrics like SR (success rate), SPL (success-weighted inverse path length), and FDT (final distance to target) -- these metrics allow for easy benchmarking with existing approaches (esp. non-interactive navigation techniques); these are also easily accessible via modern simulators that support PointGoal navigation.\\n\\nThat said, reporting only these above metrics only portrays the benefits of an interactive navigation strategy, while masking away the disadvantages. Execution time is often lost when interacting with objects, which goes unaccounted for. This becomes apparent when you consider the following counterexample: assume that an agent spends more than half its time moving (or picking up) every object encountered in its way; but ends up taking the shortest possible (i.e., optimal) path to goal. It will then end up with a success rate and SPL of 1 and an FDT value of 0. However, in reality, an agent that takes a twice as long path to the goal (but does not interact with any object) will end up reaching the goal at about the same time, and will have the same SPL, SR, and FDT values (recall that, in this hypothetical scenario, the interactive agent spends half its time interacting with obstacles in its path). This calls for a different approach to evaluate interactive navigation approaches; ideally the SPL metric should also account for time lost due to interaction. Measuring this time could be challenging (or impossible) to do in the first place, so here are a few potential mitigation strategies to consider.\\n\\n* While episode lengths are fixed, to ensure the agent does not take an indefinite amount of time, to compare fairly against non-interactive agents, each episode length must be capped to the number of timesteps in which a non-interactive agent completes the task. This will ensure that a fair comparison is possible, when a reasonably accurate time estimate is available for each interaction.\\n* An alternative would be to consider evaluating solely in scenarios where it is impossible to reach the goal without interacting with objects. (more nuance on this follows in [W2] below).\\n\\n[W2] **Eval on data subsets**: I would have liked to seen more granularity in terms of the quantitative results presented in Table 3. It would, for instance, be useful to split the dataset into a variety of categories, depending on whether or not interaction is required to solve an episode, and the level of difficulty of the episode. This becomes more important, because the dataset is claimed as a contribution. Table 2 goes a bit along this direction, indicating the number of obstacles per room; however, it is not clear how many of these episodes absolutely require interactive navigation (i.e., cannot be solved by a non-interactive optimal agent). (The dataset construction seems to ensure a 50% likelihood that a path is unavailable -- I would argue in favor of forming two splits of the dataset, one where no non-interactive agent trajectory exists; and one where an optimal non-interactive agent will need to take a longer path).\\n\\n\\n[W3] **[Minor]** The paper, in its current form, falls short in terms of technical rigor when discussing aspects of causal inference. E.g., lines 134-135 \"However, without considering the causalities from obstacles, it’s hard to generalize to unseen environments or large-scale datasets.\"; line 38 \"... , learning causality through RL training is challenging due to the existence of unobserved...\"; line 137 \"The above confounding bias can be tackled...\". Neither the \"causalities stemming from obstacles\" nor the \"confounding bias\" have been clearly been defined in the paper. It is also important to clearly define the type of causal relationships that are being learned by design (perhaps section 4.2 is a good place to do so).\\nRevising these aspects of the paper will make the descriptions of the approach more accurate.'},\n",
       " 'review_308': {'summary': 'This paper introduces a causally-inspired hierarchical policy framework for the interactive navigation task in the AI2THOR environment. The framework consists of a master policy, intent policy, and three sub-control policies. The intent policy embeds intuitive intents from the sub-control policies into the master policy, enabling it to make counterfactual decisions. The proposed approach, named CaMP, is evaluated on a newly collected dataset in the ProcTHOR multi-room scenes. The experimental results show that CaMP outperforms the baselines, achieving the best performance on the interactive task.',\n",
       "  'strengths': '+) The interactive navigation (IN) task is an interesting and challenging task in the field of embodied AI. This paper contributes to the progress in this area by introducing a causally-inspired hierarchical reinforcement learning (HRL) policy. The use of a newer and larger dataset with complex scene layouts and diverse objects enhances the realism of the task. The results demonstrate the effectiveness of the proposed HRL policy, highlighting the advancements in tackling the challenges of interactive navigation.\\n\\n+) The decomposition of the embodied policy into a master policy and sub-control policies is a reasonable and effective approach for the IN task. This work demonstrates the potential of HRL in tasks where interactions with the environment are crucial for achieving goals.\\n\\n+) The explanation of confounding bias and the causal diagram provided in Fig. 2(a) help clarify the concept and its relevance to the IN task. However, the discussion of heavy obstacles as an example may need further refinement.\\n\\n+) The experimental results presented in the paper provide strong evidence for the effectiveness of CaMP. It outperforms several baselines, including PPO, NIE, and HRL, on the IN task using the newly collected large-scale dataset in ProcTHOR multi-room scenes.',\n",
       "  'weaknesses': \"-) The connection between confounding bias resulting from unmeasurable obstacles and the counterfactual policy design is not adequately explained. It remains unclear how the counterfactual policy, through the intent policy, effectively addresses the bias caused by obstacles. The paper lacks a convincing explanation for the direct line from $O$ to $A$ in Fig. 2(b). It is not clear how the weighted-sum of action logits from the sub-control policies can fully capture the policies' intents and uncover the causality depicted in Fig. 2(a) ($O$ -> $A$ and $O$ -> $R$).\\n\\n-) The model design lacks intuition. Instead of introducing an additional Intent Policy to generate intents, a more straightforward approach would be to recursively use the Master Policy to obtain intents $P^j(i_t)$ and provide feedback to the Master Policy. This recursive feedback mechanism could be extended to multiple levels, denoted by $j$ ∈ $J$, with $P^0(i_t)$ representing a void intent. Additionally, rather than using the action logits from the sub-control policies to represent intents, exploring the utilization of hidden features returned from the GRU in each sub-policy would offer a more intuitive approach.\\n\\n-) Several implementation details are missing, such as determining which object to interact with when using Push/Pick actions, the force applied during the Push action, and whether the force is correlated to the object's mass. Further clarification on these aspects would greatly enhance the understanding of the proposed approach. More questions regarding missing details can be found in the Question.\"},\n",
       " 'review_309': {'summary': 'Broadly, the paper tackles the Interactive Navigation task: navigating to a goal and interacting with obstacles as necessary, e.g. pushing a chair out of the way. \\n\\nThey use the ProcTHOR simulator with 12k multi-room scenes and generate navigation episodes that are suitably cluttered with obstacles. Their embodiment is abstract, with a discrete high-level action space (e.g. PushLeft, PickUp, Drop, RotateLeft).\\n\\nTheir approach is a hierarchical model, with three pre-trained low-level \"action policies\" (skills): navigate, push, and pick. A master policy sequences the three. Specifically, the navigation policy is run by default; the master policy can interrupt it by invoking an interaction policy (push or pick); the interaction policy then runs exclusively until it self-terminates, returning control to the master policy.\\n\\nTheir main contribution is the addition of an intent policy; they claim this helps the master policy make better decisions in the presence of obstacles. I\\'ll describe this more below.\\n\\nThey evaluate their approach against several baselines:\\n* random actions\\n* a monolithic (non-hierarchical) sensors-to-actions policy trained with end-to-end RL, labeled as PPO\\n* a prior approach labeled as NIE that aims to predict state change of observed objects\\n* a hierarchical policy that uses the same nav/push/pick action subspaces as CaMP but differs in how they are combined\\n* a monolithic sensors-to-actions policy with the addition of CaMP\\'s intent policy\\n\\nThey also study ablations related to the intent policy.\\n\\nI\\'ll now describe the intent policy in detail, with the caveat that I\\'m looking for further clarification from the authors here (see Questions section).\\n\\nThe architecture of the intent and master policy are mostly identical; their inputs include goal embedding and extracted visual features and they feature recurrent units.\\n\\nAt timestep t, the intent policy outputs w\\'.t, a distribution over the three action policies, essentially choosing between push/pick/navigate. Meanwhile, each action policy j ouputs a\\'.t^j, a distribution over discrete actions. Finally, the intent is the sum of all a\\'.t weighted by w\\'.t. For example, if the intent policy on a given step is biased towards push and the push action policy is biased towards the PushLeft action, the overall intent will be biased towards PushLeft.\\n\\nThis intent is fed to the master policy alongside observations (together, \"intent-specific state\"), which chooses an action policy (either allowing the nav policy to continue, or interrupting by invoking push or pick).\\n\\nThe intent policy and master policy generally share parameters and generally behave similarly, except the intent policy is synced from the master policy only periodically during training, such that in practice the intent will differ from the taken action some of the time.\\n\\nThey describe this intent-informed policy as \"exploring counterfactuals\", and a component here is learning a value function for the above-mentioned intent-specific state.',\n",
       "  'strengths': 'The InterNav task is a challenging, relevant task for Embodied AI.\\n\\nThe task, scene/episode dataset, and model architecture are clearly communicated in figures and text, with minor exceptions noted below.\\n\\nThe scenes and episodes appear diverse and high-quality.\\n\\nBaselines and ablation study are rigorous.\\n\\nThe authors show strong performance against their baselines.',\n",
       "  'weaknesses': \"There's ambiguity on some paper details. I'll list bullets here; see my questions for more details:\\n\\n= action space and positioning of objects\\n\\n= object dynamics in ProcTHOR\\n\\n= details of invoking and terminating interaction subtasks\\n\\n= learning for the intent policy parameters\\n\\nThe paper doesn't discuss sim-to-real transfer or otherwise discuss how CaMP might be applied in a real-world setting. \\n\\nThe biggest weakness is that the intuition and conceptual value of the intent component aren't clearly articulated. For details, see my questions below.\"},\n",
       " 'review_310': {'summary': 'This paper introduces the multi-room interactive navigation problem and proposes a novel model that is motivated by counterfactual reasoning. In particular, the paper posits that obstacle objects serve as a confounding factor when understanding the relationship between actions taken and the outcomes observed / reward received. To address this, a counterfactual reasoning based model is proposed, which explicitly encourages exploring actions outside the distribution predicted by the policy (i.e., what would happen if I did action X instead of Y?). The proposed model is hierarchical in nature, with low-level policies for navigation, picking, and pushing skills, and higher-level policies for selecting a skill to execute. The higher-level policy is conditioned on an intent, specifying where the policy is likely navigating to next. This is expected to allow the policy to account for the intent and explore actions that go against the intent.  Results on the ProcThor simulated dataset demonstrate the superiority of the proposed policy over alternative baselines.',\n",
       "  'strengths': '* The idea of performing counterfactual reasoning is interesting and novel in the context of embodied AI.\\n* The problem setting proposed is a good extension to prior work on single-room interactive navigation and is valuable for the community to work on.\\n* The paper clarity is good, but it makes assumption about how knowledgable the reader is with causal inference (see weaknesses). \\n* The experiments are well designed and ablation studies convey useful information to understand the overall model. The proposed model also performs much better than reasonable baselines.',\n",
       "  'weaknesses': '# Post-rebuttal comments\\n* The authors have sufficiently addressed my concerns and provided new experiments to quantify the improvement in interaction-ability. I\\'m happy to raise my rating to accept.\\n\\n--------------------------------------------------------------------------------------------------\\n# Paper writing clarity\\n* The paper writing clarity can be improved quite a bit with regards to causal inference. Since this is a relatively new topic to the embodied AI space, most readers may be unfamiliar with the topic and jargon like \"counterfactual reasoning\", \"confounding factors\", \"structural causal model\", \"structural functions\", etc. also, L129 was not obvious from my first reading (i.e., the difference between do(A) and A). \\n* More clarity can be provided about what the counterfactual situations here are (e.g., more examples like L131-133). \\n* In Figure 3, is the entire model differentiable? For example, are gradients from the loss propagated through to intent predictions w_t^{\\'} and a_t^{\\'}?\\n* In the experiments, an explicit connection should be made to how the proposed model is using counterfactual reasoning and how it addresses the issue of confounding factors. \\n\\n# State vs. obstacles as confounding factors \\nThe idea of treating obstacles as confounding variables makes sense. But at a high level, isn\\'t the state variable itself a confounding factor? What is the value is isolating only obstacles here?\\n\\n# Experiment section can be improved\\n* Error bars are missing in Tables 3 and 4. It will be useful to have results from training and evaluating on multiple seeds, especially for the top-3 methods (NIE, PPO+intent, CaMP). Similar issue for Table 4.\\n* In Table 4, why is \"sync. /3*rollout\" worse than \"integrated intent\"? Aren\\'t they both the same models?\\n* In Table 4, why is \"sync. /epoch\" worse than \"wo/intent\"? If CaMP is synchronized frequently, I would expect the intent to be selected as the action itself, leaving little to no room for counterfactual exploration. So \"sync. /epoch\" should match \"wo/intent\", right?\\n* There is no analysis on how well each models interact with the \"relevant\" obstacles, i.e., obstacles that lie along the shortest path and can be moved. This can be measured via precision and recall metrics. \\n    * Precision = fraction of interacted objects that are \"relevant\" obstacles\\n    * Recall = fraction of \"relevant\" obstacles interacted with'},\n",
       " 'review_311': {'summary': 'This paper tries to solve the knowledge-based visual question answering (VQA) by proposing a new approach that utilizes LLMs for calling visual modules in a task-oriented manner. The method employs a reasoning-hypothesis-verification process in multiple rounds to progressively find the answer. Evaluations are conducted on OK-VQA and A-OKVQA to demonstrate the effectiveness of this method.',\n",
       "  'strengths': '1. Multi-round interactions and reasoning-hypothesis prompting are introduced in this paper. Compared with previous one-time program generation, those two improvements are reasonable intuitively and can benefit on reported benchmarks.',\n",
       "  'weaknesses': \"1. In the title, abstract and introduction, `task-oriented` seems to be emphasized as the main advantage of this paper over others. However, ViperGPT and Visual Programming are also task-oriented. The main difference between this paper and the previous two are rationale and multi-rounds. The corresponding part should be rewritten.\\n2. I don't understand the necessity of the hypothesis. From the given examples, it seems without an assumed hypothesis, the LLM should still be able to call the right verification function. In Fig3's examples, imagine you remove the hypothesis, the workflow of LLM seems still smooth and reasonable, and many hypotheses are actually None. In Tab3's ablation, both reasoning and hypothesis are removed which is not indicative enough. Can you do an ablation to remove the hypothesis while preserving reasoning and verification and answer?\\n3. Why don't you compare with ViperGPT in OK-VQA? Is that because ViperGPT is in a zero-shot manner, while yours is in a few-shot manner? Then why your method must be reported in a few-shot manner and what performance it can achieve in the same manner as ViperGPT?\\n4. Only two benchmarks are compared. In ViperGPT/Visual Programming, 4/3 datasets are benchmarked. To demonstrate the generalization ability of the proposed method, at least one or two more typical datasets are needed.\\n5. Similar ideas of multi-rounds and reasoning in each step have been used in [1]. Please compare the difference.\\n6. Many visual models are employed in this paper however the technical details as well as related prompts are not included in the paper. It makes reproduction difficult.\\n\\nRef:\\n[1] See, Think, Confirm: Interactive Prompting Between Vision and Language Models for Knowledge-based Visual Reasoning\"},\n",
       " 'review_312': {'summary': 'Early methods for Knowledge-based visual question answering (VQA) explicitly retrieve knowledge from external knowledge bases, often introducing noisy information. Current large language models like GPT-3 as implicit knowledge sources cannot effectively understand image inputs. Thus, extracting the image information and inputting it into large language models remains an open problem. Using image captioning and object descriptions to represent the image may either drop the essential visual information to answer the question correctly or involve irrelevant objects to the task of interest. To address this problem, the authors propose to let large language models make an initial hypothesis according to their knowledge, then actively collect the visual evidence required to verify the hypothesis. In this way, the model can attend to the essential visual information in a task-oriented manner. The authors leverage several vision modules from the perspectives of spatial attention (i.e., Where to look) and attribute attention (i.e.,16 What to look), which is like human cognition. ',\n",
       "  'strengths': '- The idea to exploit ChatGPT to solve knowledge-based VQA interactively seems novel.\\n- Compared to the recent similar method, Visual Programming, the proposed method shows favorable performance, and the authors provided an ablation study and hyper-parameter analysis to verify the characteristics of each component of the proposed method.',\n",
       "  'weaknesses': '- It would be more helpful to add an experiment to verify whether the proposed method can be generally applied to other tasks. For example, can the proposed ChatGPT-based interactive framework also help improve the performance of other datasets, such as the VQAv2 dataset?'},\n",
       " 'review_313': {'summary': 'This paper addresses knowledge-based visual question answering by leveraging a large language model (LLM) as a knowledge source. To mitigate the limited capability of vision models, the paper suggests letting the LLM predict hypothesis and actively gather visual evidence. Experimental results show that the proposed method outperforms baseline approaches in open-ended knowledge-based VQA.',\n",
       "  'strengths': '- The paper is well-written, clearly structured, and easy to follow.\\n- The motivation behind using an LLM for VQA to assist imperfect vision models is reasonable, and qualitative results demonstrate that the method behaves as intended.\\n- Ablation studies reveal that the multi-round dialogue strategy and hypothesis-verification process positively contribute to the approach.\\n- The experiments are thorough, offering insights into the impact of design choices.',\n",
       "  'weaknesses': \"- The method's reliance on heuristic prompting may limit its generalizability to other LLMs. \\n- The validity of post-processing, which paraphrases predictions using a predefined vocabulary, is unclear. A small analysis of the post-processing would make the paper more convincing. For instance, providing examples of raw predictions and post-processed ones would help readers better understand the post-processing.\"},\n",
       " 'review_314': {'summary': 'This paper proposes task-oriented active VQA (TOA), which uses LLM as an implicit knowledge source and answers the question through a sequential hypothesis-verification process. This method can more accurately attend to the essential information in the images and reduce the introduction of irrelevant information. And they develop a multi-round dialogue approach to solve the problem progressively and decide the next step dynamically, which has a clear answering process and better tolerance of mistakes in previous steps. The experiments show the method outperforms the baselines and presents clear reasoning procedures.',\n",
       "  'strengths': '1. The idea of this paper is very novel, and the key visual content is obtained through multiple rounds of dialogue.\\n\\n2. The method takes full advantage of the rich knowledge and application flexibility of LLM.\\n\\n3. The process design of reasoning-hypothesis-verification can reflect clear reasoning procedures and has better interpretability.\\n\\n4. Experiments show that the performance of the method is very good, and verify the validity of the design idea.\\n',\n",
       "  'weaknesses': '1. Most of the sub-modules are somehow similar to existing models, and the design of the reasoning-verification process may be ad hoc and has great limitations.\\n\\n2. In the  experiment, other methods use GPT-3 and this method uses ChatGPT, which is a bit unfair.\\n'},\n",
       " 'review_315': {'summary': 'This study addresses the problem of best arm identification (BAI) in the context of dependent arms. Unlike conventional settings, efficiency can be enhanced by exploiting the inherent correlation structure. This setting holds broad applications, including in clinical trials. Specifically, the authors concentrate on bandit scenarios with bounded and Gaussian rewards. The validity of their approach is substantiated through simulation studies.',\n",
       "  'strengths': 'The authors introduce a novel setting for Best Arm Identification (BAI) with fixed confidence. By accommodating correlation, we can devise more efficient strategies for identifying the optimal arm. This setting is intriguing and holds significant practical utility.',\n",
       "  'weaknesses': \"I believe several claims are not sufficiently substantiated. I have detailed these claims in the subsequent 'Questions' section. If the authors fail to adequately address my queries, these unsupported claims would constitute a weakness in the study.\\n\"},\n",
       " 'review_316': {'summary': 'This paper focuses on the question of identifying $\\\\epsilon$-optimal arms given a confidence input $\\\\delta$, or in other words, under the PAC model. Instead of pulling only one arm and observing the rewards, the authors leverage the underlying structure of arm distributions by allowing multiple queries per round (Protocol 1). Compared to related works, this paper looses the assumption of independent arms distributions, Protocol 1 can estimate the means and covariances of arms and accelerate the best arm identification by utilizing the extra information. They propose two algorithms, one for scenario where the arms are bounded, and one for arms follow a Gaussian distribution. The lower bounds for both algorithms are also provided. ',\n",
       "  'strengths': 'The idea of exploring the underlying structure of arms by allowing simultaneous queries is attractive. It not only solves the assumption of independent arms distributions, which is not realistic in various scenarios; but also accelerates best arm identification by leveraging the shared information between arms. Based on multiple queries protocol, the authors provide two main theorems for bounded variables and Gaussian distributions along with the corresponded lower bounds. They also manage to notice some failure mode of the algorithm, like shown in line 183, and give some solution. In addition, the paper is well-structured and easy to follow. ',\n",
       "  'weaknesses': 'The authors emphasize their results are adaptive to unknown covariance, but based on the algorithms and simulations, it can only solve the type of same covariance between all arms (correct me if I were wrong), which reduces the practical use of this paper. In addition, as stated in the related work part, the topic of best arm identification under PAC-Learning framework is well-studied, so as the stochastic combinatorial semi-bandit problem. The motivation and main contributions of this papers are a little bit unclear. As for the simulation part, It would be helpful to provide some explanation for the three chosen benchmark algorithms to add on reliability. I was expecting to see the comparison of proposed algorithm and old algorithms who assume independent arms on scenarios where the assumption fails.  '},\n",
       " 'review_317': {'summary': 'This paper considers the problem of best arm identification with covariance in the fixed confidence setting, where arms can be dependent and rewards can be sampled simultaneously. The authors design algorithms that adapt to the unknown covariance of arms and prove that substantial improvement can be achieved over the standard setting. The authors also provide lower bounds and experimental results that support their theoretical findings.',\n",
       "  'strengths': '1.\\tThe considered problem is interesting and well-motivated.\\n2.\\tThe theoretical analysis looks sound. Both upper and lower bounds are provided.\\n',\n",
       "  'weaknesses': '1.\\tWhat is the additional novelty and contribution of Theorem 5.1 compared to Theorem 4.1. It seems that there is no significant difference between the algorithm design and analysis for the bounded reward setting and that for the Gaussian reward setting. Why not unify them, e.g.,  present this work in the unified sub-Gaussian setting? Please correct me if my understanding is wrong.\\n2.\\tCould you compare Theorems 4.1 and 5.1with the results of existing covariance-adaptive bandit works?\\n'},\n",
       " 'review_318': {'summary': 'Authors investigate the stochastic Best Arm Identification (BAI) problem when the arms have an unknown correlation structure.\\nIn contrast, the majority of BAI literature focuses on independent arms with unknown variances.\\nAuthors propose algorithms for BAI in two settings (bounded random variables and gaussian random variables) and analyze the sample complexity of these algorithms.\\nIn order to leverage the correlation structure, multiple arms are allowed to be sampled at each round.\\nThey show that improved sample complexity can be achieved by estimating the correlation structure; moreover, the sample complexity is within a constant factor of the sample complexity for independent arms (even when independence is unknown in advance).\\nSimulations are run to demonstrate the method on a synthetic dataset.',\n",
       "  'strengths': 'The main strength of the paper is an investigation into the stochastic BAI problem where independence between the arms is not assumed.\\nAuthors develop algorithms where the covariance structure is estimated and used to help quickly eliminate suboptimal arms.\\nOf course, multiple arms must be sampled simultaneously in order to estimate the covariance between them.\\nOn one hand, the analysis (and simulations) show that nice speed-ups in sample complexity can be obtained when the covariance structure is taken into account.\\nOn the other hand, the analysis seems to indicate that the asymptotic rate of the sample complexity does not increase even when the arms are independent (but this dependence is unknown).\\nThis has exciting implications for a variety of real-world settings where arms may be expected to be correlated.',\n",
       "  'weaknesses': 'There are two main weaknesses of the paper.\\n\\nThe first main weakness is that the paper seems to not discuss (and sometimes ignore?) what I would consider to be a very important consideration: the \"overhead cost\" of estimating the covariance.\\nIt seems intuitive that a method which places no assumptions on the covariances -- and therefore must estimate them -- must incur some overhead cost when compared to a setting where there are structured assumptions on the covariance (e.g. the independent setting).\\nThis overhead cost may not be very large, but I am pretty certain that it should exist.\\nA couple of times throughout the paper (Lines 103, 247) authors claim that the sample complexity bounds they obtain are smaller than the independent case; however, it seems that they are smaller than a constant factor (say, 2) of the sample complexity of the independent case.\\nIn terms of the asymptotic rate of the sample complexity, this doesn\\'t matter; however, in terms of finite sample, practical performance, this does seem to matter and it points out exactly this \"overhead cost\".\\nOverall, I think that the paper would be stronger if authors more appropriately discussed their results in this context, i.e. the existence of the overhead cost of estimating covariance relative to assuming it, but with large gains when dependencies help.\\n\\nThe second weakness of the paper is that the exact nature of the guarantees on the sample complexity are not so clear.\\nFrom what I understand, these algorithms need to contain the best arm with probability $1 - \\\\delta$ for some total number of arm queries $N$ and this stopping time is a random variable.\\nThe goal of the algorithm designer is that, under appropriate conditions, $N$ is small in some sense, as a random variable.\\nSo what does it mean then in Theorems 4.1 and 5.1 that authors write $N \\\\leq XYZ$? Does this happen with probability 1 (that seems unlikely)?\\nDoes this mean that $N$ is order $XYZ$ in probability? \\nOr is $N$ not a random variable?\\nPerhaps there is some convention in the BAI literature so that this is very clear; but to someone in adjcent fields, this could use clarification.\\nI\\'m hopeful that this can be clarified and the fix is relatively easy.\\n\\nFurther comments on clarity and discussion of results are given below.\\n\\n### Minor Comments\\n\\n1. (Line 58): What is the $\\\\pi$ subscript in $N$ represent and why does it never appear again in the paper? Moreover, the last sentence in this paragraph seems to be a sentence fragment that is missing a part.\\n2. (Line 64): Could you describe more precisely what \"comparing the means\" is referring to here? What is the precise statistical problem i.e. estimation, hypothesis testing etc ?\\n3. (Line 71): A motivating example of clinical trials is discussed, \"whre the effects of drugs on patients with similar traits or comparing drugs with similar components may exhibit underlying correlations\". However, the correlation between counterfactual outcomes (arms) can\\'t be simultaneosuly observed in a causal inference setting -- only one outcome may be observed for each patient, often known as the \"fundamental problem of causal inference\". I recommend rephrasing this motivation so that arms cannot be interpreted to be counterfactual (and thus not simulatenously observable) outcomes, or selecting a different motivating example.\\n4. (line 103): authors write that \"quantity (3) is always smaller (up to a numerical constant) than its independent case counterpart\". I think this is phrased in an unfortunately misleading way. I presume that the authors mean \"quantity (3) is no larger than a constant times the independent case counterpart\". Unfortunately, writing the phrase \"always smaller\" gives the wrong impression that quantity (3) is at most quantity (2), which does not seem to be true. Great care should be given to statements like this, so they are not misrepresenting what authors have shown.\\n5. (Line 140, 157) citations appear in parathensis when other citations appear in brackets. A consistent stlye should be used throughout the paper.\\n6. (Line 142) \"The objective is to maximize the cumulative regret...\" is this a typo, i.e. \"maximize\" should be \"minimize\"?\\n7. (Line 172): The estimated quantities $V_{i,j,t}$ and $\\\\mu_{i,t}$ should be defined (markdown doesn\\'t like the hat notation, sorry for dropping it). In particular, these quantities are perhaps ill-defined without reference to the algorithm: how should we interpret the sample covariance up to iteration $t$ if arm $i$ was sampled at some round $s \\\\leq t$ but $j$ was not?\\n8. (Line 7 of Algorithm 2): \"Jointly query all the experts in $C$\". The terminology \"experts\" is not defined, so I\\'d recommend not using it here.\\n9. (Line 247): Authors write \"the sample complexity is on the order $X$ which is larger than both our bounds (5) and (6)\". If I understand correctly, it seems that the correct statement is that \"(5) and (6) are less than 2 $X$\". It seems very important for authors to correctly characterize their contributions so readers do not misinterpret them.\\n10. (Line 275): the reference (20) is perhaps misplaced.\\n11. (Line 305): \"$\\\\delta$-sound algorithm\" is used but not defined. From context clues, I think I understand, but authors should clarify it for the readers.\\n12. (Line 309): Authors claim that \"Algorithm 2 is nearly optimal\" but this is up to a $\\\\log(K)$ and $\\\\log(\\\\Lambda)$ factors. I understand $K$, but I think that $\\\\log(\\\\Lambda)$ deserves some discussion. How large should we expect this to be?\\n13. (Line 319): \"Theorem 6.2 demonstrates that our algorithm achieves near-optimal performance...up to a logarithmic factor\". Same as above.\\n14. (Line 329): Authors write that \"We stress that both variants guarantee a $\\\\delta$-sound decision on the optimal arm\" but it seems that reducing $82 t$ to $2 t$ actually doesn\\'t necessarily satisfy $\\\\delta$-sound? If I am correct in this understanding, then the claim should be modified appropriately.\\n15. (Line 356): Authors write that there is \"an algorithm that compares candidate arms with convex combinations of the remaining arms\" but this is not discussed in the main body nor in the simulations. This seems it requires more discussion to better contextualize it within the current work or be removed all together.\\n16. (Line 347): Authors write \"In both experiments, we observe that Pairwise-BAI+ performs worse compared to Pairwise-BAI, indicating that, empirically, in the given scenarios, continuing to sample sub-optimal arms does not contribute to improved performance\". There is either a typo here or I am a bit confused. I thought that Pairwise-BAI+ was where the number of extra rounds was reduced, so if it performs worse wouldn\\'t that indicate that we need those extra rounds? I think there is a typo, but I want to bring this to the attention of the authors to confirm or deny.'},\n",
       " 'review_319': {'summary': 'This work focuses on best arm identification, that is, determining the arm with highest average return within a small number of samples (sample complexity). The twist is that authors propose a framework where sets of arms (of arbitrary size) can be queried at the same time, and the set of corresponding rewards is observed. This setting goes beyond classical frameworks, as observations in a set of simultaneously queried arms are dependent. Moreover, the arm pairwise covariances are unknown to the bandit algorithm. Authors propose an algorithm tackling this problem, which nearly matches associated lower bounds, and empirically evaluate it.',\n",
       "  'strengths': '- Originality: Authors introduce a novel best arm identification setting which might have interesting real-life applications. Differences with prior works are thoroughly discussed and the discussion covers a large set of related settings. \\n- Quality: The results in this paper seem technically sound, although I did not check the proofs in detail. The experimental study is convincing and supports theoretical claims. The code is available, which helps reproducibility and potential future follow-up.\\n- Significance: The setting tackled in this paper introduces new technical challenges (in particular to derive lower bounds), and the technical tools used in proofs can be of independent interest.',\n",
       "  'weaknesses': '- Clarity: I appreciated the many examples provided in order to illustrate intuitions behind the papers, although I believe the section from Line 59 to Line 123 is a bit messy and hard to follow. Adding more structure to this section and clearly highlighting the different points covered in that paragraph would really help.\\n- Significance: The number of rounds after which an arm can be safely eliminated from the set of “queriable” arms seems really large and not very practical. However, this weakness has been identified in this paper and properly discussed (notably by providing a version of the upper bound when elimination happens when an arm is not more considered a candidate).'},\n",
       " 'review_320': {'summary': 'This paper focused on the combination of predictive control and model learning. An autogressive dynamic model based on a ReLU neural network is first learned over the observation space. The authors then aimed to sparsify it after introducing the indicator mapping function. To make the optimization feasible, the Gumbel-Softmax trick is applied to replace the greedy operation. Once the sparse dynamic is learned, mixed-integer programming solvers are used to obtain the control policy. Finally, the authors validated the proposed method across a few tasks and showed its promising performance.',\n",
       "  'strengths': '1. The proposed framework of sparse neural dynamics in predictive control looks interesting. The use of Gumbel-Softmax to reparameterizing the original discrte optimization makes the gradient based methods feasible, and is indeed a reasonable idea. \\n\\n2. The optimization for the control part is more efficient, compared with the gradient based methods, which constitutes another contribution of this paper. \\n',\n",
       "  'weaknesses': 'Regarding the experimental comparison, it would be more convincing if the authors can test on commonly used reinforcement learning benchmarks. The only comparison regarding control policy is from Figure 3 (b) and it only involves different optimization solvers. The current results would leave the impression that the proposed method may overfit on these tasks only.'},\n",
       " 'review_321': {'summary': 'This paper proposes a framework for model-based planning with forward dynamics represented as sparse neural networks. The paper examines different ways of inducing sparsity in MLP and GNN based forward models, and performs real robot manipulation experiments investigating the tradeoffs with sparsity and performance. ',\n",
       "  'strengths': '- the paper targets an interesting problem of learning efficient world models for control, by reducing optimization costs in learning the forward model. The specific approach of investigating how sparsity can enable this efficient learning of the forward model for real robot manipulation scenarios, is novel in my understanding.\\n\\n- the paper is easy to follow, with detailed descriptions of the different ways of inducing sparsity, and the different architectures. The research questions investigated are well formulated, and adequately addressed in the experiments\\n\\n- the experiments are on interesting real robot manipulation tasks like object sorting, and rope manipulation, so the findings are amenable to be deployed in real world control scenarios. ',\n",
       "  'weaknesses': \"- the main weakness of the paper is that there aren't comparisons to prior model-based RL approaches, e.g. PETS, Dreamer, MBPO etc (https://arxiv.org/abs/1805.12114,https://arxiv.org/abs/1912.01603, https://arxiv.org/abs/1906.08253)  . If it is difficult to compare them on hardware experiments,  there should be comparisons done on simulated robot control tasks. \\n\\n- it is unclear how general are the findings in terms of being applied to different model-based control frameworks. There should be a disucssion (and possibly experiments) about if we can take any prior model-based RL algorithm and replace the forward model with a sparse neural network, and see benefits under certain assumptions - if not, then a discussion of what exactly are the requirements on how the model should be learning and how a policy (or plan) should be learned is needed.\\n\\n- the experiments results in my understanding are on low-dimensional states instead of images. Is there a reason for not evaluating with image observations? Encoding image observations into latent states, and then doing policy learning is a common practice in the community now - so it will be helpful to have a discussion regarding this.\"},\n",
       " 'review_322': {'summary': 'This paper proposes a new framework for model-based control. The approach focuses on learning a sparse deep neural network and using a mixed-integer program solver for closed-loop planning. Experimental results are presented on several tasks including object and rope manipulation tasks. The results show that the proposed approach improves performance over strong baselines.',\n",
       "  'strengths': '- The framework proposed in this paper elegantly combines concepts from deep neural network (DNN) pruning and mixed integer programming (MIP) into a solution for model-based control.\\n- The specific technique for sparsifying a DNN by removing non-linearities rather than simply dropping nodes intuitively matches the goals of eventually using the model with a MIP solver.\\n- The experiments demonstrate that the approach is effective in both simulation and in the real-world on real hardware -- providing strong evidence that this is a generally applicable approach.\\n- The technique is demonstrated with both MLP and GNN based models, showing the versatility of the proposed approach.\\n- The supplemental video presents strong qualitative evidence supporting the efficacy of the approach on real-robots.\\n- The paper is very well written.',\n",
       "  'weaknesses': '- It is unclear if the performance gains in Figure 5 are significant. On the Object Pushing and Rope Manipulation tasks MIP does not appear to outperform MPPI. And the improvements of MIP on the Object Sorting tasks appear to be within the error bars.\\n- A key ablation is missing. One of the main claims in this work is that the proposed sparsification technique, which focuses on removing nonlinearities rather than neurons, improves performance. Only a partial ablation in support of this claim is provided in the appendix A2. Specifically, A2 shows that the proposed approach leads to lower prediction error. However, to quote L277-279 in the main paper, “what we really care about is the performance when executing optimized plans in the original simulator or the real world. Therefore, it is crucial to evaluate the effectiveness of these models within a closed-loop control framework.” I agree. Thus, it is similarly crucial to perform this ablation in a closed-loop setting.'},\n",
       " 'review_323': {'summary': 'This paper proposes a method for pruning neural networks with ReLu activation functions during training. When employed for learning the dynamics of a control system, this often leads to networks with few activation functions performing similarly as large networks. This allows to apply mixed integer programming techniques to determine optimal control policies. The effectiveness of this approach is demonstrated in a comparison with a sampling based optimizer on several tasks for a robotic manipulator.',\n",
       "  'strengths': 'The idea of formulating planning problems with neural network dynamics as mixed integer program seems novel to me. Moreover, I find the proposed approach of reducing the number of neurons during training very interesting, but I cannot comment on its novelty since I am no expert on this topic. Overall, the paper reads very well and has a good structure. The nice demonstration of the proposed method in a real-world robotic experiment is also a strength of the paper.',\n",
       "  'weaknesses': 'My biggest concern is the missing discussion of computational complexity/computation time. I am not an expert on mixed integer programming, but a quick search suggests that even mixed integer linear programming is already NP hard, so this seems to be a problem in general. I understand that this problem can be mitigated through a sufficiently small number of neurons (‘If only a few ReLUs are left in the model, Equation 10 can be efficiently solved to global optimality’), but I am missing a clear specification what sufficient means in this context. Moreover, I would expect it to be connected to the prediction horizon, i.e., the number of time steps considered in the sum in (10). Therefore, I think a complexity (e.g., in O notation) should be provided to give the reader an impression how severe the computation times grows. This weakness also limits the usefulness of the evaluation in my opinion. Why would you reduce the number of neurons for MPPI in practice? I think the performance in relation to computation time is rather the important metric to look at for this comparison, i.e., a complexity-performance trade-off comparison would be essential. Therefore, the comparison seems a little unfair at the moment. This similarly extends to the robot experiment in Sec. 4.3, where the sampling and the horizon rate of the MPC are not specified. Moreover, it is not clear how fast the robot moves. These are all parameters which crucially influence how challenging the problem is.\\n\\nIn general, the method seems tailored to piece-wise affine systems or systems that look almost like that. The examples seem to go into this direction, but I cannot say for sure since I could not find information what dynamics are actually learned in the robotic examples. I think it would be interesting to see how many activation functions are needed for accurately learning highly nonlinear dynamics, e.g., cart-pole swing-up, and how this affects the control performance. \\n\\nOverall, the novelty seems to be mainly the (straightforward) connection of existing ideas, even though I admit that it is a very clever combination. The proposed reduction of neurons is not even targeted to achieve a high control performance, but only to maintain high model accuracy. High control performance is only addressed a posteori by selecting the best model observed in experiments. Doing it as described in lines 206-208 runs the risk of executing a potentially bad controller on a real system. This seems like a dangerous thing to generally do. I think it would be much more interesting to directly optimize the model for achieving the best control performance.\\n\\nFinally, I find the comparison in the numerical evaluation a little weak. When no experiment has to be done like for the open-loop planning performance evaluation, I think more methods than only MPPI should be investigated. I am not an expert, but I know there exists more than one planning/control method for nonlinear systems, e.g., MPC with NN dynamics (Salzmann et al., 2023). Moreover, I do not understand why the learned dynamics model is not used as environment for the classical RL methods. It is apparently accurate enough to allow for a direct transfer to a real-world experiment. So why are the interactions limited to a relatively small number with the real environment, when a large number of interactions with a potentially only slightly more inaccurate model are available?\\n\\nT. Salzmann, E. Kaufmann, J. Arrizabalaga, M. Pavone, D. Scaramuzza and M. Ryll, \"Real-Time Neural MPC: Deep Learning Model Predictive Control for Quadrotors and Agile Robotic Platforms,\" in IEEE Robotics and Automation Letters, vol. 8, no. 4, pp. 2397-2404, April 2023'},\n",
       " 'review_324': {'summary': \"The authors investigate offline RL in linear MDPs and introduce a novel LP-based method. They assert that their proposed approach achieves the lowest sample complexity of $O(1/\\\\epsilon^4)$ among computationally efficient algorithms. In comparison, existing computationally efficient algorithms can achieve $O(1/\\\\epsilon^5)$. Additionally, the author's theory can be extended to the average reward setting.\",\n",
       "  'strengths': '* To the best of the author’s knowledge, in offline linear MDPs, the result in the average-reward setting is novel. \\n* The LP formulation in linear MDPs is worthwhile to investigate \\n',\n",
       "  'weaknesses': \"* I am uncertain about whether it is appropriate to claim that existing offline RL algorithms in linear MDPs achieve $O(1/\\\\epsilon^5)$. It appears that [38] may have better sample complexity. In Table 1 of the manuscript, the author mentions that [38] cannot handle the discounted setting. However, extending from the finite-horizon to the discounted infinite-horizon setting is relatively straightforward. Hence, this comparison may not be entirely fair. If [38] indeed has better sample complexity, it significantly impacts the author's contribution. Thus, I currently rate the paper with a score of 4.\\n\\n* I am not entirely certain about the significance of the extension to the average reward case.\\n\\n* Presently, I cannot determine whether the reason [9] and [36] cannot handle the average reward case is due to the algorithms or their analysis. If this limitation arises from their analysis, their algorithm has the potential to be superior as it can handle more general MDPs.\"},\n",
       " 'review_325': {'summary': 'This paper considers the problem of offline reinforcement learning (RL) for linear Markov Decision Processes (MDPs) under the infinite-horizon discounted and average-reward settings. The authors propose a primal-dual optimization method based on the linear programming formulation of RL, which allows for efficient learning of near-optimal policies from a fixed dataset of transitions under partial coverage. The proposed algorithms improve the sample complexity compared to previous methods from $O(\\\\epsilon^{-5})$ to $O(\\\\epsilon^{-4})$ under the discounted setting and provide the first line of result in the average-reward setting with realizable linear function approximation and partial coverage.',\n",
       "  'strengths': '1 The proposed algorithm improves existing algorithms in both statistical efficiency and computational efficiency under the discounted reward setting with the linear function approximation (we note the baseline may handle problems beyond the linear MDPs).\\n\\n2 The algorithms presented in this paper do not explicitly leverage the principle of pessimism, but focus on the linear programming formulation of MDP, and rely on a new reparametrization trick extended from the tabular case. The technique itself seems to be novel to me.\\n\\n3 The algorithms present the first line of work for the offline average-reward MDP.  \\n\\n4 The paper is easy to follow, with a thorough comparison with existing work that clearly positions the results in the literature.',\n",
       "  'weaknesses': '1 I am confused about the requirement of $\\\\Lambda$ to be invertible (line 140) as this seems to be very closely related to the uniform coverage condition where we assume that the smallest eigenvalue of $\\\\Lambda$ is lower bounded from zero. I am wondering what is the key difference between them. Can you elaborate on this with some intuitions or examples?\\n\\n2 The authors discuss the relationship between the coverage condition considered in this paper and that of [1] and show that the coverage condition is a low-variance version of the standard feature coverage ratio if $c=1/2$. However, in this case, the algorithm explicitly uses $\\\\Lambda$, while the PEVI proposed in [1] does not. In contrast, $c=1$ leads to a worse bound but we do not need the knowledge of $\\\\Lambda$. Could you provide a more detailed characterization or example to illustrate the difference between these two cases?\\n\\n\\ntypo: line 328, $\\\\epsilon^2 \\\\to \\\\epsilon^{-2}$\\n\\n[1] is pessimism provably efficient for offline rl'},\n",
       " 'review_326': {'summary': 'This paper studies offline reinforcement learning with linear function approximation. They propose a primal-dual algorithm, formulating linear RL into a minimax problem and solving it with gradient descent-ascent. Sample complexity analysis is provided for infinite-horizon discounted and average-reward MDPs, where the rate is $O(\\\\frac{1}{\\\\epsilon^4})$ for both settings.',\n",
       "  'strengths': '1. The algorithm is primal-dual and thus easy to implement in practice.\\n2. The paper provides rigid theoretical analysis.',\n",
       "  'weaknesses': \"1.  The newly defined coverage ratio $C_{\\\\phi,c}$ is a little strange when $c\\\\neq \\\\frac{1}{2}$. For example, when we choose $c=1$ and thus we don't need the knowledge of $\\\\Lambda$, the coverage ratio $C_{\\\\phi,1}=\\\\sum_{x,a}(\\\\frac{\\\\mu^*(x,a)}{\\\\mu_B(x,a)})^2$. Then when $\\\\mu^*=\\\\mu_B$, $C_{\\\\phi,1}$ will become $|X||A|$. However, in the literature, when the behavior policy is the same as the optimal policy, the coverage is typically 1. The authors claim that we can estimate the $\\\\Lambda$ via the offline dataset so that we can choose $c=\\\\frac{1}{2}$, but do not provide any theoretical analysis about this point. I will be more convinced if the authors can give more rigid proofs for this method.\\n2. The sample complexity is worse than the typical rate $\\\\frac{1}{\\\\epsilon^2}$.\"},\n",
       " 'review_327': {'summary': 'This paper studies offline reinforcement learning (RL) with linear function approximation and partial data coverage. The authors propose a primal-dual optimization method based on the linear programming (LP) formulation of RL. They prove a $O(\\\\epsilon^{-4})$ sample complexity in both discounted setting and average-reward setting.',\n",
       "  'strengths': '1.\\tThe algorithm proposed in this paper only requires near-minimal dataset coverage assumption, which is important in offline RL.\\n2.\\tThe paper also considers average-reward offline RL, which is often neglected by literature.\\n3.\\tI like the table for comparison to previous work, which makes the presentation more clear (although I think there is some missing important literature, which I will mention in the weakness section).\\n4.\\tThe proposed algorithm is both computationally and sample efficient.',\n",
       "  'weaknesses': '1.\\tThe first concern is the ‘linear function approximation’ setting, which is restricted. Actually, the main motivation that this paper studies function approximation beyond tabular settings is large state (or action) spaces in practice. However, in real settings, the linear function approximation assumption hardly ever holds. Even in Table 1, many algorithms in previous work apply to general function approximation, which further makes the setting studied in this paper restricted.\\n2.\\tAlgorithm 1 in this paper achieves a $O(\\\\epsilon^{-4})$ sample complexity. This is in terms of expectation (as shown in Theorem 3.2) instead of high probability. The previous results that the authors are comparing to are high probability bound (e.g., [1,2]), so it would be more comparable if the authors could also show a $O(\\\\epsilon^{-4})$ sample complexity bound under high probability. Also, since the previous work studies general function approximation while this paper studies only linear function approximation, it is hard to say that a $O(\\\\epsilon^{-4})$ sample complexity bound in linear function approximation setting is better than a $O(\\\\epsilon^{-5})$ bound in general function approximation setting. Moreover, [3] achieves the near-optimal sample complexity $O(\\\\epsilon^{-2})$ with near-identical settings of [1,2]. (So I disagree with the statement that ‘It is very important to notice that no practical algorithm for this setting so far, including ours, can match the minimax optimal sample complexity rate of $O(\\\\epsilon^{-2})$’. Therefore, a $O(\\\\epsilon^{-4})$ in linear function approximation is not that attractive compared to previous work.\\n3.\\tThe authors use an LP formulation of offline RL. I think it would be better to compare to other work using LP formulation, e.g. [4,5], where [4] is computational and sample efficient under partial data coverage and general function approximation, and [5] achieves near-optimal sample complexity under similar settings.\\n4.\\tThe authors compare the computational complexity. However, it is not that direct to compare an $O(n)$ complexity in linear settings to a $O(n^{7/5})$ complexity in general settings. If the authors really want to demonstrate that their algorithm has better computational complexity, it would be better to do some simulations in the same environment (even in some toy examples).\\n5.\\tAnother advantage that the authors claim is that their algorithm could be adapted to average-reward setting. However, neither did the authors emphasize and explain the importance and challenges of average-reward settings, nor discuss why (or whether) previous work could not be adapted to average-reward settings. I suggest the authors discuss this a bit more.\\n\\n**References**\\n\\n[1] Xie, T., Cheng, C. A., Jiang, N., Mineiro, P., & Agarwal, A. (2021). Bellman-consistent pessimism for offline reinforcement learning. Advances in neural information processing systems, 34, 6683-6694.\\n\\n[2] Cheng, C. A., Xie, T., Jiang, N., & Agarwal, A. (2022, June). Adversarially trained actor critic for offline reinforcement learning. In International Conference on Machine Learning (pp. 3852-3878). PMLR.\\n\\n[3] Zhu, H., Rashidinejad, P., & Jiao, J. (2023). Importance Weighted Actor-Critic for Optimal Conservative Offline Reinforcement Learning. arXiv preprint arXiv:2301.12714.\\n\\n[4] Zhan, W., Huang, B., Huang, A., Jiang, N., & Lee, J. (2022, June). Offline reinforcement learning with realizability and single-policy concentrability. In Conference on Learning Theory (pp. 2730-2775). PMLR.\\n\\n[5] Rashidinejad, P., Zhu, H., Yang, K., Russell, S., & Jiao, J. (2022). Optimal conservative offline rl with general function approximation via augmented lagrangian. arXiv preprint arXiv:2211.00716.'},\n",
       " 'review_328': {'summary': 'This paper proposed an primal-dual framework for offline reinforcement learning in linear MDP Contrary to the more common case of finite horizon, they considered the case of infinite horizon with discounted reward. They reduced the problem of offline reinforcement learning to a problem about solving the saddle-point of a Lagrange form. They designed an algorithm which uses stochastic gradient-based optimization to solve the saddle point. They provide a sample complexity of O(\\\\eps^-4) for both cases of discounted MDP and averaged-reward MDP, and their algorithm is also computational efficient. \\n\\nTo summarize, the formulation of offline RL into a linear programming problem is very interesting. The proof seems very solid, and I like the comparison for the concentrability constant in the last discussion section. The comparison for the constant C is thorough and very good. \\n\\nHowever, I still have some questions about some details in the main text.',\n",
       "  'strengths': '1. The formulation of offline reinforcement learning to a linear programming problem is very good.\\n2. The algorithm is clearly motivated by solving the saddle points of a Lagrange form. The algorithm itself is simple and computationally efficient, with a guaranteed sample complexity for both discounted MDP and averaged-reward MDP.\\n3. They proposed a new concentrability constant C and compare it to other constants appearing in other literatures about offline RL. I think the understanding of the relationship of these concentrability constant is basically correct and very clearly expressed.\\n4. The proof seems very solid and the result in averaged-reward case is new.',\n",
       "  'weaknesses': \"1. I have some question about your comparison to previous results. Your main references are Cheng et al and Xie et al. \\n\\n1.1 For Xie et al, the Theorem 3.2 in https://proceedings.neurips.cc/paper_files/paper/2021/file/34f98c7c5d7063181da890ea8d25265a-Paper.pdf implies that their sample complexity is O(1/\\\\eps^2) when applied in linear function approximation. This result is based on assumption3 in their paper. This assumption naturally holds in your paper since you consider linear MDP and they consider the case of 'linear function approximation' (for their difference, see point 2). So it is natural for you to compare your sample complexity to this result, not the O(1/\\\\eps^5) one. [notice that, their algorithm in section 3 is computationally inefficient]\\n\\n1.2 In Theorem 4.1 in Xie's paper, their sample complexity is O(1/\\\\eps^5) when applied on general function approximation, and O(1/\\\\eps^3) when reduced to linear function approximation case (see paragraph 'Dependence oon T'). Again, their assumption for linear function approximation holds in your case. **This algorithm, however, is computationally efficient.** So you should also compare with this alg with  O(1/\\\\eps^3) sample complexity.\\n\\n1.3 In Cheng's paper, in theorem 5, their sample complexity seems to be O(1/\\\\eps^3), not O(1/\\\\eps^5). I wonder how you derive their sample complexity in Table one.\\n\\n1.4 I am not sure how you get the O(n^{7/5}) computational complexity for Xie's paper. Could you derive it in more detail?\\n\\n2. I think in many places in your paper, you confuse the two terms: linear MDP and linear function approximation. Your case is called linear MDP instead of linear function approximation, so I suggest you changing the wrong terms. For reference, both Xie's paper and Cheng's paper consider the 'linear function approximation' case.\"},\n",
       " 'review_329': {'summary': 'This paper studied offline RL in linear MDP setting, where the transition and reward have low-rank structures and the feature $\\\\phi$ is known. The authors formulated the problem in a primal-dual way and proposed a gradient-based algorithm. They provided convergence guarantees, which only requires coverage over optimal policy. ',\n",
       "  'strengths': 'The paper writing is clear and easy to follow.\\n\\nThe discussion and comparison with previous works is very detailed.\\n\\nThe algorithm is computationally efficient. The algorithm design has some interesting points, especially the reparameterization design to avoid knowlegde of $\\\\Lambda^{-1}$ and updates for variables $v$ and $u$.\\n\\nThe coverage assumption seems weaker than previous literatures.',\n",
       "  'weaknesses': \"I didn't see too much technical novelty in the method and proof.\\n\\nThe setting is linear MDP, which is kind of restrictive.\\n\\nConvergance rate is kind of far away from optimal.\"},\n",
       " 'review_330': {'summary': 'This paper proposes an efficient stage-wise initialization for the federated learning paradigm, named FedInit, which could be extended as a plug-in to several existing methods. It provides the theoretical analysis on both the convergence and generalization to illustrate how consistency term affects the FL. Experiments also show its efficiency in practical scenarios.',\n",
       "  'strengths': '1. FedInit is a light and nimble technique that does not introduce extra communication costs in the FL framework. Compared with other algorithms, FedInit can almost achieve the same performance as SOTA algorithms while maintaining the same communication cost as the vanilla FedAvg. And, Relaxed initialization (RI) could be easily extended into other advanced algorithms as a plug-in and efficiently improve their performance.\\n\\n2. This paper explores the impacts of global consistency constraints in FL, which is an essential and interesting problem in federated learning. It also indicates the relationships between generalization and optimization.\\n\\n3. This paper provides a theoretical analysis of the excess risk to comprehensively explain how the dominant factors affect the final performance (test accuracy) throughout the training process. Ablation studies are conducted to validate the conclusion of the theoretical analysis on the hyperparameters, i.e. local interval $K$, coefficient of RI $\\\\beta$.\\n',\n",
       "  'weaknesses': '1. The relaxed initialization (RI) looks like an extrapolation algorithm between the global model and the local models as $w+\\\\beta(w-w_i)$. Several methods including the benchmarks of this paper, i.e. FedProx, and FedCM, are accustomed to applying interpolation methods to adjust local training to make the entire heterogeneous training smoother. So what is their essential difference? I think the author should add a paragraph to discuss it.\\n\\n2. This paper involves a lot of analytical proofs, so I suggest that the author write a simple proof sketch for each sub-sections to facilitate reading.\\n\\n3. In Table.2, RI helps to largely improve the performance of FedSAM and SCAFFOLD but shows limited help for FedCM and FedDyn. What is the main reason for this phenomenon? Does it imply that RI is subject to some existing algorithms? I think the author should add a paragraph to discuss it.\\n\\n4. Some typos (for example):\\n(1) Line.150 \"... ... its generality\"\\n\\n(2) Line.79 \"client drift\" and Line.151 \"client-drift\"\\n\\n(3) Line.192 the sentence is difficult to read\\n'},\n",
       " 'review_331': {'summary': 'This paper aims to solve the “client-drift” problem in Federated Learning, which is caused by the NonIID data. Specifically, this paper proposes initializing the local model of each client with its personalized model to alleviate the problem. Further, the paper theoretically analyzes the impact of inconsistency on the convergence of FL. Besides, extensive experiments also demonstrate the effectiveness of the proposed method.',\n",
       "  'strengths': '1.\\tThe idea of initializing the local model for solving the NonIID problem is interesting.\\n2.\\tThe theoretical analysis for the proposed method is solid. \\n3.\\tThe experimental results demonstrate the effectiveness of the proposed method.\\n',\n",
       "  'weaknesses': '1.\\tAlthough the theoretical results are sufficient to verify the convergence of the proposed method, they cannot present the effectiveness of the initialization strategy in principle. More specifically, how does the proposed method reduce the divergence term compared to the vanilla FedAvg?\\n\\n2.\\tThe workflow of the proposed method seems not correct. Are the locations of line 10 and line 12 placed correctly?\\n\\n3.\\tHow to obtain the value of $w_{i,k}^{t-1}$ is not clear. The client may not participate in the previous round $t-1$ under the setting of random client selection. If the local model $w_{i,k}^{t’-1}$ is obtained in many previous rounds, the motivation of bias correction using $ w_{i,k}^{t’-1} - w^{t-1}$ is not reasonable due to the significant gap between $t’$ and $t$.\\n\\n4.\\tThe key hyperparameter K is set inappropriately. In typical FL literature, the number of local epochs is usually set to range from $5$, $10$, and up to $20$, which may contain many local iterations (mini-batches). However, the experiment of this paper only adopts a small number of local iterations instead of local epochs, e.g., 5 local iterations in Table 1, which seems manually adjusted.\\n\\n5.\\tIt would be better if there is a figure to illustrate the principles of the proposed method.\\n'},\n",
       " 'review_332': {'summary': 'This paper proposes to initialize the local state by moving away from the current global state toward the reverse direction of the latest local state. They demonstrate theoretically and empirically that this revision can help consistency for better performance. The method is also a practical plug-in that could easily to incorporated into other methods.',\n",
       "  'strengths': '- This paper goes deeper into how consistency work in FL systems, and provides a simple and effective initialization-based solution.\\n- This paper gives a comprehensive theoretical analysis of the problem, which I think is a good contribution.\\n- The paper is well-written and easy to follow.\\n- Experiment shows good performance.',\n",
       "  'weaknesses': '- I understand there might not be enough space for experiments and the focus looks to be theoretical analysis, but it would be better if the authors can give more experimental results for different FL settings, e.g., more clients/datasets, which may help evaluate the method better. For example,  100 clients/10% participation rate and 200 clients/ 5% participation rate can be relatively limited. Maybe can we have a curve for participation rate with the same amount of clients and perhaps a curve for number of clients to see how these FL settings influence the performance?'},\n",
       " 'review_333': {'summary': 'The manuscript proposes a novel federated learning method to alleviate the negative impact of the \"client drift\" problem and enhance consistency in the FL paradigm. The manuscript also analyzes the intrinsic impact of local consistency on optimization error, test error, and generalization error. Several experiments are conducted to validate the efficiency of the proposed method.',\n",
       "  'strengths': '1. The proposed method outperforms baseline methods without increasing communication costs and can be easily incorporated into other methods.\\n2. The manuscript provides ample theoretical analysis to demonstrate the theoretical bounds of the proposed method.',\n",
       "  'weaknesses': '1. The hyperparameters were not tuned for different methods. Since the experiments are highly sensitive to hyperparameter settings, the superiority of the proposed method is likely due to the selection of hyperparameters. Given that the personalized process proposed in the manuscript bears resemblance to the momentum of parameter updates, I suspect that when tuning the learning rate for the baseline method, the baseline method may outperform the proposed method.\\n2.  The results shown in Figure 1 suggest that the proposed method is highly sensitive to the choice of beta.'},\n",
       " 'review_334': {'summary': 'The authors extend the diffusion Schrodinger bridge methodology to mult-marginal setting whereby each marginal is ordered sequentially, in addition, introducing  momentum into the diffusion Schrodinger bridge framework. The method shows excellent performance on trajectory inference tasks.',\n",
       "  'strengths': '- The proposed work fills a gap in the literature, and the authors demonstrate how diffusion model based Schrodinger bridges [1] and implementation of [2] can feasibly be plugged into the multi-marginal setting [3]. \\n- The method shows excellent performance on trajectory inference tasks, outperforming other methods. The approach feels quite natural.\\n\\n[1] Bortoli et al https://arxiv.org/abs/2106.01357 \\\\\\n[2] Chen et al https://arxiv.org/abs/2110.11291 \\\\\\n[3] Chen, Multi-marginal Schrodinger bridges, 2019',\n",
       "  'weaknesses': '- The computational complexity of the algorithm is not discussed. It appears multiple (2N reverse diffusions?) must be computed per IPF step. This seems quite costly. I would appreciate discussion and more transparency on this.\\n\\n- It is very difficult to clearly see what is the main algorithm and training procedure from the main text. I see algorithms are provided in the appendices but these are also not very well detailed in my opinion. The paper would improve in clarity and reproducibility if this was given more attention. This is especially true as no code is provided. Indeed, some training details like caching trajectories are mentioned in passing (as was introduced in [1], which should be cited) but it is not clear from this paper what the authors mean and without a reference it is difficult to know.\\n\\n- Possible error in likelihood proof / explanations\\n\\nIn line 454, $\\\\mathbb{E}[y_0]$ (and for $\\\\tilde{y}_0$) is decomposed into $\\\\mathbb{E}[y_T]$ minus the path integral of the SDE for $y$. This seems fine. However, my understanding is that unless the diffusion has fully converged to the prior (i.e. after convergence of the IPF, or with infinite regularization in SB), the term  $\\\\mathbb{E}[y_T]=\\\\mathbb{E}[\\\\log p(m_T)]$ is from the terminal point in the diffusion (which is not fixed until after convergence) hence must depend on the network parameters used to define the diffusion. This is commented on in Theorem 2 of [3]. This term is dropped in [2] and in this paper, which makes the likelihood interpretation incorrect for training each step of the IPF.\\n\\nInstead further work is required, as in [3], to show that time-reversal is a bound of the likelihood and gives **approximate** likelihood training.\\n\\nThe training procedure will still work as it coincides with the time-reversal of a diffusion and the same training procedure as given in [1] but the likelihood explanation does not seem justified as it is currently written. \\n\\nIt appears other reviewers had similar concerns with [2], and also that the overall procedure really is not likelihood training but IPF with time-reversal where each time-reversal can be viewed as approximate likelihood. https://openreview.net/forum?id=nioAdKCEdXB\\n\\n\\n-------- \\n\\n\\nI am conflicted by this paper. Whilst overall I think it is a good contribution methodologically and believe it can be justified with extra work. I have concerns about clarity and more importantly that this likelihood interpretation is misleading and possibly incorrect.\\n\\nI would be happy to increase my score if the authors address this. I am happy to be corrected if I misunderstand the likelihood interpretation.\\n\\n- [1] Bortoli et al https://arxiv.org/abs/2106.01357\\n- [2] Chen et al https://arxiv.org/abs/2110.11291\\n- [3] Song et al, Maximum likelihood training of score-based diffusion models, 2021'},\n",
       " 'review_335': {'summary': 'The paper addresses the topic of multi-marginal trajectory inference in high dimensions using Schrödinger Bridge (SB). In particularly, the authors focus on the so-called momentum SB in phase space where the resulting trajectories in position space are smooth interpolations between the intermediate marginals. The motivation for this is that in real physical systems smooth trajectories are often more likely than abrupted changes in drift direction at intermediate marginals. After an introduction of the preliminaries of Schrödinger Bridge and Bregman iterations, the phase space formulation of SB is introduced, which this work then builds upon. By restructuring the problem formulations and introducing an efficient training scheme for the involved function approximators, the authors show how to solve the multi-marginal momentum SB problem in a computationally efficient way. This is then utilized in the experiments which comprise both a synthetic as well as a 100-dimensional real-world use-case.',\n",
       "  'strengths': '- Originality: The authors make several important technical contributions that allow for a computationally efficient solution of the (multi-marginal) momentum SB problem in high-dimensional phase spaces. Related work and the foundations the authors build upon are discussed and cited in the manuscript. \\n- Quality: All original propositions are supported with detailed proofs in the appendix (which I did not check). The experimental results show a convincing improvement over the state of the art. In the conclusion, limitations of the work are addressed.\\n- Clarity: The paper has a good introduction of the work it builds on. In addition, the novel contributions are clearly stated. The submission is well written and quite accessible on pages 1-4 where the relevant prior work is explained. \\n- Significance: The presented contributions are likely to enable machine learning practitioners to apply the momentum (multi-marginal) SB method to many interesting high-dimensional trajectory-inference problems. The advances over the state of the art are demonstrated convincingly on both an artificial and a real-world use-case. Further, the approach is also applicable if the marginal velocity distributions are not available, which is probably relevant in many real world use-cases where velocity information can be much harder to obtain the positional information. ',\n",
       "  'weaknesses': '- Clarity: The novel contributions are likely difficult to understand for a non-expert reader. While proofs are presented in great detail in the appendix, a more intuitive explanation or interpretation of propositions 3.1, 4.2, 4.4, 4.5 is lacking. In addition, reproduction and/or extension of the results is probably a significant effort because the source-code is not provided.'},\n",
       " 'review_336': {'summary': 'In this paper, the authors present an algorithm, DMSB (Deep Multi-Marginal Momentum Schrödinger Bridge), to approximate solutions to an extension of the Schrödinger Bridge (SB) problem into phase space (mmmSB), where (i) marginal constraints on the position are given across time and (ii) stochasticity is only introduced on the velocity variable (which makes trajectories smoother). This framework aims at solving multi-marginal trajectory inference problems, i.e., inferring likely stochastic dynamics of particles on a time interval, given snapshots of them at certain time steps. This work proposes several contributions: (i) it extends the approach proposed by [1] (which solves a single-variable formulation of SB) to phase space (Proposition 3.1), (ii) it presents an efficient numerical scheme for the Iterative Proportional Fitting (IPF)-type algorithm presented by [2] and restated in Proposition 4.1, to solve mmmSB in practice, (iii) it shows great performance on realistic high-dimensional single-cell RNA sequencing ($d=100$) compared to previous baselines [3,4].\\n\\n[1] Likelihood training of schrödinger bridge using forward-backward sdes theory, Chen et al., 2021.\\n\\n[2] Multi-marginal Schrödinger bridges, Chen et al., 2019\\n\\n[3] Manifold interpolating optimal-transport flows for trajectory inference, Huguet et al., 2022.\\n\\n[4] Neural Lagrangian Schr$\\\\backslash$\" odinger bridge, Koshizuka et al., 2022. \\n',\n",
       "  'strengths': 'This work provides a well-motivated and theoretically well grounded adaptation of the SB problem to the multi-marginal setting with smooth trajectories. The authors derive a solid framework and present convincing numerical experiments on real-world data.',\n",
       "  'weaknesses': '- In my opinion, this paper is not easy to follow and some statements are provided without context or comment, which consists in the main limitation for me at this stage. Since I find the content pretty good, I will increase my score if the authors accept to be clearer in the main paper, by answering my questions and following my general comments given below.\\n\\n- This paper lacks a theoretical result of convergence (at least non-quantitative, in the ideal setting where the neural networks would perfectly fit the drift terms of the forward and backward SDEs). It is not clear to me how the convergence result stated in [5] extends to the current setting.\\n\\n[5] Iterative Bregman projections for regularized transportation problems, Benamou et al., 2015.'},\n",
       " 'review_337': {'summary': \"The paper aims at solving efficiently in high dimensions the multi marginal momentum Schrödinger Bridge, that is Schrödinger Bridge in phase space with multiple marginal constraints. They also tackle the issue of marginals constraints where only the positions are enforced. They reach this objective by proposing a new algorithm: DMSB.\\n\\nThe paper first focuses on adapting the iterative proportional fitting (IPF) algorithm to the momentum Schrödinger Bridge with fully specified marginals in phase space. They show that the IPF can be seen as an alternating maximization of log-likelihood.\\n\\nNext they focus on the multi-marginal momentum Schrödinger Bridge. They propose a new formulation of the marginals constraints in order to apply their version of IPF as log-likelihood maximization via policy specification. Moreover they prove that the optimality conditions for the optimal bridge (under their new set of constraints) allows to sample the velocities when they aren't initially specified.\\n\\nIn order to train efficiently in high dimension they adapt a neural network parametrization of the policies known in the classical SB setting to the momentum SB setting.\\n\\nFinally they test the the performance of DMSB on synthetic data. The performance on high dimensional data is higher than the baselines algorithm. Moreover they are able to recover velocity distributions which is a novelty.\\n\\nThe contributions can be summarized as follows:\\n- Extend the IPF to the momentum SB\\n- Introduce a new set of constraints for the Bregman iterations which allows for a neural net parametrization of the policies and sampling of velocities when they are not specified.\\n- Proposal and benchmark of a new algorithm DMSB made to solve momentum multi-marginal SB\\n\\n\\n\\n\\n\",\n",
       "  'strengths': 'The presented use case of their algorithm is cell profiling over time. In that regard the proposed algorithm performs well above baselines and adresses the following technical challenges: sampling of the velocities, curse of dimensionality, partial informations on the marginals.\\n\\nThe sampling of velocities and curse of dimensionality are both tackled by a combination of proposition 3.1 and proposition 4.2/4.3. Proposition 3.1 proposes a novel and interesting formulation of the half bridge using log-likelihood. This is combined with a novel way to deal with the marginal constraints which is a key advance towards efficient high dimensional computing with respect to prior works.\\n\\nGlobally the article puts swiftly together multiple well known ideas and adds key ingredient (decoupling of marginal constraints, log-likelihood IPF) in order to produce an algorithm which removes limitations from prior algorithms. Those limitations being :\\n- lack of scalability\\n- need for fully specified velocities\\n- robustness to missing marginals\\n\\nFinally the benchmark contains multiple metrics which is helpful in the high dimensional context since the curse of dimensionality renders some metrics less meaningful as they point out.\\n\\nThe explicit description of the algorithm in the appendix is appreciated because it makes the article whole: it contains the theoretical and practical aspects.',\n",
       "  'weaknesses': 'Though inspired by a prior work the section on the neural nets parametrization lacks clarity. How does the log-likelihood minimization is tied to the mean matching objective and thus the loss Lmm? This link is succintly pointed out in the appendix B.5 equation (38).\\n\\nThe training scheme section goes rapidly over how the neural networks are trained. The figure 8 in appendix clarifies a lot the training. The explanation on the discretization method is unclear in section 4.5.\\n\\nFinally the main advantage of the algorithm DSMB is the scalability however there are no complexity analysis of the algorithm with respect to dimensions and number of marginals. '},\n",
       " 'review_338': {'summary': 'The paper tackles the multi-marginal Schrodinger bridge space in phase space, by proposing a computationally tractable solver (DMSB). It leverages alternating Bregman projections to adapt the iterative proportional fitting algorithm in order to deal with multiple convex constraint sets.\\n\\nThe DMSB framework constrains the stochasticity of particle dynamics to their velocity component and therefore ensures smooth trajectories. The authors show how the proposed algorithm better describes scRNA-seq data by reconstructing lower-variance trends in the dynamics and (approximately) recovers the velocity field of particles.\\n',\n",
       "  'strengths': 'The paper builds on well-known results involving Schrödinger bridges (SBs) and convex optimization to practically solve the multi-marginal SB problem while ensuring smooth trajectories. It extends SBs [13] by considering random velocities, rather than random infinitesimal displacements. Furthermore, it generalizes the popular critically-damped Langevin diffusion (CLD) [12] framework to non-gaussian velocity marginals at the extremes.\\n\\nA key contribution consists in performing 2 alternate optimization stages over the two sets $k_{\\\\text{boundary}}$ and $k_{\\\\text{bridge}}$, containing appropriately-partitioned constraints. The extension of the mean-matching objective to the phase space is also novel but relatively straightforward.\\n\\nThe content is well-motivated and appropriately described. Both mathematical results and algorithmic solutions are accompanied by remarks and informal insight, which help to understand their purpose and significance.\\nSeveral tables and diagrams further clarify the presentation by (i) precisely stating the notation used (Table 2), (ii) the problem description (Figure 1), (iii) the comparison against previous work (table 1), and the structure of the algorithm (Figure 2).\\n',\n",
       "  'weaknesses': 'The rationale behind the decoupling of constraints, i.e. the requirement that marginalizing joint densities over the previous/next timesteps yield the same distribution, could be made more explicit to the reader. In particular, it would be advisable to explain why the solution proposed by the authors avoids the “geometric averaging issue” (line 156) which affects instead the solution in [20].\\n\\nI think that Proposition 4.5 should be followed by a more extensive discussion on the differences between constraints in Eqs. 9b and 10b: Why a conditional distribution appears in the former and a joint one in the latter?\\n\\n**Miscellaneous**\\n\\nIn addition, I point out minor inaccuracies found while reviewing this draft:\\n- The quantities optimized in the formulas in the first row of Figure 1 are incorrect ($u$ and $a$ do not appear anywhere in the optimization objective).\\n- Proposition 4.1 looks more like a definition (and it is not even stated as a proposition in the work cited as a source).\\n- Wrong sections are cited on the right of Figure 2.\\n- There are spelling mistakes in lines 34, 66, 89, and 246.\\n- I would suggest refining the references to the Appendix, by clearly specifying if the link points to a proposition or a section (e.g., in line 128).\\n'},\n",
       " 'review_339': {'summary': 'This paper adapts DDPM for trajectory generation within smart cities. The major contributions include the combination of different factors and the integration of some existing modules. The experiments over two real-world datasets can demonstrate the efficacy of the proposed model.',\n",
       "  'strengths': '1. The paper is well-written and easy to follow. \\n2. The paper addresses an essential and important task in spatio-temporal data mining.\\n3. The experiments demonstrate the effectiveness of the proposed model over two real-world datasets.',\n",
       "  'weaknesses': '1. Technical contribution is a bit weak. DDPM is popular in the era of AIGC. The paper adapts DDPM to trajectory generation but lacks novel or innovative designs. This drawback can be also seen in recent studies that borrow the idea of DDPMs to spatio-temporal data mining, e.g., DiffSTG [1]. By the way, this paper is very similar to DiffSTG, from model design to speed-up. \\n2. The paper suggests that incorporating the influence of external factors is challenging, but this claim may not be entirely supported. To the best of my knowledge, existing models can easily handle such influence, e.g., conditional GAN. As the proposed model simply integrates these factors as a condition in DDPM, it is unclear why capturing external factors would pose a significant challenge. Additionally, the paper lacks an ablation study that examines the impact of these external factors on the proposed model\\'s performance.\\n3. To establish the generalizability of the proposed model, more real-world datasets from diverse applications and domains are needed. The exclusive use of datasets from DiDi in this paper limits the scope of the model\\'s applicability and may not reflect its performance on other datasets.\\n4. The paper omits some important related work, such as [1, 2, 3]. Furthermore, [3] and [4, 5] (included in the paper) should be used as baselines for comparison to provide a comprehensive evaluation of the proposed model\\'s performance.\\n\\n\\nRef:\\n\\n[1] Wen, Haomin, et al. \"Diffstg: Probabilistic spatio-temporal graph forecasting with denoising diffusion models.\" arXiv preprint arXiv:2301.13629 (2023).\\n\\n[2] Yuan, Yuan, et al. \"Spatio-temporal Diffusion Point Processes.\" arXiv preprint arXiv:2305.12403 (2023).\\n\\n[3] Feng, Jie, et al. \"Learning to simulate human mobility.\" Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining. 2020.\\n\\n[4] Liu, Xi, Hanzhou Chen, and Clio Andris. \"trajGANs: Using generative adversarial networks for geo-privacy protection of trajectory data (Vision paper).\" Location privacy and security workshop. 2018.\\n\\n[5] Zhang, Jing, et al. \"Dp-trajgan: A privacy-aware trajectory generation model with differential privacy.\" Future Generation Computer Systems 142 (2023): 25-40.'},\n",
       " 'review_340': {'summary': 'The paper introduces a good approach for generating realistic GPS trajectories based on a diffusion probabilistic model. The paper addresses the challenge of generating personalized trajectories that capture both temporal and spatial dependencies while ensuring privacy preservation. \\nThe paper proposes the DiffTraj framework, which combines a personalized transition matrix and a diffusion process to generate trajectories that closely resemble real-world GPS data. The personalized transition matrix captures the individual movement patterns of users, while the diffusion process introduces randomness and ensures diversity in the generated trajectories. Overall, the model is reasonable.\\nThe paper presents a comprehensive evaluation of the DiffTraj framework using real-world datasets. The experimental results demonstrate that DiffTraj outperforms existing trajectory generation methods in various aspects. The proposed approach achieves high accuracy in replicating individual movement patterns while maintaining privacy by generating trajectories that deviate from the original data.\\n',\n",
       "  'strengths': '1 The paper introduces a unique approach to GPS trajectory generation by utilizing a diffusion probabilistic model, setting it apart from existing methods that may rely on different techniques or assumptions. The proposed diffusion probabilistic model captures both temporal and spatial dependencies, allowing for more accurate trajectory generation. This consideration enhances the realism and relevance of the generated trajectories. The diffusion probabilistic model captures both spatial and temporal dependencies, enabling the generation of trajectories that reflect the underlying dynamics of user movements.\\n2 Incorporating user preferences into the trajectory generation process adds a personalized aspect, enhancing the relevance and usefulness of the generated trajectories for individual users. This feature contributes to the practicality and applicability of the proposed method. The generated trajectories exhibit high diversity, capturing the variability in user behaviors and preferences. This diversity expands the range of applications where the trajectories can be utilized.\\n3 The paper provides a comprehensive comparison with baseline methods, showcasing the advantages of the proposed approach. The comparisons highlight the strengths and improvements of the diffusion probabilistic model for trajectory generation.  The authors provide sufficient details and code availability, enabling other researchers to reproduce the experiments and verify the results. This transparency contributes to the reliability and integrity of the presented work.\\n4 The paper discusses potential applications of the proposed method beyond trajectory generation, such as urban planning, transportation analysis, and location-based services. This discussion broadens the scope of the paper and highlights its practical relevance.\\n',\n",
       "  'weaknesses': '1 The paper could provide more in-depth discussions on the assumptions made by the diffusion probabilistic model and their potential impact on the generated trajectories. Understanding these assumptions is crucial for interpreting and contextualizing the results.\\n2 No clear instruction is provided on how the hyperparameters are selected for DiffTraj. \\n'},\n",
       " 'review_341': {'summary': 'The paper provides an innovative diffusion probabilistic-based model to simulate realistic GPS trajectories. The main contributions are as follows: 1) The paper introduces a diffusion-based probabilistic model that captures spatio-temporal dependencies in GPS trajectories. This model allows for personalized trajectory generation, considering individual preferences and behaviors. 2) The proposed approach generates personalized trajectories for individual users, enhancing the realism and accuracy of the generated trajectories compared to traditional methods. 3) By incorporating real-world GPS data, the generated trajectories closely resemble actual user movements, making them suitable for various location-based applications. 4) The paper demonstrates the scalability of the proposed method, enabling the generation of large-scale trajectory datasets efficiently. 5) The authors perform an extensive experiment of the proposed approach, comparing it with existing trajectory generation methods, showcasing its superiority in terms of trajectory realism and diversity.\\n\\nOverall, the paper presents a significant advancement in trajectory generation by introducing a diffusion probabilistic model and demonstrating its effectiveness in generating personalized and realistic GPS trajectories. The approach has the potential to impact various domains, including LBSs, transportation, and urban planning.\\n',\n",
       "  'strengths': \"1.Generating realistic and personalized GPS trajectories has wide-ranging applications in various fields. The paper addresses this important problem and proposes a solution that has the potential to enhance applications such as LBSs, transportation, and urban planning. The diffusion probabilistic model offers a novel perspective and advances the state-of-the-art in trajectory modeling and generation.\\n\\n2.The proposed approach generates personalized trajectories, allowing for a more accurate representation of individual user movements. This customization increases the applicability of the method in various domains. The generated trajectories closely resemble actual user movements, exhibiting realistic patterns and behaviors. This realism enhances the reliability and usability of the trajectories for real-world applications.\\n\\n3.The authors present a well-designed study, including an extensive evaluation of their method using real-world datasets and appropriate statistical analysis. The experiments and comparisons with baseline methods demonstrate the robustness and effectiveness of their approach. The evaluation is thorough and includes relevant metrics, ensuring the validity and reliability of the presented results.\\n\\n4.The proposed approach demonstrates scalability and efficiency in handling large datasets. This characteristic makes it suitable for real-time applications, where processing speed and performance are crucial. The work presented in the paper has the potential to advance the field of trajectory generation, providing a valuable tool for generating context-aware GPS trajectories. The paper's contributions can benefit various domains that rely on precise GPS data for decision-making and analysis.\\n\\n5.The paper is well-written and organized, effectively conveying the methodology, experimental setup, and results. The logical flow and clear explanations contribute to the ease of understanding for readers.\\n\",\n",
       "  'weaknesses': '1. Some details of experiment setup are not clearly provided, such as datasets, metrics, and baselines.\\n\\n2. While the paper provides detailed descriptions of the proposed method, the absence of an openly available implementation or codebase limits reproducibility and further exploration by the research community.\\n\\n3. It is better to discuss about the generality of the propose model. Can it be applied to other application domains?'},\n",
       " 'review_342': {'summary': 'The paper proposes DiffTraj: a trajectory generation model based on probabilistic diffusion. The model is trained using real spatio-temporal trajectory data, and aims to generate new trajectories with similar characteristics. This is motivated by the purpose of preserving privacy information that may be present in the actual data. Like all diffusion-based models, the proposed model has a forward and a reverse process, and the latter has an U-Net component, whose importance is highlighted in the ablation studies. Contextual information such as the starting time and location can be provided as input to the model in an encoded form, using a neural network trained on the actual dataset. The influence of this contextual information on the generated data can be controlled by a parameter. It is shown that the trajectories generated by DiffTraj are statistically more similar to the original ones (in two datasets) compared to other trajectory generation models. It is also shown that the trajectories generated by DiffTraj can be used instead of the original trajectories to train models for downstream tasks such as inflow and outflow predictions from particular blocks in the cities.',\n",
       "  'strengths': '1) A new model DiffTraj is proposed for trajectory generation. It uses the currently popular probabilistic diffusion framework, but modifies it to bring in encoded contextual information, and an U-Net component in the reverse process to predict the noise levels for every next step\\n2) Good generative performance is shown, where the trajectories generated by this approach are shown to be statistically more similar to the original ones compared to those generated by other methods\\n3) The authors explore various practical uses of their model, such as downstream tasks (eg. inflow/outflow prediction), transfer learning (training model on one city and adapting it to another) etc\\n',\n",
       "  'weaknesses': '1) The model considers all trajectories as IID and does not aim to utilize any notion of \"trajectory clustering\" into their model. [In their defence, the encoded contextual information may carry such clues]\\n2) The downstream task experiment is introduced almost as an afterthought, though such tasks seem to be the main motivation for the work. Also, these experiments seem to be incomplete [see questions below]\\n3) The model includes U-Net as an important component for the reverse process, and its success is highlighted through ablation studies. But the exact role or contribution of the U-Net is not discussed\\n4) The evaluation metrics used seem to be based mainly on spatial aspects, not temporal aspects\\n\\nOverall, I like the broad idea of the paper. I am willing to improve my ratings if the authors can address my concerns.'},\n",
       " 'review_343': {'summary': 'This paper explains that benign overfitting when the dimensionality of data is fixed is possible if one looks for estimators differently from conventional minimal norm. If one allows the estimator to be spiky, benign overfitting can still be possible. These results are extended via NTK to two-layer infinite-width neural networks. The authors showed that a nearly imperceptible sinusoid added to a RELU nonlinearity allows the trained neural network to overfit noisy data without compromising generalization.',\n",
       "  'strengths': '(Please note that I could not have proofread the submission as well as I would have liked, due to various external obligations.) This paper extends the results on consistency / inconsistency for infinite-dimensional data to the finite dimensional data case. Although the main points - allowing the estimator to go out of its \"smooth\" way to fit noisy data - could have been argued to be expected, actually seeing this established is still a contribution of remark. The other main point - replacing commonly used non-linearity with one that contains tiny level of sinusoidal perturbation - is not expected by me, that\\'s a very nice way of understanding the non-linearity for neural networks.',\n",
       "  'weaknesses': '(Please note that I could not have proofread the submission as well as I would have liked, due to various external obligations.) This paper promotes benign overfitting, but it still leaves open whether not allowing overfitting is better or worse than going into benign overfitting, and within the space of benign overfitting how to reach good results, for a given (n,d). \\n\\nIn Section 6.2 I felt that the noise standard deviation of 0.25 and the neural tangent kernel of gamma = 1/5000, these two quantities are somehow linked. It could turn out that claiming that such a network can be trained to overfit without regularization might be a dangerous overstatement.'},\n",
       " 'review_344': {'summary': 'In this paper, the authors studied the problem of benign overfitting for kernels and wide neural networks (in kernel regime) in fixed dimension. The authors showed that benign overfitting is possible if and only if the learner model has large derivatives. This implies that benign overfitting is not possible for those models with small derivatives (including ReLU NTK). On the other hand, they showed that for certain spiky-smooth activations/kernels, benign overfitting is achievable. Experiments are provided in the paper to verify the results.',\n",
       "  'strengths': '1.\\tThe paper is clearly written and easy-to-follow. The proof sketch is given to help the readers to understand the proof easier.\\n2.\\tUnderstanding benign overfitting phenomenon is an important problem for deep learning. The current paper focuses on the kernel regression setting and connects to neural networks via the neural tangent kernel (NTK) theory\\n3.\\tThe idea of introducing spiky terms in NTK seem to be interesting. The observation in the proof that such spiky term in NTK behaves like regularization term so that the whole solution is now approximating kernel ridge regression also seems to be interesting.\\n\\n',\n",
       "  'weaknesses': '1.\\tThe current paper focuses on kernel regression and neural networks in the kernel regime. It would be more interesting to go beyond the kernel regime to see if similar results would also hold (e.g., in feature learning regime).'},\n",
       " 'review_345': {'summary': 'This paper extends previous results on the inconsistency of ridgeless kernel regression in fixed dimension by showing that non-interpolating estimators whose norm grows comparably to the minimum-norm interpolator are also inconsistent. On the other hand, it is shown that so-called spiky-smooth kernels whose derivatives grow with the number of samples are able to interpolate training data consistently. These results are further specialized to Neural Tangent Kernels and Neural Network Gaussian Processes, and experimental results support the theory.',\n",
       "  'strengths': '* The paper is generally well-written with understandable and insightful theorem statements and proof ideas, even for non-experts.\\n* Modifying the kernel to achieve consistency in fixed dimension via inspirations from high-dimensional benign overfitting seems novel and interesting.\\n* The assumptions seem to be transparent and clearly stated in the main text.',\n",
       "  'weaknesses': '* Having explicit rate estimates in addition to asymptotic consistency guarantees could provide further insight into how the spiky-smooth kernels/activations must be designed to achieve optimal performance.\\n* While mathematically exciting and valuable, the results might have limited applicability in modern settings with typically high-dimensional datasets.\\n* The results concerning the NTK can be applied to networks in the kernel regime (a.k.a. \"lazy training\"), which can only provide a partial picture as there is increasing evidence that in certain settings, neural networks can generalize better in the \"feature learning\" regime, see e.g. [1].\\n\\n[1] Malach et al. \"Quantifying the benefit of using differentiable learning over tangent kernels.\" ICML 2021.\\n'},\n",
       " 'review_346': {'summary': 'This work studies the generalization behavior of overfitting methods in terms of the smoothness of the estimator, showing that only non-smooth estimators can interpolate benignly. They give a discussion of this result in the context of NTKs and their corresponding infinite-width architectures.',\n",
       "  'strengths': \"Originality and quality: this work seems to shed some new light on a well-studied problem. I'm not very familiar with background results on asymptotic risk w.r.t. function smoothness, so it's difficult for me to assess the first several theorem statements. I'm quite familiar with the latter results on NTKs, and to my knowledge this observation about spikiness in activation functions is new, and I find it well-explained.\\n\\nClarity: the paper seems pretty clear and well-written.\\n\\nSignificance: the math here is nice, and it seems like this might lead to some more clarity regarding exotic activation functions.\",\n",
       "  'weaknesses': 'On significance: it\\'s sort of unclear to me how this matters, or where we go from here. For example: the results of Mallinar et al. suggest that early stopping in nets (or including a ridge parameter in KRR, as shown by prior work too) is enough to make fitting consistent. These questions like \"how do we design our model so it overfits benignly?\" seem like they\\'re actually missing some motivation -- why do we need to do that? Can\\'t we just use a ridge parameter or optimal stopping?\\n\\nThe results around spike-inducing kernels seem quite hacky. The fact that the spike has to get smaller with dataset size makes it clear that this is just effectively adding a ridge. (The authors acknowledge this, but it\\'s still not a surprising conclusion in my view.) It\\'s also not useful -- the authors do not try to train their Hermite-polynomial nets, and (based on my own attempts to do such things) I suspect this may be because they\\'re unstable, even at moderately large width!\\n\\nAs stated above, I\\'m unfamiliar with prior art around function smoothness and overfitting behavior, so there\\'s a fair bit of uncertainty in my assessment here.'},\n",
       " 'review_347': {'summary': \"This paper generalize existing inconsistency results to non-interpolating models and more kernels to show that benign overfitting with moderate derivatives is impossible in fixed dimension.\\nMoreover, this paper proves that interpolation with spiky-smooth kernels can be consistent and such kernels can be induced by certain activation functions.\\nThere are also experiments supporting the authors' claims.\",\n",
       "  'strengths': 'The paper is well-written and easy to follow.\\nIt also provides us with novel understandings of the benign overfitting phenomenon: the smoothness of the estimators, and not the dimension, matters.\\nIn particular, by considering spiky-smooth kernels, the authors find that interpolation with kernels can be consistent in fixed dimension.\\nThis new result is very interesting.\\n\\nOn the technical side, the authors improve previous inconsistency results for RKHS equivalent to Sobolev RKHS of smoothness $s > d/2$ on the sphere $\\\\mathbb{S}^d$. The techniques here are solid.\\n\\n',\n",
       "  'weaknesses': 'N/A'},\n",
       " 'review_348': {'summary': 'The 3DIT model is a language-guided 3D-aware image editing tool that allows for effective object editing while considering scale, viewpoint, lighting, and object occlusions. The model builds upon previous work in scene rearrangement and image generation, and incorporates a diffusion process to render object transformations. The authors conducted human preference evaluations to measure geometric and lighting consistency, and found that 3DIT outperformed relevant baselines in both categories.\\n\\nOne of the key strengths of 3DIT is its ability to add, remove, or edit shadows to maintain consistency with scene lighting. This is achieved through a shadow generation module that takes into account the position and orientation of the light source, as well as the geometry of the objects in the scene. Additionally, 3DIT accounts for object occlusions by using a novel occlusion-aware rendering module that predicts the visibility of each object in the scene.\\n\\nThe authors also introduced a new benchmark dataset called OBJECT, which consists of 3D scenes with multiple objects and associated natural language descriptions. They trained 3DIT on this dataset and found that it generalized well to images in the CLEVR dataset as well as the real world. This demonstrates the robustness and versatility of the model, and suggests that it could be applied to a wide range of real-world scenarios. Overall, by enabling users to edit objects in a natural and intuitive way, 3DIT opens up new possibilities for creative expression and visual communication.\\n',\n",
       "  'strengths': '- The 3DIT model is a novel approach to language-guided 3D-aware image editing that builds upon previous work in scene rearrangement and image generation. The model incorporates a diffusion process to render object transformations and uses a novel shadow generation module and occlusion-aware rendering module to maintain consistency with scene lighting and object occlusions.\\n\\n- The authors conducted human preference evaluations to measure geometric and lighting consistency, and found that 3DIT outperformed relevant baselines in both categories. This demonstrates the effectiveness of the model in producing high-quality, visually consistent image edits.\\n\\n- The authors trained 3DIT on a new benchmark dataset called OBJECT and found that it generalized well to images in the CLEVR dataset as well as the real world. This suggests that the model is robust and versatile, and could be applied to a wide range of real-world scenarios.\\n\\n- The potential applications for this technology are vast, including virtual and augmented reality, gaming, and e-commerce. The model could be used to create personalized avatars for virtual reality environments, or to generate realistic product images for e-commerce websites. Additionally, the model could be extended to support more complex scenes and interactions, such as object physics and collision detection.\\n',\n",
       "  'weaknesses': \"- The ablation study is relatively weak. It's unknown which component contributes most to the final performance and which is effective.\\n\\n- The shadow of the box did not follow the rotation action in the shown GIF. And some artifacts are obvious.\\n\\n- How did the method choose which box to be moved? Or did it need a handcrafted mask as the selection?\\n\\n- What is the number of samples used for calculating FID? Normally FID is not reliable of the number of samples is small.\\n\\n- The comparing table did not include the previous method. I believe several important baselines [a] methods are missing.\\n\\nReferences:\\n[a] Editable free-viewpoint video using a layered neural representation\"},\n",
       " 'review_349': {'summary': 'The authors propose a large dataset of  3D aware image edits along with editing instructions built on the objaverse dataset. They also introduce a model finetuned on Zero-1-to-3 for 3D aware editing tasks which include object insertion, removal, translation and rotation. Comparisons are provided against state of the art models for each task and performance improvement is demonstrated. ',\n",
       "  'strengths': '1. **Clarity**: The paper is well written with attention to detail. All the necessary details particularly with regards to the dataset creation have been adequately explained.\\n2. **Interesting dataset**: The 400k dataset of images along with edit instructions would serve as an interesting training and benchmarking dataset for the task of 3D aware editing. \\n3. **Quantitative metrics**: A number of qualitative comparisons and user studies are provided to demonstrate the geometric consistency of the edits and lighting consistency.\\n',\n",
       "  'weaknesses': '1. **Novelty**: Although the proposed dataset represents an important contribution, the proposed approach relies on zero-1-to-3 and finetuning on a new dataset.\\n2. **Need for zero-1-to-3**: The approach finetunes a model on top of zero-1-to-3 to incorporate edit instructions. Can the finetuning be done on top of base SD?. Adding an ablation to this effect will be helpful to demonstrate the need for the 3 stage curriculum. \\n3. **Related work**: Several related work that may provide important context are missing. The authors might find some of the following works relevant and interesting [1,2,3,4]. Although some of these works are pre-prints and do not warrant strict comparisons, incorporating them into the related work section would place the proposed work appropriately w.r.t the landscape of current literature \\n4. **Changes in the edited image** : There are certain global changes in the edited image, that dilutes some of the claims w.r.t editing. Particularly, for the CLEVR dataset, the provided supplm examples show changes in the color of certain objects upon insertion/ removal\\n\\n\\n[1] ControlNet\\n[2] InstructPix2Pix\\n[3] InstantBooth\\n[4] GLIGEN'},\n",
       " 'review_350': {'summary': 'The paper formulates a task of 3D aware editing using the language guidance. The task aims to insert, remove, translate or rotate objects in a scene (2D images) by maintaining the details like shadows, 3D consistency of the object, changes in the object sizes due to perspective projections etc. The model is based on Stable diffusion, Zero 1-to-3 method and fine tuning on the given dataset having editing information and text to describe the edit. The paper promises to release the dataset OBJECT derived from Objaverse, which the authors use to train their model on.  The results in the teaser figure and others show that the model is able to perform the given edits, while preserving the semantics of the image. For examples, the objects are translated and it respects the perspective projection, shadows and placement on the surface. The authors also claim that the method is generalizable to the real images.',\n",
       "  'strengths': '1) The paper is able to show that the manipulations possible with the method can preserve the 3D properties of the scene including localization of the objects, scaling, shadows and consistency of the inpainted regions. \\n\\n2) The paper compares with the image based baselines, for examples uses SAM to segment the images and translates the objects in the scene. It also compares with the a 3D baseline for rotation using Zero 1-to-3.\\n\\n3) The paper shows quantitative and qualitative results of their method comparing scores such as PSNR, SSIM, LIPIPS and FID between the original and edited images. The authors also conduct a user study to access the quality of lighting and geometry.',\n",
       "  'weaknesses': \"1) The method to train on the given dataset is not clear to me. There is no pipeline figure to explain the stages of the training. The first two steps are previous works. The contribution which is in the third step is not explained properly in the paper. Is this fine-tuning stage similar to Zero-1-to-3? How was the editing sequence fed to the network? How is it 3D aware besides the Zero-1-to-3 training? Is the method's 3D consistency (for example in rotation) upper-bounded by Zero-1-to-3?\\n\\n2) While the images shown in the paper show that some properties are preserved as the editing operations are done, the results in the gifs show some obvious flickering artifacts which do not respect the properties like shadows. This does not go well with the objective of the paper. Besides the problems with Stable Diffusion , where do the problems arise?\\n\\n3) How is the quality drop if number of sequential operations are done? For example once can perform insertion-> rotation ->translation etc for the same/ different objects in the scene. How does the quality drop compare with the Stable diffusion image editing methods? This is more interesting to me. A 3D aware editing  framework should be able to handle multiple sequential edits with consistent results.\\n\\n4) Another baseline would to use a monocular depth estimation model (eg Zoedepth, Midas) to extract the surface and perform the edits using Zero-1-to-3. This can handle the perspective projection of the objects, and/or even lighting and shadows. Did the authors try similar more strong baselines? How do they compare with the current method?\\n\\n5) The paper claims to generalize to the real scenes. This is a significant claim and needs to be evaluated. The issue of synthetic and real image domain gap is an active research area. How does the current method solve that in this particular task? Were real images considered in Table 2?\"},\n",
       " 'review_351': {'summary': 'This paper constructs a dataset containing 400K examples, which is used for the task of language-guided 3D-aware image editing. This paper also proposes a model, named 3DIT, to solve this task. The model is based on 2D diffusion model, which first goes through the pre-training of text-to-image generation and Zero-1-to-3, and then is fine-tuned on the dataset for the 3D-aware image editing task. The model is evaluated on the proposed dataset and achieves state-of-the-art performance.',\n",
       "  'strengths': '1. This paper constructs a large-scale dataset, which is a good contribution. And language-guided 3D-aware image editing is an important task.\\n2. The paper is well written and easy to understand.\\n3. The experiments show that the proposed model trained on the proposed dataset have a reasonable ability on the task of language-guided 3D-aware image editing.',\n",
       "  'weaknesses': 'My biggest concern is that the performance of the proposed model is not very good.\\n\\n1. The GIF results in the supplementary material exhibit incorrect results on the shadow.\\n2. The lighting and shadow of experimental results on real-data is not realistic. The quality of edited images degrade a lot.\\n\\nDue to the poor performance, I am not sure if the quality and diversity of the proposed dataset is good enough.\\n\\nThe illumination and background of presented real data is too simple. It would be great to add more challenging test data to see the upper bound of the proposed model.'},\n",
       " 'review_352': {'summary': 'The paper studies the problem of object-centric image editing. The authors first curate a dataset based on Objaverse by selecting high-quality textured samples, and then simulate+render them on a plane. The objects can be manipulated in 3D and rendered correspondingly, which generates the groundtruth for training learning-based object editing models. The paper further presents a diffusion-based object editing model (3DIT) based on zero-123, where the major difference is the addition of editing prompt conditioning. Results in quantitative and qualitative experiments show 3DIT outperforms baselines based on foundation models.',\n",
       "  'strengths': 'The dataset curation using 3D simulation for the object-centric image editing task makes sense. This task intrinsically requires understanding of the 3D world and 3D-aware image formation process. The proposed dataset is guaranteed to be 3D-correct, and would be useful for research along this direction. The proposed method also achieved great performance compared to the baselines. Besides, the paper is well-written and easy to follow.',\n",
       "  'weaknesses': \"1. The realism of the generated dataset is still limited: \\na) The single directional light (why not multiple lights or Image-based lighting?) which makes the shadow and shading's distribution not diverse/realistic enough.\\nb) The size range of the object is quite limited (0.8 ratio threshold), in practice, there are a lot of cases where different sized objects are placed nearby (also the true size seems not kept, so chairs and lamps appears to be of similar scale).\\nThe authors indeed show some qualitative results of direct transfer to real data, but no 1) quantitative evaluation of sim2real or 2) comparison to baselines' generalization have been provided.\\n\\n2. Although the data is generated with 3D, the method follows a 2D design. Such a model does not exhibit a great understanding of 3D objectness -- for example, the identity of the object is sometimes not well-kept during rotation or translation (e.g. the change of coke/headphone texture in Fig 1), or the cast shadow or the shading do not make full sense w.r.t. the whole scene if we look close enough (e.g. first 3 rows of clevr in Fig 1). Having some systematic analysis of the failure cases here would have been very helpful for future research.\\n\\nMinor questions/comments:\\n1. Why is the background always black? This seems to be creating domain gap, as usually we don't have pure black background in real life.\\n2. Wrong number highlight in Table 1, 3DIT(Multitask) - insertion - LPIP, 0.585 is worse than the other two.\\n3. The multi-task model is much worse in terms of FID (Table 1), but not other metrics. Are there any specific reason for this?\\n\"},\n",
       " 'review_353': {'summary': 'In this paper, the authors proposed the first learning-based work that can handle event-to-point cloud registration (E2P). More specifically, a novel Event-Points-to-Tensor (EP2T) network is proposed to encode the data from the event camera into features tensors in the form of a 2D grid. The temporal patch aggregation and spatial patch aggregation combined with spatio-temporal kernel are applied to obtain the global feature. Then based on the output gridded tensor, a standard 2d-3d feature based algorithm is applied to obtain the structure and motion of the final 3D reconstruction scene.\\n\\nThe experimental results based on the two representative datasets demonstrate the performance, mainly in terms of accuracy, of the proposed E2PNet on the task of event to point cloud registration.',\n",
       "  'strengths': 'The motivation of this paper is well designed, that is introducing the first learning-based architecture to handle the sparse reconstruction based on event cameras. More specifically, the spatial and temporal attention mechanism together with the feature propagation module to obtain the final output gridded tensor. The design of the EP2T network is straightforward, elegant and easy to follow.\\n\\nIn addition to its innovative approach, the paper stands out for its well-structured writing style that includes a clear and concise method statement. The authors have taken great care in presenting their research in a manner that is easily understandable to the readers. Furthermore, the inclusion of visual representations helps to further elucidate the concepts and techniques discussed in the paper.\\n\\nMoreover, the performance shown in the statistical experiments especially in Table 1 demonstrate the superior performance of the proposed approach over the previous state-of-the-art approaches.',\n",
       "  'weaknesses': 'My major concerns lie in the following two aspects.\\n\\nFirst, the statistical experiments in Table 1-3 only demonstrate the accuracy in terms of camera position and direction, while the efficiency especially the time and memory efficiency is missed. \\n\\nSecond, the limitations or failure case of the proposed approach need to be discussed. I am wondering the performance of the proposed approach on more complex and even comparatively large-scale environment.'},\n",
       " 'review_354': {'summary': 'This paper proposed a Event-Points-to-Tensor (EP2T) network, which treats event data as spatio-temporal point clouds, to process event signals without losing the spatiotemporal information of event signals (especially temporal information, compared with other voxel grid-based methods). In terms of experiments, this work demonstrates the effectiveness of the EP2T network by using event-based point cloud registration as an example, resulting in the development of E2PNet. Furthermore, the authors have gone a step further and tested the generalization ability of the EP2T network in tasks such as optical flow estimation, image reconstruction, and object recognition, obtaining promising results.',\n",
       "  'strengths': 'The proposed Event-Points-to-Tensor (EP2T) network in this paper takes a different approach compared to most existing event signal processing models. This method treats event signals as three-dimensional spatio-temporal point clouds and employs operations such as Local Aggregation (LA), Spatio-temporal Separated Attention (STA), and Feature Propagation (FP) for extracting and preprocessing spatio-temporal features of events. Finally, tensorization is performed to obtain event feature representations compatible with traditional visual models. Compared to previous models that always tensorize event signals before feeding them into the model, this method can fully utilize the discrete and sparse characteristics of events. It effectively extracts spatiotemporal features from events, especially rich temporal domain information. Additionally, the LA operation separates the extraction of features in the temporal and spatial domains, enabling feature extraction and aggregation on different dimensions/domains, considering the distinct physical meanings of the three dimensions in the event signal \"point cloud\".',\n",
       "  'weaknesses': 'Although the proposed EP2T network in this paper achieves sparse processing of event signals in the first half, it still requires tensorization of the events in the end. In practice, such an operation can significantly degrade the temporal precision of events. While the 2D-3D Registration task proposed in this paper may not aim for high temporal resolution, it is crucial for tasks that are sensitive to event precision, such as high-frame-rate video reconstruction and low-latency object tracking. Furthermore, although the idea of using point cloud networks for sparse processing of event signals in this paper is innovative, the intuitive motivation behind this approach is not clearly presented in the writing. For instance, compared to the operation of tensorization followed by feature extraction, it is not discussed in the paper which events EP2T can handle better and what advantages EP2T possesses. This discussion is lacking in the paper.'},\n",
       " 'review_355': {'summary': 'This paper proposes a learning-based event-to-point cloud registration method, which encodes event spatio-temporal data into a grid-shaped feature tensor, and propose a framework to construct E2P datasets using existing SLAM datasets. Experiments are conducted on MVSEC-E2P and VECtor-E2P datasets, and state-of-the-art results are achieved on these datasets.',\n",
       "  'strengths': '1. The presentation is easy to understand. \\n2. Experiments are well conducted and convincing.',\n",
       "  'weaknesses': '1. Since event-based applications require a high response speed, the efficiency analysis should be given about the comparison of the runtime and memory usage between the proposed method and other state-of-the-art methods.\\n2. Since the experimental datasets are generated by the authors, did the authors retrain the learning-based models on the datasets in order to compare with these learning-based methods?\\n3. The comparisons are done to a few methods in the current manuscript, I suggest more state-of-the-art methods should be included for comparison.\\n4. Minor Typos / Writing  \\nFigure 3: what does O_{E} mean?  \\nLine 211: the definition of f_{SP} is missing.'},\n",
       " 'review_356': {'summary': 'The paper presents an method to perform point cloud registration using event camera data.\\nThe method first learns a feature representation (E2PT) from a point cloud of events. This representation is used as input to standard registration networks.\\nThe experimental section shows better accuracy compared to other event-based feature represenations as well as frame-based approaches.\\nOther experiments also show that the E2PT representations is generic and cna be used for other event vision tasks. ',\n",
       "  'strengths': 'The paper addresses a novel problem of using event camera data for 2d-3d registration. They adapt existing registration pipelines taking into account the specificity of the events.\\nThey propose a new learned event-based representation which leads to good experimental results for the registration problem, but also for other event vision tasks (optical flow, classification, image reconstruction).',\n",
       "  'weaknesses': 'The clarity of the paper can be overall improved.\\nIn particular the method section is not always clear and some details are missing.\\nFor example it is not clear how the features Ft , Fs , and Fst are built (Sec. 3.1.1). the authors mention some \"multi-layer convolution\", but is not clear what is the input to these convolutions, what exactly is the architecture, if tehre is a separate network for  Ft , Fs , and Fst or if it is shared. What is the size of Ft , Fs , and Fst etc. Describing the algorithm with more equations and pseudo-code can make the method clearer, since text and figures alone can be ambigous.\\n\\nSimilarly there is no description in the method section of the E2Pnet architecture, which is presented as the second main contribution in the introduction. From the experimental details it seems that standard architecture from previous works [1,11] are used? '},\n",
       " 'review_357': {'summary': 'This paper provides a finite-time analysis of Neural-Q-Whittle. The authors propose Neural-Q-Whittle, a novel Whittle index-based Q-learning algorithm with neural network function approximation for RMAB. Their analysis leverages a Lyapunov drift approach to capture the evolution of two coupled parameters, and the nonlinearity in value function approximation further requires us to characterize the approximation error. They also conduct experiments to validate the convergence performance of Neural-Q-Whittle, and verify the sufficiency of their proposed condition for the stability of Neural-Q-Whittle.',\n",
       "  'strengths': '1. This paper provides a non-asymptotic convergence rate analysis of Neural-Q-Whittle with two coupled parameters updated in two timescales under Markovian observations without the extra projection step.\\n2. The authors propose Neural-Q-Whittle, a novel Whittle index-based Q-learning algorithm with neural network function approximation for RMAB.\\n3. The authors establish the first finite-time analysis of Neural-Q-Whittle under Markovian observations. Their analysis leverages a Lyapunov drift approach to capture the evolution of two coupled parameters, and the nonlinearity in value function approximation further requires us to characterize the approximation error.\\n4. The writing is good.',\n",
       "  'weaknesses': 'Compared with existing works [13, 22, 58] for Q-learning with neural network function approximation, the technique contribution of this paper is kind of limited. It will be better if the authors could include additional parts to clarify the technical contribution of the paper, compared with prior works.'},\n",
       " 'review_358': {'summary': 'This paper studies Whittle index-based Q-learning with neural network function approximations restless multi-armed bandits (RMAB) problem, which is a model-free low-complexity reinforcement learning (RL) heuristics for RMABs. Since state-action space of RMABs is exponentially growing with the number of arms, common Q-learning techniques as well as tabular Q-Whittle algorithm suffer from curse of dimensionality. Instead, the authors analyze a low-complexity neural network approximation method for Whittle index-based Q-learning under non-iid Markovian state-action observations, namely Neural-Q-Whittle. The authors formulate Neural-Q-Whittle as a nonlinear two-timescale stochastic approximation (2TSA) where the parameters of the neural network Q-function and the Whittle indices  are mutually coupled and the former is updated on a faster timescale than the latter. Leveraging a Lyapunov function method, the authors provide a finite-time convergence analysis of Neural-Q-Whittle with non-iid Markovian data. The analysis involves characterizing the error between two Lyapunov functions: one for the neural network Q-function and one for the linear approximation of the neural network.',\n",
       "  'strengths': 'This paper is original in the sense that it removes some of the limitations in the previous theoretical works on finite-time analysis of Whittle index, Q-learning, and nonlinear 2TSA and generalizes to neural network Q-function approximation in two-timescales under non-iid ergodic state-action process.  The theoretical analysis and proofs seem technically solid and mostly clear. \\n',\n",
       "  'weaknesses': 'Since this work builds upon the limitations in the related past works, it would be easier to follow and appreciate the novelty and significance if you could provide a table comparing to related works in various aspects (eg. methods, assumptions, convergence rates, computational (time or space)  and sample complexities). It could also help with presentation if you give an informal version of your main theorem beforehand or simplify Theorem 1 using asymptotic notation and state the full version in the appendix.\\n\\nI believe it should also be emphasized more that your convergence result relies on diminishing error bound of linear approximation of overparameterized neural networks. \\n\\nAlthough this is mainly a theory paper, it would be interesting to see the experimental comparison to other methods such as Q-Whittle-LFA and references 13, 22, 58.\\n\\n'},\n",
       " 'review_359': {'summary': 'This paper investigates the finite-time analysis of the Whittle index-based Q-learning policy for the RMAB problem under neural function approximation. The authors formulate the algorithm as a nonlinear two-time-scale stochastic approximation problem and present a convergence rate of $K^{2/3}$.',\n",
       "  'strengths': '1. The Neural-Q-Whittle algorithm eliminates the projection step.\\n2. The paper provides finite-time analysis.\\n3. Simulation results are included to verify the convergence performance.',\n",
       "  'weaknesses': '1. It is unclear whether the approximated Q-functions converge or not.\\n2. The errors diminish as $m\\\\rightarrow \\\\infty$, indicating the need for overparameterization.\\n3. The simulation setting is too simple to sufficiently demonstrate the advantages of neural approximation. Consideration of a larger state and action space is warranted.'},\n",
       " 'review_360': {'summary': 'This paper presents a neural Q learning method to compute the Whittle indices in restless multi-armed bandit problems. The paper provides an algorithm using two-timescale stochastic approximation (2TSA) to update the parameters in the neural networks and the Whittle indices jointly with different learning rates. The authors also show that the 2TSA method guarantees convergence to the optimal/approximately optimal solution of Whittle indices. One of the major contributions is the breakthrough of not using projection step in the 2TSA algorithm. The algorithm proposed by the authors doesn’t require the functional class to contain the optimal functional approximator. The corresponding approximation guarantee also shows an additional term dependent on the distance of the true optimal to the span of the functional bases used in neural networks. Lastly, the authors provide experiments to show the convergence of the proposed algorithm and empirically verify the assumptions made in the paper.',\n",
       "  'strengths': 'I like the idea of projecting the neural networks using ReLU to linear functions to enable downstream analysis. The paper also generalizes the theoretical analysis in previous work to quantify the impact of approximation error in the functional approximator class. I didn’t go through the appendix, but the proof sketch is clear to me. Overall, the paper is nicely written with new theoretical contribution compared to the previous work. It would be great if the authors can further emphasize and summarize the contributions in the theoretical analysis that are incurred due to not using projection steps. The convergence rate also matches the previous work using projection steps.',\n",
       "  'weaknesses': 'The comparison to the previous algorithm is not clear. I didn’t fully understand why the previous algorithm requires a project step to force the parameters in a bounded set and why your algorithm doesn’t. I believe it is due to the analysis in the convergence guarantee where unbounded parameters can lead to useless bound or divergence. Could you please clarify and emphasis this in the paper more to highlight your contribution more clearly? Especially this seems to be the major contribution of the paper. It deserves a larger portion of the paper to clarify it.\\n\\nPlease also clarify why the definition of Whittle index is different from Whittle et al. and most of the literature. Please see below for more details. I am worried that the different definition can impact the convergence analysis (especially the linearity and Lipschitzness in the proof). Please either justify the use of your definition and any references showing this different definition is valid, or show us that the analysis is not impacted by the definition.\\n\\nThese two are my major concerns of the paper. Please clarify them and I am happy to update my score based on the response.\\n\\n[Answered by the authors during the rebuttal]'},\n",
       " 'review_361': {'summary': 'This paper proposes a neural network approach to learning the Whittle index policy. In addition, the paper gives a finite-time analysis for the algorithm, and shows that the algorithm indeed learns the Whittle index values for restless bandits. \\n',\n",
       "  'strengths': 'The paper’s sections are well-written and the technical claims of the paper are sound. In addition, the paper provides sufficient analysis of the two-timescale stochastic approximation used here (to learn the Whittle index values and the action-value function for each arm). Also, the paper offers finite time performance bounds in the neural network setting which is a largely unstudied area.\\n',\n",
       "  'weaknesses': 'While the paper is well-written, I believe it’s better if less remarks/lemmas blocks are used and if they are written as paragraphs. Other than that, the technical details appear correct to the best of my knowledge. \\n'},\n",
       " 'review_362': {'summary': 'This paper delves into the intersection of large language models (LLMs) and their applications in vision-and-language tasks, specifically focusing on text-to-image (T2I) generation. The authors identify a gap in the existing literature: no thorough analysis has been conducted on the synergy of LLMs and various visual modules for \"complex\" T2I generation tasks.\\n\\nTo address this they propose two novel frameworks: VPGEN: This framework offers a step-by-step approach to T2I generation, segmenting the process into three distinct stages: object/count generation, layout generation, and image generation. They use Vicuna to fine-tune to manage the first two stages, and the results demonstrate improved control over layout creation. The final stage, image generation, incorporates existing models like GLIGEN. Notably, VPGEN’s design capitalizes on the inherent knowledge of pre-trained LLMs, granting it the ability to recognize objects that have not been predefined—surpassing the capabilities of older layout-guided T2I techniques.\\nVPEVAL: This authors propose this for evaluation of the generated images. Unlike conventional T2I evaluation methods which primarily gauge visual quality and image-text alignment through a singular visual module, VPEVAL emphasizes interpretability and a multiple modules to evaluate the generated image. In essence, it employs evaluation programs that activate a variety of visual modules, to distinct T2I skills.\\nThe papers findings indicate that VPGEN+GLIGEN combination showcases relatively better performance, especially when precision in layouts and spatial relationships is paramount. The VPEVAL evaluation method seems to aligns with human assessment.\\nIn summary the contributions are:\\nThe introduction of VPGEN, an interpretable T2I generation framework that dissects the T2I process into three modules.\\nThe proposal of VPEVAL, an evaluation framework for T2I tasks that enhances the explainability and thorough analysis by invoking diverse visual modules.\\nA detailed analysis of various T2I models, highlighting the superior layout control of VPGEN and the human-centric alignment of VPEVAL.\\n',\n",
       "  'strengths': 'Overall its a great work and the paper addresses some fundamental limitations in a unique way.\\nThe paper addresses a very important problem in image generation realm. Most of the existing image generation models including the ones trained on massive datasets, are not good at generating images with spatial consistency, generating the correct number of objects , or understanding the size of the objects. This bias has been highlighted by various papers since 2018 and is still existing in modern generative models. The paper proposes a solution to the same by combining LLMs fine tuned on text to layout pairs and layout to image generation model. This fine tuning provides the LLMs with the ability to understand the spatial etc relationships between the generated objects. Thus removing a limitation from the prior results.\\nThe proposed VPEval combined several modules to evaluate the generated quality of the images and also interpretable due to the generated programs. Using such visual programming is novel.\\nAdaptability - as the modules in image generation and image evaluation improve the proposed approach would also improve in performance.\\nOffering visual+textual explanations is a strength as it increases the interpretability of the evaluation.',\n",
       "  'weaknesses': 'The proposed 5 evaluation modules might still not capture the generated image quality and other complex semantics. Other image quality could be incorporated and evaluated.\\n\\nThe paper emphasizes heavily on the two step generation - object count and layout generation , but fails to conduct any ablation studies to prove the effectiveness of this pipeline. Since the process is decomposed into different steps, the interplay and coherence between these steps are vital. Errors or inconsistencies in earlier steps (like object/count generation) could cascade and affect the final image\\'s quality.\\n\\nRelying on bounding boxes to represent layout may be simplistic. The boxes encode basic spatial relations for sure but might miss more detailed pose, occlusion, and depth information.\\n\\nAssociating object names in texts to layouts could be unreliable for ambiguous or synonymous words. The model may lack grounding to map words to visual concepts.\\nFor example, consider the word \"bat\" - this could refer to: A baseball bat A flying bat animal\\nOr the word \"apple\" could refer to: The fruit apple The technology company Apple\\nWithout proper grounding between language and vision, the model may struggle to determine which visual concept is being referred to based on just the word alone.\\nSome detailed examples to illustrate this:\\nThe text \"a man holding a bat\" is ambiguous - is this referring to a baseball bat or a flying animal bat? The model may wrongly depict it without the proper grounding. The text \"a logo of an apple\" could wrongly depict the fruit when the technology company was meant. Synonyms like \"couch\" vs \"sofa\" would need to be mapped to the same visual concept. So in summary, relying purely on language without grounding it properly to visual concepts can lead to ambiguity in mapping words to the intended visual representations. Providing more context and grounding is important to resolve this.\\n\\nGranularity of Layout Representation: VPGEN decomposes bounding box coordinates into a [0,1] scale and quantizes them into 100 bins. Such discretization can potentially lead to a loss of finer details in bounding box representation, which might impact the accuracy of object placement in the generated images.\\n\\n2 human evaluators are slightly less to conclude that the results align with human and also the setting of human evaluation is a bit unclear. Like humans evaluate it subjectively (esp. with open ended tasks) . So could the authors shed some light on this setting? Also given that the correlation doesnt seem very high for objects ( 63.7?)\\n\\nMinor comments:\\nThe word skill has been mentioned earlier without much context which might be ambiguous to the readers ( so just a minot presentation suggestion) .\\nExplaining what the paper means by \"challenging\" T2I tasks might be helpful in terms of better clarity and presentation.\\nScaling the approach to generate complex high-resolution images with many objects and intricate relations may be difficult. The text-to-layout-to-image pipeline has limitations. Any further results to prove or disprove this might be helpful.\\n'},\n",
       " 'review_363': {'summary': 'This paper proposes a text-to-image (T2I) generation approach along with a new evaluation framework. This can be summarized in Figure 1. First, VPGen (Sec. 3) breaks T2I down into 3 steps, with an LM to generate a “program” of objects and layouts that is then fed into the final generation module. Second, VPEval (Sec. 4) is an interpretable evaluation for T2I that invokes diverse visual modules to evaluate the generated image and the prompt’s components.',\n",
       "  'strengths': 'S1: Both VPGen and VPEval are sound. It leverages existing tools to make the T2I process more controllable (via layout) and interpretable.\\n\\nS2: The paper is well-written.\\n\\nS3: Solid experiments. The paper compares various image generation models (Table 1) and provides results based on particular skills (skill-based prompts) and their combination (open-ended prompts). Further, the paper shows a good correlation of VPEval to human judgments. Though for this point, I do have a concern since the VPEval is “gamed” to showcase VPGen (see Weaknesses).\\n\\n',\n",
       "  'weaknesses': 'W1: It is unclear how generalizable/robust the proposed T2I approach and evaluation protocol are to “non-canonical” prompts shown in Figure 1. For VPGen, what if the prompts are really complex with multiple objects that interact with one another? What if the prompts do not include the numbers of objects (e.g., Pikachus on the table)? Similarly, since VPEval is geared toward showcasing VPGen, some aspects of evaluation are missing such as object attributes (L206) (e.g., a purple Pikachu and a pink Pikachu).\\n\\nW2: The novelty of both VPGen and VPEval should be highlighted further. Perhaps expand L99-105 in more detail and demonstrate L101-102 empirically. Furthermore, it would also be appreciated how the VPEval is compared to VQA-based approaches (L35) like TIFA and SeeTRUE (https://arxiv.org/abs/2305.10400), which in my opinion are also interpretable.  \\n\\n'},\n",
       " 'review_364': {'summary': 'This paper extends previous work in the vision and language space that use visual programs as an intermediate step, to the problem of text to image generation and subsequently, its evaluation. It proposes VPGen, a neuro-symbolic method that is composed of specific modules that count objects, generates layouts using a LLM and then generates an image using GLIGEN, a layout-to-image model. This allows for interpretable inspection of the intermediate steps as well as allows for more controllability in the image generation process. The paper also proposes VPEval, a method to evaluate T2I models using specific modules that also generate interpretable programs inspecting specific skills such as counting, existence of object, spatial, scale and text rendering. The proposed method (VPGen) outperforms previous approaches on skills such as count, spatial and scale, demonstrating that the approach allows for better fine-grained control over the image generation process. ',\n",
       "  'strengths': '## Quality, Originality and Significance\\n* There have been several methods that were proposed over the last year for text to image generation, such as stable diffusion, Imagen, Parti, etc but the community still lacked an adequate method for evaluating the quality of the generated image in a way that is also interpretable. This paper provides both, an interpretable text to image generation pipeline that either outperforms or is competitive with existing (open source) state of the art text to image generation models, as well as a way to evaluate them.\\n* Improvements in layout generation by using an LM, allowing generalization to unseen concepts instead of depending on pre-defined class set broadens the scope of the type of prompts that can be incorporated into this interpretable pipeline. \\n* Human judgements and correlation analysis of existing evaluation methods compared with the proposed method demonstrates that VPEval is a suitable metric for T2I generation both in terms of interpretability while also being correlated with human judgement. \\n\\n## Clarity\\n* The paper is very well written, and is very easy to follow. \\n* The paper together with the appendix provides sufficient information on implementation details, qualitative examples and analysis of programs and prompts. \\n',\n",
       "  'weaknesses': '* Missing error analysis or categorization on the types of examples that VPGen fails to produce accurate images (both when the layout generator fails, as well as when GLIGEN fails would be useful). '},\n",
       " 'review_365': {'summary': 'This paper proposes a visual-program-based evaluation method VPEval to evaluate text-to-image models. Their method relies on LLM which can call different expert models in different tasks like object detection, OCR, spatial understanding, etc. to evaluate the consistency between the text and the generated image. The human evaluation shows that compared to traditional metrics, their evaluation method aligns with human better. Besides, they introduce a novel interpretable step-by-step text-to-image generation framework VPGen to improve the consistency between generated images and texts in count, spatial, and scale skills.',\n",
       "  'strengths': '1.\\tThe paper writing is clear\\n2.\\tTheir framework VPGen is simple and novel. I like the idea to first train a LLM that generates image high-level layouts from the given prompt, then generates the image based on the layout.\\n3.\\tVPGen is effective with improved consistency in counting/spatial/scale relationships. \\n4.\\tThe evaluation framework VPEval based on visual program is also novel and has better interpretability compared to previous methods. Besides, it aligns with human judgement better.',\n",
       "  'weaknesses': '1.\\tThis paper is highly related and based on visual programing. Although the author cites the related papers like Visual Programming [11] and ViperGPT [12] in the related work section L110, a brief introduction of visual programming and a discussion of the difference between [11,12] and this paper are missing.'},\n",
       " 'review_366': {'summary': 'This paper makes two contributions. VPGen is a T2I generation framework that first generates object/count, then layout, and finally image. VPEval is a T2I evaluation pipeline that provides a more comprehensive analysis correlated to human. Authors demonstrate that the step-by-step VPGen approach generates images more aligned with the input text compared to stable diffusion and other baselines. This is evaluated using the newly proposed VPEval scores.',\n",
       "  'strengths': 'The proposed VPGen decomposition demonstrates better controllability for image generation, especially in terms of following the exact object count and spatial relation from text prompts. The new VPEval score offers a more comprehensive evaluation beyond just image quality. I believe this score will be useful for evaluating controllable generation.',\n",
       "  'weaknesses': 'Result section lacks the standard evaluation metric for image generation such as the FID and IS score. While the focus of this paper is on better controllability, and the proposed VPEval is clearly a better choice, I still like to see some benchmark on the image quality and diversity. \\n\\nFirst step of VPGen seems limited. In the examples provided, text has to include the exact number for each object. So is the first step just doing text parsing? Will it still work if I give it a sentence like “a small cozy office room”?\\n\\nAlso the motivation for training a LM is not clear to me. Many existing works can generate the layout bounding boxes directly, what is the extra benefit of training a LM? Can you do interactive editing?'},\n",
       " 'review_367': {'summary': 'The paper proposes a few approaches to improve the contrastive learning framework of the unsupervised graph representation learning (UGRL) problem. Building on top of the prior works in supervised GRL and UGRL areas (e.g., filter bank construction, etc.), the authors argued that 1) filter-based augmentations (essentially treating filter banks as \"additional views\" in contrastive learning schemes) is able to provide useful representations across cases that require high-freq and low-freq components; and 2) we can leverage a lot of techniques long known in the ML/DL community like RFF to efficiently reduce the computational complexity of these latent representations in UGRL.',\n",
       "  'strengths': \"The paper proposed a relatively novel approach of leveraging different filter banks as additional views in a contrastive graph representation learning problem. The method basically builds upon the MI maximization scheme proposed in methods like DGI but extends the approach to also include filter bank $F=\\\\{F_1, \\\\dots, F_k\\\\}$ such that each filter's encoder output's MI with the input data is maximized. The empirical analysis reveals that the approach is superior (and likely compatible with?) to the previous UGRL approaches that didn't use filter-bank-related augmentations; and that RFF provides a reasonable boost to low-dimensionality representation learning in graphs. Specifically:\\n\\n1. The paper provides a reasonable empirical analysis of the approach on a diverse set of heterophilic and homophilic datasets, demonstrating improvements in both settings. \\n2. Numerous ablative studies were made, including on low and high dimensionalities, encoder weight sharing, efficiency, and filter bank selection.\\n3. The idea of including multiple filters in the contrastive learning framework itself makes sense to me and is a novel addition to the UGRL literature.\",\n",
       "  'weaknesses': 'A few weaknesses of the paper:\\n\\n1. The main idea of the approach (maximizing mutual information of encoder output and input; applying discriminator to the patch-readout pair), which is described in Sec. 5.1, is still mainly built up on the discussion of the DGI paper. Although the inclusion of the filter bank discussion is new (which follows from other recent work like BernNet, GPRGNN, and ChebNet), this still limits the novelty of the approach itself.\\n2. The contribution of RFF projections, as shown in Sec. 6.2, is largely orthogonal to the FiGURe approach itself. I wonder whether it\\'s the best idea to include it in this paper whose title is on FiGURe and filter augmentations. For example, the efficiency analysis in Sec. 6.4 clearly is lacking the comparison to DGI/MVGRL + RFF, and is thus unfair. Moreover, as the authors suggested in the supplementary materials, the RFF projection they used was based on a Gaussian kernel. Whether and how different projections (e.g., Laplacian) make a difference is unknown; the gradient instability of using RFFs in the architecture (which is an important problem in RFFs\\' usage in Transformers) is not discussed, etc. I personally feel there is a lot of value to the analysis of RFF itself.\\n3. I\\'m less certain whether \"shared encoder weight\" is a contribution (as listed on line 48) of this paper. It seems more like a remedy to the computational burden added by the FiGURe approach, but is not required otherwise?'},\n",
       " 'review_368': {'summary': 'The paper proposes a contrastive learning model for learning node embeddings on a graph, with two technical innovations: First, the authors propose a new augmentation scheme during contrastive learning. Secondly, the authors re-map high dimensional embeddings into lower dimensional space using random Fourier features. The authors claim improvements attributed to both technical innovations on a variety of datasets.',\n",
       "  'strengths': 'Presentation if the paper is mostly clear, figures are well readable, and results are clearly presented.',\n",
       "  'weaknesses': '- Although the word \"augmentation\" is very present in both the paper title and abstract (6 occurences), it only appears once in the paper. It is not fully clear how the abstract claims map onto the technique in the paper, beyond the preliminary info in Section 4.1. The terms should be used more consistently here. It is somewhat inferable from 4.1 what the \"augmentations\" are, but this needs to be clarified in Section 5.\\n- Presentation in section 5 is a bit unclear to me. The algorithm proposes two innovations (filter augmentations and random Fourier features), but the experiment section is not grouped accordingly. I would propose to split the content in 5.1. and 5.2. differently to aid the understanding of the different algorithmic components and their implementation.\\n- l. 183 claims \"Maximizing JS is equiv. to reducing BCE\" --- can you add a suitable reference for this claim?\\n- **Baselines**: I checked a few of the reported baselines numbers. For instance, [SUGRL (Table 1)](https://ojs.aaai.org/index.php/AAAI/article/view/20748) reports $83.5 \\\\pm .5$ on Cora vs. $81.21 \\\\pm 2.07$ here, $73.0 \\\\pm 0.4$ on CiteSeer vs. $67.5 \\\\pm 1.62$ here. Also some other baseline numbers seem to be off. Could you comment on possible discrepancies, and whether the code you are running for your experiment can reproduce the numbers reported in the literature? Some of the differences I mentioned above are similar in scale to the ones you use to claim the effectiveness of your method.\\n- From Table 3 (which I find convincing), it seems like RFF substantially improves many of the baseline methods. It is not really clear to me whether the reported gains are mostly due to the proposed augmentation, or mainly due to the RFF. A clean ablation experiement, ideally on all the datasets would help. Specifically, is the method SOTA also *without* RFF, i.e., due to the different representation learning approach? This is not addressed by the experiments currently.\\n- In general, the experimental results seem limited. See my clarification questions below.\\n\\n**Minor:**\\n\\n- The choice of colors in Table 1 is probably not well readable by readers with colorblindness. \\n- The word \"significant\" is used multiple times in the text, but no statistical tests were run. I propose to either add statistics to your tables (my recommendation), or drop/replace the term.'},\n",
       " 'review_369': {'summary': 'This work proposes a model and contrastive learrning method for acquiring a comprehensive specturm of graph representation by employing filters of various levels. They are adaptively aggregated with learnable weights for downstream supervision tasks. As a result, this approach performs well on both homophilic and heterophilic graphs. Additionally, by utilizing a random featrue map for kernel approximation, it demonstrates effectiveness with low computational cost.  They employ a shared encoder for multiple filters, which not only reduces computational load compared to using independent filters for each, but also improves performane in some cases. Experimental results exhibit performance improvement on average. ',\n",
       "  'strengths': 'They conducted experiments on data with multiple characteristics, demonstrating that their approach works for both homophilic and heterophilic graphs. They proposed various methods for computational efficiency and provide evidence of the effectiveness through experiments. The contribution of their work is clearly described through abtract and introduction sections.',\n",
       "  'weaknesses': 'This paper requires some improvements in terms of presentation, as it contains inconsistent notation (such as size of tilde and hat in the line 147 and 149) and deferred explanation for newly introduced symbols that is difficult to follow and numerous mathematical errors. The presence of these mathematical errors prompted a desire to check the implementation, which unfortunately was not provided by the authors. If these issues are addressed in the rebuttal and the necessary improvements are made, it would be considered for increasing score. It is necessary to clarify the notation and provide better explanations to ensure that readers can follow the content more easily.\\n\\nFor example, in Section 5.1, the notation $D_w$ is introduced for the first time on line 149, while the explanation for it appears much later, specifically on line 166.\\n\\nAdditionally, there seem to be errors in the equations. In Equation 1, the correct formulation of the MI estimator should be:\\n\\n$E_{P_i}[-sp(-T)] - E_{P_i \\\\times \\\\tilde{P}_i}[sp(T)]$.  (details are omitted here. Just refer the ‘-‘ sign) \\n(7th slide in [this lecture](http://people.ee.duke.edu/~lcarin/Jiachang3.20.2020.pdf))\\n\\nThis formulation intuitively maximizes MI, as the first term increases the similarity between local and global features obtained from the same graph, while the second term decreases the similarity between local and global features obtained from different graphs. Similar errors can be observed in Equation 3, where minimizing the given objective $\\\\mathcal{L}_{F_i}$ seems to result in learning that decreases the similarity between local and global representations from the same graph, particularly in the first term. Moreover, in the second term of Equation 3, only the corrupted one $(\\\\tilde{X}_i, \\\\tilde{F}_i)$ is considered for expectation and $h_g^{F_i}$ is not covered, which, leads to ambiguous representation. Furthermore, in Section 6, $\\\\sigma$ on lines 227, 233, and in Equation (6) refer to different functions, causing confusion.\\n\\nOverall, it is crucial to address these issues related to notation, mathematical accuracy, and clarity throughout the paper to enhance its quality and ensure a better understanding for readers.'},\n",
       " 'review_370': {'summary': 'The proposer proposed a contrastive learning method for graphs. The goal is to learn representations for nodes in an unsupervised way, by maximizing mutual informations between the local representation and global representation of a graph, training a single encoder to learn node representations. The method proposes to use multiple different filters to learn representations with different emphasis on the graph structure (as seen through the spectral representation), and then combine those representations on downstream tasks, by learning the mixing coefficients in addition to a linear classifier.\\n\\nThe proposed method, FIGURe, being slower than the other methods it is compared to, when learning 512 representations, the authors also explore ways to produce more compact representations, 32 and 128 in width, using RFF to recover some of the lost accuracy on downstream tasks.',\n",
       "  'strengths': '* The results show improvement compared to other self-supervised approaches. Although FIGURe does not get the first place on every single benchmark, it performs very consistency across datasets, leading to the highest average performance.\\n* The versions of FIGURe with smaller representations are leading to good results as well, underlying the soundness of the approach followed by the authors to reduce the dimension of representation and then recovering part of the lost accuracy.\\n* Overall, the paper is well written, and easy to follow. The preliminary section is concise and yet very useful.',\n",
       "  'weaknesses': '* The study of the authors is limited to 1-layer GCN. It would be interesting to know how the method compares to others as the GNN architecture gets bigger (in particular deeper).\\n* The authors justify the need for learning representations of smaller sizes due to the prohibitive cost of contrastive learning, but this part lacks justification in my view: the mean epoch time does indeed increase compared to baselines (+50%), but we are missing details in the paper related to how many epochs it is trained on (in absolute and compared to others methods) - this would help justify the need for the lower dimensionality version and the RFF tricks used afterwards\\n* The authors present the shared encoder as an efficiency approach, but it seems from Table 4 that it is also increasing performance.\\n* In general, I would appreciate having more details on the experimental section, and in particular on the training recipe and the evaluation recipes - some of these questions will be asked in the \"Questions\" sections of this review - as this would help understanding if the comparison are fair (and help reproducing results)'},\n",
       " 'review_371': {'summary': 'This paper studies the problem of providing faithful and \"efficient\" uncertainty estimates for GNNs. Here faithful means the unknown groundtruth is contained in the prediction set with a probability higher than a threshold; efficient means the prediction set should be as small as possible. Specifically, the proposed method is based on the conformal prediction method, which uses a separate calibration set to determine the threshold used to decide whether a class (for classification) is included in the prediction set. \\n\\nThe authors first show that conformal prediction can be applied to GNNs as long as the samples in the calibration and test sets are exchangeable. This further leads to the observation that the test time coverage of the predictions fluctuates a lot when the number of test samples is small. The authors term this problem as the \"inefficiency\" during conformal prediction.\\n\\nTo improve both faithfulness and efficiency of the uncertainty estimates, the authors propose to train a new GNN that uses the original GNN\\'s predictions as input and adjusted predictions as output. Instead of employing the original predictive loss, the paper proposes a loss that is a differentiable proxy of the efficiency metric. This model is trained with a pseudo calibration and test set split from the original validation set.\\n\\nExperiments show better uncertainty estimates compared to well-known approaches such as MC dropout, although the baselines are not designed specifically for GNNs.',\n",
       "  'strengths': '- The paper formally justifies that conformal prediction can be used under the exchangeability assumption.\\n\\n- The proposed method is simple yet effective: directly optimizing for better uncertainty quantification on a potentially much smaller model.',\n",
       "  'weaknesses': '- It seems that the calibration GNN needs to be trained for every $\\\\alpha$ separately if we want to have multiple calibration thresholds. It would be nice to show whether it is possible to train a model that adapts to multiple $\\\\alpha$s.\\n\\n- It would be useful to show the tradeoff between the predictive performance and the uncertainty quantification performance. For example, the change in top-1 accuracy of the calibrated and original prediction.\\n\\n- Could the calibration GNN suffer from overfitting? In an extreme case, if $\\\\mathcal{V}_{\\\\mathrm{cor \\\\_cal}}$  and $\\\\mathcal{V}_{\\\\mathrm{cor \\\\_test}}$ are both small, it might be possible that the calibration GNN minimizes its loss by overfitting the labels and make all Vs trivially 0? Maybe this is one reason for only giving the calibration GNN the output of the base GNN?\\n'},\n",
       " 'review_372': {'summary': 'This paper proposes a conformal prediction method tailored for graph-structured data. The proposed correction method is topology-aware and based on an empirical observation that inefficiencies correlate highly with network edges. The method updates node predictions based on its neighbors, and it is trainable alongside the GNN model. They also show how regular conformal prediction methods work under ',\n",
       "  'strengths': '[1] The well-motivated problem, clean writing, and detailed related works.\\n\\n[2] The first conformal prediction method for graph-structured data with exchangeability and validity assumptions is GNN agnostic and intuitive.\\n\\n[3] Rigorous proof and method to show exchangeability and validity of conformal prediction on graph-structured data for the first time in the literature.\\n\\n[4] Capable of achieving conditional coverage, which is a stronger version of marginal coverage.\\n\\n[5] In-depth experiments and ablation studies show the efficacy and efficiency of the proposed method.',\n",
       "  'weaknesses': '[1] Inductive settings for GNN problems are more realistic compared to transductive settings. It is also not motivated why authors start with a transductive setting. \\n\\n[2] There could be ablation studies/experiments over the conformity score functions, such as testing with RAPS[1].\\n\\n[3] Even though the original coverage definition is used to measure inefficiency, for graph-structured data, there is an inherent non-IIDness in the data. Therefore each sample having equal weights in the coverage calculation is not appropriate. Weighting based on the degree of a node could be a great idea. Would love to discuss this part during the rebuttals.\\n\\n[4] Why is there no experimental comparison with DAPS[2] (ICML23), which is also a conformal prediction method for node prediction? \\n\\n[5] The paper\\'s assumption of exchangeability is strict. What happens if exchangeability does not hold?\\n\\n\\n[1] Angelopoulos, Anastasios, et al. \"Uncertainty sets for image classifiers using conformal prediction.\" arXiv preprint arXiv:2009.14193 (2020).\\n\\n[2[ Zargarbashi, Soroush H., Simone Antonelli, and Aleksandar Bojchevski. \"Conformal Prediction Sets for Graph Neural Networks.\" (2023).'},\n",
       " 'review_373': {'summary': \"This paper presents a new approach, known as conformalized Graph Neural Networks (CF-GNN), designed to bring reliable uncertainty estimates to graph-structured data prediction models. The study's primary contribution is the innovative adaptation of conformal prediction (CP) to Graph Neural Networks (GNNs). The proposed CF-GNN model is capable of generating prediction sets or intervals that encapsulate the true label, with a level of coverage probability (90%) that can be predefined. \",\n",
       "  'strengths': 'The idea of extending conformal prediction to GNNs is quite interesting and timely. The authors establish a permutation invariance condition that justifies the application of CP on graph data and gives a precise outline of test-time coverage. The empirical evidence from numerous experiments validates the effectiveness of CF-GNN, demonstrating that it can meet any specified target marginal coverage while drastically reducing prediction set or interval size by up to 74% when compared to baseline models. The overall presentation is easy-to-follow, and the technical contribution is non-trivial. ',\n",
       "  'weaknesses': 'I don\\'t see major flaws in this manuscript, but the introduction to how to construct correlation datasets can be more clear. In addition, the manuscript seems to miss a portion of works [1, 2, 3] on quantifying the uncertainty in GNN predictions. If the proposal of conformal prediction is to quantifying the uncertainty of GNN prediction, then other approaches on uncertainty quantification of node classification with GNNs should not be neglected.\\n\\n[1] Stadler, Maximilian, et al. \"Graph posterior network: Bayesian predictive uncertainty for node classification.\" Advances in Neural Information Processing Systems 34 (2021): 18033-18048.  \\n[2] Zhao, Xujiang, et al. \"Uncertainty aware semi-supervised learning on graph data.\" Advances in Neural Information Processing Systems 33 (2020): 12827-12836.  \\n[3] Gao, Jiayi, et al. \"Topology Uncertainty Modeling For Imbalanced Node Classification on Graphs.\" ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2023.'},\n",
       " 'review_374': {'summary': 'The authors propose Conformalized Graph Neural Networks (CF-GNNs), which extends conformal prediction to graphs for uncertainty quantification. The framework allows a GNN to produce confidence intervals for its predictions, based on an uncertainty estimation on a withhold calibration set. Under permutation invariance condition, they provide theoretical guarantee for the coverage of test-time confidence intervals. Furthermore, a learnable correction model is introduced to empirically produce more efficient prediction intervals. Experiments show that CF-GNNs acheive a better coverage rate over baselines and meanwhile have a more efficient (smaller) confidence interval than a naive conformal prediction.',\n",
       "  'strengths': '- [originality] the authors extend conformal prediction to node-level task and give theoretical coverage guarantee. As far as I know, this adaption and theorical results are new.\\n- [significance] this work makes solid theoretical and empirical contributions to uncertainty quantifications of graphs. The proposed method has a greater coverage rate and a smaller prediction intervals size. ',\n",
       "  'weaknesses': 'See Questions.'},\n",
       " 'review_375': {'summary': 'Conformal Prediction (CP) outputs a prediction set that contains the true label with a certain likelihood given assumptions on exchangeability. It is a well-known and popular uncertainty quantification (UQ) technique.  The authors propose a technique that unites GNNs and CP called conformalized GNN (CF-GNN). The technique is crucially permutation equivariant and topology aware. ',\n",
       "  'strengths': 'The paper tackles an interesting problem of unifying CP and GNNs. UQ is an important area of research and CP offers strong sound guarantees to tackle such a problem. The paper is well-written and I appreciated that the authors keep important considerations such as permutation equivariance, efficiency and topology in mind when developing their technique. The evaluation is extensive and shows good results. ',\n",
       "  'weaknesses': 'The technique focuses on a transductive setting only. While this is still a valid and interesting setting, the fact that the technique focuses on this setting only is a weakness. '},\n",
       " 'review_376': {'summary': 'The Hippocampus is postulated as a generative model to learn latent state representations and generate sensory predictions to solve spatial and nonspatial tasks. Theta-band oscillations are used to gate information flow into the generative model to modulate learning. A ring attractor develops within the generative model for path integration and flexibly transfer structures between environments. These computations are performed using biologically plausible learning rule.',\n",
       "  'strengths': '-\\tScheduling neural dynamics with theta oscillator: Model neurons are usually described as input summation followed by a nonlinear transformation. Here, the authors expanded the computational dynamics of a neuron by coupling the membrane potential with the theta oscillator (Eq. 4). This affords fine-grained control or better scheduling of the neurons and plasticity using a central gating mechanism.  \\n\\n-\\tBiologically plausible learning rule: The model seems to be an extension of the MESH architecture which uses the Pseduoinverse learning rule. Here, the network is using Hebbian like learning algorithms to learn a ring attractor for path integration and can dynamically relearn a new environment even with some of the weights are fixed, adding to the list of biologically plausible models.  \\n',\n",
       "  'weaknesses': '-\\tNot a completely novel architecture: Although the multi-compartment neuron architecture controlled by the theta oscillator is novel, past works have described similar neural architecture (Sharma et al., 2022; Han et al., 2020) of having two hierarchical layers recurrently connected. I am curious to know how these neural architectures correspond to the author’s proposed architecture and if there can be some overlap in learning performance?\\n\\n-\\tInsufficient analysis: It is not clear what computations the generative model performs using the ring attractor. The inference model seems to resemble place like receptive fields in Fig. 4b but so does the generative model? I anticipated grid like fields instead but this is not the case? It might also be interesting to show the synaptic weights ($Wgb$, $WpA$) evolve through learning and offer some insights to its computation, similar to Fig. 3c.\\n\\n-\\tInclusion of network prediction prior to learning: Could the authors include the y axis information in Fig. 2b to show how much of the prediction error has been reduced through learning, and the activity of the inference (Fig. 2c) and generative (Fig. 2d) model prior to training to determine the difficulty of the task and the effectiveness of learning? \\n\\n-\\tPath integration capability: Fig 3e demonstrates that the mean decoding error increases monotonically beyond 20 cm by 5 seconds. Can this high error still be claimed to be accurate path integration, where prior to the lesion, error was almost 0? What else could be integrated into the model such that the error does not increase as fast as in Fig. 3e?\\n\\n-\\tApplication to a 2D navigation task: Authors demonstrated the model’s application to a 1D navigation task (left and right) which is rather limiting. Learning to path integrate in a 2D environment will be much more convincing. Furthermore, if the authors could demonstrate the agent ability to perform vector-based navigation by estimating its location using path integration and recalling a goal location from a memory system (Kumar et al., 2023; Foster et al., 2000), this will be a complete contribution to the research in biologically plausible spatial navigation using the entorhinal-hippocampal model. \\n\\n-\\tInsufficient ablation studies: Ablation studies of the theta oscillator, multi-compartment neurons and individual layer plasticity will give us a better understanding of the roles played by each of these components for learning a ring attractor for path integration and remapping to a new environment. \\n\\nReferences:\\n\\nHan, D., Doya, K., & Tani, J. (2020). Self-organization of action hierarchy and compositionality by reinforcement learning with recurrent neural networks. Neural Networks, 129, 149–162. https://doi.org/10.1016/j.neunet.2020.06.002 \\n\\nSharma, S., Chandra, S., & Fiete, I. R. (2022). Content addressable memory without catastrophic forgetting by heteroassociation with a fixed scaffold. ICML. http://arxiv.org/abs/2202.00159 \\n\\nKumar, M. G., Tan, C., Libedinsky, C., Yen, S., & Tan, A. Y.-Y. (2023). One-shot learning of paired associations by a reservoir computing model with Hebbian plasticity. ArXiv. http://arxiv.org/abs/2106.03580\\n\\nFoster, D. J., Morris, R. G., & Dayan, P. (2000). A model of hippocampally dependent navigation, using the temporal difference learning rule. Hippocampus, 10(1), 1–16. https://doi.org/10.1002/(SICI)1098-1063(2000)10:1<1::AID-HIPO1>3.0.CO;2-1 \\n\\n'},\n",
       " 'review_377': {'summary': 'This work presents a neat model that incorporates aspects of hippocampal function under one umbrella: \\n* first, the input from the environment (z) goes into the sensory layer (p) and activates the internal state (g) in a certain way, the model captures this an \"inference\" or \"wake\" stage of the training\\n* next, a set of recurrent connections in the \"internal state layer\" g simulates the prediction-making, guessing the next internal state, simulating the predictive mechanism in navigation (or potentially other cognitive functions)\\n* finally, a generative pathway goes the opposite way from g down to p and attempts to generate what the sensory input should look like\\n\\nTraining of the inference and the generative parts of the model is alternative with a 5 Hz square wave function, which reflects existing observations of the role of this oscillation in hippocampus.\\n\\nThe contribution of the paper is just to propose a model that describes the dynamics of simple dynamical processes, with potential extension to path integration.\\n\\n------------- Update after the rebuttal period -------------\\n\\nI would like to thank the authors for a very detailed rebuttal and being engaged in the discussion on both the technical and the ~philosophical levels.\\n\\nMy main criticism was based on the idea that just training a model that captures something is not enough, because there is an infinite number of models & architectures that will be able to do that. However, after the rebuttal period and skimming the paper again I came to think that the model presented in this paper achieves more that just capturing the dynamics by \"any means necessary\", but actually does so under heavy restrictions, and, while there are still multiple such models possible, the fact that the model still works under said restrictions makes this result interesting.\\n\\nI am raising my score to \"7: Accept\" as this work, in my estimation achieves exactly the required level of \"high impact on at least one sub-area\" (computational modelling of hippocampal formation) and has \"good-to-excellent evaluation, resources, reproducibility\".',\n",
       "  'strengths': 'This is a well-written paper, it has a good flow and is quite understandable. The proposed model combines various ideas about brain function in an elegant way and, while remaining simple, does manage to make those ideas to work in unison. The relevant work section gives great context for the work. The experimental work is well explained and documented.',\n",
       "  'weaknesses': 'As someone who is not coming from the attractor perspective I fail to understand the significance of an attractor appearing. In my mind (please help me understand why this is not the case) the appearance on an attractor is exactly the goal and purpose of training. Basically, the way I see it, if we have a certain dynamical process, and we have successfully trained a neural network to capture this dynamics (the model can predict s(t+1) from s(t)) then saying \"it formed an attractor\" is equivalent to saying \"the learning has converged\". But isn\\'t that precisely the purpose of training the model? The mere fact of it converging (and forming an attractor that captures the training data trajectory on a manifold) is, of course, a good thing -- the learning was successful, but is not in any way unexpected or remarkable. After all this is precisely what we wanted to happen -- we make an effort to build a model and the learning process that captures the data, and if done correctly, that\\'s exactly what it is going to do.\\n\\nIn this work the fact that the generative part of the model had formed an attractor (aka \"can generate the dynamical process correctly\") is presented as a significant outcome. But from the machine learning perspective this is a trivial result, that IS what happens when you train something successfully and is not sufficient to imply a special biological significance of the model.\\n\\nPut it this way: if I would make this model to have not 1 sensory and 1 hidden layer, but, let\\'s say 3 sensory and 4 hidden layers -- it would, of course, also form some sort of an attractor (with a more complex underlying manifold and shape due to the fact that we have more layers), but that would not tell me anything about this model\\'s biological plausibility.\\n\\nI guess what I would like to discuss with the authors and other reviewers is whether creating A machine learning model has scientific value, or (as I posit) we need to make a step further and offer a model that would satisfy more than just capturing the dynamics, but also make predictions or coincide with biological restrictions that we did not explicitly encode, etc. Then -- yes -- we could say that not only this model captures the dynamics, but it also the only variant (or at least belongs to a small family of variants) that also do X, Y and Z the way the brain does it.\\n\\nIn the olden days of modeling proposing a set of differential equations that capture the dynamics was impressive because it was not a given than such a set of equations can ever be found. The outcome of such scientific endeavor could fail if the scientist was not able to describe the dynamics. So when a model was found nonetheless it made the contribution significant. But can we really apply the same criteria to ML-driven modeling? Because in the case of ML it is almost a given, that a \"set of equations\" (now represented by an artificial neural network) will be found to satisfy the data. Which tells us nothing more that \"this data can be described\" (which is rather noncathartical) and the is likely to be an infinite amount of such models that would do so (even the same architecture, trained again from a different initialization starting point would likely produce a \"new\" model).\\n\\nI am looking forward to discussing this with other reviewers and the authors, to help me understand (1) am I wrong about the (in)significance of an attractor appearing and (2) whether it is too much and prohibitive for science to ask more from a model in order to count it as a significant contribution to the field than just it being able to capture the data, especially when this data is simulated?\\n\\nFor the authors, one way to make this critique constructive and actionable I guess would be to say more in the paper about why this particular model (it\\'s architecture and other characteristic) is especially suited to described hippocampal dynamics and why all the same conditions would not be satisfied by any number of similar models.\\n\\nOther points:\\n\\n* It would be great to see some ablation experiments that would help understand that the observed experimental results are unique to the proposed model and would not emerge if some of the critical components of the model are turned off (and help assess their criticality).\\n\\n* I also ask this as a question below, but I wonder why 2D environments were not explored experimentally? It would add so much to the work, make it relevant to more people and help build connections to existing work on hippocampal function, in particular place/grid cells.'},\n",
       " 'review_378': {'summary': 'In this work, the authors give a continuous version of the \\'impression learning\\' [1] and use the theta oscillation to modulate wake-sleep phase.\\n\\n[1] Bredenberg, Colin, et al. \"Impression learning: Online representation learning with synaptic plasticity.\" Advances in Neural Information Processing Systems 34 (2021): 11717-11729.',\n",
       "  'strengths': \"The authors links the theta oscillations to $\\\\theta_t$ in 'impression learning', which gives a neural implementation of the wake-sleep algorithm in Helmholtz machine.\",\n",
       "  'weaknesses': \"From a computational perspective, the contribution lacks novelty.\\n\\nIn Seciton 5.2, the authors clearify their relationship to 'impression learning'. They list four differences:\\n\\n1. continuous version. \\n\\nThe discrete version is equivalent as long as the time steps are sufficiently small. And the authors did not provide the mathematical form of the Evidence Lower Bound (ELBO) for the continuous-time version.\\n\\n2. $\\\\theta_t$ can be ignored.\\n3. disregard $1-k_t$.\\n\\nThese are only technical improvments.\\n\\n4. Link the theta oscillation (5Hz) to $\\\\theta_t$\\n\\nThis is a special case of  'impression learning'.  And the authors did not provide an explanation of how it is implemented from a computational standpoint. They merely established the connection without detailing the computational aspects.\\n\\nOverall, compared to 'impression learning,' I do not believe this work has enough novelty from a computational perspective. Although it provides a biological explanation of 'impression learning,' I do not think this paper is suitable for the current venue. Perhaps journals like Nature Neuroscience/Communications, or eLife would be more appropriate.\\n\\n\\n\\n\"},\n",
       " 'review_379': {'summary': \"The paper is an application of the learning scheme derived in Bredenberg et al. 2021 to representation learning and path integration in the MEC and HPC. By adapting the aforementioned scheme to continuous time, and by relating the proposed oscillatory 'gating' signal to theta oscillations that have been observed to gate dynamics in HPC and MEC, the authors propose to model representation learning in these two brain areas as a form of rapidly alternating 'wake-sleep' learning where brief periods of generative prediction dynamics alternate with more standard position-driven dynamics and deviations between path-integrated predictions and sensory stimulus-driven inputs are used to drive learning at both apical and basal synapses. Subsequently they demonstrate that their MEC model is able to capture two interesting features, learned exclusively through local synaptic plasticity rules:\\n\\n1. The MEC is able to learn a ring attractor capable of path integration based only on motion cues that is able to accurately predict subsequent dynamics.\\n2. This attractor can easily generalize to a new environment without modifications to its recurrent synaptic weights.\",\n",
       "  'strengths': \"While previous models have successfully captured the features I previously mentioned through various optimization schemes, they have not shown how such learning could occur through local, biophysically-motivated synaptic plasticity which can be cleanly related to any representation learning objective function (in this case, the authors relate their learning to a variant of the ELBO objective). This is the principle success of the paper, and in my mind could prove to be a very important model for learning orchestrated between the MEC and HPC.\\n\\nThe authors also relax several constraints on the learning derived from Bredenberg et al. 2021:\\n1. They generalize learning dynamics to continuous time.\\n2. They include self-motion information in the 'generative' part of learning dynamics, which allows for path integration.\\n3. They relax constraints on gating of plasticity that are tied to theta cycles, simplifying learning and requiring fewer assumed variables that are locally available to synapses.\\n\\nFurthermore, the paper is clearly written and logically presented.\",\n",
       "  'weaknesses': \"To me, the principal weaknesses of the paper come from additional analyses that the authors could have done, but did not do. I will list several below:\\n\\n1. The authors do not test their learning algorithm in more complex environments. Simple two-dimensional environments such as boxes or circles could be used to test whether or not the learning algorithm is sufficient to develop grid-like cells in MEC. More complex image-based environments could be used to test the scalability of the proposed learning algorithm, and could potentially test whether or not the proposed learning algorithm is also sufficient to develop place cell responses (rather than having them hand-provided for the system). Given that algorithms similar to Wake-Sleep do not scale as well to high-dimensional problems as backpropagation and that the brain is presumably able to learn place cell information indirectly from multimodal sensory input (vision, audio, vestibular inputs, etc.), this is a valid concern.\\n\\n2. The authors do not discuss testable predictions for their learning algorithm--I can identify several, which I would like to see discussed in more detail. In particular, though the authors suggest that after learning has converged the 'generative' and 'inference' phases of learning 'become indistinguishable,' this is both untested and unlikely to be true for nondeterministic systems and agents operating in partially observable environments with stochastic transitions. In particular, conditioned on the system being in the generative phase, stochasticity in the neural network and uncertainty in the environment should cause the precision of the path integration estimate to decrease throughout time (as the system advances deeper into the theta phase). In fact, the authors' results (Fig. 3e) appear to show exactly this phenomenon. In particular, this is closely related to results from Ujfalussy & Orbán,  Elife, 2022, which use similar phenomena to support the notion that some form of sampling tied to theta phase oscillations is occurring in the hippocampus.\"},\n",
       " 'review_380': {'summary': 'This paper provides a tighter bounds for robust generalization compared to previous results and as tight as standard generalization.',\n",
       "  'strengths': \"1. The paper studies an important topic on adversarial robustness and provide a tighter bound with detailed theoretical analysis.\\n2. The paper is well-written and the conclusions are sound as far as I understand (I didn't check the proof in Appendix).\",\n",
       "  'weaknesses': '* As the paper is an improvement on Farnia et al. (2018), thus the technical novelty is less significant. \\n* The authors should explain why a tighter upper bound is insightful for the robustness community. In my understanding, the robust generalization bound is usually used to explain which factor affects the robust generalization, or why robust generalization is worse than standard generalization. The authors should discuss more on the implications from the new result.'},\n",
       " 'review_381': {'summary': 'In this work, authors use PAC-Bayesian bound to characterize the generalization gap of adversarial robustness. Their work is mostly based on the bound derived from (Neyshabur et al., 2017b) so the resulting bound is valid for a deterministic model.  \\n',\n",
       "  'strengths': 'The major contribution from this work is the new PAC-Bayesian bound for adversarial robustness. The bound works for both Lp and non-Lp cases on both feed-forward networks and ResNets. Authors also compare their bounds with existing ones that only target specific attacks, and show their bounds are more generic. I appreciate the paper’s contribution of the bound (but I do have a question regarding the tightness of the bound which I will elaborate in the next part). The paper has pushed the use of PAC-Bayesian theories to scenarios beyond standard generalization. \\n',\n",
       "  'weaknesses': 'The first weakness of the paper is probably that this newly derived bound largely relies on the work from Neyshabur et al., which has been phrased as an advantage of Theorem 1 being tight at least as Neyshabur et al.’s. However, this might be misleading as I believe the correct description would be when $\\\\epsilon=0$ Theorem 1 reduces to Theorem 2 so they are as tight as each other. I am not sure I understand what does it mean for Theorem 1 and 2 to be equally tight when $\\\\epsilon > 0$? Do you mean that what is in the big O notation is around the same magnitude? However, I do not see the value of $p$ (in $\\\\ell_p$) plays any role in the new bound and the paper talks about the general $\\\\ell_p$ robustness, thus I assume the bound works in any $\\\\ell_p$ space. I hereby have the following question, if the bound is p–norm-agnostic, how come it is equally tight for all $p$? Does this bound simply characterize the robustness of the model in the largest ($\\\\ell_\\\\infty$) perturbation ball for a given $\\\\epsilon$? If that is the case, perhaps the derived bound is pretty loose for $\\\\ell_2$ perturbations. Can you elaborate more here (and in the paper) about the tightness of the bound for different $p$. \\n\\nAnother weakness is the empirical study to demonstrate the tightness of the bound in Table 1. This table is poorly captioned because I do not know how these models are trained, what architectures are used, what $\\\\epsilon$ and attack techniques are used to report the numbers. Also, what does $\\\\infty$ means for Theorem 3? Does this mean the assumption about gradient norm in Theorem 3 does not hold? Do you have experiments about the gradient norms? Moreover, I think it might be useful to use more models and more statistically significant numbers to show the proposed bound is tighter, like the measurement done in this paper [1]. \\n[1] Jiang, Y., Neyshabur, B., Mobahi, H., Krishnan, D., & Bengio, S. (2019). Fantastic Generalization Measures and Where to Find Them. ArXiv, abs/1912.02178.\\n'},\n",
       " 'review_382': {'summary': 'This paper improves previous PAC-Bayesian bounds on robust generalization. The previous bound in Farnia et al. (2018) has a term that is not bounded, and this work provides a bound to that term using the Lipschitzness of feed-forward ReLU networks. The basic idea is that coordinate-wise Lipschitzness preserves under L-inf perturbation.',\n",
       "  'strengths': 'I am quite familiar with this field and spent 3 hours reviewing this paper. Though I do not closely follow the robust generalization line of research, I believe that this work could be helpful to people working in the same direction. The overall framework is very clear and the results are intuitive and easy to understand. Though there are some confusing parts in some sections and the writing can still be improved, overall this looks like a nice paper and should make it to NeurIPS.\\n\\nThe overall framework is clean, and the proofs are easy to read. I quickly checked all the proofs, and they look good to me. I am not 100% sure that all proofs are sound, but even if there are small errors, they should be fixable because the results are very intuitive.',\n",
       "  'weaknesses': 'My only concern is that the significance of this work might not be obvious to a person who is not very familiar with this field. This work is addressing a very specific issue in a previous theorem, and while this issue is important, I think the authors should clarify more about why it is important, what is the main challenge and how this paper fixes it, right at the beginning of the paper. Right now I would say that those things are quite scattered. For example, the main challenge is in Section 6.2. I think the authors could include the following in the intro:\\n- What is the main issue in the previous PAC-Bayes bounds?\\n- Why is it difficult to fix this issue?\\n- What additional assumptions does this work make in order to fix this issue?\\n- What is the main technical contribution in the proof of this work?\\n\\nAs someone very familiar with learning theory and adversarial robustness, I can find the answers to these questions easily in the paper. However, if the authors want to appeal this work to a more general audience, I suggest them rearrange the paper a little bit, and discuss these questions in the intro.'},\n",
       " 'review_383': {'summary': 'This work tries to develop a PAC-Bayesian spectrally-normalized robust generalization bound.',\n",
       "  'strengths': 'This work tries to understand robustness from theoretical perspective.',\n",
       "  'weaknesses': \"1. unclear definitions:  \\nsecond line in Eq. (4)  \\n$\\\\mathbf{x}(\\\\mathbf{w})=\\\\arg \\\\inf_{\\\\left\\\\|\\\\mathbf{x}-\\\\mathbf{x}^{\\\\prime}\\\\right\\\\| \\\\leq \\\\epsilon} g_{\\\\mathbf{w}}(\\\\mathbf{x})$ (I guess it's $\\\\mathbf{x}(\\\\mathbf{w})=\\\\arg \\\\inf_{\\\\left\\\\|\\\\mathbf{x}-\\\\mathbf{x}^{\\\\prime}\\\\right\\\\| \\\\leq \\\\epsilon} g_{\\\\mathbf{w}}(\\\\mathbf{x'})$)  \\n$\\\\mathbf{x}(\\\\mathbf{w}')=\\\\arg \\\\inf_{\\\\left\\\\|\\\\mathbf{x}-\\\\mathbf{x}^{\\\\prime}\\\\right\\\\| \\\\leq \\\\epsilon} g_{\\\\mathbf{w}'}(\\\\mathbf{x})$  \\n$\\\\inf_{\\\\left\\\\|\\\\mathbf{x}-\\\\mathbf{x}^{\\\\prime}\\\\right\\\\| \\\\leq \\\\epsilon} g_{\\\\mathbf{w}}(\\\\mathbf{x})$  \\netc\\n\\n2. Assumptions are not clearly described before theorem 1:  \\nWhat are the conditions on $B$ and $\\\\gamma$ for your theorem?  \\nE.g., Neyshabur et al. (2017b) assumes $\\\\mathcal{X}_{B, n}=[ \\\\mathbf{x} \\\\in \\\\mathbb{R}^n \\\\quad | \\\\quad ||\\\\mathbf{x}||_2 \\\\leq B ]$  and  $\\\\mathbb{P}_\\\\mathbf{u} [\\\\max_\\\\mathbf{x} | f_\\\\mathbf{w+u}(\\\\mathbf{x})-f_\\\\mathbf{w}(\\\\mathbf{x}) |_\\\\infty<\\\\frac{\\\\gamma}{4} ] \\\\geq \\\\frac{1}{2}$ (or $\\\\ell_2$ norm).  \\n\\n3. Miss citation for Line 482.  \\n\\n4. What is $||W_i-W_i||$?\\n\\n5. Please provide the details from Eq. (10) to Eq. (11).  \\n\\n6. As claimed in the contribution: **without any additional assumption**, **as tight as**, **how to obtain a robust generalization bound**.  \\nMy concerns are: **Does this bound provide new information for us?**  In my opinion, for (middle or large) DNNs, PAC-Bayes is not a tight bound but may provide inspiration for us to get a better generalization model. For the bound of this work, it just replaces $B$ with $B+\\\\epsilon$. To me, it simply implies that $||\\\\mathbf{x}||_2\\\\le B$ (clean data), $||\\\\delta||_2\\\\le \\\\epsilon$ (attack radius) thus $||\\\\mathbf{x}+\\\\delta||_2\\\\le B+\\\\epsilon$ (adversarial data), but it holds no significant meaning.  \\n\\nFor the above reasons, I think this work should be rejected. \\n\"},\n",
       " 'review_384': {'summary': 'The authors study the effect of data augmentations on the classwise performance under data imbalance. They focus on the rezised cropping operation and  distinguish between 4 different failure cases by using multi-label annotations. They also show that it is possible to recover some of them but using an informed class-conditional augmentation. ',\n",
       "  'strengths': 'The tackled problem is very relevent since it aims to understand the failure cases introduced but the standard data augmentation pipeline. \\nThe authors provide decent empirical support to their claims and the paper is overall well written. ',\n",
       "  'weaknesses': \"* Although the introduced class conditional augmentation seems to help recovering some failures cases,  the overall performance of the model is not improving!  This unexpected behavior is worth more investigation\\n\\n* The last category of failures denoted 'semantically unrelated' remains unexplained \\n\\n* Minor: in line 267, 268: the authors claim that figure 3 shows the confusion between bath towel and pillow while it acctually shows the confusion between muzzle and sandal.\"},\n",
       " 'review_385': {'summary': 'The paper presents a meta study on the effects of data augmentation over classes. In particular, authors works on ResNet50 architectures trained on ImageNet, and show how for some classes, strong data augmentation drastically decreases the per-class accuracy. The paper focuses on random resized crop augmentations and specifically by varying the lowest possible crop size. Authors discuss these results in light of different types of overlap between classes and show how considering a different ground truth shows that the models are not always learning something wrong, but maybe learn to focus on object parts rather than whole objects. ',\n",
       "  'strengths': '- Interesting study overall, which extends prior work on the same topic. The paper exposes some effects that might be obvious, but does so in a systematic and well constructed manner. \\n- The paper is very well written, and well presented. It was easy to follow and to understand main points. \\n- Supplementary materials contain interesting plots and additional results nicely complementing the paper. ',\n",
       "  'weaknesses': '- Limited to one data augmentation strategy, it would be interesting to see how other potentially aggressive class-confusing augmentations effect the classification scores (eg. colour changes, contrast enhancements, affine transformations, etc.) interact with RRC and among them. I understand this would make such analysis considerably more complex, but in the end, those are commonly used and it rarely happens that one relies exclusively on RRC.  \\n- The study is strongly limited by the use of ImageNet only, other datasets have multilabel annotations. It would be really beneficial to understand the effects on other datasets, where the total number of classes is lower and potentially the relatedness across classes also reduced. \\n- Similarly, it would be interesting to understand if other CNN models or ViT would behave the same. I think it would nicely close the circle. I think such study on different models and different datasets would be quite interesting overall.\\n- In conclusion, although well done and well presented, I think this paper does not make a substantial contribution in this current form, but could potentially do so if the breadth and scope are extended.  \\n- I kept wondering what would happen if I train / fine tune the classifier in a multi-label setting, instead of just using ReaL as enhanced ground truth. It could be possible to do so using eg. coco? '},\n",
       " 'review_386': {'summary': 'The authors explore the role of random resize crop in ImageNet performance. First, they improve on analysis in prior work and show that class-level performance degradation has been over-stated, and that when multi-label annotations are used one of the labels is often still predicted. Next, by inspection, the authors find that many  classes whose accuracies are affected random-resize crop are either completely ambiguous (sunglass vs sunglasses) or co-occurring (suit, tie; car, wheel). Finally, they suggest an intervention which takes false positives into account in addition to false negatives, dramatically improving accuracy on most-affected classes while preserving overall accuracy.',\n",
       "  'strengths': 'Originality: The idea of using multi-label annotations to judge the severity of the mistakes is sensible.\\nThe idea of using False Positives for conditioning augmentation is an interesting one. \\nIn general, the idea of using labels in the training procedure as a conditioning mechanism outside of the loss is interesting. \\n\\nQuality: The methodology seems sound and the claims are supported by the evidence. \\n\\nClarity :The paper is clearly written and the figures are well understood. \\n\\nSignificance: The paper is significant in that it sheds light on a process which is often used as a black box (data augmentation), and moves us towards more bespoke models. It is the case that we often report best top-1 accuracies, averaged over a validation set, and that this obscures the variation in different kinds of mistakes. However, certain kinds of mistakes are much more expensive than other kinds. Then, improving performance for certain classes while retaining performance of others is an important intervention for developing deployable models.  This work takes a step towards the understanding needed for making these kinds of trade offs. ',\n",
       "  'weaknesses': '* The analysis is done only on a single model (supervised ResNet-50), on a single dataset (ImageNet). While I expect conclusions to be similar across other datasets/models, it would be interesting and important to confirm this. \\n\\n* Similarly, only consider RRC. What about other common augmentations? \\n\\n* ImageNet pretraining is frequently used for transfer learning. Does the class-conditional augmentation intervention impact transfer performance? '},\n",
       " 'review_387': {'summary': 'This paper studies Data augmentation (DA). Although DA improves overall accuracy, recent studies have pointed out that it can adversely affect individual class accuracy by up to 20% on ImageNet. This happens due to a lack of understanding of how DA impacts class-level learning dynamics. This research offers a framework to understand this interaction. By using high-quality multi-label annotations on ImageNet, it is found that most affected classes are inherently ambiguous, co-occurring, or involve fine-grained distinctions. Although multi-label annotations explain many previously reported performance drops, the analysis reveals other sources of accuracy degradation. It is demonstrated that class-conditional augmentation strategies, informed by this framework, can enhance the performance on classes negatively impacted by DA.\\n\\n\\n--------Post-rebuttal------------\\n\\nThe rebuttal has fairly addressed my concerns. Accordingly, I have improved my score.',\n",
       "  'strengths': 'This study conducts an analysis of data augmentation bias, a process that bears significant practical implications for real-world applications. The meticulous examination of such bias provides insight into how it affects and shapes models in practical scenarios.\\n\\nThe research specifically investigates the impact of random crop scale on model training. It is revealed that the class-level performance drop experienced during ImageNet training can be mitigated through multi-label annotation. Intriguingly, the primary cause of this drop is found to be the co-occurring, ambiguous, and noisy conditions present within the class labels. This discovery is not only fascinating but potentially inspiring, opening up new avenues for further exploration in this domain.\\n\\nThe study introduces a novel class-conditional data augmentation strategy. This innovative approach shows promise in further alleviating data augmentation bias, thereby enhancing the robustness and performance of models in real-world deployments.',\n",
       "  'weaknesses': 'This work is limited by only one augmentation method (i.e., random crop ) and only CNN-based architectures (ResNet and EfficientNet).'},\n",
       " 'review_388': {'summary': 'This paper studies the static output feedback $\\\\mathcal{H}_{\\\\infty}$ control problem. It proposes a derivative-free policy optimization algorithm via randomized smoothing and further provides sample complexity analysis for the cases with exact and inexact zeroth-order oracles. To validate the performance of the new algorithm, the authors also conduct some numerical experiments and compete against the model-based methods in the literature. ',\n",
       "  'strengths': '1. As the authors claim, the proposed algorithm is the first derivative-free policy optimization algorithm for constrained structured $\\\\mathcal{H}_{\\\\infty}$ control problem (there have been some works on the unconstrained setting).\\n2. The authors also consider the inexact oracle setting.\\n3. The paper provides both theoretical analysis and numerical experiments.',\n",
       "  'weaknesses': 'I am not very familiar with the problem studied by this paper and it looks fine to me. However, I feel like the paper is mainly a combination of existing techniques (such as randomized smoothing and gradient sampling with zeroth order feedback). Would the authors highlight any novel techniques they apply in the analysis or explain what makes the problem different from other nonsmooth nonconvex problems such that this paper is not simply A+B?'},\n",
       " 'review_389': {'summary': 'This paper focuses on the structured $H_\\\\infty$ control problem. They provide sample complexity bounds for policy optimization in $H_\\\\infty$ control problem. \\nThe results are provided for two separate scenarios namely: \\n- Exact Oracle Setting  (exact $J(K)$ for any $K$ is available, for the given closed loop system)\\n- Inexact Oracle Setting (the system matrices are not known)\\n\\nThe theoritical results provide the sample complexity of $H_\\\\infty$ norm estimation.\\nFinally, the paper provides a few numerical experiments supporting their theoritical results along with comparison to some model-based approaches. ',\n",
       "  'strengths': '- $H_\\\\infty$ control problem is one of the important setting in linear systems , which is well studied in adaptive control literature but has received less attention in recent learning theory literature unlike the standard LQR setting. The paper highlights the various challenges involved in the analysis of $H_\\\\infty$ control due to non-convexity and non-smoothness.\\n\\n- The Sample complexity of the $H_\\\\infty$ norm estimation are provided by exploiting the randomized smoothing techniques.\\n\\n',\n",
       "  'weaknesses': \"- The algorithm relies on access to an oracle. More discussion on the oracle is warranted. \\n- The simulation section in the main body (as well as the appendix) of the paper is meager. The presentation quality of plots included can be improved. \\n- Authors mention in the appendix that (line 806) that when necessary, one can reinitiate to avoid bad local minima, but how would one know that they are at a 'bad' local minima.\\n\"},\n",
       " 'review_390': {'summary': 'This paper considers solving the $H_\\\\infty$ control problem using zero-th-order policy optimization. The main results are sample complexity bounds for both the exact Oracle setting and the model-free setting. Numerical simulations are conducted to demonstrate the effectiveness of the algorithm.',\n",
       "  'strengths': 'This paper is well-written. The $H_\\\\infty$ control problem is known to be challenging and the policy optimization results are likely to be of great interest to the learning-in-control community. The sample complexity result, while not necessarily optimal, is the first non-asymptotic result in the literature.',\n",
       "  'weaknesses': '(1) Related Work: The related work section could be more structured. I went through [32] to complete the review of this work. It seems that the main technical tools are already developed in [32]. However, [32] does not provide any sample complexity result. What are the major technical challenges (and the ideas used to overcome them) in going beyond the global convergence in [32] to the sample complexity results in this work?\\n\\n(2) Theorem 3.7 and Theorem 4.2: Usually for high probability bounds, as the tolerance level $v$ decreases, more iterations are needed. However, for Theorem 3.7 and Theorem 4.2, as $v$ decreases, $T$ also decreases, which seems counter-intuitive. Moreover, the bound has a polynomial tail rather than an exponential tail. Is this an artifact of the proof or are exponential tail bounds not achievable?'},\n",
       " 'review_391': {'summary': 'This paper proposed a star-shaped denoising diffusion probabilistic model (DDPM), which extends DDPM to non-Gaussian noises. As a result, the backward/generative process requires conditioning on tails. The authors then propose an efficient tail conditioning strategy which works when the forward process follows an exponential family with linear parameterization. Duality between star-shaped and Markov diffusion processes are also established which provides theoretical support for star-shaped DDPM for its ability to go beyond Gaussian noises. The effectiveness of star-shaped DDPM is demonstrated on several experiments.',\n",
       "  'strengths': '1. This paper is written very clearly and well organized. \\n2. It also provides a general framework for DDPM that can incoporate no-Gaussian noises, where previous efforts are designed for specific noises and not generalizable to other distributions.\\n3. Duality between star-shaped and Markovian diffusion is established, which shows SS-DDPM and vanilla DDPM are equivalent in the Gaussian case. ',\n",
       "  'weaknesses': '1. While experiments on synthetic data demonstrate the ability of SS-DDPM to deal with non-Gaussian noises, the effectiveness of SS-DDPM on real data needs further verification. The current experiment on real data seems a bit inadequate.\\n\\n2. Star-shaped denoising diffusion models have been proposed before (Rissanen et al. (2022)), and there is no comparison to this previous method.'},\n",
       " 'review_392': {'summary': 'The paper presents the Star-Shaped DDPM (SS-DDPM), a general recipe for designing a diffusion model with a noising process lying in a general subset of the exponential family. With a Gaussian noising process, SS-DDPM recovers the DDPM. Diverse experiments on synthetic and practical image and text datasets demonstrate the effectiveness of the proposed SS-DDPM.',\n",
       "  'strengths': '(1) A general recipe for designing a diffusion model, termed Star-Shaped DDPM (SS-DDPM), is proposed.\\n\\n(2) The recipe is derived and analyzed in detail, with convincing statistical justifications.\\n\\n(3) Diverse experiments are conducted to demonstrate the effectiveness of the SS-DDPM.',\n",
       "  'weaknesses': '(1) Many technical details are given in the supplementary material.\\n\\n(2) The advantages and disadvantages of the SS-DDPM over the DDPM are not explicitly discussed.'},\n",
       " 'review_393': {'summary': 'This paper proposes a non-Markovian diffusion model named the star-shaped diffusion model that generates a sequence of noised image from the original image in the forward process.\\n\\nThis paper studies the theoretical foundation of such new type of model showing that if the forward process is based on a subset of the exponential family of distribution, a tail statistics is sufficient statistics for the reversed process. Based on such a foundation, the reversed process can be conducted.\\n\\n',\n",
       "  'strengths': 'The overall structure of this new diffusion model is new, novel and interesting.\\n\\nThe application of PKD theory is sound.',\n",
       "  'weaknesses': 'Although the model is pretty novel and new, there is a lack of motivation from practical problems -- the experiment are weak and kind of toy. A showcase of the unique application of this model is appreciated.\\n\\nLack of comparison of some other non-markovian diffusion on constrained domains such as [1,2]\\n\\n[1] Learning Diffusion Bridges on Constrained Domains\\n[2] First Hitting Diffusion Models for Generating Manifold, Graph and Categorical Data'},\n",
       " 'review_394': {'summary': 'This paper proposes a star-shaped diffusion probabilistic model, which is non-Markovian, and more like an autoregressive way of predicting intermediate states xt. Specifically, the authors define a forward process q(xt|x0) that each intermediate state xt is directly related to the initial state x0. The reverse process is defined by p(xt|xt, xt+1, ..., xT). To efficiently solve p(xt|xt, xt+1, ..., xT), the authors propose a compressive representation Gt(xt, xt+1, ..., xT) to extract all the information of x0 contained in history states {xt+1, ..., xT}, so the modified distribution becomes p(xt|Gt). The training and inference go in a similar way as DDPM. Simple experiments show that the proposed method performs better than the baseline methods MTD and DDPM.',\n",
       "  'strengths': '1. This paper provides a novel view of the definition of diffusion models and is very inspirational. It is worth thinking about whether the Markov process is the best design choice considering the fact that the whole history {xt, xt+1, ..., xT} contains more information than a single state xt. \\n\\n2. The author proposed a novel diffusion model with basic evaluations, which may inspire the community for further exploration. ',\n",
       "  'weaknesses': '1. The presentation needs to be improved: (1) T, Ωt, and ht in Eq.13 lack interpretation; (2) It is not well proved that Gt covers all the information of x0 in {xt, xt+1, ..., xT}. Although the authors mention that there are explanations in the supplementary material, you need to ensure the reader has a basic understanding by just reading the paper.\\n\\n2. The advantage and application value of the proposed method is not clear. For example, can you provide a practical case that DDPM can not address while SS-DDPM can?\\n\\n3. The experiments are too simple and not persuasive. To prove the advantage of SS-DDPM, it is encouraged to compare with state-of-the-art methods on diverse benchmarks, \\n\\n4. As the authors said in line 128, \"In general case the dimensionality of Gt would grow with the size of the tail\"\\n\\n4. There is no evidence that SS-DDPM can apply acceleration methods like DDIM.'},\n",
       " 'review_395': {'summary': 'The paper introduces a new probabilistic structure for denoising models that does away with a Markov forward process. The authors derive the reverse process in terms of a sufficient statistic that allows for efficient reverse sampling. The form of the model is derived for a variety of noising distributions and the model is evaluated on a range of different data modalities.',\n",
       "  'strengths': 'This work can potentially help many people in the generative modelling community because there has been a lot of work trying to extend corruption process to different data types e.g. discrete, manifold data and this paper has a general recipe that appears to work for a large chunk of these and more which could be really helpful when encountering non-standard data types. The example of the Wishart distribution on positive definite matrices is very cool.\\n\\nI can foresee many extensions to this work, looking to bring more distributions into the framework, extending it to continuous time which could bring up a lot of interesting technical problems and broadening the class of possible distributions by introducing approximate sufficient statistics.\\n\\nThe paper has a good suite of experiments on a variety of real world practically relevant data such as text and images and the performance of the model seems good',\n",
       "  'weaknesses': \"I think the paper could benefit from more intuitions and visualizations for the role of G. Initially, the model seems strange as x_t can jump a lot between x_t and x_{t+1} due to going to x_0 and resampling q(x_t | x_0). However, it seems that G instead is the smoothly changing statistic that is more analogous to the state in previous diffusion models. For example, I think figure 9 in the supplementary is quite interesting and could be moved to the main as it shows that a correctly normalized G looks very similar to the state in norm diffusion models. It would be good to have more intuition as to the role of G and how it is more closely linked to the 'x_t' of normal diffusion models.\\n\\nFurther, there is not really a experiment that really motivates the use of these more interesting distributions in a scenario where normal diffusion models really don't work at all. I appreciate that this is somewhat an open question at the moment in the literature more generally and the community has already proven an interest in adapting the corruption process to the data modality of interest so this may not be a big requirement.\\n\\nEdit after rebuttal: I have read the authors rebuttal and appreciate the answers to my questions about the derivations and the FID scores. I intend to keep my score as it is.\"},\n",
       " 'review_396': {'summary': 'This introduces the so-called Star-Shaped DDPM (SS-DDPM). Instead of using Gaussian forward diffusion step in a Markovian manner, the diffusion process is directly conditioned on the data, in order to construct the \"true\" reverse process (posterior), resulting in the star-shaped diffusion process. This opens the door for using other transition process as demonstrated in the paper.  ',\n",
       "  'strengths': '1. This is a solid paper that I have reviewed so far.  All the conclusions are backed by the theory.\\n2. The paper is well presented and easy to follow the main the idea with full materials in the supplementary\\n3. The idea presented in the paper is novel and may have wide applications.',\n",
       "  'weaknesses': 'Frankly speaking, I like to see this paper to be accepted.  I cannot form any weakness.  The only point I may raise is it would be much much better for the authors to share their implementation source code.'},\n",
       " 'review_397': {'summary': 'This paper propose a novel approach of breaking down NAS problem into a Combinatorial Optimization problem. ',\n",
       "  'strengths': 'The paper is well-written and easy to follow. The authors provide clear explanations and examples throughout the paper. \\n\\nBreaking down the search problem into a Combinatorial Optimization problem seems novel and interesting, and reducing the search cost to polynomial time, which is clearly a breakthrough to the research community. \\n\\nLayerNAS can be applied to operation, topology and multi-objective NAS search\\n\\nResults on ImageNet seems to surpass state-of-the-art methods by a clear margin, evidencing their effectiveness of LayerNAS. \\n\\n',\n",
       "  'weaknesses': 'I do not particular have a question, this paper seems to be easy enough to follow. '},\n",
       " 'review_398': {'summary': 'The authors propose LayerNAS with polynomial complexity. Namely, this work transforms the multi-objective NAS problem into a Combinatorial Optimization problem with proper assumptions. \\nLayerNAS is benchmarked against recent NAS arts on ImageNet classification task, as well as on dedicated NATS-Bench in terms of quality, stability, and efficiency. \\nAlgorithm details and searched architectures are provided, which might benefit the community. ',\n",
       "  'strengths': '1. The paper is clearly written and easy to follow. The detailed algorithm and searched architectures are provided, which makes the results replicable. \\n\\n2. Extensive results are reported on NASBench-101, and the results are promising. \\n\\n3. The limitation of the assumptions are properly discussed. \\n\\n4. Performing NAS in polynomial complexity is of good research impact and real-world applications. ',\n",
       "  'weaknesses': '1. There are some format flaws, e.g., the abstract should be a single paragraph. \\n\\n2. Table 2 is not informative enough. It would be better to include more details such as training epochs, augmentations, whether distillation is utilized or not, etc. for comparison. Plus, sometimes it is hard to tell whether LayerNAS is better than previous arts when MAdds or Params are not aligned (e.g., LayerNAS has 50% more params than MobileNetV3-Small). I wonder if it is possible to strictly align both params and MAdds and compare accuracy, as anyway, LayerNAS is a multi-objective search. \\n\\n3. I wonder if there are latency-driven search results. '},\n",
       " 'review_399': {'summary': 'The paper tries to overcome a drawback of Neural Architecture Search (NAS), an enormous search space that hard to traverse whole space to design a well-optimized network.\\nFrom an assumption that a previous layer in a network doesn’t affect the subsequent layers, the paper converts multi-objective NAS to a combinatorial optimization problem.\\nWith the proposed method, the paper designs optimized networks layer by layer, unlike other works that design the whole network simultaneously. It leads to reducing the search complexity of NAS to polynomial complexity.',\n",
       "  'strengths': '- Writing is easy to follow.\\n\\n- The paper compares the proposed method with other methods fairly with NATS-Bench.',\n",
       "  'weaknesses': '- The proposed method that removes networks from search space by their costs is not novel.\\n\\n- The search cost of the proposed method is still worse than one-shot NAS.\\n\\n- The paper naively analyzes the cost of searched networks with MAdds, omitting other metrics such as energy consumption or latency, etc.'},\n",
       " 'review_400': {'summary': 'The paper introduces LayerNAS, which is a method for neural architecture search (NAS). The idea is to reduce the computational cost of NAS, which is exponential in the number of layers. As such, the paper introduces a layerwise search option with the idea being that the current layer can be directly determined based on the results of the previous layers. This enables polynomial computational complexity. The paper goes one step further and establishes the inclusion of the cost-constraints, e.g. in eq. 4. LayerNAS is then empirically validated in ImageNet and in a standard benchmark of NAS, which includes cifar10, cifar100 and Imagenet16 datasets. \\n\\n\\n\\n**Post rebuttal**: I appreciate the effort by the authors and their numerical evidence. I would urge the authors to include the references and the discussion in the camera-ready version. I would strongly encourage the authors to also include the numerical result on the cost per layer (see answer 2 in the original responses) and the additional results in transfer learning. One thing that I believe should be explained better in the main paper is the reasoning for the separation from larger architectures, e.g. the somewhat arbitrary 600 MAdds.',\n",
       "  'strengths': 'The reduction of the computational cost of NAS is an important aspect that makes the paper relevant for the NeurIPS community. Besides, a number of papers on NAS are published in NeurIPS and related conferences (**relevance**).  The solution proposed for the layerwise search has appeared before, but the paper makes a complete framework to support the idea and empirically validates the framework. In addition, the paper makes a clear statement of the limitations and the assumptions that led to those (**clarity**). This enables the research community to extend this paper further.',\n",
       "  'weaknesses': 'I am not sure what the novelty of the proposed method is, this is not clearly stated at the moment. \\n\\nI find that the train-free methods of NAS are more important for the story and as alternative methods than the two lines devoted to the end of the related work. Having said that, I do understand that they do not cover the contribution of this work.'},\n",
       " 'review_401': {'summary': 'This work proposes a novel GAN for diverse shape completion from partial point clouds. To enable diverse completions, a style-based generator is introduced that leverages style codes from a learned distribution of complete shapes for style modulation. Further, a multi-scale discriminator and a diversity penalty are proposed for better diversity.',\n",
       "  'strengths': 'The paper is well-written and easy to follow. The experimental evaluation is thorough and supports the main claims in the paper. Both quantitative and qualitative results demonstrate the efficiency of the proposed approach over existing works.\\n',\n",
       "  'weaknesses': 'While the supplementary includes an ablation with different diversity penalties, it should also contain an experiment without the diversity penalty for completeness. As the diversity penalty is one of the contributions of this work, I would consider moving the study to the main paper. \\n\\nIt would further be interesting to report the nearest neighbors in the training set for the completed regions in the results because the style encoder learns a distribution over the completed shapes.\\n\\nA discussion of failure cases should be added to the supplementary.\\n\\nFor completeness, the missing values in Table 3 for “Ours \\\\dagger” should be added.\\n'},\n",
       " 'review_402': {'summary': 'The goal of multimodal shape completion is to generate many different plausible completions of an incomplete shape. Based on the conditional GAN, this paper introduces two key concepts to improve the diversity and accuracy of multimodal completion. One is to use style codes instead of random noise, which means better distribution of complete shapes. The other is the use of multiscale discriminators to refine the predicted shapes from coarse to fine. The method is evaluated on both synthetic and real data sets and shows significant improvements over comparable methods based on standard metrics.',\n",
       "  'strengths': '1. The results of multimodal completion look very clean and diverse. The numerical results show a new SOTA.\\n\\n2. The use of the learned style codes instead of Gaussian noise is reasonable since the former is more similar to the distribution of complete shapes.',\n",
       "  'weaknesses': '1. Ablation study with and without $\\\\mathcal L_{comp}$ and $\\\\mathcal L_{div}$ is not provided.\\n\\n2. The flat and thin structures of the shapes generated by the proposed method look good, while other methods are more noisy. For the task of multimodal completion, this is quite impressive.\\nAccording to Figure 5 in the supplementary file, the main reason is probably the use of multiscale discriminators, since the results of a single scale are noisy. Is this true? And why are 4 scales used? If more than 4 scales are used, is the quality continuously improved?\\n\\n3. The distribution of style codes should better reflect the actual shape distribution. To better verify this, a visual analysis comparing the distribution of the different conditional codes is helpful.'},\n",
       " 'review_403': {'summary': 'The paper proposes a diverse shape completion method by extracting style codes from complete shapes and learning a distribution over them. Moreover, diversity penalties and discriminators at multiple scales are introduced as well to prevent conditional modal collapse to generate various object shapes. To verify the effectiveness of the method, various experiments are conducted, and promising results are observed.  ',\n",
       "  'strengths': '1. The paper is well written and organized.\\n2. The methods are interesting and promising results are obtained. ',\n",
       "  'weaknesses': \"1. According to line 156, “style codes” carrying category information are learnt from the distribution of complete shapes, however, the goal is to generate diverse shapes not only among different classes but also within the same class. Hence, how to get the diverse information for a single class seems missing in the paper. \\n2. What is the difference of style encoder technique compared to VAE? According to the illustration in Sec. 3.2, it looks the same to VAE, which potentially results in limited novelty of the proposed style encoder. \\n3. It would be better to also show some ablation studies on the network architectures by removing specific components to see how different parts contribute to the overall performances, which could be done by settings specific loss's weight to 0.\"},\n",
       " 'review_404': {'summary': 'The paper proposes to reconstruct partial point cloud inputs using a multi-modal process, where the generator can output multiple plausible shapes. The key idea is to have a separate network (StyleEncoder) that extracts style from an input, in addition to a separate network (PartialEncoder) that extracts structural information, that are then combined to generate the final reconstruction. Another contribution is a multi-scale discriminator that checks real and fake pairs at multiple generator output stages. The entire pipeline is essentially a conditional GAN network for generating 3D shapes. ',\n",
       "  'strengths': 'The paper proposes to address an important problem where there could be multiple potential reconstructions given a partial input. Limitations of recent work (SeedFormer [7]) are addressed with a clever network design strategy. The method is evaluated on three public datasets (3D-EPN, GSO, and Part-Net) with promising quantitative results.',\n",
       "  'weaknesses': 'The methodology section is difficult to follow, and I found it hard to understand the training process. In addition, it seems that the proposed technique is heavily based on previous work (e.g., SegFormer). It may help to explain the key technical contributions with respect to these previous works and defer the reader to the other papers for understanding technical details. \\n\\nIn addition, the validation of the proposed technique is rather limited. The training procedure, and validation steps are not clearly described. Is the method sensitive to shape orientation? What type of data augmentation is used during training, and is it trained on a per-category level (thus learning certain shape priors) or category-agonostic level? \\n\\nI would have expected to see ablation experiments with same methodology but different network architecture. Finally, the authors evaluate on PartNet, yet, never quantify part level accuracy.\\n\\nIn Tables 5 and 6, ablation studies of the style code and discriminator have very similar MMD metric but large UHD metric. I did not understand the choice and motivation behind these metrics. Why not use standard Hausdorff distance instead?\\n\\nFinally, the method is geared toward generative multiple outputs given a single input, yet this capability is never evaluated. I would have expected to see additional examples where multiple plausible reconstructions an input can have, followed by a user study or a qualitative evaluation of the results. '},\n",
       " 'review_405': {'summary': 'This paper proposes a new conditional generative network that can produce diverse completions of a partially observed point cloud. The stochasticity is introduced via style modulation. A style code is learned to explicitly carry shape category information leading to better completions. Moreover, diversity penalties and discriminators at multiple scales are also set to prevent conditional mode collapse. Experiments show that the proposed framework can achieve significant improvements in respecting the partial observations while obtaining greater diversity in completions.',\n",
       "  'strengths': 'The results on different datasets show the effectiveness of the proposed method.',\n",
       "  'weaknesses': '1.\\tThe main target of this paper is to achieve diverse synthesis. However, no such visual samples are provided. The authors should provide the diverse synthesis for different categories in the main paper.\\n\\n2.\\tHow to decide the optimal values for loss weights in Eq. 7? Although the authors claim that the same loss weight setting can lead to good results on all experimental datasets, the experimental datasets only contain several categories. More categories should be considered into analysis.\\n\\n3.\\tThe idea of this paper is derived from the 2D StyleGAN. The difference about the idea should be clearly indicated.\\n\\n4.\\tThe method has not compared with SOTA methods that use the diffusion model, like [30, 31]. And this method should also support unconditional point cloud synthesis?\\n'},\n",
       " 'review_406': {'summary': 'This paper proposes a novel solution for blind face restoration. Instead of modeling the degradation process, the authors propose to model the desired properties of high-quality images as classifiers. Similar to guided diffusion, the authors guide the diffusion generation process with specific classifiers to achieve image restoration. Visual results well proved the effectiveness of the proposed methods.',\n",
       "  'strengths': '1. The idea of modeling the desired properties of high-quality images as classifiers is novel and interesting.\\n2. The proposed method can solve blind image restoration and can restore images following the reference properties, e.g., color and identity, which is novel and practical.\\n3. The paper is well-written and easy to follow.',\n",
       "  'weaknesses': '1. There seems no quantitative evaluation. It is not persuasive enough with only visual comparisons. \\n2. The setting of hyperparameters may be difficult.\\n3. Some overclaims. For example, the author said in line 115, \"Our partial guidance does not assume any prior knowledge of the degradation process.\" However, PG needs to know the degradation type. For inpainting, the mask is also needed. (2) '},\n",
       " 'review_407': {'summary': '\\tThis paper proposes partial guidance, an approach exploiting pre-trained diffusion models for face restoration. Instead of making assumption about the specific degradation process, partial guidance models properties of high-quality images such as structure and color statistics to implement classifier-guidance during the reverse diffusion process. This approach suits a range of restoration task and can be extended to composite tasks. Experiments demonstrate the effectiveness of the proposed method.',\n",
       "  'strengths': '-\\tThis paper considers exploiting image properties irrelevant to specific degradation process to tackle versatile face restoration problems, which has demonstrated effectiveness in experiments.\\n-\\tThe qualitative results of the proposed method provided in the paper and the supplementary material are sufficient and impressive.\\n',\n",
       "  'weaknesses': '-\\tExcept blind face restoration task, more quantitative results are expected in the remaining tasks like face colorization and face inpainting.\\n-\\tIn blind face restoration task, the pretrained restorer (such as Real-ESRGAN stated in the supplementary material) is employed and finetuned to predict smooth semantics, but these intermediate results are missing, and the improvement of the proposed method compared to the pretrained/finetuned restorer is not demonstrated or analyzed.\\n'},\n",
       " 'review_408': {'summary': 'This paper proposes to use some simple properties to guide the reverse diffusion process. The proposed approach makes no assumptions about the degradation process. This paper also shows many different face restoration visual results to demonstrate the superiority of the proposed method.\\n',\n",
       "  'strengths': '1.\\tThe proposed method has been experimented with in many different face restoration tasks, which demonstrates that the proposed method can be easily adapted to other face restoration tasks.\\n2.\\tOverall, this paper is well-writing and easy to understand.\\n',\n",
       "  'weaknesses': '1.\\tThe main contribution of this paper is using some simple properties to guide the reverse diffusion process, which is inherited from classifier guidance [7]. What is the technical and original contribution of this paper? Please discuss the technical differences between the proposed work and classifier guidance [7].\\n2.\\tHow to choose the properties that are used in different tasks? This deserves an ablation study. Please show the influence of some different properties.\\n3.\\tThis paper claims one of the advantages of the proposed method is no assumption of the degradation process. As far as I know, the DifFace also does not need to know the degradation process. What is the advantage of the proposed method against DifFace?\\n4.\\tNo quantitative results are found in the manuscript. Only visual results are not enough to evaluate the proposed method. Please provide a fair quantitative comparison against other comparing methods such as commonly used datasets CelebA-Test, and three real-world testing datasets proposed in GFPGAN.\\n5.\\tThe inference time is also important to evaluate the proposed method. Please provide the inference time comparison again with other comparing methods.\\n6.\\tSome failure cases can contribute to understanding the limitation of the proposed method. Please show some failure cases.\\n'},\n",
       " 'review_409': {'summary': 'The current restoration approaches based on diffusion prior rely on prior knowledge of the degradation process,  and thus fail to seamlessly adapt to different scenarios. Motivated by this, the paper proposed a \" partial guidance\" approach to directly modeling the distribution properties of high-quality images and then exploit it to serve as guidance for the diffusion process. The extensive experiments demonstrate the advantage of the proposed approach.',\n",
       "  'strengths': '- The proposed method diverges from traditional practices of modeling the degradation process, and instead, focuses on modeling the desired visual properties of high-quality images. The learned vision cues are then served as diffusion guidance for the generation process. This motivation and the proposed model are technically sound to me. As demonstrated in the paper, it showcases adaptability to different degradation situations, yielding outstanding results.\\n\\n- The experiments conducted in the study seems solid, featuring comprehensive comparisons with various baseline approaches.',\n",
       "  'weaknesses': \"- For face restoration, it's important to make sure the restoration is performed in an identity-preserving way, and quantitative evaluation regarding this is crucial. However, such quantitative evaluation seems to be missing in the paper. \\n\\n- To clarify further,  I have no doubt the image quality of the proposed approach outperforms the baseline, but I'm concerned if the quality is improved at the cost of degradation in identity. So it's important to get a quantitative evaluation regarding this\"},\n",
       " 'review_410': {'summary': 'This paper, following the framework of Balasubramanian et al., shows that for target distributions that are non-log-concave, isoperimetric inequalities on subsets of the state space will yield fast mixing for the conditional distributions of MCMC on that space. This adds formal justification for the observed phenomena of metastability and “local convergence”. Additionally, some analogous conditional convergence results are also reported for a random walk on a hypercube.\\n',\n",
       "  'strengths': 'The definition and usage of these local isoperimetric conditions is entirely novel, as well as the local mixing results. In particular, the mixing rates seem to offer very good insight into the phenomenon of “metastability”, i.e. that particular modes may be well-explored while the global structure is not correct. \\n\\nThe paper is well illustrated with examples such as the Gaussian mixture and the posterior sampling example, with transparent computation of the constants. In particular, it is easy to see when the conditions of the paper hold, and to compute the resulting rate estimates.\\n\\nThe hypercube sampling result is novel, although it is difficult to assess this in the context of existing literature since the assumptions/results differ greatly.\\n\\nExperimental evidence is also provided to quantify the phenomena of local convergence.\\n',\n",
       "  'weaknesses': 'The rate of local mixing in both local LSI and local Poincare cases are quite bad. See my remark in the “Questions” section.\\n\\nThe discrete state space case is difficult to assess compared to other results for discrete space MCMC. If this is to be a main result in the paper, I would recommend a more detailed survey of the literature on discrete space MCMC with relevant comments be included in the Related Work.\\n\\nThe experiments are not surprising and seem to illustrate the same phenomena as seen in earlier works on multimodal sampling, but I would argue that they are still fairly useful illustrations in the context of this paper. In my opinion, the experiments section could be shortened.\\n\\nThis paper could benefit from some proofreading to catch grammatical mistakes, of which I was able to find quite a few.\\n\\nTo summarize, I feel that this paper makes unique contributions to the theory and intuition of MCMC algorithms, and the issues with it are relatively minor. Therefore I am happy to recommend acceptance.\\n'},\n",
       " 'review_411': {'summary': 'This work studies the convergence of MCMC algorithms for sampling from non-log-concave distributions. This is much less well-understood than the log-concave setting. The authors introduce the notion of conditional mixing, this occurs when the markov chain is close to the true (conditional) distribution when conditioned on being in some specific part of the space. They give sufficient conditions under which conditional mixing occurs. They give applications to sampling from mixture distributions of gaussians and related problems.',\n",
       "  'strengths': 'The authors propose a new framework to go beyond log-concave sampling, an important problem in the sampling literature and give evidence for its utility. They show that in some cases conditional mixing can appear very quickly, whereas global mixing provably takes much longer.\\n\\nThe paper is overall well-written.',\n",
       "  'weaknesses': 'I think non-expert readers could benefit from a high-level technical overview.'},\n",
       " 'review_412': {'summary': 'The paper studies MCMC algorithms like the Langevin dynamics and Gibbs sampler on non-log-concave distributions. Many natural distributions are non-log-concave and multimodal, for example, mixtures of Gaussians and the posterior distribution of Gaussian mixtures. While classical results show that MCMC algorithms suffer from slow mixing on such multimodal distributions, the paper shows that when isoperimetric inequalities such as Poincare or log-Sobolev hold on a subset X of the state space, the conditional distribution of the MCMC iterate over X mixes fast to the conditional distribution of the target distribution on X. Thus, the paper shows that while MCMC algorithms converge to the true global distribution slowly, it can still converge very fast locally. For example, on a mixture of two isomorphic Gaussians, the Langevin dynamics (LMC) converges to the true conditional distribution around each mode but might put the wrong weight on the two Gaussian components. i.e. the true distribution is mu = 1/2 N(-u, sigma^2) +1/2 N (u, sigma^2) but the distribution of the LMC might be 1/3 N(-u, sigma^2) + 2/3 N(u,sigma^2). To show these results, the paper uses that for any target distribution mu, including non-log-concave ones, the LMC quickly converges to a distribution nu whose Fisher information to mu is small [Balasubramanian, Chewi, Erdogdu, Salim, Zhang—PMLR’22], then uses isoperimetric inequalities for the conditional distribution of mu on subsets of the state space to show that if the conditional distribution of mu on S satisfies isoperimetric inequality, then either nu puts small mass on S or the conditional distribution of nu on S is close to that of mu on S in Kullback-Leiber or chi-square distance (see Lemma 1, Corollary 1 for the case when the conditional distributions satisfy log-Sobolev inequalities, and Lemma 2, Theorem 2 and Corollary 2 for the case when the conditional distributions satisfy the weaker Poincare inequalities). Note that this is essentially the best statement one can hope for: for example, if mu is a mixture of two Gaussians whose centers are very far apart, and the LMC is initialized at the center of the first Gaussian, then the LMC will put almost all mass on the first Gaussian component and almost 0 mass on the second Gaussian component and one cannot have any reasonable guarantee about the conditional distribution of the LMC iterate on regions around the mode of the second component. In Theorem 2, the paper proves an analogous result for Gibbs sampler on discrete state space such as the hypercube.  For a distribution mu supported on the hypercube {0,1}^d, the Gibbs sampler operates by picking one random coordinate and flipping the value at that coordinate from 0 to 1 or 1 to 0 with probabilities chosen so that mu is the stationary distribution (see Section 5). The paper shows that if the vertices of the hypercube can be partitioned into subsets X_1,.., X_m such that on each subset, the Markov chain induced by the Gibbs sampler has a large spectral gap, then either the distribution nu produced by the Gibbs sampler puts small mass on X_i or the conditional of nu on X_ is close to that of mu on X_i. ',\n",
       "  'strengths': 'The paper shows an interesting result using relatively simple techniques. While fast convergence of LMC iterates in Fisher information for general non-log-concave distribution and local isoperimetric inequalities are known and used in previous works (see [Balasubramanian, Chewi, Erdogdu, Salim, Zhang—PMLR’22] and [Mou, Ho, Wainwright, Bartlett, Jordan’2019]), the paper cleverly combines these two ingredients together to show local mixing of familiar MCMC algorithms likThe paper shows an interesting result using relatively simple techniques. While fast convergence of LMC iterates in Fisher information for general non-log-concave distribution and local isoperimetric inequalities are known and used in previous works (see [Balasubramanian, Chewi, Erdogdu, Salim, Zhang—PMLR’22] and [Mou, Ho, Wainwright, Bartlett, Jordan’2019]), the paper cleverly combines these two ingredients together to show local mixing of familiar MCMC algorithms like the LMC and Gibbs sampler on multimodal distributions. The main results appear to be novel and correct. I verify the proof of Lemma 1, Corollary 1, and Lemma 3.e the LMC and Gibbs sampler on multimodal distributions.  ',\n",
       "  'weaknesses': 'The result on mixtures of Gaussians requires the assumption that the Gaussian components share the same covariance. It’s unclear if this assumption is natural, and the author(s) don’t give any justification for this assumption.\\nThe paper has a few typos. Details below.\\n- Proof of Lemma 1, supplement, appendix A: The claim is either $\\\\mu(S) \\\\leq sqrt{\\\\epsilon}/sqrt{\\\\alpha}$ or $Ent_{\\\\pi|S}(\\\\mu|S || \\\\nu|S )\\\\leq sqrt{\\\\epsilon}/sqrt{\\\\alpha}$ but the proof instead show that either $\\\\mu(S) \\\\leq \\\\sqrt{\\\\epsilon}$ or $Ent_{\\\\pi|S}(\\\\mu|S || \\\\nu|S )\\\\leq sqrt{\\\\epsilon}/\\\\alpha.$ The fix is simple, in line 416, it should be $\\\\mu(S)\\\\leq \\\\sqrt{\\\\epsilon}/\\\\sqrt{\\\\alpha}$ and in line the following displayed equation, the rhs should be $\\\\epsilon/(\\\\sqrt{\\\\epsilon}/\\\\sqrt{\\\\alpha}) = \\\\sqrt{\\\\epsilon \\\\alpha}.$\\n- In proof of Lemma 3, supplement, appendix C.1: c is undefined, though I believe c = min_i w_i so that c\\\\leq w_j and cp_j \\\\leq w_j p_j holds in the first line of the proof. The proof, Lemma 3 only proves that p |S_j satisfies LSI with constant 1/min_i w_i sigma^{-2},  but lemma 3 claims that the LSI constant is max_i w_i/min_i w_i sigma^{-2}. However, 1 \\\\leq m max_i w_i where m is the number of components/parts in the partition of the state space, so the bound the proof achieves is only worse than the claimed bound by a factor of m, which doesn’t significantly affect the result.\\n-In the statement of Lemma 2, in both the main paper and supplement, pi satisfies PFI -> pi satisfies PI.\\n-In section 4.3.1 of the main paper, line 210, P is undefined, but I believe the author(s) mean U.\\n-In Lemma 5, lines 239 and 240 of the main paper, the author claims that the target distribution satisfies local LSI, but its proof (Lemma 13, line 467 of the supplement) states that the target distribution only satisfies local Poincare inequalities.\\n\\n'},\n",
       " 'review_413': {'summary': 'This paper introduces a new concept of conditional convergence of an algorithm (i.e. convergence of the distribution restricted to e.g. a local mode), and presents extension of recent results using e.g. Poincare Inequality to bound this new measure.',\n",
       "  'strengths': 'I think this paper tackles an important problem: sampling from multi-modal distributions is likely to get stuck in a local optima and so understanding how well it samples from that mode is sensible (particularly when thinking about how a sampling based approach compares to an optimisation one).\\n\\nThe idea and definition of conditional convergence is new and interesting -- and one could see a new body of research around this type of topic.\\n\\nThe theory is based on a single, simple results (Lemma 1) which can then be used to generalise existing results on convergence to conditional convergence.',\n",
       "  'weaknesses': 'The main weakness is that the current result, e.g. Corollary 1, are weaker than one would hope. In particular \\n\\nCorollary 1 seems to have a time-dependent step-size (so to understand pi_T we need a smaller step size as T increases). This is different from how algorithms are implemented.\\n\\nThe conclusion after corollary 1 does not make sense to me. “Either the probability mass … over S converges to 0, or…” : But whilst LMC can converge slowly, it still converges to pi (if we ignore the discretisation error). Thus surely for any set S that is not a null-set of pi we have pi_T(S) will be non-zero in the limit as T goes to infinity?\\n\\nMore generally, this corollary is quite the result you want. You want something that says “if I have a partition of the the state-space in sets S_1,S_2,\\\\ldots, and observe that the proportion of time LMC stays in S_i is greater than … then the LMC output restricted to S_i will be close to pi restricted to S_i” or similar. \\n\\nSo I struggle to really understand the practical importance of the result.\\n\\nSeparately, the presentation could be improved in places: \\n\\nE.g. missing “the”s for *the* local Poincare inequality, and *the* Poincare Figure information (and e.g. “fisher”->”Fisher”, gaussian to Gaussian etc.); also “Gibbs sampling on discrete state *spaces*” etc.\\n\\nWhen describing Langevin Monte Carlo, there are two different approaches depending on whether you use a Metropolis correction. The paper could be clearer about what its results relate to. Form the definition in Algorithm 1 it looks like you are considering the unadjusted Langevin algorithm (ULA).\\n\\nIf you are using ULA, then there is a discretisation error — i.e. the stationary distribution for ULA is different to that of the Langevin diffusion/the distribution you want to sample from. I think the paper could be up-front about this, and discuss how this impacts the results in the paper. I also wonder if informal statements such as “The convergence of LMC” (top p.4) are really referring to the convergence of the Langevin diffusion and not ULA. The paper does comment on “PI .. implies the convergence of LMC when the step size h is small”, but this could be more precise. I guess part of the confusion is that you are commenting on converging, but it is not completely clear what you are converging to. In general the ULA will not converge to pi for a fixed (albeit small) step-size as the discretisation error will change the stationary distribution.\\n\\nThe argument under Fisher information seems to ignore the discretisation error — i.e. be just for the Langevin diffusion, but is says for LMC. (Though this is corrected in Proposition 1 which is for LMC). This part could have been improved with some references to the results you are summarising.\\n\\n[It may be that a cleaner presentation would be to have had a subsection commenting on the approximation error between ULA and the Langevin diffusion, and then presenting the results just for the Langevin diffusion?]\\n\\n'},\n",
       " 'review_414': {'summary': 'The paper proposes RFold, a simple and effective RNA secondary structure prediction algorithm. It adopts attention maps to learn informative representations for RNA rather than hand-crafted features. Then, based on a decoupled optimization process, RFold simplifies and guarantees satisfying the hard constraints on the formation of RNA secondary structure. Through the empirical experiments, the authors demonstrate that RFold achieves state-of-the-art performance with better computational efficiency compared to the previous works.',\n",
       "  'strengths': '- The proposed decoupled optimization seems simple, but surprisingly effective for RNA secondary structure prediction. To the best of my knowledge, the proposed method is novel in the domain and might be promising for the broader machine-learning community.\\n- The proposed method shows great performance in three RNA benchmark datasets outperforming the previous state-of-the-art method by a significant margin. Some issues need to be addressed regarding the experiment setup (please refer to the weaknesses), but the improved performance seems truly impressive.',\n",
       "  'weaknesses': 'Major comments:\\n- [Data Split] To best approximate real-world applications that may require the prediction of novel structures, RNAs from the train/val/test set should bear minimal sequence and structural similarities. In contrast, it seems the authors have split datasets so that each RNA family has a similar fraction in each set. I think it may overestimate the true prediction performance of RFold. Likewise, “generalization to other datasets” experiments do not provide information about sequence/structure similarities between the datasets. If they are similar, it may not be a fair evaluation of generalization performance.\\n- Since the authors stated deep learning methods do not ignore the biologically essential structure such as pseudoknots, can you provide additional separate evaluation under the (non-) existence of pseudoknots?\\n- According to UFold, the bpRNA dataset contains mostly within family RNA species and does not adequately show the true generalization performance of the models. Can you provide additional evaluations with cross-family experiments?\\n- [Inference Time] It’s unclear whether the results are credible. The inference time can be quite different based on what type of machine (CPU, GPU, etc.) is used for the measurement. Since the other results seem to be excerpted from the UFold paper, the environments of UFold and RFold are likely to be different.\\n- [Reproduciblity] Architectural hyperparameters are missing. In addition, training codes do not seem to be included in the supplementary.\\n\\nMinor comments:\\n- [Data Split] The authors stated that they split the RNAStralign dataset following the E2Efold paper. Can you confirm that all the methods including RFold used the same data splits? RNA sequences often have high sequence and structure similarities, so if you used different data splits it might affect the performance. \\n- As the authors stated, other algorithms often post-process the outputs to satisfy the constraints. Can you also show how the results are improved for RFold-E/S with the post-processing?'},\n",
       " 'review_415': {'summary': 'This work presents an efficient and accurate approach for end-to-end RNA secondary structure prediction.\\nThe optimization problem formulation and its solution are well defined.\\nThe results are strong and supported by visualizations and ablation studies.',\n",
       "  'strengths': 'The key strengths of this work are:\\n1. Inference is an order of magnitude faster than previous methods.\\n2. Inference is between 4-20% more accurate than previous methods, with significant gains specifically in long-range interactions.\\n3. A well defined optimization problem formulation and solution.\\n4. Including visualizations and ablation studies underscores the gains achieved through the optimization formulation and attention architecture.\\n5. The results are validated using multiple datasets and baselines.',\n",
       "  'weaknesses': 'Weaknesses of this work are:\\n1. There is a discrepancy in the definition of G in equation 12, where it does not incorporate the softmax function. \\nHowever, in equation 15, it is assumed as if it does. This can be fixed by introducing a new notation, such as G_{hat}, \\nwhich includes the softmax function and will ensure consistency.\\n2. The definition of well-known metrics in section 5 is redundant.\\n3. The comparison between Rfold and Ufold could be more comprehensive, \\ndescribing their similarities and differences.\\n4. There are a few minor typos, and the writing may be improved.'},\n",
       " 'review_416': {'summary': 'The paper introduces RFold for RNA secondary structure prediction (a prediction of LxL binary matrix). It proposes to add a row-column-wise softmax at output of the model, before computing the L2 loss with respect to the ground truth. The experimental results show higher precision and recall compared to prior works.',\n",
       "  'strengths': '- The paper is well-written with necessary backgrounds and basic introductions, problem formulations. Thus, this paper suited well for general audience of NeurIPS.\\n- RFold delivers strong performances in two commonly used datasets for evaluating RNA secondary structures.',\n",
       "  'weaknesses': 'The main concern is the limited novelty, RFold is incremental over Ufold. Both methods follow the paradigm of mapping a sequence RNA (using $\\\\theta_{1}$) to $[L \\\\times L \\\\times n]$ features and further mapping the $[L\\\\times L \\\\times n]$ features (using $\\\\theta_{2}$) to $[L \\\\times L \\\\times 1]$ output prediction. RFold differs from Ufold in two parts:\\n- RFold proposes $\\\\theta_{1}$ to be represented by an attention-based layer. (RFold and Ufold use a similar, if not identical, $\\\\theta_{2}$.)\\n- RFold adds a column-wise and a row-wised softmax after the $\\\\theta_{2}$, before computing L2 loss.\\n\\nThus, RFold makes a few architectural modifications and improves the results.\\n\\nE2Efold and Ufold also have a section on evaluation with pseudoknots on the RNAStralign test dataset, which this submission does not have.'},\n",
       " 'review_417': {'summary': 'In this paper, the authors propose a way to decouple the optimization process of RNA secondary structure prediction. Specifically, they decompose the constraint satisfaction problem into row-wise and column-wise optimization. Instead of hand-crafted features, attention maps are used to learn the pair-wise interactions of the nucleotide bases.',\n",
       "  'strengths': '1. The authors show that it is more effective to use the attention maps as the input and then use U-Net to predict H, compared with using the hand-crafted features as input, which is interesting.\\n2. The proposed method reduces the inference time dramatically compared to various methods.\\n3. It achieves promising results on the RNAStralign dataset and large-scale benchmark evaluation.\\n',\n",
       "  'weaknesses': '1. The generalization ability is limited because the proposed method cannot achieve the best recall on ArchiveII and bpRNA-TS0 datasets.'},\n",
       " 'review_418': {'summary': 'This paper studies the multi-objective optimization, and in particular, focus on the generalization and stability analysis. By decomposing the Pareto stationarity error into the generalization and optimization error, the authors then analyze and upper-bound these two errors respectively. The distance to the conflict-avoidant direction, which optimizes al objectives jointly, is also analyzed. A stochastic variant of MGDA named MoDo has been developed and analyzed. Based on the theoretical derivations, the authors find a three-way tradeoff among the optimization error, generalization error and the CA error. Some implications on the parameter selection and illustrations are provided.  ',\n",
       "  'strengths': '1. The studied topic on multi-objective optimization has received increasing attention thanks to the important applications like multi-task learning. Studying the generalization, stability and the tradeoff is important and under-explored.\\n\\n2. Although generalization has been studied for multi-objective optimization, stability has not been explored. This work seems to be the first one to fill this gap.\\n\\n3. The tradeoff among optimization and generalization is not surprising, but their tradeoffs with the CA direction error seem to be new given the multi-objective structure. ',\n",
       "  'weaknesses': '1. How is (4a) equivalent to (4b)? Can the authors provide some more details?\\n\\n2. Before (4a), it says that CA direction maximize the minimum descent of all objectives. But (4a) seems to say that the direction minimizes something. \\n\\n3. The upper bounds in the nonconvex case may not be very tight given the large exponential dependence, and hence may not be able to exactly capture the generalization and tradeoff behaviors. Is it possible to provide a lower bound in this case? Or what challenges in getting a tight bound? \\n\\n4. The analysis uses Frobenius norm, which may be large in practice. Instead, spectrum norm may be more proper. Can the authors comment on why use Frobenius norm rather than spectrum norm?\\n\\nOverall, I appreciate the studied problem and the analysis in this work, but I am also open to other reviewers’ comments. '},\n",
       " 'review_419': {'summary': 'This paper studies three-way trade-off in multi-objective learning: 1) optimization error caused by sampling and stochastic training; 2) generalization error that measures the difference between source and target sets; 3) conflict-avoidance direction error that is the bias between the calculated direction and the right one. The authors propose the MoDo algorithm to optimize this trade-off in one algorithm. Plenty of theoretical analysis supports the claims.',\n",
       "  'strengths': '1. This paper considers the multi-objective algorithmic design in a bigger picture by compositing three-way trade-off together, and provides solid analysis to solve it.\\n\\n2. This paper is well written. In particular, Table 1 and Figure 2 help to understand the contribution better.',\n",
       "  'weaknesses': '1. The proposed algorithm needs to compute three batches of gradients to run an iteration, which is much less computationally efficient. \\n\\n2. Benchmarks are too limited that only contain static and MGDA (2018 proposed), experiments have not compared with other typical methods like PCGrad and CAGrad, which have better empirical performance. \\n\\n3. Several claims are out-of-date. In 34-35 \"Unfortunately, the reason behind this empirical performance\\ndegradation is not fully understood and remains an open question\" is not accurate, since [1] has proved that the vanilla MGDA algorithm and also PCGrad and CAGrad will not converge to Pareto optimal. In 268 \"This can be overcome by increasing the batch size during optimization [25]\" is wrong, because the assumption on Lipschitzness for $\\\\lambda$ with respect to gradients has been proved to be wrong (Proposition 2 in [1]). Also, it can be proved that even a stochastic error of the gradient can cause a significant bias in the direction, so only increasing the batch size does not work.\\n\\n[1] S Zhou, W Zhang, J Jiang, W Zhong, J Gu, W Zhu - Advances in Neural Information Processing Systems, 2022'},\n",
       " 'review_420': {'summary': 'This work considers the multi-objective learning problem. The classic idea of dynamic weighting in MOL is to take gradients from each objective and to weight them using a fixed procedure to avoid conflicts between different objectives. Empirically, however, there often seems to be performance degradation when using these methods. They discover that this is due to a tradeoff between optimization, generalization, and conflict avoidance. They propose a new algorithm, MoDo, that interpolates between static weighting and dynamic weighting and find parameters that can control this tradeoff effectively.',\n",
       "  'strengths': 'Overall, this is a strong work that provides a lot of insight into dynamic weighting in multi-objective optimization. The highlights are as follows:\\n- The paper is very intuitively written and easy to follow. Specifically, the three-way tradeoff is clear both intuitively and quantitatively. In addition, Figures 1 and 2 are very well done and extremely insightful.\\n- The proposed MoDo algorithm is very simple and intuitive while brilliantly highlighting the three-way tradeoff inherent in dynamic weighting algorithms. I found the remark about being in the early stopping regime for generalization error to diminish (T = o(n)) interesting, and it is also empirically highlighted later in the work.\\n- The tradeoffs for both strongly convex and nonconvex cases are analyzed\\n- The findings in this work translate to a practical explanation of the behavior of dynamic weighting algorithms',\n",
       "  'weaknesses': \"- While MoDo is a great theoretically inspired algorithm that controls the aforementioned tradeoffs, I am not sure how well it performs empirically. While there is an empirical result, the tasks seem rather simple. In addition, as Table 2 shows, MoDo does not consistently outperform MGDA. In practice, I feel handling the conflict avoidance tradeoff shouldn't matter much as long as the accuracy for the task is good. Therefore, I am not sure how applicable the algorithm would be in practical situations. \\n- As the authors mention in their limitations section, the analysis is only about one specific algorithm in one specific setting, which makes it unclear how general the principles in this work would apply when the assumptions are relaxed. I feel this given this work is meant to analyze a practical phenomenon, this is a substantial weakness, as it is unlikely that Assumptions 1-3 are all true in real-world settings (such as the image classification setting the authors test on)\\n- There is no intuition of the proof in the main text, and while this is common in optimization papers, it would be useful to learn about the key insights towards the proof.\\n\"},\n",
       " 'review_421': {'summary': 'This paper has two contributions:\\n(1) MoDo algorithm which is a variant of MGDA with a double sampling to obtain an unbiased stochastic estimate of the gradient problem.\\n(2) A solid theoretically analysis on the error of multi-objective optimization.\\n',\n",
       "  'strengths': 'This paper has a very detailed analysis on the optimization error and generalization error of multi-objective optimization.',\n",
       "  'weaknesses': 'In the experiments, authors only compare MoDo with MGDA, but there are many other algorithms, like CAGrad, GradNorm, Uncertainty Weight. This baseline is not enough to demonstrate the effectiveness of the proposed method.\\n\\nOverall, MoDo is better than MGDA. However, in two objectives out of three (table 2), MGDA is better than MoDo, also not convincing enough on the effectiveness of the proposed method.'},\n",
       " 'review_422': {'summary': 'In this paper, the authors introduce representation learning with the unsupervised information bottleneck to multi-view clustering. Based on the framework of information bottleneck, the authors theoretically summarize 3 key properties (comprehensiveness, concentrate, and cross-diversity) required by multi-view clustering representation. Finally, a DEC module is added to obtain the clustering assignment. ',\n",
       "  'strengths': '- The paper is well-motivated and easy to follow. The pointed three desiderata are convincing although there may be some typos in the definition.  \\n- The paper is technically sound. ',\n",
       "  'weaknesses': '- There are many typos, especially in key concepts. For example, \\n    - there may be plenty of typos of notations in Definition 3.1, which causes my major concern about the soundness of this paper. \\n    - In Line112-113, \"minimize $I(Z^{(1)}, X^{(2)})$ and $I(Z^{(1)}, X^{(2)})$\" seems wrong. \\n- The experiment may be a little insufficient. For example,\\n    - The ablation experiments to study which 3 different desiderata are more important are missing. \\n    - The visualization of learned $Z$ is also helpful to improve the quality. Since the primary contribution is the representation learning and there seems no apparent contribution to the clustering module, it is important to show whether the quality of representation is better.  \\n    - The running time is missing.\\n- The used mathematical techniques to derive the variational bound lack novelty (widely used in VIB, GIB, etc.).  '},\n",
       " 'review_423': {'summary': 'This paper presents an innovative information-theoretic framework for multi-view clustering, which overcomes the limitations of existing methods that rely on strict semantic consistency assumptions. By leveraging deep neural networks, the proposed method achieves more stable and superior clustering performance on several datasets.',\n",
       "  'strengths': 'The idea of incorporating the information bottleneck into multi-view clustering is intriguing and enlightening.',\n",
       "  'weaknesses': '1. The importance of Eq. 3 in the proposed method is evident, as it provides the IB-based objective for the clustering approach. However, the paper lacks an explanation of how the original IB objective (Eq. 1) is transformed into the clustering objective, and why it takes the specific form presented. Additionally, if the information bottleneck based clustering is not an original contribution of this paper, it should be properly referenced.\\n2. The concept of the three desiderata is unclear. From Fig. 1, it appears that the final result of optimizing the three desiderata is to maximize I(Z; X^{1,2}), minimize I(Z; X{1,2}), and maximize I(Z; Z^{1,2}). This optimization seems contradictory, particularly when it aims to maximize the mutual information between Z and view-specific Z^{1,2} while minimizing that between raw data X and Z^{1,2}. Furthermore, the paper lacks an explanation of why these three desiderata are useful for learning cross-view representation, and there are no ablation studies to investigate their influence.\\n3. The proposed generalized multi-view clustering framework seems to differ from Eq. 3 only in the information shift term. This should be clarified and elaborated upon.\\n4. The experiments conducted on relatively simple and small-scale datasets limit the persuasiveness of the results. Additionally, the comparison baselines appear outdated, raising concerns about the effectiveness of the proposed method.\\n5. There are some typos, such as line 112: \"I (Z^{(1)}; X^{(2)}).\"'},\n",
       " 'review_424': {'summary': 'This paper reformulates the multi-view clustering problem from an information-theoretic perspective and propose a general theoretical framework. The authors extend the information bottleneck theory to unsupervised multi-view learning and achieve representation learning and clustering by leveraging deep neural networks and stochastic gradient variational Bayes.',\n",
       "  'strengths': '1. This paper combines information theory with multi-view clustering and gives some new definitions to portray some properties of the multi-view domain, which is a very innovative idea that can contribute to the field.\\n2. This paper provides a solid theory and some key proofs are detailed and complete.\\n',\n",
       "  'weaknesses': '1. The datasets used in the experimental part are a bit less and small, and there are many challenging and large datasets in the field of multi-view clustering, the authors should add more experiments to enhance the sufficiency.\\n2. Parameter analysis part should show parameter changes on all datasets, you may show the figures of all datasets under one metric.'},\n",
       " 'review_425': {'summary': 'This paper proposes a new framework for unsupervised multi-view learning based on information bottleneck theory. The paper defines three desiderata for multi-view representation learning in terms of mutual information, namely, comprehensiveness, concentrate, and cross-diversity. The paper further introduces a clustering term to preserve the original data structure and leverages deep neural networks and stochastic gradient variational Bayes to optimize the objective function. The paper evaluates the proposed method on four real-world datasets and shows that it outperforms several state-of-the-art algorithms in terms of clustering performance.',\n",
       "  'strengths': '•\\tThis paper provides a general and principled information-theoretic framework for multi-view clustering that does not rely on strict assumptions about semantic consistency across views.\\n\\n•\\tIt incorporates three requirements for multi-view representation learning that balance the trade-off between informativeness, compression, and diversity of the latent features.\\n',\n",
       "  'weaknesses': '•\\tThe authors should clarify how their definition of comprehensive, concentrative, and cross-diverse multi-view representation differs from the one used by Completer [22], which also maximizes the mutual information between views and minimizes conditional entropy of different views. \\n\\n•\\tThe loss function consists of four terms with different roles: data reconstruction, multi-regularization, information shift, and clustering. The authors should conduct ablation studies to show the contribution and necessity of each term for the proposed method.\\n\\n•\\tThe balance parameters $\\\\beta$ and $\\\\gamma$ control the trade-off in the objective function. The authors should provide some theoretical or empirical guidance for choosing the optimal values of these parameters for different datasets or scenarios.\\n\\n•\\tAs the robustness of the model is important to evaluate, what is the definition of robustness in this paper and the relation between the robustness and the proposed information bottleneck theory?\\n\\n•\\tIn Eq.(4), what is the difference between $\\\\mathbf{Z}^{(v)}$ and $\\\\mathbf{Z}$? How to learn $\\\\mathbf{Z}$?\\n'},\n",
       " 'review_426': {'summary': \"The authors study a collaborative normal mean estimation problem, where m strategic agents are trying to estimate the mean \\\\mu of an unknown normal distribution with given variance. The agents can acquire samples drawn from the distribution at a cost of c per sample. In addition, each agent can share their samples with a mechanism, which will reward them by providing some of the samples other agents have submitted. Given that the agents are strategic, they can also omit or alter their samples prior to sharing, or even fabricate additional samples at no extra cost.\\n\\nThe strategy of each player therefore is how many samples to obtain, what to report and how to estimate \\\\mu given the response of the mechanism. The cost of the agent has a worst case flavour: it is the cost of the samples plus the maximum expected quadratic estimation error (with the supremum taken over all possible true values of \\\\mu and the expectation over the samples received directly or by the mechanism, which further depends on the strategies of other agents). The solution concept used is the Nash equilibrium. The mechanism needs to satisfy Incentive Compatibility (IC) and Individual rationality (IR). IC is about the players following the 'honest' strategy, which in this case is suggested by the mechanism and includes taking a certain number of samples and honestly sharing all of them. If IC holds (more on that in the questions), then following this honest strategy is the best option for any agent, as long as every other agent is also honest. IR dictates that for the honest strategy, every player should have lower cost than if playing in isolation.\\n\\nThe mechanism also needs to efficient, which means that the expected sum of costs (given the recommended IC strategy) should be a close approximation of the 'optimal' cost, which is the minimum that can be achieved by any mechanism and agent strategy (ignoring IC and IR constraints). In this case, it is shown that the optimal non-strategic mechanism simply collects samples are forwards them to all agents, who use a minimax estimator.\\n\\nThe designed mechanism called C3D collects samples from agents and then for each agent i: it splits all collected samples into two sets Z_i and Z_i', where Z_i contains min(|Y_i|, \\\\sigma / \\\\sqrt{c m}) samples where Y_i are the samples submitted by agent i. The samples Z_i' are then perturbed by adding random noise, increasing in the difference between Y_i and Z_i. This mechanism is both IC and IR (which is implied since submitting no samples is a valid strategy) and has an approximation ratio of 2.\\n\\nThe authors also consider extensions where the agents have to submit their true samples or where the mechanism itself calculates \\\\mu (thus the agents cannot misreport and then ignore their input from their estimation). In the first case, a simpler mechanism is completely efficient, while in the second a 1+ \\\\epsilon mechanism can be designed for all \\\\epsilon > 0.\",\n",
       "  'strengths': 'The setting of collaborative mean estimation is very interesting and particular care has been taken to establish a nuanced model where this question can be meaningfully posed and answered. The presentation of the paper is excellent, with all ideas communicated clearly and in the right order. Before any rigorous proof, an appropriate amount of intuition is provided. \\n\\nThe mechanism itself is very natural and seems robust, while achieving a good approximation.',\n",
       "  'weaknesses': 'No lower bound is provided for the 2-approximation.\\n\\nUsually, Incentive Compatibility refers to a strategy being optimal no matter what the other players are doing, whereas here the definition given is essentially the same as the Nash equilibrium. \\n\\nIn any sensible mechanism IC would imply IR in this setting. Given that the paper is very well presented this is a minor point, but a bit of content could be cut and simplify the notation by restricting mechanisms wlog.'},\n",
       " 'review_427': {'summary': 'This paper studies collaborative normal mean estimation, where strategic agents collect i.i.d samples from a normal distribution at a cost. This paper designs a \"truthful\" mechanism such that the strategic players will try to collect data instead of doing some \"random\" thing that harms the system and benefits themselves for federated learning systems.',\n",
       "  'strengths': 'The problem it studies is very interesting, and has the potential impact for further directions and research. The theory is solid. I think this kind of research that consider the robustness of the system / robust statistics will gain much attention for federated learning (and related) community.',\n",
       "  'weaknesses': 'I am not very familiar with AGT, and thus will not point out the weakness on the theory part. However I do have some minor concerns with respect to the model and motivation.\\n\\n+ In this paper, the author only considers estimating the mean of Gaussian distribution from samples, which is a one-round scenario. The clients can communicate with each other and send the raw data. While in real applications, it is always not good to directly send the data because of the privacy issue. Thus the optimization problem may include several round of interactions. Is it possible to extend the current single-round results to a multi-round protocol?\\n+ In federated learning or collaborated data-sharing applications, different clients may have different data-distribution (in the current paper, different clients may have different mean $\\\\mu_i$). Thus, some clients may also untruthfully report the data to take advantages for their own sake. The current model may be too easy (all clients consider the same data distribution). Is it possible to extend the current results / mechanism to the non-IID setting where different clients may care about different distribution?'},\n",
       " 'review_428': {'summary': \"The paper designs a mechanism that collects data from n agents to estimate the mean of a Gaussian distribution. The agents incur costs to collect data, they can misreport data, and they strategically choose the level of effort and the data to report. They propose a mechanism that corrupts the returned datasets according to the difference between an agent's reported data and others' data. They prove that their mechanism is IC, IR, and achieves a 2-approximation of the optimal social welfare.\",\n",
       "  'strengths': 'The paper studies an interesting problem and the presentation is clear.',\n",
       "  'weaknesses': 'The result may be overshadowed by the results in (Cai et al., 2015), which is not cited in the current paper. Although the problem is formulated without payments, it is pretty much a mechanism design problem with payments, because the designer knows the agents\\' utility function exactly and can add arbitrary noise to adjust an agent\\'s utility freely. This is very similar to adding a numerical payment to the allocation function, which makes the problem very close to (Cai et al., 2015). However, (Cai et al., 2015) achieves a much stronger result: they are able to achieve optimal social welfare at a dominant strategy equilibrium. In addition, when their mechanism is used, the agents do not have the incentive to misreport data, which means that truthfully reporting data will be a weak BNE. In this paper, only 2-approximation is achieved at a BNE, which is pretty far from the potential optimal. It may not be straightforward to apply (Cai et al., 2015) because adding noise can only give negative payments, but it is also not clear whether (Cai et al., 2015) can yield a better result than 2-approximation.\\n\\nCai et al., 2015, \"Optimum Statistical Estimation with Strategic Data Sources\"'},\n",
       " 'review_429': {'summary': \"The author consider the problem of designing a data-sharing mechanism that encourages a group of $m$ agents to share their iid collected samples truthfully and further uses the shared data to refine their estimations of the normal mean. To ensure truthful reporting, the mechanism introduces additional noise into the shared data.  The amount of noise is determined based on the discrepancy between the mean of an agent's reported data and the mean reported by other agents, with the noise variance increasing proportionally. The authors demonstrate that this mechanism achieves both individual rationality and incentive compatibility. In addition, the mechanism is also efficient compared to the minimum social penalty. The authors further extend the result to estimation of the mean in high-dimensional settings with a bounded variance.\",\n",
       "  'strengths': 'The problem of data sharing is well motivated by real world applications and has gained great attention in recent years. The difficulties associated with this type of problem often involve determining the appropriate pricing strategy for data to incentivize genuine data collection while discouraging data fabrication. This paper addresses the problem in an elegant way in the language of normal mean estimation. \\n\\nThe authors explore the methods of inserting noise into the reallocated data whose variance depends on the quality of an agent’s report. The idea has occurred in many previous work, but the authors show that by carefully designing the noise level, the mechanism can be at the same time IC, IR and efficient. Moreover, the results hold for any number of agents and can also be extended to non-normal distribution. I believe that this work may be of interest to the community.\\n\\nThe paper is well-written and the results are sound. ',\n",
       "  'weaknesses': 'It seems that the current result is quite limited to the specific form of the social/individual penalty. The proof of the IC also seems to heavily rely on this specific structure. Can the results be extended to more general penalty functions?\\n'},\n",
       " 'review_430': {'summary': 'The paper considers a collaborative mean estimation\\nsetting where a set of agents can all collect\\ni.i.d samples from an underlying Gaussian distribution,\\nand their goal is to share data with each other in order\\nto estimate the mean of the distribution. \\nEach agent has a fixed cost for collecting each sample\\nand its negative utility equals the sum of the estimation error and\\nthe sampling cost.\\nNaturally, each agent has an incentive to free-ride\\nand under-collect, reporting false data to\\nthe data collecter and using other agents\\' data instead.\\nThe goal is to design a mechanism that can incentivize\\nthe agents to share their data more truthfully, in order\\nto ensure successfull mean estimation.\\n\\nThe authors propose an\\nincentive compatible and individually rational mechanism based on the idea\\nof \"punishing\" agents whose estimates deviate too much\\nfrom the true mean by sharing false data with them,\\nand use a minimax estimator on the collected\\ndataset to estimate the mean.\\nThe authors show that the mechanism\\'s social\\npenalty is at most twice the global optimum.\\n',\n",
       "  'strengths': 'The authors propose an interesting problem, and provide a nice solution to it.\\nThe paper is well-written.\\nThe result is somewhat surprising and I believe may be important for future research.',\n",
       "  'weaknesses': 'The presentation of the result suggests that the mechanism is incentive\\ncompatible globally and not just in the equilibrium point. This\\nshould be clarified earlier in the paper.\\n'},\n",
       " 'review_431': {'summary': \"- The authors study normal mean estimation in a collaborative setting. N agents each aim to obtain a good estimate for the unknown mean while incurring as little cost for data acquisition as possible. \\n- The authors show that a naive data aggregation mechanism leads to freeriding. Then, they propose a novel mechanism in which a central entity collects all data and only sends players noisy information about other players' samples, with the magnitude of the noise depending on the deviation from a player's sample to others' samples. \\n- The authors show that their mechanism fulfills desirable properties (Incentive compatibility, Individual rationality and Efficiency) in the single-dimensional Gaussian case and retains approximate versions of these properties more generally. \\n**I am keeping my positive score after reading other's reviews and the rebuttal.**\",\n",
       "  'strengths': '- The paper is generally well written and offers a relevant new take on data-sharing incentives in federated learning.\\n- The proposed mechanism does not rely on side payments and is therefore quite flexible. \\n- The authors consider a very general class of player strategies and still manage to prove strong theorems.',\n",
       "  'weaknesses': '- The placement of \"recommended strategies\" within the formalism is a bit confusing, as there does not appear to be any difference in the analysis of recommended vs non-recommended strategies. \\n- As the recommended, desirable strategy profiles are only shown to be Nash equilbria but not dominant strategies, some discussion of other equilbria would be nice (in particular, are all equilbria essentially equivalent to the recommended strategies modulo some simple transformation, or are there very different equilbria?)  \\n- Some very relevant citations seem to be missing from the related work section. In particular, the proposed mechanism is very similar to the idea of [peer prediction](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.1050.0379) and connections to that strain of work could be highlighted better.\\n- Minor comments: \\n    - 256-258 contains \"simply\" twice in the same sentence\\n\\n    - 352 seems to contain a grammar error/typo (\"given her\")'},\n",
       " 'review_432': {'summary': 'This paper studies the generalization guarantees of non-parameteric methods in RKHS under covariate shift.\\nCompared to previous work (Ma et al. AOS2023), the authors extend their results from the squared loss to general Lipchitz loss functions.\\nThe derived results show that\\n\\n- under the uniformly bounded case for the importantce ratio, the unweighted estimator achieves the optimal learning rates in the $L2(d PT)$ space, where $PT$ is the target distribution. \\n- under the bounded second monment case, the above estimator is sub-optimal.\\n- under a truncated ratio, a sharp learning rate can be achieved.\\n',\n",
       "  'strengths': '- generalization analysis under covariate shift is derived from the squared loss to general loss functions\\n- Under the the uniformly bounded case and bounded second moment case for the importantce ratio, the results can recover the result under the squared loss\\n- the results are derived under the truncated case',\n",
       "  'weaknesses': '- Extension from the squared loss to general Lipschitz loss functions is based on Assumption 2. More discussion on this assumption is required for specific loss functions. If the space is limited, the discussion can be deferred to the appendix.\\n\\n- There are several parts unclear in the proof. For example,  in the proof of Lemma C.1.2, the notations $P_n$ and $P$ are undefined in Eq.(2), and more details are needed for the first inequality in Eq. (2). \\n\\n- The proof idea and structure is almost the same as (Ma et al. 2023). For example, there is no significant difference between the proof of Theorem 3 and Lemma 2 in (Ma et al. 2023). This is because, under Assumption 2 and Eq. (10), the results under Lipschitz loss functions can be well controlled. \\n\\n\\n'},\n",
       " 'review_433': {'summary': 'The authors study the covariate shift setting of nonparametric (kernel) methods\\n(Regularized Empirical Risk Minimization with optional importance weighing) with\\nan analysis which includes a wide array of losses and and two conditions on the\\nimportance function. They establish sharp convergence which corroborate other\\nrates in literature. Additionally they provide experiments showing these rates\\nin practice.\\n',\n",
       "  'strengths': '- Quality: The authors extend the results to a wide array of losses and two types of covariate shift problems which is nice.\\n- Clarity: The paper is well-written and notation makes it easy to follow\\n',\n",
       "  'weaknesses': '- There are quite a bit of terms which are unknown in practice and they need to\\n  estimate the importance function which limits the practical impact of the\\n  method.\\n'},\n",
       " 'review_434': {'summary': 'The paper provides a unified analysis of convergence properties for different kernel-based estimators under covariate shift. The analysis covers different loss functions and is focused on standard and importance weighted empirical risk estimators. The former are specified in Eq. (1) and the latter in Eq. (3). \\n\\nThe first assumption is pretty standard and requires a uniformly bounded kernel function. The second assumption enforces a locally strong convexity on the expected loss function relative to source and target marginal distributions (source available during training, target assumed to be shifted and available at test time). The assumptions that characterize the distribution shift are given on page 4 (lines 131 and 132): i) in the first case the importance weights are $\\\\alpha$-uniformly bounded, ii) in the second case the second moment of the importance weight function is bounded. \\n\\nTheorem 1 gives convergence bounds relative to case i) under the assumptions above. Further assumption is made to give a more readable interpretation of the bound in Corollary 1 which ties the convergence rate to kernel spectrum decay.\\nTheorem 2 gives a similar convergence result in a more difficult case ii), again under the assumptions listed above.\\nTheorem 3 considers an estimator that uses importance weighted empirical risk estimator, with truncated importance weights to avoid issues with tail samples. It is for case ii) and bounded second moment of importance weights. The latter result indicates much tighter convergence rate than the one in Theorem 2 that considers standard estimator without importance weighting.\\nEmpirical analysis illustrates the tightness of the bounds on synthetically generated learning tasks and a real-case study. ',\n",
       "  'strengths': 'While I have not checked the proofs, the theoretical part of the paper is its strongest point. It is also an interesting characterization of distribution shift carried into the bounds and would be interesting to see what other more granular specifications are possible for future studies. A relative comparison between Theorem 2 and 3 also illustrates the utility of truncated importance weighted estimator, which might be important for practical applications. ',\n",
       "  'weaknesses': 'Empirical study might be the weakest part of the paper but given its nature should be fine. It might also be interesting to see how relevant are the assumptions on distribution shift relative to practical applications and datasets. '},\n",
       " 'review_435': {'summary': 'This manuscript presents convergence rates for kernel methods under covariate shift. Results fit quite a general framework, including common classification and regression losses. Two approaches are analyzed: (i) a usual M-estimator and (ii) an importance-sampling-like M-estimator. It is shown theoretically and empirically that the latter outperform the former.',\n",
       "  'strengths': 'The analysis presented in this paper provides interesting theoretical results regarding learning under covariate shift, which is a contemporary topic. The manuscript is well organized; it explains clearly the problem, state the results while discussing the hypotheses and, at the end, illustrates the theoretical findings by a numerical experiment.\\nI would like to stress that discussions regarding hypotheses are opportune and corollaries provide intelligible results.\\nThe take-home message, stating that the importance-sampling-like estimator is better that the naive one, is interesting and confirms practitioners’ intuition. ',\n",
       "  'weaknesses': 'Major remarks:\\n1) My main concern is about the novelty of the proofs: hypotheses (i) and (ii) look like straightforward tools to link expectations under the source distribution to the target distribution by linearity or Cauchy-Schwarz inequality. I had a very quick glance to the supplementary material and it confirmed this guess (although I admit that I may be wrong). I think that its important, in order to assess the contribution of the paper, that the authors explain the original derivations appearing in the proofs, with respect to techniques used for obtaining similar results without covariate shift (unfortunately, I have no reference in mind).\\n2) Another (minor) point is that Figure 1 does not seem to verify neither hypothesis (i) nor (ii) since $\\\\phi(x)$ seems to explode when $x \\\\to \\\\infty$. If it is the case, it would be better to find another example (or at least to discuss this point). If it is not the case, it would be informative to explain it.\\n\\nSome suggestions of improvement:\\n1)  $f^*$ is defined in Section 2.1, before the problem setting in Section 2.2. However, in practice, it corresponds to the optimal function under the target distribution, which is not clearly stated. I suggest to make it clear.\\n2) Although an informed reader understand definitions Line 113, it is not totally clear that expectations are conditioned by observed data. I suggest to had this information.\\n3) $D$ could be added after “Finite rank” in Table 1.\\n4) Line 264, it is not totally clear that “For the moment bounded case” correspond to Figure 3. I suggest to had it.\\n\\nTypographical remarks:\\n1) Extra “the” Line 5.\\n2) “that” instead of “that is” Lines 126, 131 and 132.\\n3) In Theorems 1-3, $\\\\delta_n$ should satisfy an inequality that involves $\\\\delta$ instead of $\\\\delta_n$.\\n4) There are $\\\\phi(\\\\textrm x)$ instead of $\\\\phi(\\\\textrm x)^2$ Lines 212 and 223.\\n5) Full points are missing in captions.'},\n",
       " 'review_436': {'summary': 'This paper presents a framework that uses LLM as controller over modularized and specialized task models to plan and execute a complex task. The approach is to prompt LLM to decompose a given task command into a execution DAG, and for each step, parse model specifications (as metadata expressed in HuggingFace model cards) and select according modularized models for execution, and finally summarize a response to give it to the user. The idea is on the line with recent works on LLM-based planning and tool using.',\n",
       "  'strengths': 'I think the idea is rather novel. It aligns with recent works on using LLM as a central component to query more specialized models to complete a complex task. This paper proposes to exploit the vastly available models hosted on Hugging Face in a combinatorial way. If things work out well, it could have a substantial application impact.',\n",
       "  'weaknesses': \"The biggest selling point of this paper, as is repetitively mentioned in the paper itself, is the planning. But compared to recent works, the planning strategy in this paper is actually rather simple. Existing works on planning often involves an iterative process where LLM plans, executes, and observes, and improves (for instance, Reflexion, AdaPlanner, Self-Refine, etc). In this paper, it's just plan and execute. So, on the planning part, I do not see any contribution. Maybe, compared to the planning, a bigger contribution of this paper is the task decomposition.\\n\\nExperiments are very limited.\\n- Data scale is quite small (46 trace annotations).\\n- No planning baseline, no ablation study, and no insight about model interplay.\\n- Comparisons are all on different LLMs; this has little to do with the claimed contribution on planning.\\n\\nA simple baseline can be directly using specialized models. I think even if in some cases the proposed HuggingGPT does not outperform, it still gives reader a good picture about the pros and cons. An immediate ablation study I can think of is why not merge the model selection and task planning into one step, or what is the impact of model selection, especially given the large number of models on Hugging Face. I see no clue in this paper.\\n\\nIt is not clear how the proposed approach rely on the few-shot demonstration. Prior works on planning mostly rely on few-shot in-context prompting. It seems this paper is also on this technical line. But such dependency is also a limitation in the general use case. It's also no clear about the variance of the few-shot prompt used, e.g., whether the few-shot examples are fixed, and what about their diversity.\"},\n",
       " 'review_437': {'summary': 'This paper considers large language models (LLMs) like ChatGPT as a controller and presents a new framework called HuggingGPT, which connects various AI models in the existing ML community (i.e., HuggingFace). Specifically, HuggingGPT consists of four steps including task planning, model selection, task execution, and response generation. By leveraging the strong capability of LLMs and numerous AI models in different modalities, HuggingGPT can solve sophisticated AI tasks and achieve promising results.',\n",
       "  'strengths': '1) The idea to connect LLMs with rapidly developing ML communities like HuggingFace is novel. It largely extends the applicability of LLMs to solve multi-modality AI tasks by fully utilizing the existing powerful models in HuggingFace.\\n2) Each step of HuggingGPT is well designed from Figure 2. The whole paradigm of HuggingGPT is neat and effective.\\n3) This paper is well written and easy to follow.\\n',\n",
       "  'weaknesses': '1. In Section 3.1, the demonstration examples may have an important impact on the parsing performance. The authors should provide more details such as the number of demonstration examples and the method to select these examples. The demonstration case provided in Table 1 is somewhat confusing for me because it only involves the tasks about images and texts. Can these demonstration examples benefit the parsing of tasks in other modalities like audio? I also wonder whether the demonstration examples for each user request are the same.\\n\\n2. In Section 3.2, the authors propose a model selection strategy based on in-context alignments and the number of downloads. But in my view, the contribution of this module is questionable. Since the performance gap between different models for each task may be significantly large due to model scales (e.g., GPT-2 and LLaMA for text generation), it’s nearly impossible to select weaker models to dealing with the corresponding task. Thus, I’m curious about the performance if we directly use the best model for each task. There are also no empirical results to show the necessity of model selection.\\n\\n3. The experimental result is somewhat weak in terms of the following points:\\n\\n(1) The authors only conduct the empirical analysis on task planning. Other modules should be also tested individually. \\n\\n(2) The authors only use automatic evaluation metrics to measure the model performance. However, even GPT-4 score may have potential biases in the evaluation of generated texts. It’s better to involve human evaluation to make experimental results stronger.'},\n",
       " 'review_438': {'summary': \"The authors propose HuggingGPT , a collaborative system for solving AI tasks, which is composed of a large language model (LLM) and numerous expert models from ML communities. They provide methods for each of the four stages involved in HuggingGPT's workflow: task planning, model selection, task execution, and response generation.\",\n",
       "  'strengths': 'Impactful and well written paper\\n- simple strategy for handing resource dependencies for executing tasks\\n- compelling idea of chaining of expert models to provide a tool to decompose a task into sub-tasks and identify the appropriate expert models to solve these sub-tasks\\n- reasonable format for inputting task request along with examples from the user\\n- robust evaluation  - human evaluation along with automated evaluation',\n",
       "  'weaknesses': \"I don't see any weaknesses in the experiments, evaluation or novelty of this paper.\"},\n",
       " 'review_439': {'summary': 'This paper presents a pipeline to manipulate many autonomous agents (mainly open-sourced models in  Hugging Face) . Tother with these models could solve NLP, CV, audio and Video tasks,  the resulted HuugingGPT could could complicated multi-modal tasks that might be decomposed a sequence  of atomic  tasks or a graph. \\n',\n",
       "  'strengths': '- The phylosophy is interesting and insightful. I like the idea very much.\\n- This seems be a promising direction to solve multi-modal tasks using HuggingGPT.\\n',\n",
       "  'weaknesses': '- The whole pipeline seems to provide a series of prompts to solve some combined tasks. The method is not scientific from a traditional point of view.\\n- The evalaution protocol seems not mature.  For example, there is not evidence to check whether the evalution makes sense or not.\\n'},\n",
       " 'review_440': {'summary': 'The paper studies an interesting and important question, i.e., how to automate LLMs to call existing models for solving specific tasks. The authors propose a novel framework that contains the following steps: (1) task planning, (2) model selection, (3) task execution, and (4) response generation. The experimental results well support the claim. By leveraging ChatGPT and abundant AI models Hugging Face, the proposed method is able to cover numerous sophisticated AI tasks in different modalities and domains and achieve impressive results in many tasks.',\n",
       "  'strengths': '+ The paper is well-written and easy to follow.\\n\\n+ A novel idea proposed and well-supported experiments conducted.',\n",
       "  'weaknesses': '- The method heavily relies on the existence of SOTA LLMs (e.g., ChatGPT), which may involve some practical issues (e.g., unaffordable API costs). It remains under-explored whether open-source LLMs (e.g., vicuna) can be leveraged for the framework (or how to adapt vicuna for better task planning).'},\n",
       " 'review_441': {'summary': 'This paper studies the problem of the actual learnability of unlearnable datasets. Specifically, the authors have demonstrated that unlearnable datasets that are generated by existing methods can actually be used to learn generalizable features. In addition, the authors show that it is not necessary to make poisons linearly separable for achieving effective poisoning effects. Furthermore, based on the fact that most existing poisoning methods rely on linear separability, the authors propose a simple yet effective countermeasure to recover clean images for training.',\n",
       "  'strengths': '- It is valuable to revisit existing work in a popular field like data poisoning.\\n- The paper is very well written, with a thorough review of related work and sufficient descriptions of technical details. \\n- Experiments are extensive in terms of the number of models, datasets, settings, compared baselines, and so on. \\n- Several visualizations are provided to help support new findings.',\n",
       "  'weaknesses': 'I very much appreciate the paper, and there are no major weaknesses but minor ones about tuning down some claims:\\n\\n1. This paper is not the first to find a counterexample to the linear separability hypothesis considering that previous work has intentionally relied on ideas beyond linear separability for generating unlearnable datasets [a].\\n\\n2. The orthogonal projection method is not the only simple yet effective countermeasure considering [b], where the simple image compression-based method, ISS, is applied to remove poisoning perturbations. About the results, it seems that ISS is more globally effective than the orthogonal projection method. In addition, It would also be appreciated if diffusion models [3] and error-maximizing augmentation [20] can be compared. These two methods are also conceptually simple because they rely on either a per-trained (diffusion) model for pre-processing or data augmentation (that may not necessarily be adversarial). \\n\\n[a] Is Adversarial Training Really a Silver Bullet for Mitigating Data Poisoning? ICLR 2023\\n\\n[b] Image Shortcut Squeezing: Countering Perturbative Availability Poisons with Compression. ICML 2023'},\n",
       " 'review_442': {'summary': 'This paper conducts an analysis of the properties of unlearnable dataset methods to evaluate their potential for future viability and security assurances. It is demonstrated that neural networks possess the ability to learn generalizable features from unlearnable datasets, while also suggesting that image privacy may not be effectively preserved. Additionally, a counterexample is provided to challenge the widely held belief that unlearnable datasets induce learning shortcuts through the linear separability of added perturbations. To address this issue, an orthogonal projection attack is proposed, which enables learning from various unlearnable datasets. The results of this approach demonstrate that linearly separable perturbations should not be relied upon.',\n",
       "  'strengths': \"1. The originality of the paper is good, as it gives us a different view to unlearnable examples and poisoning attacks by\\n    (a). Demonstrating that neural networks possess the ability to learn generalizable features from unlearnable datasets \\n    (b). Giving a counterexample is provided to challenge the widely held belief that unlearnable datasets induce learning shortcuts through \\n      the linear separability of added perturbations\\n    (c). Proposing a new evaluation framework and a novel attack method to assess the viability and security promises of unlearnable datasets.\\n   Overall, The paper's findings challenge some widely held beliefs about unlearnable datasets and provide insights into their limitations and \\n   potential vulnerabilities\\n2. The proposed method can achieve good results on some of unlearnable tasks (class-wise) and is more effective than adversial training.\\n3. This paper is well-writen\",\n",
       "  'weaknesses': '1. The motivation for the paper does not align to me. I hope that the proposed method is motivated by the findings (Sections 4.2 and 4.3), however, the authors only illustrate the relationship between linearly separable perturbations and the proposed orthogonal projection method, making Section 4.2 a superfluous. There should be more discussion on the relationship between the findings and the methods presented in Section 4.4.\\n2. The author uses the DFR method to prove that DNN can learn useful features, but it is not convincing to me. The improvement in accuracy may simply come from using cleaner samples. (eg Figure 2, pictures (b), (c)). Also, I think the act of loss should also be involved in this part. There should be more references to why \"the higher the test accuracy after DFR, the more likely the model will pick up on private image features present in the original clean data\".\\n3. Although the authors give a counterexample to challenge the commonly held view that non-learnable datasets induce learning shortcuts by adding perturbed linear separability, it lacks theoretical analysis.\\n4. The method only achieves satisfactory results on Class-Wise perturbation, but the generalization of the method is not enough. In contrast, adversarial training has better generalization ability.\\n5. Limited evaluation: Evaluation requires more datasets.\\n\\n'},\n",
       " 'review_443': {'summary': 'This paper suggests that DNNs can learn useful features from unlearnable datasets and provides a counterexample, demonstrating that linear separability of perturbations is not a necessary condition. They propose the Orthogonal Projection method to recover unlearnable datasets.',\n",
       "  'strengths': '1. A new method called Orthogonal Projection is proposed to recover unlearnable datasets. On class-wise unlearnable datasets, this method achieves similar (or even betters) performance compared to adversarial training. Moreover, it is much faster than adversarial training.\\n2. This work suggests the risk of using class-wise perturbations to craft unlearnable datasets.',\n",
       "  'weaknesses': '1. For the claim \"DNNs can learn useful features from unlearnable datasets\", your experimental evidence is not sufficient and the logic is not very solid. See Question 1.\\n2. Though the intuition of Orthogonal Projection is clear, the purpose of its mathematical form is still ambiguous. Especially it cannot explain why this method is good at treating class-wise perturbations rather than sample-wise ones. See Question 2.\\n3. Sections 4.2, 4.3 and 4.4 have weak connections with each other, appearing as if they are independent from one another. The results in sections 4.2 and 4.3 are not interesting enough.'},\n",
       " 'review_444': {'summary': 'This paper comprehensively evaluated existing unlearnable examples and showed a surprising result. Unlearnable examples aim to prevent the model from learning useful features from the data. However, results show that several methods that networks actually can learn useful features. This is revealed by applying an existing feature reweighting method. Such results indicate that \"privacy\" might not be preserved. This paper also demonstrated that the recent findings of linear separation in unlearnable examples are not a necessary condition and an orthogonal projection attack can break class-wise linear separable unlearnable noise. ',\n",
       "  'strengths': '- By using an existing method of Deep Feature Reweighting (DFR), the finding is very interesting and new in this field. This paper has comprehensively evaluated the existing different methods for generating unlearnable examples. It is surprising to see model can \"actually\" learn useful features on several unlearnable methods. Interestingly, the error-minimizing does not. Although the exact cause remains unknown, such findings provide valuable insights for future works. Additionally, this also indicates that future works should consider DFR as a reasonable evaluation method for unlearnable examples. \\n- Based on recent work, Yu et al. [34] show that unlearnable examples rely on linearly separable noise. This paper extended the analysis to a wide range of different generation methods. Results show that although unlearnable examples are commonly induced linear separable noise, one particular method, Autoregressive perturbations, does not fall into this category. This indicates that linear separable noise is not a necessary condition. These results provide insights for future works that there could be more effective non-linear separable unlearnable noise. \\n- The presentations in this work are very good. It covered comprehensive related works, motivations, challenges and limitations in unlearnable examples.',\n",
       "  'weaknesses': 'My main concern is the Orthogonal Projection attack. Although it is technically sound, it is unclear what is the main contribution or the insight of this proposed method. \\n- Class-wise noise is known to be easily detected in unlearnable examples. Considering an additive noise, Yu et al. [34] show averaging across classes can easily expose the class-wise noise. One trivial solution that might consider is to subtract the noise for each class. Does an Orthogonal Projection attack more effective compared to this trivial solution? For Orthogonal Projection attacks, does it have any effect on the sample-wise setting?\\n- Compared to adversarial training (AT), the main benefit is efficiency. However, AT has other desired properties, such as adversarial robustness and learning robust features. As for effectiveness, it seems to be no significant benefit of the Orthogonal Projection attack. For OPS or OPS+EM, the constraint is a single pixel, while AT evaluated in this paper is $L_\\\\infty$, changing AT constraint might be effective against the OPS-based method. '},\n",
       " 'review_445': {'summary': 'This paper improves upon existing memory replay-based continual learning methods for anomaly detection. First the authors extend class balancing reservoir sampling (CBRS) and develop ECBRS, using global information in order to keep more accurate information about class imbalance. Second, the authors proposed a perturbation-assisted parameter approximation (PAPA) method for estimating virtual SGD parameter (VSP) updates, resulting in reduced training time for methods like maximally interfered retrieval (MIR). The proposed methods are evaluated on intrusion detection, computer vision, and anomaly detection datasets, and shown to increase performance while reducing training time.',\n",
       "  'strengths': 'This paper relies on simple heuristics that are shown to be quite effective for improving upon existing CL methods. The authors have also done extensive evaluation of their methods using several datasets, including ablation studies. In addition to performance improvements, the proposed methods can also reduce training times, resulting in better scalability.',\n",
       "  'weaknesses': \"- Since the paper heavily relies on CBRS and MIR, I suggest that the authors briefly describe these methods to make the paper more standalone and to make its novelties more clear. \\n- While the proposed methods are sound, I am not sure if the utilized evaluation datasets can fully support the paper's claims. The paper mainly focuses on learning from data with distribution shifts, however all but one of the evaluated datasets correspond to a short time period with little to no distribution shift.\\n- Related to the above, I am not sure if the inclusion of image datasets is needed as the proposed methods are presented for network intrusion datasets. The authors mention that they include image dataset to evaluate learning on data with distribution shifts, but I am not sure if image datasets contain any distribution shift.\\n- The authors should also include the standard deviation of AUC scores in Tables 2, 3.\"},\n",
       " 'review_446': {'summary': \"The authors propose techniques for improving how to select samples for\\nreplacement in the memory for continual learning and how to estimate\\nvirtual SGD in MIR to reduce computation.\\n\\nFor replacement in memory, CBRS does not keep track of class counts,\\nand replacement might occur on non-majority samples in the memory.\\nInstead the authors propose ECBRS (Extended Class Balancing Reservoir\\nSampling) keeps track of class counts (global information) and\\nreplacement prefers classes with the highest count.  Each class c has\\ngamma(c) as the expected count in the memory with weights favoring\\nsmaller classes.  Based on gamma(c), the next largest class might be\\nchosen.\\n\\nThey also propose Perturbation Assistance for Parameter Approximation\\n(PAPA) for MIR. In MIR sampling from the memory is informed by the\\nloss from virtual SGD parameter (VSP) updates for each sample, which\\nincur additional overhead.  They observe that VSP overlaps or scatter\\naround regular SGD parameter (RSP) updates.  They modeled the\\ndifference between VSP and RSP with a two-component Gaussian Mixture\\nModel (GMM).  Then they estimate VSP from RST and GMM.  The GMM is\\ntrained on one task and used in the remaining tasks.\\n\\nEmpirical results indicate that ECBRS generally outperforms 7 existing\\non 12 datasets.  ECBRS can also improve the performance of MIR.  The\\ntraining time for PAPA is lower than MIR on 11 datasets, but achieve\\nsimilar accuracy.\\n\\nI have read the authors' response and commented on them.\",\n",
       "  'strengths': '1.  The idea of estimaing virtual SGD updates is interesting.\\n\\n2.  Empirical results indicate that ECBRS generally outperforms and\\n    PAPA can reduce training time.',\n",
       "  'weaknesses': '1.  While PAPA is interesting, the reasoning for the error\\n    distribution from one task is applicable to another task could be\\n    further discussed/explored--see questions below.\\n\\n2.  Font sizes for Table 2-4 and some figures are quite\\n    small--difficult to read.\\n\\n3.  Some items can be clarified--see questions below.'},\n",
       " 'review_447': {'summary': 'The paper considers the application of deep learning (DL) for network intrusion detection systems (NIDS). The paper correctly points out that, in real contexts, NIDS must be continously updated with new data-points to mitigate the impact of \"concept drift\". A way to do so is by employing \"continual learning\" (CL) methods---which, unfortunately, are affected by many issues which the paper seeks to address.\\nSpecifically, the main contribution is a novel approach to deal with (i) class-imbalance problems leading to \"catatrophic forgetting\" (CF); and (ii) the computational overhead deriving from ways to mitigate CF. These contributions, whose intuitions are based on empirical evidence, are experimentally assessed on many datasets. The results show a good improvement over the baselines.',\n",
       "  'strengths': '+ Relevant problem\\n+ Large evaluation\\n+ Good results\\n+ (somewhat) theoretically grounded\\n+ Multiple repetitions\\n+ Good quality of writing\\n+ The supplementary material is rich with details\\n\\nThe paper addresses a relevant problem within the machine learning (ML) domain, which has received only limited attention in the specific context of network intrusion detection (NID). The proposed methods are theoretically grounded (especially Section 3.1), and the findings are derived by a large sets of experiments carried out on various datasets (which are not limited to NID data) and considering many baselines. The conclusions are drawn by repeating the experiments 5 times, increasing the overall soundness of the results---showing a substantial improvements over the baselines.',\n",
       "  'weaknesses': '\\n## High Level\\n\\n- Inappropriate datasets\\n- (somewhat) confusing theoretical arguments \\n- Bold assumptions\\n- (risk of) data snooping\\n- (some) missing details\\n\\n## Low Level (and suggestions)\\n\\nBelow is an extended description of the abovementioned weaknesses. I will also provide some actionable means to rectify such issues, as well as abundant references that can be used to improve this paper and/or support some of my critiques. \\n\\n### Inappropriate datasets\\n\\nThis is by far the biggest concern I have with the paper: the data used as basis for the experiments is inappropriate to test the hypothesis and provide a _convincing_ answer. Let me explain.\\n\\nFirst, the paper deals with the problem of NID. As such, _any finding that derives on data that does not pertain to NID is redundant_. This automatically makes all the evaluations carried out on, e.g., on CIFAR, SVHN, CLEAR to be of zero-value to the NID community (do note that a recent paper [D] highlighted that many papers on security problems carry out evaluations on data that does not reflect a security context, leading to skepticism by practitioners). I acknowledge that these datasets were added due to some limitations of (some) existing datasets for NID, but this is not an acceptable reason: if the authors were better aware of the NID context, they would know that there are (publicly available) datasets that allow a better representation of a real CL scenario. (more on this below).\\n\\nSecond, among the chosen NID datasets, there is the NSL-KDD and KDD Cup\\'99. These datasets are well-known to be flawed [C]; furthermore, they are also almost 25 years old, and the security community does not find them to be of any interest from a practical viewpoint [B, I]. Hence, even these experiments do not allow to provide a convincing argument in favor of the paper\\'s conclusions.\\n\\nThird, the NID datasets also include the CIC-IDS17 and its enhanced variant, the CIC-IDS18. Unfortunately, also these two datasets are flawed [G, H]. Note that [G] came out in 2021, and it has already been well-received by the NID community (e.g., [A, F]), so it is concerning that this paper (which has been submitted to a top-venue such as NeurIPS) performs the experiments on the \"flawed\" variant of these two datasets---especially given that a \"fixed\" version exists (provided both in [G] and [H]). In short, these experiments are questionable; plus, what is even more questionable is that CIC-IDS17 and CIC-IDS18 are used to derive some observations that motivate the theoretical design of the proposed method.\\n\\nFourth, overlooking the previous two points, all the NID datasets span over a very short period of time, and do not enable any assessment that can be used to test \"time-aware\" applications of machine learning-based NIDS [F] -- or, at least, do so in a way that is appropriate for NeurIPS. The only exception could, potentially, be ANONIDS: however, such a dataset contains data-points from different networks, which raises many concerns [S, O]. Hence, even this dataset has dubious utility for the problem at hand.\\nThe way to circumvent all these issues is not to use \"image datasets\", but rather to use NID datasets captured (i) over a long period of time and (ii) in the same network: _such datasets **exist**_, and a prominent example is the MCP dataset, which is built upon the well-known CTU13 dataset (see [J,K]). \\n\\nTo summarize: all the experiments carried out in the paper are performed on datasets that are inappropriate to test the underlying hypothesis without there being a sensible reason to do so.\\n\\n### Bold Assumptions\\n\\nThis is a \"pragmatic\" weakness, which does not invalidate the paper, but significantly limits its real-world relevance.\\n\\nPut simply, the paper proposes a method that is rooted in the application of \"deep learning\" (DL) for NID. The problem, however, is that real developers of ML-NIDS are very skeptical of DL in NID [L]. The reasons are many, but at the basis of this is that they are hardly explainable [M], but also that they are outperformed by \"traditional\" machine learning approaches (assuming that they can be applied). For example, [E] shows that multi-layer perceptrons are inferior to a random forest from a detection-performance perspective. Moreover, [B] reveals that fine-tuning a DL method requires months of data. Finally, the recent [F] shows that training \"shallow\" methods (such as decision trees) is very short. Note that [F] uses similar datasets as the ones used in this paper: to give some context, training a binary classifier using a decision tree on UNSW-NB15 requires less than 5s, whereas the MLP used in this paper requires 350s (looking at Table 3) -- and the experiments done in this paper entail much better hardware.\\n\\nIn light of this, it is questionable whether the proposed method has any relevance in reality. Yes, perhaps it provides some advantages -- but if the price of such advantages is an unacceptably high training time (which the method itself seeks to reduce) then the overall contribution of this paper to the state-of-the-art is low.\\n\\nTo address this issue, I invite the authors to include also \"shallow\" methods that do not entail (deep) neural networks, and show that the proposed method allows the resulting architectures to achieve a comparable degree of performance of \"shallow\" methods.\\n\\n\\nNotwithstanding, there is another \"bold assumption\" made in the paper: the fact that the \"malicious classes\" are going to remain stable. Indeed (to the best of my understanding), the paper seeks to analyze the effect of distribution shift of the \"benign\" samples (this is explicitly stated in the introduction), and the set of malicious classes is always known beforehand. This is quite unrealistic (and it had been known since [O]), and may further decrease the value of the proposed method in practice: what would happen in case a new \"unknown\" attack appears, and is then assigned a \"new\" label? \\n\\nOn this note, the other \"practical\" limitation is that the paper assumes that there will be an influx of (correctly labelled) samples that are fed into the system. How is this done in practice? Abundant work (see [N] for a summary) pointed out that doing this is expensive, and especially so in NID context. As a matter of fact, what is not shown in the paper is a clear \"use-case\" that depicts how the system is designed to be deployed in practice: without such a schematic, it is difficult to determine if the proposed method is even \"conceivable\" to be deployed into real systems (as also highlighted in [F], practitioners are very interested in the \"system infrastructure\" envisioned in research papers). Note that I did look in the supplementary material, but the \"schematic\" provided in Figure 3 does not allow to answer my doubts: the \"continual learning module\" appears to be a \"black-box\" that receives its inputs from a \"training dataset\". However, how is such training data collected (given that we are in an \"continual learning\" setting)? The way I see it, it requires an enormous amount of manual effort.  \\n\\n\\n### (somewhat) confusing technical arguments\\n\\nWhile I had no issues in understanding the rationale of Section 3.1 (aside from the following unclear sentence ```In our approach, we choose this parameter based on global information.```), I found that the description of Section 3.2 to be lacking in terms of clarity and soundness. Setting aside that the experiments are based on \"inappropriate\" datasets, I did not find compelling evidence of ```virtual SGD parameter update is a slowly varying process.``` -- and this may be due to Figure 3 not being introduced in any way (e.g., what do the x and y axis report? what is the line? the y-axis is also not uniform).\\n\\nI also did not find the \"motivation\" (mentioned in the Introduction) that leads up to Section 3.2 to be clear. To my understanding, the problem is that the implementation of memory-replay techniques is expensive from a computational perspective---but is this really the case for NID? As I mentioned above, \"shallow\" methods are much faster to train.\\n\\nAlso, at the end of the Introduction it stated that ```[PAPA] lead[s] to improved scalability.```. What does this mean? The key-term is \"scalability\". I do not see any evidence in Section 3.2 that makes me believe that PAPA leads to better scalability. I invite reading [P, Q].\\n\\n\\n### Potential Data Snooping\\n\\nI have reason to believe that the methodology followed in the paper is affected by the \"data snooping\" problem [15]. In other words: the proposed method is designed in a way that would not be typically \"known\" in advance.\\n\\nThis is epitomized by Section 3.2, wherein some conclusions are drawn by analyzing CIC-IDS18 (and CIFAR), and then used to develop the proposed methodology. At the same time, this is also likely to be present in the experimental setup:\\n\\n> The intuition behind the memory size is to store nearly 1% of the total training sample of the benchmark dataset in the buffer memory, and 75% of the buffer memory samples will be used for replay.\\n\\nThe point is that a real developer has no clue about the size of the \"training dataset\": in real settings, an organization will collect some training data, and then use it to train a model; however, they would not know \"how much data will appear in the future\". It is possible to address this later issue by assuming a \"fixed amount\" (e.g., 1000 samples) which does not depend on the size og a given benchmark (this is what is done, e.g., in [N]). \\n\\n\\n### Some additional issues:\\n\\n* In the caption of Figure 1, it is not stated what \"m\" refers to\\n* Bad formatting on Page 6 (the text overlaps with Algorithm 2)\\n* Also about formatting: tables and figures (and their captions) are almost impossible to discern from the text itself. I think the authors played too much with margins.\\n* Given the importance of hardware in determining the runtime [F], the main paper should include also details on the experimental platform.\\n* There is an excessive usage of acronyms in the paper. For instance, SBCP occurs only 3 times (and is strikingly similar to CBRS). Also, MR and MIR are very similar in how they appear, but they denote different concepts. HIDS is also redundant. \\n* Reference [14] is incomplete\\n* In Section 3.1, I had a hard time distinguishing between terms such as \"maximal\", \"majority\", \"full\", \"largest.\"\\n* The \"Limitations\" are only mentioned in the supplementary material\\n* The features used to train the models are not mentioned (I found such a lack to be surprising given that the paper cites [15]). Some network features have been demonstrated to be redundant for the sake of NID classification (see [G, H, S]), and not mentioning them casts doubts on the experiments done in the paper. Note that I did not find any mentioning of these also in the supplementary material\\n* I was surprised of not finding [A] among the cited works, and especially among the \"comparison\" methods, given that it considers a very similar problem (and is also evaluated on the --fixed-- CIC-IDS17)\\n* Please report the size of the training / test data. I couldn\\'t find a clear mention of this in the experimental section (note that this is a well-known problem in related literature [N]). \\n* The \"bread and butter\" of CL is that the performance should be measured \"over-time\". However, given the way the experiments are designed (at least based on how the results are presented), I cannot understand if this is truly the case. \\n\\nThe following is a list of paragraphs in the text for which I have concerns:\\n\\n> NIDS must evolve continuously and effortlessly learn from the limited novel attack data.\\n\\nWhat does \"limited novel attack data\" mean? How is such \"novelty\" determined?\\n\\n> Furthermore, formulating NID as a supervised binary classification problem (SBCP) will be helpful in differentiating out-of-distribution normal samples from known intrusions well.\\n\\nIsn\\'t this the de-facto standard in many NIDS evaluations? I think this statement is redundant.\\n\\n> (e.g., the difference between the number of samples of the minority classes DDOS attack-HOIC and SQL Injection of the CICIDS-2018 [18] dataset is 0.68 million).\\n\\nUnclear.\\n\\n> However, this strategy has a pitfall when the count of minority class samples in the finite buffer memory appears to come from a majority class.\\n\\nUnclear. Plus, what does such \"pitfall\" lead to?\\n\\n> making our approach suitable for large-scale training.\\n\\nWhat does this mean? Plus, is this a problem in NID?\\n\\n> Typically, the benign class samples must be chosen for replacement whenever new minority class samples arrive.\\n\\nDefine \"typically\". Is it \"typical\" in research? Is it typical \"in practice\"? On what grounds is this statement made?\\n\\n> we use original class labels to organize the buffer memory to learn SBCP and chose class samples in memory with higher running statistic values for the replacement to accommodate newly arriving samples.\\n\\nThis statement is clear, but it contrasts with the underlying assumption of seeing NID as a binary classification problem. Indeed, providing (accurate) fine-grained attack labels is a tough problem in NID [N, R].\\n\\n> This ensured that each task contained a mix of benign and attack data, maintaining the class imbalance resembling real-world network traffic.\\n\\nHow is the \"resemblance\" achieved?\\n\\n> We created five tasks for KD249 DCUP’99 [22] and NSL-KDD [49], ten 250 for CICIDS-2017/2018 [18, 50], nine for UNSW-NB [24, 51, 52, 53, 54], and ten for ANOSHIFT [25] benchmark contains naturally occurring distribution shifts spanning over ten years of network traffic.\\n\\nThe last sentence does not connect with the previous ones.\\n\\n> We use M=13333 for CICIDS-2017/2018, Anoshift, 5333/1333 for KDDCUP’99/NSL-KDD, 500 for SVHN, CIFAR-10/100 and 666/2666 for CLEAR-10/100.\\n\\nI do not understand why the first settings have only \"M\", and the others have two numbers.\\n\\n### EXTERNAL REFERENCES\\n\\n[A]: Andresini, Giuseppina, et al. \"INSOMNIA: towards concept-drift robustness in network intrusion detection.\" Proceedings of the 14th ACM workshop on artificial intelligence and security. 2021.\\n\\n[B]: Apruzzese, Giovanni, et al. \"The role of machine learning in cybersecurity.\" Digital Threats: Research and Practice 4.1 (2023): 1-38.\\n\\n[C]: Kim, Daniel E., and Mikhail Gofman. \"Comparison of shallow and deep neural networks for network intrusion detection.\" 2018 IEEE 8th Annual Computing and Communication Workshop and Conference (CCWC). IEEE, 2018.\\n\\n[D]: Apruzzese, Giovanni, et al. \"“Real Attackers Don\\'t Compute Gradients”: Bridging the Gap Between Adversarial ML Research and Practice.\" 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). IEEE, 2023.\\n\\n[E]: Pontes, Camila FT, et al. \"A new method for flow-based network intrusion detection using the inverse Potts model.\" IEEE Transactions on Network and Service Management 18.2 (2021): 1125-1136.\\n\\n[F]: Apruzzese, Giovanni, Pavel Laskov, and Johannes Schneider. \"SoK: Pragmatic Assessment of Machine Learning for Network Intrusion Detection.\" IEEE EuroS&P (2023).\\n\\n[G]: Liu, Lisa, et al. \"Error Prevalence in NIDS datasets: A Case Study on CIC-IDS-2017 and CSE-CIC-IDS-2018.\" 2022 IEEE Conference on Communications and Network Security (CNS). IEEE, 2022.\\n\\n[H]: Engelen, Gints, Vera Rimmer, and Wouter Joosen. \"Troubleshooting an intrusion detection dataset: the CICIDS2017 case study.\" 2021 IEEE Security and Privacy Workshops (SPW). IEEE, 2021.\\n\\n[I]: Silva, João Vitor Valle, Martin Andreoni Lopez, and Diogo MF Mattos. \"Attackers are not stealthy: Statistical analysis of the well-known and infamous kdd network security dataset.\" 2020 4th Conference on Cloud and Internet of Things (CIoT). IEEE, 2020.\\n\\n[J]: Dietz, Christian, et al. \"DMEF: Dynamic Malware Evaluation Framework.\" NOMS 2022-2022 IEEE/IFIP Network Operations and Management Symposium. IEEE, 2022.\\n\\n[K]: Venturi, Andrea, et al. \"Drelab-deep reinforcement learning adversarial botnet: A benchmark dataset for adversarial attacks against botnet intrusion detection systems.\" Data in Brief 34 (2021): 106631.\\n\\n[L]: De Shon, Markus. \"Information Security Analysis as Data Fusion.\" 2019 22th International Conference on Information Fusion (FUSION). IEEE, 2019.\\n\\n[M]: Jacobs, Arthur S., et al. \"AI/ML for Network Security: The Emperor has no Clothes.\" Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 2022.\\n\\n[N]: Apruzzese, Giovanni, Pavel Laskov, and Aliya Tastemirova. \"SoK: The impact of unlabelled data in cyberthreat detection.\" 2022 IEEE 7th European Symposium on Security and Privacy (EuroS&P). IEEE, 2022.\\n\\n[O]: Sommer, Robin, and Vern Paxson. \"Outside the closed world: On using machine learning for network intrusion detection.\" 2010 IEEE symposium on security and privacy. IEEE, 2010.\\n\\n[P]: Hill, Mark D. \"What is scalability?.\" ACM SIGARCH Computer Architecture News 18.4 (1990): 18-21.\\n\\n[Q]: Luke, Edward A. \"Defining and measuring scalability.\" Proceedings of Scalable Parallel Libraries Conference. IEEE, 1993.\\n\\n[R]: Van Ede, Thijs, et al. \"Deepcase: Semi-supervised contextual analysis of security events.\" 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 2022.\\n\\n[S]: Apruzzese, Giovanni, Luca Pajola, and Mauro Conti. \"The cross-evaluation of machine learning-based network intrusion detection systems.\" IEEE Transactions on Network and Service Management (2022).\\n\\n[T]: Pendlebury, Feargus, et al. \"TESSERACT: Eliminating experimental bias in malware classification across space and time.\" Proceedings of the 28th USENIX Security Symposium. USENIX Association, 2019.\\n'},\n",
       " 'review_448': {'summary': \"The paper introduces a novel time series interpretability model called TIMEX. The challenge of interpreting time series models arises from the need to identify both the specific time series signals influencing predictions and their alignment with interpretable temporal patterns. TIMEX addresses the issue of model faithfulness by introducing model behavior consistency, ensuring relations in the latent space induced by the pretrained model are preserved when compared to relations in the TIMEX-induced latent space.\\n\\nTIMEX provides discrete attribution maps, giving interpretable explanations for the model's predictions. Unlike existing methods, TIMEX goes further by learning a latent space of explanations, enabling visual aggregation of similar explanations and recognition of temporal patterns.\\n\\nThe evaluation of TIMEX on 4 synthetic and 4 real-world datasets, which includes case studies involving physiological time series, demonstrates its superior performance compared to state-of-the-art interpretability methods. TIMEX's innovative components hold promise for training interpretable models that capture the behavior of pretrained time series models.\",\n",
       "  'strengths': \"Overall the proposed method is novel, effective, and well-evaluated. The main strengths of the paper are as follows:\\n\\n1. The paper proposes a novel method for explaining time series models that is based on self-supervised learning. This approach has several advantages over traditional explanation methods, such as being able to learn explanations for models with complex temporal dynamics. The paper provides a clear and concise overview of the problem of explaining time series models and provides a detailed description of the TimeX method, including the rationale behind the design choices.\\n\\n2. The authors presents a comprehensive evaluation of TimeX on a variety of experiments with time series models and datasets. The results show that TimeX is able to provide interpretable explanations that are both faithful to the model's predictions and informative about the underlying temporal patterns.\\n\\n3. The paper also includes a number of case studies that demonstrate the use of TimeX to explain the predictions of time series models in real-world applications. These experiments help highlighting TimeX's capability to be used for gaining insights into the behavior of time series models and to identify potential problems with the models.\\n\\n4. The authors evaluate TimeX through an extensive set of ablations and on a variety of time series models. TimeX shows to be effective in explaining a variety of time series models, including LSTM, CNN, and vanilla-Transformer model. This suggests that TimeX is a general-purpose method for explaining time series models.\",\n",
       "  'weaknesses': 'The are a few weaknesses that if addressed or identified as a limitation for future can improve the paper:\\n\\n1. As the current setup is presented, the model does not handle variable length time-series which is a common occurrence in medical time-series data. This could prove to be challenging to be extended from the current state of TimeX as aligning different time-series that have variable length would also become important.\\n\\n2. Another common challenge of dealing with time-series data that is not addressed in the paper, is handling irregular time-step intervals. A discussion of this important limitation is missing in the paper. Irregularly sampled time-series is predominantly present in healthcare data that this paper focuses on and is important weakness of the TimeX that is not mentioned in the paper.\\n\\n3. The method has not been evaluated on a wide range of different tasks. The authors of the paper evaluated TimeX on a variety of time series models and datasets, but they did not evaluate TimeX on a wide range of tasks. This means that it is not clear how well TimeX would perform on other tasks, such as anomaly detection or forecasting.\\n\\n4. TimeX currently does not handle temporal prediction (i.e. a prediction task where prediction is done at every time-step), and it is unclear how it can be expanded to provide explanations for models designed for such tasks.'},\n",
       " 'review_449': {'summary': 'TimeX proposes a explanation module that is trained along-side the model to provide more consistent explainiations. This is done by making the internal embeddings of explaination modules consistent with that of full model such as distance consistency and label consistency.',\n",
       "  'strengths': '1. The methodology is well motivated and presented.\\n2. The consistency losses encourage expaliation module features to learn from latent space of the model.\\n3. The synthetic experiments are well setup and model provides significant performance improvements in synthetic and real-world dataset.',\n",
       "  'weaknesses': '1. The novelty of the method seems unclear. Model consistency has been previously explored in neural explainations and this work dovtails to time-series models.\\n2.What is the additional computational complexity or resources required to train the explainer modules? How does it compare to other methods?'},\n",
       " 'review_450': {'summary': 'This paper presents an in-hoc interpretability mechanism to explain time series prediction. In particular, the authors train an interpretable surrogate model by learning H^E and G^E in the embedding space.\\n\\nThe objective function optimizes model behavior consistency by considering the distance in the training embedding, Z, and explained embedding, Z^E.\\n',\n",
       "  'strengths': '1. Discrete masking as opposed to continuous masking\\n2. Landmark to partition latent space visualization and shape of the signal\\n3. Can be generalized to other classification tasks and neural model architectures\\n',\n",
       "  'weaknesses': 'As demonstrated by the ablation studies, the label alignment (LA) loss is always better than MBC in isolation.\\n\\n'},\n",
       " 'review_451': {'summary': 'This paper proposed TimeX that creates an interpretable surrogate model for pretrained models. To ensure faithfulness to the reference model, this paper introduces a self-supervised objective, model behavior consistency, a novel formulation that ensures the preservation of relationships in the latent space induced by the pretrained model, as well as the latent space induced by TimeX. As a result, TimeX could find well-distributed landmarks and highlight a range of salient timestamps.\\n',\n",
       "  'strengths': '1. It is well-written and has strong motivation.\\n2. This is the first paper to suggest in-hoc explanations for time series data.\\n3. This article offers additional justifications for its design decisions, including discrete masking and consistency learning.\\n4. The evaluation is very convincing, using diverse datasets and many compared methods.',\n",
       "  'weaknesses': '1. No discussion about the quality of explanation. Please see questions.\\n'},\n",
       " 'review_452': {'summary': 'This paper introduces a novel method to train an interpretable surrogate of pre-trained  time series classification models. TimeX produces a latent embedding of time series observation and outputs classification probabilities that are both consistent with a reference model. At the same time, it identifies time localized patterns in the time series that allowed it to make predictions. Last, it learns landmarks in the latent space that allow the user to easily compare the observed time series.\\n\\nFrom pre-trained encoder $G$ and decoder $F$, TimeX trains an explanation generator $H_E$, encoder $G_E$ and decoder $F_E$. $H_E$ produces a discrete masking function that allows to localize and consider only sparse yet connected regions of interest in the input time series. $G_E$ and  $F_E$ are jointly trained to respectively preserve the \"topology\" of the latent spaces and the output distributions.  \\n\\nPlease note that the submission is not in my area of expertise. I can assess the soundness of the claims and the presentation but it is hard to evaluate its broader contribution to the field.',\n",
       "  'strengths': 'The notion of Model Behavior Consistency is, from my understanding, the main contribution of this paper. Although many methods aim at  embedding high dimensional observations in topology-preserving latent spaces, the idea of learning an interpretable embedding consistent with pre-trained models is novel to my knowledge. I find the approach particularly relevant as high-capacity models become more and more accessible.\\n\\nAlthough the technical description of the method is not very well written (see below), each modeling choice is convincing and well motivated (each term of the *ad-hoc* loss is easily interpretable and the need for discrete masking for time series is well demonstrated). \\n\\nThe experimental results demonstrate improved performance that I cannot really evaluate (see above).\\n\\n\\n\\n',\n",
       "  'weaknesses': '1) Some statements seem inaccurate if not incorrect. (I will be happy to be proven wrong, as I am not an expert in Time-Series Classification)\\n\\n   - line.22 \"State-of-the-art time series models are high-capacity pre-trained neural networks\" -> This might be true for time-series classification, but seems wrong in other areas like forecasting, where uncertainty quantification is key. \\n\\n   - There is an apparent conflict between the need for \"pinpointing the specific location [...] that influence the model\\'s prediction\" (line 24) and the fact that \"temporal patterns only show up when looking at time segments and long term trends\" (line 54). For example, if the feature of interest is the frequency content of a time series, it seems pointless to precisely localize it in time. From my understanding, TimeX reaches an in-between suitable to pinpoint patterns \"broadly-localized\" in time. The paper would gain in clarity by stating more clearly what the method is trying to achieve. \\n\\n   - line 47. \"the uninterpretable nature of time series data\". I would avoid such vague statements. For example, the QRS intervals subsequently analyzed are straightforwardly interpretable and corresponds to ventricles depolarization and heart contraction.\\n\\n2) The description of the method is not intelligible but could easily be improved. \\n   - line 154. The functions $D_Z$ and $D_Z^E$ are used to motivate Model Behavior Consistency, but it is not explained that they convey a notion of distance in the latent space (this only shows up line 241)\\n\\n   - Although I understand  the relationship $D_Z(z_i, z_j) \\\\approx D_Z^E(z_i^E, z_j^E)$ (line 154) and its implication, it is very confusing to write $z_j^E = G^E(E(x_i))$ (line 153).  $z_j^E$ is a latent representation of the masked time series $x^m_j$. And $E$ is defined above as explanation that takes value in $[0, 1]$ (see line 189). Did I miss something ? \\n\\n   - The notation $H^E: \\\\mathcal{X} \\\\rightarrow p \\\\in [0, 1]^{T \\\\times d}$ does not make sense (line 184). Is $\\\\mathcal{X}$ the input space of the function $H^E$ or its input ? In the former case, one should write $H^E: \\\\mathcal{X} \\\\rightarrow [0, 1]^{T \\\\times d}$. In the latter case it implies that the mask applies uniformly to the whole dataset $\\\\mathcal{X} = (x_i)_i$ which contradicts my intuition from Figure 2.\\n\\n3) Figure 4 clearly illustrates what part of the ECG the model based its prediction on. Nevertheless, there is no further analysis of the discovered temporal patterns. Are they unexpected or are they stereotyped signals easily classifiable by a physician ? In the latter case, it would have been interesting to use an additional classification task and illustrate how TimeX can identify new temporal patterns in observations, and possibly be used for exploratory data analysis.\\n\\nMinor points: line 91. XAI: abrevation not defined '},\n",
       " 'review_453': {'summary': 'This paper provides convergence results for Adaptive Moment Estimate (Adam) and its variance-reduced variant under generalized smooth and bouned-noise assumptions.',\n",
       "  'strengths': 'This paper mainly studies the convergence of Adaptive Moment Estimate (Adam) under a generalized smooth assumption. The authors drop the commonly used globally bounded gradients assumption and provide a new analysis framework, which is based on a contradiction argument, to show that gradients are bounded along the optimization trajectory. Based on this, the authors could deduce a high probability convergence bound of $\\\\mathcal{O}(\\\\epsilon^{-4})$ for Adam under the generalized smooth assumption. The paper also provides a variance-reduced version of Adam and improves the gradient complexity to $\\\\mathcal{O}(\\\\epsilon^{-3})$. \\n\\nIn general, the assumptions are standard in the analysis of adaptive methods including unbiased gradient estimate and bounded noise. The convergence results make sense and are highly valuable since the convergence result of Adam under unbounded gradients still leaves empty, to my best knowledge. As Adam is a widely used optimizer in deep learning field, the theoretical results (like parameter setting in Theorem 4.1 and Theorem 4.3) in this paper could help practitioners to better understand and use the algorithm. The central idea of analysis is inspiring.',\n",
       "  'weaknesses': 'First, the convergence result requires a dedicated tuned step-size and momentum parameters, specifically requiring prior knowledge such as generalized smooth parameter $(L_0, L_1)$ and the noise level $\\\\sigma$. However, in most realistic situations, these parameters could be unknown or hard to obtain. Thus, the result is more valuable in the theoretical aspect but may not be so useful in the experimental aspect.\\n\\nSecond, the parameter setting in Theorem 4.1 contradicts the real-one default setting on deep learning packages (such as Pytorch or Tensorflow) where $\\\\beta_1 = 0.9 $ is smaller than $\\\\beta_2 = 0.999$. It may be more persuasive to do some experiments showing the convergence under this new parameter setting.\\n\\nThird, the high probability convergence result in Theorem 6.2 does not provide an optimal rate to the probability margin $\\\\delta$, leaving space for further improvement. In addition, since VRAdam is a new algorithm, it better requires some experiments to show its convergence under the parameter setting in Theorem 6.2 and its faster convergence rate than Adam. '},\n",
       " 'review_454': {'summary': 'This paper studies the convergence of the Adam algorithm. Under a more general local smoothness assumption, the convergence of Adam to stationary points is proved without assuming boundedness of the loss gradient. Here the key technique is to show that the loss gradient along the trajectory is indeed bounded, using a proof by contradiction. A variance-reduced variant of Adam is proposed to achieve an accelerated gradient complexity.',\n",
       "  'strengths': 'The convergence of Adam is definitely an important question, and this paper seems to be a significant contribution by relaxing the bounded gradient assumption. The argument of bounding the gradients along the optimization trajectory looks neat and easy to understand. Overall the result of the paper is solid and novel, and the writing is also easy to follow.',\n",
       "  'weaknesses': \"It seems that the proof doesn't suggest the benefit of the momentum. It would be helpful if the authors can comment on this and provide some insights on the theoretical understanding of the momentum term.\\n\\nIt would also be helpful if the authors can summarize the recent results on Adam convergence in the form of a table.\"},\n",
       " 'review_455': {'summary': 'This paper studies the convergence of Adam over non-convex objectives. To begin with, this paper proposes a new non-uniform smoothness condition called $(\\\\rho, L_0,L_1)$ smoothness condition, which generalizes $(L_0,L_1)$ smoothness condition proposed in [Zhang et al. 2019]. The authors then prove the high-probability convergence rate $\\\\mathcal{O}(1/\\\\sqrt{T})$ of Adam under $(\\\\rho, L_0,L_1)$ smoothness condition and affine noise variance assumption. The authors then propose Variance Reduced Adam (VRAdam) by combining the gradient estimation of STORM into Adam, and derive the convergence rate $\\\\mathcal{O}(1/\\\\sqrt[3]{T^2})$ of VRAdam.',\n",
       "  'strengths': '1. This paper provides the first $O(1/\\\\sqrt{T})$ convergence rate of Adam without the bounded gradient assumption.\\n\\n2. The constructed stopping time is interesting and can be of independent interest. ',\n",
       "  'weaknesses': '1. Although this paper provides the first $O(1/\\\\sqrt{T})$ convergence rate of Adam without the bounded gradient assumption, the analysis is somewhat restricted because it requires a non-zero $\\\\lambda$ and the convergence rate has a polynomial dependence over $1/\\\\lambda$. However, in the previous analyses of Adam including [Défossez et al., 2020; Zhang et al., 2022, Wang et al., 2022], it is allowed that $\\\\lambda=0$ or the rate has a logarithmic dependence over $1/\\\\lambda$. I treat this as a weakness of this paper because, in practice, $\\\\lambda$ is set to very close to $0$ (for example, $10^{-8}$ as the default value in PyTorch) and may result in very loose bound.\\n\\n2.  As mentioned in this paper, the assumed noise condition is still stronger than the assumptions used for the analysis of other optimizers, for example, affine variance assumption.\\n\\n**Minor Issue**:\\n\\nThe statement with respect to [Zhang et al., 2022; Wang et al., 2022] in line 28 is not inproper. In fact, if you pick $\\\\beta_{sq}$ according to $\\\\epsilon$ in [Zhang et al., 2022; Wang et al., 2022] just as this paper does, you can derive the convergence to stationary points (but with a slower rate). Therefore, a proper statement should be \"but the convergence rate of [Zhang et al., 2022; Wang et al., 2022] is slower\".\\n\\n**References**\\n\\nDefossez et al., A Simple Convergence Proof of Adam and Adagrad, 2019\\n\\nZhang et al., Adam Can Converge Without Any Modification On Update Rules, 2022\\n\\nWang et al., Provable adaptivity in Adam, 2022'},\n",
       " 'review_456': {'summary': 'The paper proposes a new proof strategy for the convergence of Adam in the\\nnon-convex setting. The new analysis relaxes the typical assumptions\\nin the following ways: 1) it assumes relaxed smoothness, where the norm of the Hessian\\ngrows sub-quadratically with the gradient norm; 2) it does not require\\nbounded gradients. With a deterministic gradient oracle, the obtained rate is $O(1/\\\\epsilon^2)$.\\nFor the stochastic setting, the author shows a convergence rate of $O(1/\\\\epsilon^4)$\\nwith high probability.\\n\\nFurthermore, the author proposes a variance-reduced version of Adam and proves\\na rate of $O(1/\\\\epsilon^3)$. The above rates in stochastic setting is dimension-dependent\\nand can be dimension-free if the Hessian norm is sub-affine on the gradient norm.\\n\\nThe main limitation is that although the bounded gradient assumption is removed,\\nthe bounded noise is still needed.',\n",
       "  'strengths': '1. The paper is well-written and easy to follow. Specifically, the technical\\nchallenges and the intuition behind the new analysis are discussed comprehensively.\\n2. Removing the bounded gradient assumption is generally challenging. Although\\nthere are a few works for AdaGrad that address this, existing work targeting\\nthe removal of this assumption for Adam only converges to a neighborhood of\\nstationary points.\\n3. The paper considers the smoothness condition where the norm of the\\nHessian is bounded by a sub-quadratic function of the gradient norm, which\\nis more general than $(L_0, L_1)$-smoothness.',\n",
       "  'weaknesses': '1. Although the work relaxes the bounded stochastic gradient assumption\\n   commonly required in the analysis of Adam, assuming almost surely bounded\\n   noise is still somewhat strong and impractical. Since the proof technique,\\n   the contradiction argument, heavily relies on this assumption, it is\\n   unclear whether it can be used in more realistic settings.\\n2. It is difficult to assess the usefulness of the proposed variance reduction method\\nsince the convergence result does not improve upon previous methods and there\\nis no experimental evidence.\\n\\n\\nMinor:\\n\\nThe result presented for the deterministic setting is not formal. It would be\\nbetter to have a formal theorem, at least in the appendix.'},\n",
       " 'review_457': {'summary': 'The paper removes the Lipschit gradient assumption for the adaptive SGD (ASGD), making the ASGD broader to wide applications. Under the weak assumption, the authors still proved the optimal convergence rate. Moreover, they propose a variance-reduced version  with an accelerated complexity. The results are interesting and novel.',\n",
       "  'strengths': '1. They further relaxed the ($L_0,L_1$)  Lipschit gradient assumption, which is more relastic.\\n\\n2. They  develop a new analysis to show that ASGD can be convergent under the weak Lipschit gradient assumption but still with the same rate as existing works on ASGD. The results and techniques are novel.\\n\\n3. A variance-reduced version of  ASGD is proposed with provable acceleration.\\n\\n4. The authors show that the rates of ASGD and its variance-reduced version is dimension-free under certain cases.',\n",
       "  'weaknesses': '1. The proof of variance-reduced version is interesting but without any numerical demonstrations. If the authors proposed an accelerated algorithm, it is convening to present some numerics because the theory is not the focus now.\\n\\n2. In the contribution part, the authors claim that they do not assume bounded gradients. This is because you assume the a.s. bounded noise. which has been studied by previous work [Li and Orabona, 2019].\\n\\n'},\n",
       " 'review_458': {'summary': 'This paper proposes a latent space Bayesian Optimization approach based on the intuition that distances in the latent space should be correlated with differences in objective value. CoBO iteratively updates a variational autoencoder (VAE) to align distances in latent space with differences in objective function. The method leverages a lower bound on correlation to introduce new regularizers on the VAE objective. Combined with loss weighting and latent space “recoordination”, the method achieves state-of-the-art performance on diverse benchmarks.',\n",
       "  'strengths': 'The paper mostly applies existing techniques to achieve incremental but statistically significant improvement over prior state-of-the-art. Theorem 1 provides a useful result that is a significant contribution of its own, if it is in fact a new bound.\\n\\nThe paper is written very well and will likely serve as a benchmark for future BO algorithms. Algorithm 1 provides a nice, approachable, and thorough description of CoBO. Figures 4-5 show strong evidence that the CoBO objective has a strong positive effect on organizing the latent space.\\n\\nThe experimental results are convincing. An ablation study justifies the inclusion of all components of the proposed VAE objective, albeit on only one optimization benchmark (hopefully these results hold for all benchmarks studied).\\n\\nI would suggest trying to fit Table 3 from the Supplemental into the body of the paper, as it would strengthen the experimental evaluation. The results show strong performance especially in the low-budget setting.',\n",
       "  'weaknesses': 'It does not seem natural to assume that the mapping $f$ is Lipschitz for a VAE trained in an unsupervised manner. Won’t it be the case that the objective is not Lipschits in the input space of many useful models, especially over discrete spaces? Specifically, do you have any experiments demonstrating Lipschitz continuity of the objective by sampling points in the latent space?\\n\\n_Note that the “recoordination” technique claimed by this paper previously existed in Maus et al. under the name “recentering”._\\n\\nEvaluation is a little limited. Do the results hold for all Guacamole tasks? For example, Maus et al evaluates on additional GuacaMol tasks such as ranolazine.\\n\\nEvalutions on DRD3 only go up to 1,000 evaluations of the objective function. This is understandable given the expense of running the docking objective, but on the other hand, this is the most “real-world” objective studied. Would it be possible to run for longer to determine whether CoBO can eventually beat LOL-BO or GraphGA?\\n\\nThe axes for all plots start at 0; it would be more helpful to include initialization points in the evaluation budget for comparison with prior work.\\n\\nSpecific issues:\\n* Articles are missing in several locations, including in the abstract (line 12). Please proofread for small errors.\\n* Equation 4 shows a regularizer that encourages __every__ pair of distances to be exactly $c$; it does not regularize the mean as claimed in the text. Is the text or the equation incorrect?\\n* Do you recoordinate all points during fine tuning? If so, add this step to Algorithm 1 (I believe it currently only shows recentering for the trust region, not the surrogate).\\n* Is there a reason that you report the objectives in Arithmetic expressions as a minization problem, but transform the DRD3 task into a maximization task? Retaining the convention of the TDC leaderboard would improve the accessibility of the paper to a wide audience.\\n\\nSmall comments:\\n* Define “an inherent gap” in the abstract. This notion is referred to multiple times in the paper, but never precisely. Is the claim that there do not exist points in the latent space $z$ that correspond to an optimal point in input space $x$? Or that these regions are small and hard to find?\\n* It is not immediately obvious in the introduction that this method will leverage a pre-trained VAE that is trained in a purely unsupervised manner.\\n* In Equation 7, notation seems to be overloaded. Do you mean a quintile of the empirical distribution of objective values seen during training, $y_i$? At line 140, is $sigma$ a hyperparameter or equal to $\\\\sigma_Y$?\\n* Algorithm 1 line 14: typo “is the best score than”\\n* When discussing “initialization points” in Section 3, it would be useful to the the notation $D_0$ from Algorithm 1.\\n* In Figure 2, should “TDL” be “TDC”?\\n* It would be helpful to label the y-axes in Figure 4.'},\n",
       " 'review_459': {'summary': 'This paper proposes several heuristic regularization constraints for learning a Bayesian optimization latent space. It argues that the learned latent space needs to be aligned to the black-box function values, and this is achieved via keeping the Lipschitz constant small and the mean latent distance (of training samples) constant. It also argues that promising points need to be prioritized during the latent space optimization, and this is achieved via weighting the reconstruction loss and the Lipschitz regularization loss above at each training point by its function values. The paper evaluates the proposed method on several benchmark functions, yielding positive results.',\n",
       "  'strengths': 'The proposed approach makes some practical sense, and yields good performance on several benchmarks. The approach is also novel, so I believe the paper has some intellectual and practical merits. ',\n",
       "  'weaknesses': '1. I think the problem is not very clearly described and motivated. What exactly are the \"gaps\" between the latent space and the input space? Throughout the paper, I have not seen any technical description of this issue. To quote the manuscript, the two main gaps are:\\n- \"First, even though the surrogate model g learned in the latent space the objective value is still obtained by a black-box function defined in the discrete input space X so the gap between objective values and latent spaces leads to poor optimization performance\".\\n- \"Second, since the distribution of samples expected to have high objective values is different from that of samples observed in pretraining, there is a gap between the input space and the latent space that makes the optimization inaccurate\".\\n\\nNeither statements give a precise description of what these gaps are, so I cannot be convinced that the proposed solutions are meaningful.\\n\\n2. A lot of the technical details also lack motivation. Please refer to the specific questions below.\\n\\n3. Different BO approaches have different per-iteration cost, and it would be slightly unfair to only compare the performance vs. number of oracle calls. I would strongly suggest providing a plot to show performance vs. wall-clock time, or a table documenting the runtime per iteration of each baseline.'},\n",
       " 'review_460': {'summary': 'The paper addresses the problem of Bayesian optimization with the help of a low-dimensional latent space (here learned using a VAE augmented with ad-hoc loss terms).\\n\\nThe paper contributes:\\n- An analysis/recap of the state-of-the-art highlighting issues raised in other works, particularly the need for smoothness (in the latent space) around the optima.\\n- A concrete loss function augmenting previous work [10] with two additional regularisation terms to ensure smoothness in the latent space w.r.t. the objective function.\\n- Experimental study demonstrating the advantages over a suitable set of benchmarks on six problems.\\n- An ablation study examining the effect of some of the loss terms on the final BO task.',\n",
       "  'strengths': '-\\tImportant and relevant research area.\\n-\\tThe background and motivation for the derived algorithm are well-described.\\n-\\tThe included experiments indicate improvements compared to a set of reasonable baselines.\\n-\\tThe resulting algorithm seems sufficiently novel and builds on the intuition about smoothens w.r.t. to the objective function, but I have some concerns/questions…\\n',\n",
       "  'weaknesses': 'Overall weaknesses/comments/suggestions:\\n\\n-\\tThe setup does not come across as principled or consistent from a pure modeling perspective…\\n  -\\tI appreciate the algorithmic-centered view (vs. a probabilistic modeling perspective) adopted in the paper. Still, I am always a bit skeptical when rather ad-hoc loss terms are added to the VAE loss or the joint setup from [10] (which both originate from a proper probabilistic analysis). The combination of and interaction among the many loss terms (in particular the $L_z$, $L_lip$, vs. the VAE prior) would need quite a lot of analysis to work out the exact effect of the combination (and weighting). Currently, I feel the paper lacks this insight.\\n - $z$ is a random variable, yet the computation of the 2-norm in Eq. 9 is performed without recognizing this. I’d expect an expectation w.r.t.. q(z|x) to be involved in $L_z$ and $L_{lip_W}$ (or a non-central chi distribution if treated analytically)?\\n -\\tI am unsure why $L_z$ is needed – can this not be controlled directly via the variance on the prior, $p(z)$? Can the smoothness constraints be incorporated/formulated as a more principled prior for z, thus providing a complete probabilistic view and derivation of the algorithm?\\n-\\tMissing assumptions. \\n -\\tI think it needs to be argued that it makes sense to globally measure distance in the latent space using a Euclidian distance function.\\n - It is generally unclear if you assume y is noiseless or not. This seems important in Eq. 9 (and Theorem 1), i.e., do you use $p(y|x, \\\\cdot)$ or simply the observed y when computing $|y_i-y_j$? \\n-\\tThe model/loss is not fully specified in the paper, as far as I can tell. Specifically,\\n -\\tThe weights on the loss terms are left out in Eq 11, giving the impression that there are no hyperparameters related to the loss itself, yet the supplementary clearly indicates that some manual fine-tuning is needed. The main paper should be transparent about this. How sensitive is the performance to the weights on the loss terms, and how should they be set in practice? \\n -\\tl 155: $L_{joint}$ should be explained in more detail to provide a self-contained definition of the model/algorithm.\\n -\\tThere are no details in the paper or supplementary about the likelihood ($p(x|z)$); I’d suggest adding more information about this beyond a reference to the particular VAEs.\\n -\\tThere are no details about the structure and complexity of the problems or the VAE (e.g. dimensionality of z and its influence)$); I’d suggest providing this at least in the supplementary.\\n-\\tExperimental suggestions: \\n -\\tIf possible, I would suggest providing a very simple 2D (maybe 3D ) synthetic example (trained with the proposed model) to provide the reader with a better intuition about what’s going on with the many loss terms (c.f. previous comment).\\n -\\tThe ablation study (on one dataset) is interesting yet should probably include removing the $L_{joint}$ term as well.\\n\\n\\nMinor questions/comments:\\n\\n-\\tI’d suggest providing (possibly in the appendix) an optimization trace for one example with the total loss and all the individual loss terms included individually.\\n-\\tl120: I think adaptively changing setting L using the median would require more justification and explanation to clarify the properties of this scheme.\\n-\\tl212: I am unsure what is meant with “….Thompson sampling in $N(0,I)$...”?\\n-\\tFigure 5: Is this a result based on a VAE with a latent space with dimension 2 or a projection onto 2D?\\n - l 263: Fig 5 (b) seems less smooth than Fig 5 (a) as is; consider making the statement clearer (i.e. wrt to the objective)\\n-\\tMost figures lack indication of axis labels (on the figure itself or in the caption)\\n-\\tIt would be helpful with a few more words/details attached to Eq 7 (the proof) in the supplementary material.\\n-\\tSome sections contain grammatical issues interrupting the flow, e.g. sec 2.4, l. 165  (missing “the”, “a” etc.)\\n\\n'},\n",
       " 'review_461': {'summary': 'Recent advances in Bayesian optimization have shown that it is possible to exploit latent spaces of variational auto-encoders or generative models to perform the optimization of any function defined over a structured space. However, since the optimization takes place in the latent space. There is an inherent gap between the original problem formulation and the optimization of the latent space. This paper proposed a series of new losses based on the smoothness map of the latent space to enforce a correlation between the function values in the latent space and the original space. The authors propose several losses based on Lipschitz constants and local searches to improve the optimization properties. Finally, the author proposes a series of experiments to show the benefit of their method.',\n",
       "  'strengths': 'I liked Theorem 1 which provides a nice theoretical justification of the innovations of the paper. \\n\\nMoreover, it provides a nice storyline to explain the main elements of the paper and the loss introduced.\\n\\nThe paper is very clear and easy to follow.\\n\\nThere are a lot of numerical experiments showing the benefits of the method.',\n",
       "  'weaknesses': 'Overall, I really like the problem tackled in the paper. However, I have some questions with regards to the contributions, and more particularly with regards to lots of heuristics used in the algorihm:\\n\\n- although there is a nice theoretical justification of the new losses introduced (Eq 3, 4 and 9), the method presented in Algorithm 1 relies on a large number of parameters such as k, the kernel used in the Gaussian process, the batch size, the latent space update interval Nfail which might make the method hard to use in practice. For instance, it seems like some parameters presented in the Appendix such as the batch size and k are different depending on the use case. Is there a way to know how to choose those hyperparameters that work in most cases?\\n\\n- Similarly, for the halving of the trust region. It seems to be a full heuristic. Is there a justification for the value of the frequency to half the search space?\\n\\n- In Eq 7, how to you choose the value of $y_q$? What is the precise meaning of this term in the loss?\\n\\n- Bayesian optimization is mainly used when the black-box function is expensive (or costly) to evaluate. Moroever, there exists a large number of other methods for black-box optimization when the function is cheap to evaluate. However, when looking at the different experiments, it seems like the experiments can go up to 60K+ iterations. In this case, how would those methods compare to existing techniques (such as fine-tuned simulated annealing, genetic algorithms, and partitioning techniques such as the DIRECT algorithm) or even multi-start local search methods? Does using Bayesian optimization make a real difference?\\n\\n- Overall and as a last comment, since the method relies on a large number of hyper-parameters, it seems like it is not realistic to choose them in practice in the case of expensive-to-evaluate black-box functions (which is the core justification of Bayesian optimization) in which functions evaluations are scarce. How could we improve that in practice?\\n '},\n",
       " 'review_462': {'summary': \"This paper gives a new analysis of the Adam algorithm intended to close the gap between the upper bound of Adam's iteration complexity and the existing lower bound for first-order nonconvex optimization. The authors show that existing analysis of Adam either uses the bounded gradient assumption, achieves a suboptimal iteration complexity, or relies on the mean-squared smoothness assumption. Afterwards, they give a novel analysis of the algorithm that meets the lower bound in dependence on the desired accuracy $\\\\epsilon$.\",\n",
       "  'strengths': '- The new analysis of Adam is conducted under the same assumptions as standard SGD, unlike most prior work.\\n- The new analysis of Adam achieves the optimal $\\\\frac{1}{\\\\epsilon^{4}}$ complexity with no additional log factors.\\n- The authors introduce several technical tools that can be helpful in the analysis of adaptive algorithms more generally, for example the stochastic surrogates used are new.',\n",
       "  'weaknesses': '- My main problem with this paper is that the proof, as it is, is very complicated to check. It would be very helpful if the authors included a section in the deterministic case (no stochasticity) with their full proof in this simplified setting.\\n- The bounded variance condition is a bit restrictive (see [1]), can the convergence of Adam be derived under any of the more general conditions mentioned in [1]?\\n- (Minor typos) line 134 should be log 1/\\\\epsilon not log \\\\epsilon.  Line 198 $G_{t-1}$ not $G_{t-2}$. Please use \\\\left and \\\\right for braces in line 229.\\n\\n[1] Ahmed Khaled & Peter Richtárik, Better Theory for SGD in the Nonconvex World, TMLR 2023'},\n",
       " 'review_463': {'summary': 'Adam is one of the most popular stochastic optimization algorithms especially in deep learning, the existing convergence theories do not achieve a tight upper bound that meets the lower bound. Moreover, many of them require additional assumptions, such as bounded gradient. This paper shows that Adam can achieve the tight bound of $O ( \\\\epsilon^{-4} )$ without such additional assumptions. This result closes the gap between the practical success of Adam and the theoretical sub-optimality.',\n",
       "  'strengths': '- The theoretical result is strong. Although there are many existing works that analyze the convergence of Adam, this paper is the first one that proves that Adam can converge with $\\\\mathcal{O} ( 1 / \\\\sqrt{T} )$, or equivalently $\\\\mathcal{O} ( \\\\epsilon^{-4} )$.\\n- Technical improvements for deriving the result are interesting and clearly explained.\\n- This paper is easy to read, and the presentation is also clear at least to the experts on the convergence theory of stochastic optimization.',\n",
       "  'weaknesses': '**Relation to [1] is not clear**\\n\\nAlthough I am basically positive about the result of this paper, I am not sure about how it relates to the well-known result about the non-convergence behavior of Adam by [1]. They showed that there always exits a problem in which Adam fails to converge, but the authors\\' result seems that Adam can always converge with the optimal rate (i.e., $\\\\mathcal{O} ( \\\\epsilon^{-4} )$). In my current understanding, this is because Theorem 2 requires $1 - \\\\beta_2 = \\\\Theta ( 1 / T )$, which means that, in order to ensure the convergence of Adam, we need to choose the hyper-parameter $\\\\beta_2$ depending on the total number of parameter updates $T$. I think it would be better to clarify the relationship clearly in Section 7. Though the authors mention [1] in the section, the relation to their theoretical result is not clear to me. When it becomes clear in the rebuttal period, I will raise my score.\\n\\n**There are no experiments**\\n\\n- I think the condition of $1 - \\\\beta_2 = \\\\Theta ( 1 / T )$ is crucial to achieve the optimal convergence rate, so it would be better to demonstrate it experimentally (I think a toy experiment is enough).\\n\\n**Minor comments**\\n\\n- The notations of the output of Adam are inconsistent in Algorithm 1 ($\\\\boldsymbol{w}_r$) and Theorem 2 ($\\\\boldsymbol{w}_\\\\tau$), which is a little confusing.\\n- Finishing a paper with Related work is not common in my opinion.\\n- It would be better to add equation numbers to all the equations for the ease of communication between the reviewers and the authors.\\n\\n**Typos**\\n\\n- line 20: uderstand -> understand\\n- line 198: $\\\\boldsymbol{G_{t-2} \\\\rightarrow G_{t-1}}$\\n- line 248: pratice -> practice\\n\\n**References**\\n\\n[1] Reddi, Sashank J., Satyen Kale, and Sanjiv Kumar. \"On the Convergence of Adam and Beyond.\" International Conference on Learning Representations. 2018.'},\n",
       " 'review_464': {'summary': 'This paper analyzes the iteration complexity of Adam. It Is first pointed out that upper bounds in prior work do not match existing lower bound; the reason is that the lower bound is proved under smoothness and bounded noise variance, while prior upper bounds make more assumptions. This paper then proves a general upper bound (Theorem 1) which only requires smoothness and bounded noise variance and matches the lower bound up to a logarithmic factor. Later in Theorem 2, a refined analysis is given which further removes the logarithmic factor, and thus giving an upper bound that matches the lower bound exactly.',\n",
       "  'strengths': \"This paper analyzes the iteration complexity of Adam, which is a very important problem given Adam's popularity. Moreover, it is pointed out that existing upper bounds do not match lower bound, and this paper closes this gap, which is a nice contribution. The proof techniques may be of independent interest, such as the peeling-off strategy to handle the dependency between the momentum and the adaptive learning rate.\",\n",
       "  'weaknesses': 'N/A'},\n",
       " 'review_465': {'summary': 'This paper presents a convergence analysis of Adam under only the smoothness and bounded variance conditions. ',\n",
       "  'strengths': '- The strength of the paper is to present a convergence analysis of Adam under only the smoothness and bounded variance conditions, in contrast to the existing analyses (Section 3). We are interested in the analysis of Adam under only the two conditions, since the conditions are more natural and realistic than the boundedness of the gradient norm of the objective function and the Lipschitz continuity of the stochastic gradient.  \\n-  The abstract indicates that \"Especially with properly chosen hyperparameters, we derive an upper bound of iteration complexity of Adam and show that it meets the lower bound for first-order optimizers.\" Proposition 1 shows that the iteration complexity $\\\\mathcal{C}$ of a first-order optimizer is $\\\\Omega (1/\\\\epsilon^4)$, that is, there exist $c_1, c_2 > 0$ such that $c_1/\\\\epsilon^4 \\\\leq \\\\mathcal{C} \\\\leq c_2/\\\\epsilon^4$. Theorem 2 implies that Adam satisfies that $\\\\mathcal{C} = O(1/\\\\epsilon^4)$. Hence, the paper concludes the claim of the abstract. ',\n",
       "  'weaknesses': 'I understand the motivation of the paper. Meanwhile, many theoretical and practical results of Adam have been presented. Hence, unfortunately, I do not find that the results in the paper are surprised as compared with the existing ones. Please see Questions.'},\n",
       " 'review_466': {'summary': 'The paper proposes inference algorithms for credal networks for the marginal MAP inference task. The idea is to use variable elimination methods for this task. An exact inference algorithm is proposed as well as approximations using mini-bucket partitioning. Further, stochastic local search procedures combined with existing approximate marginal inference methods are proposed to solve the MMAP task. Experiments are performed on randomly generated credal networks as well as real-world Bayesian networks converted to credal networks.\\n',\n",
       "  'strengths': 'This looks to be the first work on MMAP for credal networks which seems significant since MMAP is a hard but important task for PGMs. The use of existing inference algorithms with the local search methods gives a general family of MMAP algorithms. The evaluation considers a large number of benchmarks. The paper is generally well-written with clear contributions.',\n",
       "  'weaknesses': 'The relatively poor performance of CMBE may indicate it is hard to get more reliable performance for MMAP (e.g. by increasing i-bound of CMBE) for credal networks compared to approximations for other PGMs. The stochastic local search algorithms which seem to work much better in the experiments may be harder to trade-off w.r.t accuracy vs complexity.'},\n",
       " 'review_467': {'summary': 'This work presents novel algorithms for performing exact and approximate marginal MAP inference in credal networks with discrete-valued factors, and evaluates the computational and inferential effectiveness of these algorithms on a number of benchmarks.',\n",
       "  'strengths': 'Firstly, I enjoyed reading the paper and think it’s fantastic how basic research into PGM inference is still being done. A strength of the paper is the technical depth demonstrated to devise these novel inference algorithms. I thought the design of the ablation study was solid and plenty of real-world experiments given.',\n",
       "  'weaknesses': 'One weakness is that the explanation of the algorithms proposed is difficult to follow, but perhaps this is unavoidable with a heavily technical topic. I think it would strengthen the paper to explain the significance of marginal MAP in credal networks in particular, and performing experiments on counterfactual analysis. More discussion/experiments on counterfactual inference may strengthen the apparent contribution/impact of solving MMAP in credal networks.'},\n",
       " 'review_468': {'summary': 'This paper is about a generalisation of marginal MAP (MMAP) for Bayesian networks (BNs). The authors allow the BN parameters to vary in (credal ) sets. The goal is, therefore, to find the configuration with the maximum upper (wrt the credal sets) probability. The authors first consider exact inference. A number of schemes based on mini-buckets are then obtained to address approximate inference and empirically validated.',\n",
       "  'strengths': 'The problem is important and very general (in a sense, most of the classical inferences in PGMs can be intended as a subcase of CMMMAP). This seems to be the first serious attempt to address the problem in the credal case and the experiments show how the proposed approximate schemes allows to solve a large number of non-trivial instances.',\n",
       "  'weaknesses': 'The authors only consider maxi-max and maxi-min versions of the problem. Credal networks are often used to model a condition of indecision between multiple options, and considering other decision criteria possibly leading to multiple options (e.g., maximality or interval dominance) would be interesting. This is also related to the ideas sketched by De Bock et al. (Neurips 2014).\\n'},\n",
       " 'review_469': {'summary': 'The paper studies algorithms for the marginal MAP (MMAP) problem in Credal networks that generalize Bayesian networks. The paper gives an overview of the problem, existing algorithms for Bayesian networks and generalizes the algorithms to credal networks. Overall, two exact and multiple heuristic approaches are presented. As the exact approaches were unable to deal with larger problems, the experiments are restricted to heuristic approaches. ',\n",
       "  'strengths': 'The paper is very well written and gives a good overview of the problem and related work. While Bayesian networks are an old topic, they remain relevant for probabilistic reasoning tasks that require analytical guarantees. However, one problem of Bayesian networks is that specifying the CPDs can be difficult. Credal networks are an interesting generalization that allows using probability intervals rather than point probabilities in order to capture the uncertainty about the encoded knowledge. To the best of my knowledge, there is not much literature on algorithms for Credal networks. The authors generalize state-of-the-art ideas for Bayesian networks to Credal networks and give an empirical evaluation. The paper is therefore an interesting contribution to the probabilistic reasoning literature. The code is attached in the supplementary material to reproduce the experimental results and is a useful resource for the probabilistic reasoning community.',\n",
       "  'weaknesses': 'It could be discussed in more detail what the exact relationship between the proposed algorithms and the corresponding algorithms for BNs is. Are they generalizations in the sense that if the intervals in the Credal network are tight, then the Credal network algorithms correspond to the BN algorithms? Are there challenges in generalizing the algorithms to credal nets or is the generalization straightforward? And how do the runtime guarantees for Credal networks compare to those for Bayesian networks? '},\n",
       " 'review_470': {'summary': 'This paper considers the problem of using self-supervised learning from video to obtain a representation that is well-suited to the task of estimating correspondence between a pair of images. They propose a significant modification of the MAE training procedure which is adapted for estimating correspondence: one image is not masked at all while the other has most (90%+) of its tokens masked, and the same (i.e. a siamese) encoder is applied to both. This is designed to require the model to internally establish correspondence. The model is trained for pixel prediction on Kinetics-400 and evaluated on several propagation tasks (object mask, part masks, human pose) using kNN inference to establish a dense correspondence field. SiamMAE is shown to greatly outperform existing self-supervised learning procedures with comparable backbone architectures, including methods trained on video. Ablative experiments confirm the importance of combining a siamese encoder with asymmetric masking. Visualization of the attention maps show that the model pays strong attention to object boundaries, seemingly a novel attribute.',\n",
       "  'strengths': '1. Good motivation and contextualization with respect to past work.\\n1. The modification of the MAE procedure is simple but clever, and manages to extract much more information for correspondence from video than past methods.\\n1. Visualization of predicted images is quite impressive (Figure 2), despite the main goal being to learn a feature extractor for correspondence.\\n1. Comprehensive evaluation with 3 different tasks and wide selection of relevant baselines.\\n1. Ablative experiments verify the importance of each component of the design.\\n1. Hyper-parameters provided for reproducibility.',\n",
       "  'weaknesses': \"1. I'm not sure about the emphasis on predicting the _future_. It seems that the temporal order could be reversed (i.e. predict the past given the future) or randomized and I would expect similar results. Has this already been tested?\\n1. It wasn't abundantly clear how the patch-patch similarity was obtained. It seems to be taken from the cross-attention values within the decoder (line 239). However, this could be more clear since the decoder may contain multiple cross-attention layers with each having multiple heads?\\n1. It wasn't clear how k-NN and the queue were used to perform propagation. This should be explained in more detail or a reference provided.\\n1. No code provided at this stage.\\n1. Lack of confidence intervals (not a major issue - delta is quite large in most cases).\\n1. No evaluation of ViT-B and ViT-L (not a major issue - impressive results obtained with smaller model).\"},\n",
       " 'review_471': {'summary': 'This paper focuses on the self-supervised learning for video representations. The proposed SiamMAE operates on pairs of randomly sampled video frames and asymmetrically masks them, and then predicts the missing patches for visual representation learning. SiamMAE achieves significant performance and outperforms state-of-the-art self-supervised methods on video object segmentation, pose keypoint propagation, and semantic part propagation tasks.\\n',\n",
       "  'strengths': '1 The motivation is clear and strong.\\n\\n2 The proposed asymmetric masking and cross-self decoder are effective and achieve good performance.\\n',\n",
       "  'weaknesses': '1 This paper mainly evaluates the proposed method on tracking problems. How is the performance on video classification tasks, such as UCF101 and HMDB51?\\n\\n2 In Table 2(c), grid mask achieves better performance than random mask with 0.5 mask ratio. Increasing the mask ratio will improve the performance of random masking. How is the performance when increasing the mask ratio for grid masking?\\n\\n3 This paper only investigates the ViT-S backbone. It is better to also leverage larger models, such as ViT-B, to verify the effectiveness of the proposed method.\\n'},\n",
       " 'review_472': {'summary': '* This paper propose Siamese Masked Autoencoders for learning visual correspondence from videos called SiamMAE. \\n\\n* SiamMAE randomly sample a pair of video frames and randomly mask 95% of patches of the future frame, and the pair of video frames are passed into visual encoder(VIT), and cross attention decoder to reconstruct the target.\\n\\n* The authors conduct several experiments on downstream tasks(vos, human pose propagation), showing superior performance.',\n",
       "  'strengths': '* The paper presents a simple, yet highly effective method for the challenging video self-supervised framework.\\n\\n* The proposed method is well motivated and intuitive with excellent performance.\\n\\n* The ablation is sufficient and the writing is excellent.',\n",
       "  'weaknesses': '* Experiments on video recognition experiments should be reported. \\n\\n* Although SiamMAE is pretraining on video frames, i still think the authors should conduct experiments on image downstream tasks(such coco detection, segmentation) to show image representation capacity.\\n\\n* In Table1, The previous video ssl method(VPS) is also pretrained on Kinetics with ResNet50，however，the performance of SiamMAE with ViT-S/8 is similar in DAVIS & VIP & JHMDB, any explanation for this?'},\n",
       " 'review_473': {'summary': 'The paper proposes to use Siamese Masked Encoders for establishing correspondence for video input data. Uses the concept of predictive learning based on Masked Auto Encoder. Paper proposes to use asymmetric masking for present and future frames. Achieves best results in self-supervised setting for video label propagation tasks.\\n',\n",
       "  'strengths': 'Strengths:\\n1) The paper is well written for most of the parts and aptly elucidates the advantage of using a masked auto-encoder-based method for object-based correspondence. \\n2) Discusses in detail the architecture design choices for the encoder and decoder, ans uses a final design which is intuitive and simple and  also focuses on relevant ablation studies.\\n3) The paper shows and achieves better results for object segmentation, part segmentation, and pose propagation tasks. \\n\\n',\n",
       "  'weaknesses': 'Weakness:\\n1) Frame sampling: Table 3b discusses the effect of frame gap, however, it misses to comment on what could be the minimum frame overlap between the pair of frames for which predictions are out to be done. Apart from asymmetric masking, the degree of overlap between consecutive frames is also an important factor.\\n\\n2) Fails to discuss the probable failure cases given the limitations from more qualitative results analysis belonging to various tasks.'},\n",
       " 'review_474': {'summary': 'In this paper, the authors propose a simple extension to Masked Autoencoders (MAE) to be able to pre-train on videos: SiamMAE. Two frames are sampled, independently encoded, and then asymmetrically masked. A transformer decoder is used to predict the missing patches in the masked image. The authors show that by masking a high proportion of patches (0.95) in the future frame and leaving the past frame unmasked, they are able to encourage the network to learn a more object-centric representation and focus on object motion rather than low-level image details. The authors show that this simple approach outperforms previous methods on many down-stream tasks and perform an extensive ablation to examine the architecture choices.',\n",
       "  'strengths': 'Very well written paper. Some results are particularly impressive (e.g. more than 20% gain over VideoMAE)\\n\\nSimple but effective method and the honesty of presenting this as-is (instead of disguising the method as being more complicated than it needs to be) I think should be appreciated.\\n\\nGood comparison to other work and a great ablation section explaining many design choices\\n',\n",
       "  'weaknesses': 'Can only see two minor weaknesses:\\n\\n1.\\tThe approach adds little over MAE and feels incremental, however it works very well and hasn’t been done before.\\n2.\\tThis approach relies on the temporal smoothness that is found in many curated datasets, such as Kinetics. However, for in-the-wild videos, with many sharp scene changes, this assumption becomes less likely to hold. However, it should be possible to split long videos into scenes in an unsupervised manner and then sample frames within a scene. It would be nice to a discussion on how this can be applied to large-scale internet datasets (which are becoming very popular for foundation models)\\n'},\n",
       " 'review_475': {'summary': 'This paper investigates the phenomenon of robust overfitting in adversarial training and explains it from a minimax game perspective. The authors analyze how the decay of the learning rate disrupts the balance between the model trainer and the attacker, leading to robust overfitting. They propose a method called ReBalanced Adversarial Training (ReBAT) to mitigate robust overfitting and achieve good robustness even after long training.',\n",
       "  'strengths': '1 The paper is well organized and easy to follow.\\n\\n2  The paper provides a holistic understanding of robust overfitting in adversarial training by analyzing the imbalance between the model trainer and the attacker from a minimax game perspective. This perspective helps explain why robust overfitting occurs in adversarial training and why it does not occur in other training methods.\\n\\n3 The experiments cover different network architectures and benchmark datasets, providing strong empirical evidence.',\n",
       "  'weaknesses': '1 it is better to clearly state the diffference between the defined robust/non-robust features and the previous one in [15]\\n\\n2 ReBAT[strong] seems like a strange notation, please consider to change one. \\n\\n3 The caption of Table 1 seems not correct?\\n\\n4 Does the minimax game view provide any insights on the accuracy and robustness tradeoff?'},\n",
       " 'review_476': {'summary': 'This paper studies the robust overfitting phenomenon in adversarial training. Meanwhile, this paper focuses on a specific problem “the robust overfitting occurs when we use learning rate decay techniques.” This paper proposes a game perspective to explain the robust overfitting. It claims that the robust overfitting happens because of the imbalance between the attacker and the model after the LR decay. Moreover, this paper proposes ReBAT method to improve the robustness and mitigates the overfitting phenomenon.',\n",
       "  'strengths': 'This paper studies a specific but interesting problem, the robust overfitting phenomenon. This paper explains that the overfitting happens because of the learned mapping of the non-robust features after LR decay.\\n\\nThis paper provides an intersting perspective to help us to understand the cause of the robust ovetfitting. In particular, the robust problem is a min-max problem, which could be regarded as a game. The robust overfitting is because of the breaks of the original equilibrium.\\n\\nThis paper provides extensive verification to support its explanation, which addresses most of my questions when I first review this paper.',\n",
       "  'weaknesses': '1.For the Figure 2 (b), I guess the red line denotes  w/ LR decay and the blue line denotes w/o LR decay;\\n\\n2.For section 3.2.1, the authors share an interesting and important insight. I’m afraid it is a little trifling. Could the author provide a figure to demonstrate it?\\n\\n3.In section 4.1, the authors provide some techniques to address the robust overfitting, e.g., bootstrapping, small decay factor. From the theoretical analysis in this paper,  I guess there may exist other methods to achieve the balanced learning of robust and non-robust feature, and more discussions is helpful.  Could the author provide some theoretical analysis about the proposed method for the re-balance?\\n\\n4.I find the proposed method ReBAT may cause more computation overhead to get a convergent result. Could the author discusses the limitations of this work?\\n\\n5.Could the author share more discussions about the game idea?  For example, in multi-task learning, could it be regarded as a game, where there are multiple players?'},\n",
       " 'review_477': {'summary': 'This paper empirically shows that robust overfitting is caused by the over-memorization of the non-robust features after learning rate decay. To mitigate the issue of robust overfitting, the authors propose to use a stronger training attack, a smaller learning rate decay rate, and a bootstrapped adversarial training loss. The comprehensive empirical results validate the effectiveness of the proposed method in mitigating robust overfitting and even improving robustness.',\n",
       "  'strengths': '1. This paper provides comprehensive verifications for their proposed reason for robust overfitting. The authors clearly show the effect of the false memorization of the adversarial non-robust features after learning decay in robust overfitting.\\n\\n2. The empirical experiments on various datasets and networks are comprehensive. The results support the authors’ claim.\\n',\n",
       "  'weaknesses': '1. Besides extensive empirical results, it would be better for the authors to provide some analyses from a theoretical perspective (possibly using game theory which could be related to the empirical results in this paper). \\n\\n2. The proposed method could hurt the natural test accuracy to some extent.\\n'},\n",
       " 'review_478': {'summary': 'This paper explains the phenomenon of robust overfitting in adversarial training from a minimax game perspective. The author considers AT as a minimax game between the model trainer and the attacker, pointing out the imbalance between them leads to the network memorizing non-robust features, causing robust overfitting. Based on these explanations, the author proposes several measures to rebalance the minimax game, thereby mitigating robust overfitting and improving adversarial robustness.',\n",
       "  'strengths': '1. It is interesting to study AT from a minimax game perspective.  \\n2. The paper proposes multiple measures to alleviate robust overfitting and enhance adversarial robustness.',\n",
       "  'weaknesses': \"1. The motivation is unclear. The author's explanation of the robust overfitting process is based on some observation-driven analysis, which are difficult to be convincing. For example, the attacker injects non-robust features for misclassification, and the cause of robust overfitting is the network's memorization of non-robust features. What exactly are the false non-robust mapping and the falsely memorized non-robust features? Can the authors use the intuitive and precise statement to explain the mechanism of robust overfitting?\\n\\n2. The method's novelty is limited. The author claims that previous attempts to change attacker strength have not focused much on robust overfitting. However, there is existing research in this area:   \\nYu C, Zhou D, Shen L, et al. Strength-Adaptive Adversarial Training, arXiv preprint arXiv:2210.01288, 2022.\\n\\n3. The experimental results are incomplete and not significant. 1) Did the author confirm that the robustness of MLCAT in Table 1 is lower than AWP? 2) The author introduces multiple measures to mitigate robust overfitting and reports their combined performance. However, what are the individual performances of each technique? Considering that even combining multiple existing techniques for robust overfitting mitigation can further improve robustness, it is necessary to report the experimental results of each individual technique applied to Standard AT.\"},\n",
       " 'review_479': {'summary': 'This paper proposes a method (InfEmbed) for discovering coherent slices of data such that the model fails on samples within a slice due to similar reasons. InfEmbed uses k-means to cluster a representation proposed in the work called influence embeddings, where samples with similar influence embeddings have similar influence explanations. The proposed slicing method outperforms prior work on standard slice discovery benchmarks.',\n",
       "  'strengths': '1. The work attempts to solve an important problem of surfacing failure modes of a model automatically.\\n2. The work has sufficient technical novelty: it proposes influence embeddings, relating them to influence explanations and using them in the context of slice discovery.\\n3. The work does a thorough evaluation by evaluating the proposed method against multiple slice discovery benchmarks in addition to multiple case studies.\\n',\n",
       "  'weaknesses': 'My main concerns are around hyperparameter selection and missing analysis.\\n1. The work formalizes coherence (Equation 4), but does not compare to prior works (mainly Domino) in terms of coherence.\\n2. It is not clear how the method promotes label homogeneity when all gradients of the neural network are considered. The analysis in 3.5 works only when the gradients in the fully connected layer are considered.\\n3. For a practical use case, the approach still requires the users to determine and specify the branching factor $B$ and the maximum accuracy $A$ of a slice. \\n4. The work doesn’t provide discussion on the selection of hyperparameter choices: e.g. L231 - the values of P and D, which are used in FactorHessian and the number of clusters ($K$) for the results in Table 1.\\n5. It is unclear how the authors choose the number [L286] of layers for which gradients are considered. Is it based on the total number of parameters?\\n'},\n",
       " 'review_480': {'summary': 'In this paper, the authors propose InfEmbed on the slice discovery problem. The method is derived from the influence function and surrogate embedding representations are proposed for reducing complexity. Overall, the paper is well written and the derivation of the method is reasonable. Some pros and cons are discussed as follows:',\n",
       "  'strengths': 'The paper proposes a new slice discovery method, which is based on K-Means and the influence embedding the authors proposed. The method is well-designed and I believe is relatively easy for deployment. The overall derivation of the method is clear and theoretical analysis is supported.\\n\\nThe question that the authors are addressing is of importance and the experiment results seem to validate the performance of this method.\\n\\nThe proposed method, if it is effective like the paper states, can provide insights in other domains that require identifying groups of data.\\n',\n",
       "  'weaknesses': 'The K-means is sometimes unstable. As the authors claim the clustering algorithms can be others, they should also validate the results on more cluster algorithms such as the spherical k-means. \\n\\nThe result section is not organized well. It is recommended that the authors discuss datasets, baselines, and results in different subsections and provide more details of data description and baseline methods.\\n'},\n",
       " 'review_481': {'summary': \"This paper proposes a heuristic clustering-based method for identifying errorneous groups of test examples. I'm erring on the side of caution here and go with a weak reject, but I have limited familiarity with the subfield.\\n\\nAC note: score increased 4 -> 6 after rebuttal.\",\n",
       "  'strengths': '* Error analysis tools are useful for many different ML systems; better algorithms for discovering slices might have have significant practical impact.\\n* The paper is reasonably clearly written and easy to follow.',\n",
       "  'weaknesses': '* The main algorithm for estimating the seems to be taken from Schioppa et al.; without it, the methodological contribution of the paper seems quite limited in its nature.\\n* The paper seems rather simplistic in its approach and not very exciting in its results – cf. Table 2, which is the main evaluation where the technique from the paper is compared to the related work.'},\n",
       " 'review_482': {'summary': 'The paper presents a method to discover groups of test examples on which the model performs badly, and the misclassification of the examples is caused by the same reason (defined as coherence).\\nThis problem is known as slice discovery. The method leverages influence functions to compute the influence explanation for each test example. This generates a vector of the influence of each training example on the test example. Given that this vector is high-dimensional, they derive influence embeddings that are used to cluster them by applying K-Means. The authors propose a variant in which there is no need to specify the number of clusters but only the minimum size of the slice and the maximum accuracy. The method is evaluated on several datasets.',\n",
       "  'strengths': '- the paper is well written and structured clearly. The contributions are clearly reported, and the related works are described. \\n- the problem is relevant because finding the training examples that influence a group of test examples on which the model underperforms is the first step to debug a model and to fix sporious correlations in the data.\\n- using influence functions to address this problem is novel according to the provided references and interesting\\n- the author formalizes the coherence desideratum\\n- the metho is evaluated extensively on multiple datasets (text and images) and considering multiple types of causes that induce the model to make a classification error',\n",
       "  'weaknesses': '_Reproducibility_: it is not clear if the source code of the experiments will be made available upon acceptance. The datasets are publicly available.'},\n",
       " 'review_483': {'summary': 'This work presents a method for discovering subsets of the test set of a multi-class classification task on which a trained model incorrectly classifies a large portion due to the same root cause. The method uses a factorized low-rank approximation of a bilinear influence function, parameterized using the Hessian of loss function with respect to the parameters of the classifier, to project high dimensional influence explanations into lower dimensional representations of test examples, naturally called influence embeddings. The influence embeddings preserve structure of high dimensional influence explanation space and are used to cluster the test examples into subsets using k-means. The influence embeddings are also shown to have purpose in finding slices of the test set that satisfy certain size and failure properties and can be used to find the most problematic training examples causing the failures. Empirical results show that the proposed method outperforms other slice discovery methods on benchmarks and is able to find known errors in several settings.',\n",
       "  'strengths': '* The problem is important and well-motivated\\n* The general method is easy to understand and seems scalable\\n* Empirical evidence is strong and shows the method is very suitable for the specified problem\\n* The paper as a whole is fairly well-written',\n",
       "  'weaknesses': '* Given the work of Schioppa et al. [2022], the methodological contribution seems quite small and straight-forward\\n* The clustering algorithms and procedures using clustering as a subroutine (InfEmbed-Rule) seem to treat the clustering algorithm as an after-thought. There is no justification for why k-means is used.\\n* The theoretical results are slightly over-stated in the introduction. It seems like more can be done on the theoretical side to motivate the method. Lemma 1 and Section 3.5 contain interesting results that could be strengthened and elaborated to improve the justification for the presented method.\\n* The writing in the background section could be improved a bit. It seems like notation is introduced in an unnatural order and in a slightly imprecise way. Also the definition of the Hessian (line 98) is unclear: which examples are used to define the Hessian? Training examples? Test examples? Or maybe both?\\n* Figure 1 really is not that helpful in understanding the method and takes up quite a bit of space.'},\n",
       " 'review_484': {'summary': '\\nThis paper propose a method namely operation-level early stopping to address the skip-connection domination issue in domain of differentiable architecture search (DARTS). Though this problem is heavily explored in the past, the authors believe that the key reason of skip-connection domination is because of they try to overfit the validation set used in DARTS based method, and their proposed operation-level early stop that conceptually stop the training of architecture parameter if the overfitting is observed. ',\n",
       "  'strengths': 'The problem of skip-connection dominance is a long standing problem in DARTS domain, and novel method to address this has a clear motivation. \\nThe hypothesis of overfitting is the root cause of skip-connection domination is novel and interesting. \\nAnalysis of architecture with validation loss is quite clear and justify their hypothesis.\\nI appreciate the extensive and honest experiments on all kinds of settings, even though many of the results does not surpass the state-of-the-art. ',\n",
       "  'weaknesses': '\\nI have several questions regarding this paper and hope to hear back from the authors.\\n\\n1. Utilizing gradient matching as an indicator to perform early stop seems okay, but this paper lacks of sufficient analysis of what is the key difference between GM+DARTS and their approach, especially regarding why OLES is better. In the related work section, it only describes GM-NAS introduces gradient match score into NAS literature, but this is not enough to let readers understand the difference. \\n2. In essence, use early stop to avoid overfitting in DARTS is novel, but experiments seem to show that this OLES does not surpass previous DARTS+PT, which is another indicator to select DARTS operation. I do not understand the urgency to accept another indicator work with similar performance. In addition, similar as above, I do not see much comparison of how OLES surpass DARTS+PT. I agree that OLES can surpass original DARTS, but if it cannot surpass other methods that aims to address the skip-connection domination issue, this is inadequate to appear in a top-tier conference in my humble opinion. \\n3. In general, the experiments compared to state-of-the-art is inferior. \\nTo the best of my knowledge, this approach has a close relationship with GM+DARTS and DARTS+PT, where in all experiments, the authors should compare to. However, for example, in Table 2, none of these methods exists. In addition, when solely compared to GM+DARTS, in Table 1, it is 0.05 test error better than GM+DARTS. In table 3, GM+DARTS is basically identical as OLES (24.5 v.s. 24.5). In Table 4, OLES surpass GM+DARTS by a margin of 0.2, which is kind of significant. However, in Table 5, GM + ProxylessNAS surpasses OLES again. Why we should accept a paper using the exact gradient matching score in a different manner, which seems inferior than the original approach?\\n\\nIn addition, I would like to see how this OLES address skip-connection domination with other approaches that aim the same target, not in terms of their final performance, but with respect to their performance to address skip-connection domination issue. After all, this is not the first paper aiming to address it. \\n'},\n",
       " 'review_485': {'summary': \"The paper focuses on the robustness issues in differentiable NAS, specifically the domination of skip connections. It first analyzes the issue from a novel perspective, proposing that the domination of skip connections arises due to the overfitting of operations in the supernet during training. Then, the paper proposes the operation-level early stopping method, which monitors each operation in the supernet and stops its training when it tends to overfit. The paper employs a gradient matching approach to detect overfitting, comparing the gradients' directions of operations on training and validation data. A significant deviation in direction is considered an indication of overfitting. The proposed OLES addresses the domination of skip connections with negligible additional overhead. Extensive experiments demonstrate the effectiveness of OLES on different datasets and search spaces. \",\n",
       "  'strengths': 'S1. The paper demonstrates good originality. It provides a comprehensive analysis of the issue of the domination of skip connections in the differentiable NAS by dopting a new perspective. Although straightforward, the perspective makes sense and is interesting. Specifically, the paper aims to explain the cause of this issue through the overfitting of operations in the supernet. The paper proposes the operation-level early stopping (OLES) method, which introduces gradient matching to address this matter. OLES elegantly and effectively resolves the domination of skip connections, incurring negligible additional overhead. \\n\\nS2. The experiments are thorough and well-organized, containing experiments in different search spaces and an in-depth analysis of the proposed algorithm. The empirical results demonstrate that the proposed OLES  achieves state-of-the-art performance on CIFAR. The availability of open-source codes further facilitates reproducibility.\\n\\nS3. The presentation of ideas and algorithms is clear, while the references and background knowledge are comprehensive. The background knowledge and the issue to be solved are adequately introduced.\\n\\nS4. The perspective and idea about the overfitting of operations have profound significance in uncovering the underlying causes of the domination of skip connections in DARTS. These novel perspectives, ideas, and algorithms contribute to a deep understanding of differentiable architecture search and may inspire future research in the field.',\n",
       "  'weaknesses': 'W1. It needs a thorough explanation of the used gradient matching method. The authors should provide a more detailed introduction to gradient matching and clarify the differences from other methods.\\n\\nW2. While the proposed method demonstrates significant improvements over the original DARTS in the experiments, it does not have a competitive advantage compared to other state-of-the-art methods. \\n\\nW3. The paper specifically focuses on addressing the domination of skip connections through operator-level early stopping. The authors are suggested to discuss how the concept of operator-level early stopping can be applied to other scenarios beyond differentiable architecture search.'},\n",
       " 'review_486': {'summary': 'This paper demonstrates the fundamental reason for the domination of skip connections in DARTS from the new perspective of overfitting of operations in the supernet, using preliminary experiments,  and proposed the operation-level early stopping method to mitigate this phenomenon by using the GM score metric during the searching.  ',\n",
       "  'strengths': 'The idea of using GM metric to decide whether to update the OPs is broadly used in efficient-training papers.  This paper proposes to use this metric to early stop the updating of specific OPs during the NAS procedure, based on their novel overfitting observations. \\n\\nThe comparison is intensive, showing the superiority of this proposed method, in terms of time cost, and accuracy. ',\n",
       "  'weaknesses': '1. The accuracy metric is one of the metrics to measure a NAS method. We also consider the Kendall rank correlation coefficient. Please compare with previous methods using this metric, because I am not sure whether the proposed early stopping mechanism will hurt the ranking or not. Usually, we say the ranking performance of a NAS method may be more important than the accuracy of the searched model. \\n\\n2. About the overfitting threshold, \"we determine the threshold by averaging the cosine similarity over 20 iterations for 30 randomly initiated architectures in each search space\"    Is the initial 20 iterations ok or enough for determining the threshold? The initial stages may have dramatic changes in gradient. Also, the threshold is fixed during the NAS procedure, shouldn\\'t it be adaptive or scheduled? '},\n",
       " 'review_487': {'summary': 'The authors are adressing the issue of converging to a degenerated solution (many skip connections) using DARTS. The authors connect this behavior to an overfitting to the train data. To remedy this issue, they suggest to apply early stopping based on the correlation of gradients during the architecture parameters training and the wekths parameters training. ',\n",
       "  'strengths': 'The paper is trying to tackle an interesting problem in an elegant way. The story is clearly stated and the introduced approach is a nice extension of the classical early stopping. The performance of this method is on par or better than many other more sophisticated (and to some extent complicated) method. ',\n",
       "  'weaknesses': '* The authors are claiming that the dominance of skip connections is due to the quick overfitting of weighted operations to the train data. The whole story of the paper relies on this assumption which is unfortunately not sufficiently supported. While curves on figure 1(a) are supporting this claim, figures 3(a) and 3(b) are a bit confusing.  I would have expected the test performance to drop for both cases.\\n\\n* There is an issue regarding the reported numbers: the authors are claiming that their method benefits operations with parameters and the test error is dropping (as expected), I am wondering why the number of parameters is barely different. '},\n",
       " 'review_488': {'summary': 'This paper studies the robustness issue of DARTS from the perspective of overfitting. It uses gradient matching scores to measure the overfitting issues, and proposes an early-stop strategy to address the problem of saturated skip connections in normal DARTS. The proposed approach has been evaluated on a number of search spaces, showing comparable results to the state of the art. ',\n",
       "  'strengths': '+ The idea of using similarity between gradient directions of training vs validation batch makes sense. \\n+ Extensive experiments on various search spaces and benchmarks. \\n+ Decent results on DARTS C10 space comparing to SOTA.',\n",
       "  'weaknesses': '- Although the idea to use early stopping to robustify DARTS is interesting, the metric used in this paper is very similar to that in GM-NAS [1]. Therefore it seems to me that the novelty of this paper is somewhat discounted. \\n- It is good to see experiments on a number of search spaces and benchmarks. However, the results on DARTS S1-S4 space is missing. \\n- Some discussion on overfitting is not very clear. e.g. from Fig.1, it is difficult to see quantitively how the negative correlation between arch params and val loss: indeed the curvature of the lines are different, but it would be better to have some more rigid analysis. \\n\\n\\n[1] Generalizing Few-Shot NAS with Gradient Matching. Shoukang Hu*, Ruochen Wang*, Lanqing Hong, Zhenguo Li, Cho-Jui Hsieh, and Jiashi Feng. ICLR 2022. '},\n",
       " 'review_489': {'summary': 'Existing DR approaches employ EAs after heuristic symmetrisation (symmetric-SNE). This leads to less faithful embeddings with low silhouette scores. This paper avoids such heuristic symmetrisation by enforcing symmetrisation in a related, new OT based formulation.\\n\\nTowards this goal, firstly, the EA problem is equivalently written as a (semi-relaxed) OT problem, where the transport plan recovers the EAs. Then symmetrisation is explicitly enforced as constraints on the transport map in this OT problem. Using optimality conditions it is shown that such EAs, maintain the crucial row-wise entropic equalities (prop4). As a result EAs are symmetric, doubly stochastic, and satisfy the entropic equalities, making the organically superior to the existing heuristics.\\n\\nUsing the proposed EAs, a DR formulation is proposed (leading to so-called SNEkhorn). Details of solving this problem are presented. The proposed embeddings are empirically compared to the state-of-the-art wrt. spectral clustering and dimension reduction. The improvements are significant.',\n",
       "  'strengths': '1. The organisation and write-up are well polished and makes it an easy read.\\n2. Connections made between EAs and OT are interesting, especially in the light of the symmetrisation issue with existing DR approach.\\n3. Empirical improvements over baselines are impressive.\\n',\n",
       "  'weaknesses': '..'},\n",
       " 'review_490': {'summary': 'The paper presents a novel approach to dealing with entropic affinities (EAs) used in machine learning for dimensionality reduction tasks, specifically in the popular t-SNE algorithm. It addresses the limitations of current symmetrization methods applied to EAs, which can compromise the entropy and stochasticity properties of the affinity matrix. The proposed method uses optimal transport to achieve a natural symmetrization, leading to a new affinity matrix. This new matrix is then leveraged in a new dimensionality reduction algorithm called SNEkhorn, which is demonstrated to outperform state-of-the-art methods on both synthetic and real-world datasets.',\n",
       "  'strengths': \"1. The paper introduces a novel approach to symmetrizing entropic affinities by formulating them as an optimal transport problem. This brings a fresh perspective to the problem and could open up new avenues for research and application in machine learning.\\n2. The proposed symmetrization method claims to maintain the constant entropy and stochasticity properties of the affinity matrix while being computationally efficient through dual ascent. This combination of robustness and efficiency is essential for practical applications.\\n3. The development of the SNEkhorn algorithm based on the new affinity matrix offers a practical implementation of the proposed approach. The demonstrated superiority of SNEkhorn over other baseline methods on various datasets further strengthens the paper's claims.\\n4. The paper evaluates the proposed SNEkhorn algorithm on both synthetic and real-world datasets, providing a comprehensive assessment of its performance and general applicability.\",\n",
       "  'weaknesses': 'Clarity of Presentation: While the abstract provides a high-level overview, some concepts, such as entropic affinities, optimal transport, and dual ascent, might be challenging for readers not already familiar with the domain. The paper should provide a clear and concise introduction to these concepts, ideally with intuitive explanations and illustrative examples. For example, what is P and C on paper 3 \"Symmetric Entropy-Constrained Optimal Transport\"\\n\\nRobustness Analysis: Since the proposed method claims to be robust to varying noise levels, it would be valuable to include a thorough analysis of its performance under different levels of noise in the datasets instead of two level. This could strengthen the claim of robustness and highlight the algorithm\\'s practicality in real-world scenarios.\\n'},\n",
       " 'review_491': {'summary': 'This is a very interesting paper about an application of the Sinkhorn algorithm to symmetrize the matrix of entropic affinities in methods of DR like SNE, t-SNE, etc.\\nStrong theoretical contribution.\\nSome experiments to illustrate.',\n",
       "  'strengths': 'The paper is very interesting for its vision, state of the art across multiple domains, strong theoretical contribution, revisiting of existing methods and proposal of a new method.\\nThe paper is very well written, not rushed.\\nThe symmetrization with Sinkhorn is well done and this a nice \"tour de force\" like only Brittons can do.\\nThe experiments include a grid search on the perplexity, and multiple runs for each perplexity.',\n",
       "  'weaknesses': 'The paper is well written but it is also very/too dense: much information is packed, that is nice, but it takes quite some time to digest and to decode.\\nThe notation is sometimes unconventional and difficult to follow, probably to keep it as compact as possible.\\nWhile the theoretical part is very convincing and interesting for itself, it will only appeal to a very restricted audience of people specialised in the methodological design of advanced methods of DR. Also, the experiments are not sufficient to convince practitioners that the Sinkhorn symmetrization is from now on something necessary to get the best results. The experiments lack broader comparisons with other methods that are in the state of the art (here it looks like the authors have reimplemented t-SNE and UMAP; also, there are methods that do not look for symmetry at all, although this can be detrimental in the presence of many isolated outliers). The quantitative assessment might be partly questionable: the trustworthiness is not the best DR QA indicator; what was the neighbourhood size, by the way?\\nThe lack of accelerated version is a possible weakness for dissemination, while NeurIPS would be precisely the ideal launching pad.'},\n",
       " 'review_492': {'summary': 'This paper presents a new dimensionality reduction algorithm, named SNEkhorn. By uncovering the novel links between Entropic affinities (EAs) and Optimal Transport (OT), the authors derive EAs with symmetric doubly stochastic normalization and the fixed row-wise entropy, which is the key to SNEkhorn. Besides, the authors show a dual ascent algorithm to compute this new affinity efficiently. Beyond this theoretical contribution, the authors showcase the benefits of SNEkhorn through numerical experiments on simulated data and real data.',\n",
       "  'strengths': '- Entropic affinities (EAs) needs to be symmetrized when used in popular Dimensionality Reduction (DR) algorithm t-SNE, but the symmetrization destroys the row-wise constant entropy and stochasticity properties of EAs. To derive EAs that can maintain both symmetry and its own properties is a very natural. The proposed method is novel and simple to describe.\\n- The authors discover novel connections between EAs and OT, and show a dual ascent algorithm to compute EAs from OT. The proposed algorithm provides a new perspective on EAs.\\n- For conventional DR algorithm, the latent affinity is not doubly stochastic, which imposes spherical constraints on the embedding space. The proposed methods avoid this problem.\\n- The simulation study and real data analysis are very sufficient. The authors illustrate the effectiveness from many aspects.',\n",
       "  'weaknesses': '- There is not any discussion about the computational complexity of proposed method. Although the proposed algorithm performs better than t-SNE and UMAP, how does the computational complexity of proposed method compare with t-SNE or UMAP. Since the computational cost is also important in practice. \\n- Some of the formulas and references in the article are incorrectly hyperlinked.'},\n",
       " 'review_493': {'summary': 'This work studies differentially private prediction. It has two major contributions: \\n\\na) Prediction corresponds to being given an initial labeled training set, and then subsequently making predictions on other data points based on it. This paper shows that differentially private prediction can be performed on an unbounded number of queries, with strong accuracy guarantees, with the initial training set sample complexity scaling only as a polynomial in the VC dimension of the hypothesis class. Prior work either studied prediction for a small number of queries or studied the more stringent task of private PAC learning where significantly stronger lower bounds are known (PAC learning asks for the release of an entire model as opposed to predictions alone).  \\n\\nb) Since queries correspond to data points, they are usually sensitive user information. The authors formalize a model of privacy (similar to joint differential privacy) that gives a meaningful notion of privacy for these data points, even when adversaries can choose the queries adaptively. Their algorithms satisfy this notion of privacy.\\n',\n",
       "  'strengths': 'This paper makes a valuable and somewhat surprising discovery by proving that differentially private prediction can be performed on an unbounded number of queries, with no training set sample complexity dependence on the number of queries! They leverage standard techniques such as sparse vector in clever ways to do so. They operate in rounds, and use queries themselves as data points for future rounds, calling upon techniques from the semi-supervised differentially private learning literature . Their results suggest new ways to get around lower bounds for differential privacy.\\n\\nTheir algorithms involve reducing private prediction to non-private PAC learning, and while their techniques are not yet practical in many cases (because of time complexity), their reduction can be readily extended to any non-private learning algorithm, and hence there is lots of potential for future work to come up with ways to make their techniques more practical.\\n',\n",
       "  'weaknesses': 'One (minor) drawback is that the notion of privacy defined for the adaptively chosen queries is (necessarily) not as strong as would be nice since the label for a data point needs to depend on the data point to achieve any reasonable notion of accuracy (since otherwise you can only do something like randomized response). '},\n",
       " 'review_494': {'summary': 'This paper provides an intriguing path to evading known lower bounds for differentially private PAC learning. Whereas nonprivately the sample complexity of learning is proportional to the VC dimension, the private sample complexity for (pure) DP is characterized by the representation dimension, which can be much larger. In particular, some natural classes such as threshold functions over an infinite domain (e.g. Z or R) have finite VC dimension but infinite representation dimension, so they can be learned nonprivately but not privately (even with approximate DP, by a separate result).\\n\\nThis paper shows that this impossibility only holds for privately releasing a hypothesis and not for privately classifying samples. In particular, it shows that in the online prediction setting, for any hypothesis class there is a generic stateful algorithm with sample complexity based on the VC dimension (to be precise, quadratic in the VC dimension) that can privately answer an unbounded sequence of iid queries with the same accuracy guarantee as PAC learning, but where the state of the algorithm remains hidden and only the query labels are revealed. The algorithm is allowed to remember previous queries but must be differentially private with respect to them as well as the points of the original (labeled) training set. It also shows that statefulness is necessary to achieve this result.\\n\\nFor general hypothesis classes the algorithm is inefficient, but it can be made efficient on important special cases, including threshold functions. ',\n",
       "  'strengths': 'This is a very interesting result that enhances our understanding of differentially private learning by bypassing known lower bounds. It essentially gives a separation between interactive and non-interactive private prediction, showing that interactivity reduces the private sample complexity to nearly that of nonprivate learning (as long as we only have to output predictions and not a hypothesis). The paper is quite well-written.',\n",
       "  'weaknesses': 'There are two obvious limitations of the main result, that yield very interesting open problems posed in the paper: whether it\\'s possible to come up with a similar algorithm that is computationally efficient for all hypothesis classes, and whether it\\'s possible to improve the sample complexity from VC^2 to VC.\\n\\nMinor corrections:\\n104: points --> point\\n147: \"upto\" should be \"up to\"'},\n",
       " 'review_495': {'summary': 'The paper discusses private everlasting prediction, which extends private prediction to answer an unlimited sequence of prediction queries. The goal is to present a generic private everlasting predictor with low training sample complexity. The paper introduces definitions for everlasting prediction and everlasting differentially private prediction interfaces. It then presents a generic construction called GenericBBL for private everlasting prediction.',\n",
       "  'strengths': '1. This paper introduces a formal framework for everlasting prediction.\\n2. This paper provided a comprehensive privacy analysis to the proposed privacy-preserving everlasting prediction task.',\n",
       "  'weaknesses': '1. Limited applicability: The paper focuses on the theoretical aspects of private everlasting prediction and does not provide concrete practical applications or empirical evaluations. It remains to be seen how well the proposed approach translates into real-world scenarios.\\n2. Lack of comparative experimental analysis: The excerpt does not mention any comparison or benchmarking against existing methods or alternative approaches. Without such comparisons, it is difficult to assess the novelty or superiority of the proposed method.\\n3. Lack of empirical validation: The excerpt does not mention any empirical experiments, simulations, or case studies to validate the effectiveness or robustness of the proposed private everlasting predictor. It is unclear how the proposed construction performs in terms of privacy preservation, utility, and sample complexity compared to other techniques.\\n4. The contents shown in the supplementary materials contain a lot of redundant information compared with the paper. '},\n",
       " 'review_496': {'summary': 'This work proposes the notion of private everlasting prediction. Given a training dataset, the predictor responds to a sequence of queries and privacy has to be preserved for both the training data and all queries. The authors explore the PAC learnability problem under this model and show that the sample complexity scales quadratically with the VC dimension through a generic construction from non-private learners. ',\n",
       "  'strengths': \"1. The authors formulate a new notion of private everlasting prediction. This is an original theoretical concept which extends the single query prediction model and has practical relevance.\\n2. The authors prove several interesting theoretical properties for private everlasting prediction. First it requires that the hypothesis needs to change over time. Second, the authors show that the sample complexity scales quadratically with the VC dimension of the concept class. This is a significant improvement compared to private learning which is impossible over infinite domains.\\n3. The writing is clear and easy to follow.\\n\\nUpdate: increased my score to seven after seeing the authors' response and other reviewer comments.\",\n",
       "  'weaknesses': '1. In the algorithm GenericBBL, $\\\\tau>1.1\\\\times 10^10$ seems too large. Can the constant be made any smaller?\\n2. The algorithm is not computationally efficient.\\n3. In terms of writing, the authors could provide a brief overview of the proof ideas for Theorem 5.1.'},\n",
       " 'review_497': {'summary': 'The paper focuses on the importance of exploration in the generalizability in contextual MDPs. The proposed method is built on QR-DQN where the epistemic uncertainty can be separated from aleatoric uncertainty via ensemble. The epistemic uncertainty is then used in a UCB manner to promote exploration. The resulting algorithm is tested in two benchmarks and shown significant improvement over previous baselines.',\n",
       "  'strengths': '- The paper is overall well-organized and easy to follow.\\n- The proposed method is novel, well-motivated and empirically strong.\\n',\n",
       "  'weaknesses': \"- The motivating environment introduced in Sec 3 doesn't seem exactly appropriate for the following reasons:\\n    - According to the definition of CMDP, the distribution of MDPs during training and testing should be the same, which is not the case here.\\n    - Since only the starting distribution is different, the value function is the same in both MDPs. Combined with above mentioned different distribution during training and testing, this example seems too obviously engineered towards promoting visiting more states during training.\\n    - Claiming UCB is more effective in exploration compared to $\\\\epsilon$-greedy seems dry. It would be helpful to at least compare the training stage state-action visiting frequency for both methods.\\n- Same as the motivating example, it would be helpful to show either qualitatively or quantitatively the difference in the extent of exploration among different methods.\"},\n",
       " 'review_498': {'summary': 'The paper proposes that effective exploration is important for generalization and shares a value-based method which gets good generalization performance on procgen and outperforms Rainbow on crafter.',\n",
       "  'strengths': 'originality: The idea to leverage improved exploration to improve generalization is novel/seldomly explicitly tackled.\\nquality: The evaluation is very high-quality.\\nclarity: The paper is fairly clear. I like starting with a tabular MDP to motivate that exploration improves generalization. The methods section is dense but clear.',\n",
       "  'weaknesses': 'Figure 1 could be improved to show some abstraction for how the type of exploration they propose can improve generalization. \\n\\nThe method is only evaluated on two domains. It could be improved if evaluated on more domains.\\n\\n'},\n",
       " 'review_499': {'summary': 'This paper introduces a method called EDE (Ensemble Distributional Exploration) that promotes the exploration of states with high epistemic uncertainty through an ensemble of Q-value distributions. The authors evaluate EDE and compare it to several baselines on Procgen and Crafter.',\n",
       "  'strengths': \"**Originality**\\nThe paper's originality lies in its approach to exploration in reinforcement learning. The authors introduce the concept of using ensembles for uncertainty estimation to guide exploration.\\n\\n**Quality**\\nSee Weaknesses Section.\\n\\n**Clarity**\\nThe paper is well-written and organized, making it easy for readers to follow the authors' thought process and understand the methodology and results.\\n\\n**Significance**\\nBy demonstrating that ensembles for uncertainty estimation can effectively guide exploration, the authors have opened up new possibilities for exploration in reinforcement learning. The paper's focus on improving an existing method for better exploration is particularly relevant in today's context, where there is a growing emphasis on improving the efficiency and effectiveness of reinforcement learning.\",\n",
       "  'weaknesses': 'One potential weakness is the increased computational cost associated with the method. The use of an ensemble to guide exploration, while useful, also makes the method more expensive to run. This could limit its applicability in scenarios where computational resources are constrained.\\n\\nIn Figure 5, it would be beneficial to add QR-DQN with Thompson Sampling in the ablation.\\nFurthermore, in Table 1 it would be more informative to evaluate QR-DQN, and EDE (with UCB and TEE instead of Thompson Sampling).'},\n",
       " 'review_500': {'summary': 'This paper proposes an exploration method for value-based RL for contextual MDPs (CMDP) motivated by the idea that good generalization in RL requires attention to RL specific problems such as exploration. The method uses an ensemble of quantized Q-functions to estimate the epistemic uncertainty about the value function. Then uncertainty estimate is used to conduct upper confidence bound (UCB) exploration based on the estimated distribution of the Q-values. Additionally, the algorithm samples more diverse data by using different exploration weights for the different actors. The proposed method achieves better performance than previous value-based methods on procgen, where it is also competitive with policy optimization-based methods. On crafter, the proposed method achieves performance on par with the state of the art method with much smaller network.\\n\\n## Acknowledgment\\n\\nI have read the rebuttal and the following discussion and updated my review accordingly. Concerns raised by other reviewers convinced me to lower my rating by one grade.',\n",
       "  'strengths': '## Originality\\nThis paper presents a well executed study on generalization for value-based RL algorithms in CMDPs. Other studies of generalization in CMDPs have been presented in previous work, but the focus on value-based RL and exploration seems like a relatively unexplored area. The proposed method is a novel combination of existing ideas from previous work. It is well motivated by the presented analysis and achieves state-of-the-art results for value-based RL in challenging CMDPs, so presenting this combination seems like a potentially important contribution to the RL community.\\n\\n## Quality\\nThe study of exploration as a driver for generalization is of high quality. It starts from illustrative examples and applies that intuition to more complicated cases. The paper hits a good balance in what level of detail to cover the background information. The proposed method is motivated by the analysis and each of the design decisions are carefully analysed in the empirical section. The empirical results are exceptionally thorough and well presented.\\n\\n## Clarity\\nThe paper is well written throughout. It explains its ideas at a helpful level of detail. The illustrations and figures are clear and well designed. The results for procgen are presented using a style that has been promoted as the best practice in communicating RL results.\\n\\n## Significance\\nValue-based RL is an interesting topic and for various tasks, value-based RL algorithms are found to be state-of-the-art. Therefore, contributions that improve the generalization ability of value-based RL algorithms for CMDPs can be significant contributions to the RL community.',\n",
       "  'weaknesses': '## Discussion on exploration-exploitation tradeoff\\n- The paper proposes exploration as a critical component for achieving generalization for CMDPs. Choosing a more exploratory policy always introduces an exploration-exploitation tradeoff, yet such tradeoff is not discussed in the paper.\\n- The illustrative examples assume a distribution shift between training and test time MDPs. If there was no distribution shift, using a more exploratory policy would result in an exploration-exploitation trade-off that needs to be balanced. It would be good to comment on how the presented intuition is still relevant when there is no distribution shift.\\n\\n## Other weaknesses\\n- The results for the Crafter are presented with less detail than the Procgen ones. I would have appreciated learning curves and the median/IQM/... plots for Crafter as well.'},\n",
       " 'review_501': {'summary': 'The paper motivates the importance of exploration for generalization in contextual MDP with a tabular example, where the context is either the starting state or an uncontrollable random deviations in the transition model. The authors introduce an exploration method for distributional DQN, called EDE, which estimates the epistemic uncertainty of the network as the variance of quantiles between ensemble members. They use this uncertainty in an UCB-style exploration algorithm with varying exploration coefficients, called TEE. EDE/TEE is evaluated on the ProcGen baselines and on the Crafter environment. Results indicate that the average median over test MDP of all environments is higher than baselines with epsilon greedy exploration.  \\n',\n",
       "  'strengths': 'The paper is very well written and contains an enormous amount of references, for which the authors are to be commended! The insight that exploration has a larger role for generalization in CMDP than just finding the path to the largest reward (as it is in single MDP) is very interesting and well made. The presented exploration method makes sense and outperforms epsilon-greedy baselines in some of the ProcGen baselines and probably also in Crafter. ',\n",
       "  'weaknesses': 'The biggest issue with the paper is that its two parts (exploration for CMDP and EDE) do not really have much to do with each other. EDE/TEE is a general exploration algorithm, which does not use any of the insights from the first part to explore specifically for CMDP. Furthermore, the first part could be more precise for which CMDP exploration is helpful (in the presented analogy), and the second part is not all that novel. Finally, the experiments are missing important baselines and the results of EDE do not seem to be significantly better. To clarify these criticisms:\\n- The insight given in Figure 1 is very nice, but *only* applies to CMDPs where the context is different initial states. The example given in Figure 11 goes beyond this restriction, but it remains unclear what exactly the class of CMDP that can be solved by exploration is. It appears that either the context is fully observable in the state, in which case the tabular analogy breaks down, or the assumption that all $\\\\mathcal M \\\\sim q_{\\\\mathcal M}$ have the same optimal policy $\\\\pi^*$ does not apply to most CMDP, including the ProcGen benchmarks. It also does not help that the authors phrase uncertainty about an unobserved context as aleatoric uncertainty (which is a reasonable classification), as the existence of $\\\\pi^*$ would make the distinction effectively meaningless.\\n- EDE is based on the ensemble disagreement (variance) of the output of a distributional RL algorithm (QR-DQN). While the reviewer could not find a paper that does this *exact* combination, it is a very straight forward combination of many papers that pair ensemble-disagreement for exploration (many cited by the authors) with quantile regression DQN. While not in the context of exploration, other papers have already made this combination for risk-avoiding RL (Eriksson et al., 2022; Hoel et al., 2023). In its defense, EDE/TEE uses some non-standard components, like every head being trained by their own minibatch, instead of subsets of the same minibatch as in [78, 80, 81], and different exploration parameters for different actors. These are not new, though, and the overall novelty of EDE/TEE seems low.\\n- What is the connection between the first and the second part of the paper? It seems that every exploration algorithm would help this type of CMDP generalization, so why did the author specifically propose EDE? This seems to be a missed opportunity, as the first part could be strengthened by a clearer definition of exploration, too. For example, most exploration methods (including TEE) optimize a trade-off between value and epistemic uncertainty, whereas others like task-agnostic exploration [87, 122] only maximize entropy or minimize uncertainty. Which type of exploration is the right one for CMDP generalization? \\n- Does EDE ever use the aleatoric uncertainty $\\\\sigma_\\\\text{ale}$ in any meaningful way? Is there any significant difference between EDE and a DQN ensemble trained in the same manner? The reviewer doubts that the variance of a DQN ensemble is more tainted by aleatoric uncertainty than one made of QR-DQN. Figure 5 seems to suggest this, but is DQN-UCB/TEE also been trained in the exact same way as EDE? \\n- It is commendable that the authors ran a range of comparisons in Figure 5, but it is surprising that in Figure 5 EDE seems to have a significant advantage in all quantities, but against PPO/IDAAC there seems to be no advantage in mean and optimality gap. This could be accurate, but the reviewer still recommends the authors to check their code again. Which type of exploration did the PPO and DAAC baselines use here exactly? The reviewer also would have liked a comparison with intrinsic reward methods or UBE [82], as TEE only takes local uncertainty into account, which has proven to be suboptimal for exploration. \\n- Finally, the conclusions drawn from the presented results appear questionable. Improving over PPO (assumingly without advanced exploration) w.r.t. median but not mean is suspicious and looking at the learning curves in Figure 13 shows that EDE significantly beats PPO in 5 environments, but significantly looses against PPO in another 5 environments (there seems to be no significant difference in the other 6 environments). This does not look like a significant improvement by EDE! Moreover, the story of the paper is that exploration helps generalization. Can you also plot the generalization gaps for all algorithms/environments in Figure 13?\\n\\n**Additional References**\\n- H. Eriksson, D. Basu, M. Alibeigi, and C. Dimitrakakis. Sentinel: taming uncertainty with ensemble based distributional reinforcement learning. In Uncertainty in Artificial Intelligence, pages 631-640. PMLR, 2022.\\n- C.-J. Hoel, K. Wolff, and L. Laine. Ensemble quantile networks: Uncertainty-aware reinforcement learning with applications in autonomous driving. IEEE Transactions on Intelligent Transportation Systems, 2023.'},\n",
       " 'review_502': {'summary': 'This paper proposes a new noisy label learning approach based on Optimal Transport (OT) and Pseudo-Labeling (PL). Specifically, the authors extent OT-based PL with the consideration of the intrinsic coherence structure of sample distribution. Consequently, this paper proposes a novel optimal transport formulation, namely Curriculum and Structure-aware Optimal Transport (CSOT), which constructs a robust denoising and relabeling allocator that mitigates error accumulation. Experiments on both controlled and real noisy label datasets show the effectiveness of the proposed method.',\n",
       "  'strengths': '1. The paper proposes a method named Curriculum and Structure-aware Optimal Transport (CSOT) to address the problem of noisy label learning, and the application of OT-based pseudo-labeling in tackling noisy label learning problem has not been thoroughly investigated.\\n\\n2. The experimental results on different datasets in this paper validate the effectiveness of the proposed method. Additionally, several ablation experiments are conducted to demonstrate the effectiveness of each module in the method.',\n",
       "  'weaknesses': '1. In terms of methodological novelty, OT-based PL has been previously applied to other problems, and this paper only applies it to the specific problem namely noisy label learning rather than introducing it for the first time. Additionally, employing curriculum learning to address the issue of pseudo-labeling is a common strategy in the field of weakly supervised learning.\\n\\n2. The utilization of SOT is a key contribution of this paper. However, the current motivation behind this aspect, as presented in Figure 1, is not sufficiently clear. The authors are encouraged to provide additional descriptions in this section to enhance the clarity and understanding of the motivation.\\n\\n3. Since the differences between the proposed method and the comparison methods in several cases is too small, it is hard to provide a clear comparison without the present of standard deviations. Additionally, the backbone and other parameter settings of the SOTA methods are not clearly listed, thus, further evidence is needed to establish the fairness of the comparisons.\\n'},\n",
       " 'review_503': {'summary': 'This paper proposes a novel optimal transport formulation, called Curriculum and Structure-aware Optimal Transport (CSOT) for learning with noisy labels. CSOT considers both the inter- and intra-distribution structure of the samples to construct a robust denoising and relabeling allocator. It’s worthing noting that Notably, CSOT is a new OT formulation with a nonconvex objective function and curriculum constraints. The authors developed a lightspeed computational method that involves a scaling iteration within a generalized conditional gradient framework to solve CSOT efficiently. ',\n",
       "  'strengths': '1. Novel Approach: The paper proposes a novel optimal transport (OT) formulation called Curriculum and Structure-aware Optimal Transport (CSOT) to address the challenge of learning with noisy labels. I believe this paper introduces a new perspective and potentially brings fresh insights to the field.\\n\\n2. Consideration of Global and Local Structure: Unlike current approaches that evaluate each sample independently, CSOT concurrently considers the inter- and intra-distribution structure of the samples. This consideration of both global and local structure helps construct a more robust denoising and relabeling allocator, potentially leading to improved performance.\\n\\n3. Incremental Assignment of Reliable Labels: CSOT incrementally assigns reliable labels to a fraction of the samples with the highest confidence during the training process. This approach ensures that the assigned labels have both global discriminability and local coherence, which could contribute to better generalization and reduced overfitting.\\n\\n4. This paper provides a very detailed derivation for the lightspeed computational method. ',\n",
       "  'weaknesses': 'Researchers or practitioners interested in using CSOT may need to invest additional effort in adapting or developing specialized solvers. '},\n",
       " 'review_504': {'summary': 'This paper introduces CSOT, an approach to address the challenge of noisy labels in machine learning models. CSOT incorporates optimal transport formulation to assign reliable labels during training, considering the structure of the sample distribution. The authors also propose an efficient computational method for solving CSOT. Experimental results demonstrate the superior performance of CSOT compared to existing methods for learning with noisy labels.',\n",
       "  'strengths': '- The paper is strongly motivated by theoretical analysis, particularly optimal transport analysis.\\n- The writing style is clear and easy to follow.\\n- CSOT exhibits superior performance when compared to previous algorithms.',\n",
       "  'weaknesses': '- The paper lacks a comparison with a baseline algorithm called UNICON [1], which has shown good performance in highly noisy scenarios (e.g., 0.9 noisy ratio). It would be valuable for the authors to include a performance comparison with UNICON.\\n- The authors do not analyze the case of instance-wise noisy labels, which is a prevalent type of noisy label model. Including an analysis of this case would be beneficial.\\n- The paper does not investigate the sensitivity of hyperparameters, which are required to run the algorithm. It would be valuable for the authors to perform a hyperparameter sensitivity analysis.\\n- To enable a comprehensive comparison, the authors should report both the best and last performances of the model, as models trained on noisy labels tend to memorize the noisy labels.\\n\\n[1] UNICON: Combating Label Noise Through Uniform Selection and Contrastive Learning\\n\\nMinor)\\nThe legend size in Figure 2 is too small to read.'},\n",
       " 'review_505': {'summary': \"This paper introduces a novel formulation of Optimal Transport (OT), named Curriculum and Structure-Aware Optimal Transport, for generating pseudo labels by considering both inter- and intra-distribution structures of samples. Moreover, to efficiently estimate the distribution's structure, the authors adopt a curriculum paradigm to progressively train the proposed denoising and relabeling allocator. Additionally, they present a computation method for the proposed CSOT that ensures faster processing speeds, reducing computational overhead. Experimentally, this paper achieved SOTA performance on various benchmarks.\",\n",
       "  'strengths': '1.Estimating the intra- and inter-structure coherence of samples is a convincing and reliable method for improving relabeling accuracy. The proposed prediction-level and label-level consistency constraints seem also interesting and plausible.\\n2.The combination of the proposed OT and curriculum learning for solving INL is also smooth and makes sense.',\n",
       "  'weaknesses': '1.The effectiveness for alignment of global and local structures between samples and classes is not fully convincing. The ablation results for OT in Table 3 seem weak. The comparison between row (a) with 78.07 and row (b) with 78.65 suggests that the performance improvement brought by the proposed prediction-level and label-level constraints is limited. Moreover, the introduction of two additional constraints adds complexity to the optimization. Similarly, row (e), CSOT w/o Ω^{L}, achieves the best performance, indicating that the benefits brought by the prediction-level and label-level constraints are unstable.\\n\\n\\n2.As the part that readers are most concerned about, the section 4.3, the loss function needs to be able to reflect the integrity of the method and the specific combination with its own innovation points. I can’t see the innovation of this article in the loss function here, and each loss term is an existing work. The work in this paper seems to be only used to build a dataset $\\\\mathcal{D}_{\\\\text{clean}}$ and  $\\\\mathcal{D}_{\\\\text{corrupted}}$ for training? This structure and method of writing can greatly weaken the contribution of this paper. Besides, I would like to suggest the authors provide an overall alghrothim to show the whole training process, where the proposed methods would have been used during each training epoch and the training objectives are not the key point in this paper.\\n\\n3.Considering the complexity of the proposed algorithm, and its marginal improvement over previous methods on two real datasets in Table 2, especially compared to NCE. The effectiveness of this work is questionable. Additional experiments are suggested, especially on Clothing1M. Besides, some related works[1] should be discussed which are published recently.  \\n\\n [1] OT-Filter: An Optimal Transport Filter for Learning with Noisy Labels (CVPR 2023)\\n\\n4.The results of row (g) in Table 3 are not sufficient to show that the performance improvement is brought about by the method in this paper. For example, we need a more detailed ablation study to explain the role of NCE loss and the role of CSOT.\\n\\n5.The structure of the article is confusing, which weakens the contribution of this article. Secondly, the introduction of some tool concepts is quite abrupt. For example, the proposal of Eq. (3) and (6) gives people a new form of OT formulation and will give specific solutions later. This expectation is affected by the entropy regularization in the following text, whose introduction is abrupt. This results in the final Eq. (16) which does not look significantly different from the original sinkhorn algorithm. It is recommended to introduce sinkhorn from the beginning and to emphasize that there are new constraints based on it.\\n\\n6.The characters in the figures in the experimental part are too small, which affects reading. At the same time, why are there two figures, and their labels are figure 2? Moreover, Fig. 4 is quoted in the description of the text, but there is no figure 4 in fact.'},\n",
       " 'review_506': {'summary': 'The paper studies the problem of noisy label learning. The paper adopts an optimal transport approach to generate pseudo labels for noisy samples. Particularly, the paper builds on the existing method and adds additional regularization terms to enforce the consistency between sample classes and learned representations. The paper also extends the sinkhorn algorithm to solve the proposed OT objective efficiently. Empirically, the proposed method has improved performance over baselines on widely used datasets with various noisy ratios.',\n",
       "  'strengths': '1. The paper extends the existing optimal transport approach to include the consistency between the sample representations and predictions/labels. It is a novel objective and a solid idea intuitively.\\n\\n2. The paper extends the sinkhorn algorithm to solve the proposed new OT objective efficiently.\\n\\n3. The proposed method has strong empirical performance, especially for high noise ratios.\\n\\n4. As a pseudo-labeling step, the proposed method can potentially work with other noisy label learning objectives.',\n",
       "  'weaknesses': '1. The proposed method is a regularization of the existing optimal transport pseudo-labeling method. The novelty is thus limited.\\n\\n2. The introduced regularization uses the same weight kappa for the two terms, while the two terms could have quite different behaviors/values.\\n\\n3. It is not clear to me how does the method perform or should be modified in the case where the class distribution is imbalanced.\\n\\n4. The OT objective is not directly related to the training objective but serves as a sieving step. It would be great if a more comprehensive training objective can be formalized to include the OT based selection.'},\n",
       " 'review_507': {'summary': 'The authors study the problem of causal discovery from data under different conditions/contexts. The approach uses an algorithmic model of causation, where the idea is that causal mechanisms provide short (or simple) descriptions of the observed data. Under this principle, the authors propose a score function for models where the functional mechanisms are Gaussian processes (GPs). The main contributions of this work are Theorems 3.1, 3.2, and 3.3, where the authors show identification of the MEC or ground-truth DAG. The core assumptions for such theorems are:\\n* Causal sufficiency\\n* All contexts share the same DAG\\n* Additive noise model with GPs\\n* Causal minimality \\n* $\\\\Pi$-faithfulness\\n* Independence of mechanism shifts\\nThe authors develop LINC to learn the causal DAG from different contexts, and provide some experiments to validate their results.',\n",
       "  'strengths': '### Potential Reasons for Acceptance\\n   - The paper provides a fair investigation into the core assumptions that many causal modeling approaches, including SMS, rely upon, and moves the field forward by addressing these assumptions.\\n   - Novelty of the proposed approach \"LINC\": By adopting the algorithmic notion of independence and Gaussian Process models, the authors elevate the ability to identify the accurate causal model and extend the scope beyond partially directed graphs.\\n   - Identifiability theory: The authors provide theoretical justification for their approach, followed by some empirical evaluations on both synthetic and real-world datasets which aim to validate their claims.\\n',\n",
       "  'weaknesses': '### Potential Reasons for Rejection\\n   - The DAG from a single context is identifiable as it is a nonlinear additive noise model.\\n   - Theorem 3.2 seems very unrealistic when considering infinite number of contexts. While the authors try to provide some justification to it by providing a finite-sample statement in Theorem 3.3, I got confused with the idea of $C$ falling into some \"bins\". What does it mean for $C$ to fall into two or more different bins? The notion of bins were never used until this theorem and was not properly described  in my opinion.\\n   - Dependency on number of datasets:\\n     - The effectiveness of the proposed model heavily depends on certain characteristics of the dataset such as having enough contexts, which might not always be the case. \\n  - Complexity of the proposed solution:\\n     - The proposed solution is relatively complex, particularly concerning the computational cost. Several experiments are performed on a very small number of nodes, e.g., six-node graphs.\\n     - Some heuristics are provided in the appendix to alleviate this issue, however, some details are missing. For example, in  Figure 8(b), MC seems faster and obtains similar F1 scores to LINC.\\n   - The writing can be improved by a fair margin. Learning a DAG from different contexts is not a new setting and the authors could greatly reduce the amount text of somewhat repetitive definitions of the model in Line 69, Assumption 1 and Assumption 2. Indeed Assumption 1 seems useless if Assumption 2 already holds, no? If the theoretical results rely on GPs, why not simply state that in the problem setting? Finally, Theorems 3.1 and 3.2 mention a  \"sufficiently small $\\\\lambda$\", but such $\\\\lambda$ does not appear in the result. By looking at the text there is a $\\\\lambda$ from the RBF in Line 139; however, in the appendix I got confused as it seems to refer to a different quantity.'},\n",
       " 'review_508': {'summary': \"This paper addresses the problem of causal discovery with heterogenous data coming from multiple contexts where contexts are characterized by soft/hard interventions. Previous work differs in assumptions on how non-iid data is produced, the primary assumption being the Sparse Mechanism Shift assumption which assumes that the number of mechanism changes is small. The current paper proposes a score-based approach to discovering the casual graph from data coming from different contexts. For each variable, the set of contexts can be partitioned where in each bin of the partition, the mechanism that represents the cause-effect relationship between the variable and its parents is unchanged. The score-based approach comprises of a) functionally modeling the relationship between variables and their parents using Gaussian processes (GPs) for each context bin and b) computing a score that is based on minimum description length (MDL) of the GP model. The paper provides identifiability guarantees for identification up to its Markov Equivalence class (MEC). With an additional assumption about independence of context-partitions the authors are able to obtain asymptotic (in the number of contexts) identification guarantees beyond the MEC. Numerical results on synthetic, semi-synthetic and real datasets validate the proposed method's superiority over existing methods. \",\n",
       "  'strengths': \"This paper provides a novel algorithm for an important problem of causal discovery using heterogenous data. The main strength of the paper lies in the experimental validation of its proposed method, LINC. The evaluation is done on multiple types of datasets and LINC is shown to outperform or is at least competitive to existing methods on all. While, the idea of using MDL-based scores is not novel in causal discovery, the idea of combining Kakade et. al.'s work in causal discovery is novel. On the theoretical side, while I have questions about the assumptions that I elaborate in the sections below, the paper proves identifiability guarantees in both the asymptotic (in number of contexts) and and finite-context settings. \",\n",
       "  'weaknesses': \"Listing out a few weaknesses: \\n1) Justification of assumptions: The core result of identifiability beyond the MEC depends on the independent mechanism shift assumption. I wasn't convinced about why this assumption makes sense. In particular, why does the assumption imply Line 184-185. I also didn't find any practical justification of the fixed-partition sizes assumption. In general, justifying the assumptions more clearly and with a practical example in mind can help strengthen this weakness. \\n2) Writing: The writing can be improved greatly. There are undefined notations and a lot of important content of the paper that has not been explained in the first 9 pages. Some examples: a) The main score function in Line 161 is not explained or defined anywhere. Given that LINC is explained only in the appendix, I found it difficult to even understand what the score function was. b) Independent mechanism shift also contains notation \\\\Pi_i(C) which hasn't been defined before (but is clear from context). c) Assumption numbers mismatched. d) words used without defining - algorithmically independent in line 109, direct intervention in Line 34, \\n3) Experiments: Most of the evaluation is based on recovery of the causal graph whereas identification guarantees also address recovering the partitions.  Can some experimental results be shown to verify if the partitions are being discovered correctly? \"},\n",
       " 'review_509': {'summary': 'The authors present a novel approach for causal discovery that goes beyond partially directed graphs by utilizing Gaussian Process (GP) models. The proposed method aims to identify\\nthe correct causal model under certain conditions. The key idea is to leverage algorithmic independence to achieve a concise and lossless description of the data, particularly in the presence of multiple contexts. Unlike existing approaches such as Sparse Mechanism Shift (SMS), which require conditional independence tests, the proposed method employs a scoring criterion based on GP models.\\nThe authors established the theoretical soundness of this approach by providing a clear and concise explanation of the underlying principles. Additionally, they demonstrate the effectiveness of the method through several examples, which serve to evaluate its performance and help to illustrate the practical implications and potential benefits of the proposed method. Overall, the proposed method offers a new perspective on causal discovery by utilizing Gaussian Process models and algorithmic independence.\\n',\n",
       "  'strengths': 'LINC (Learning causal models under Independent Changes) proposed in this paper seems original utilizing GP and its complexity measure for discovering a mixture of mechanisms. Non-iid data can be typically challenging but in this paper’s setting, multi-context is a key to identifying the underlying causal structure. The overall flow of the paper is smooth, and it appropriately makes necessary assumptions. ',\n",
       "  'weaknesses': 'Not a major weakness but minor weaknesses (more like comments)\\n\\nReadability: It would have been beneficial to include explanatory information on prerequisite knowledge to enhance the accessibility of the paper. In particular, “algorithmic independence” seems very crucial, but it is just referenced without properly articulating its definition or the difference to conditional independence. \\n\\nAssumptions numbering is problematic. It seems that the authors removed one of the assumptions at the very last stage of writing. E.g. Assumption 5 is mentioned in Theorem 3.1, which is in the previous section. Also for Theorem 3.2 refers Assumption 6. Theorem 3.3 calls for Assumption 7 which does not exist. \\n\\nIt is less clear whether C is part of data or not.\\n'},\n",
       " 'review_510': {'summary': 'The author propose a score-based method for causal discovery from multi-environment data. Identifiability of the causal model and the environment partition were shown for the proposed score function. The proposed algorithm was evaluated on synthetic and multiple real data sets. ',\n",
       "  'strengths': '1. The toy example provides a nice illustration of the proposed idea.\\n\\n2. Using a measure of the complexity of GP models as the score function for causal models is an interesting idea.\\n\\n3. There are sufficient evaluations on synthetic and real data sets.',\n",
       "  'weaknesses': '1. The score function (4) is written in terms of the true conditional probability, while the empirical score function is not defined. In the algorithm, it was not mentioned how to estimate the score function using the data. \\n\\n2. There are missing explanations and plenty of typos in the main results. \\n\\nMissing explanations:\\n\\n(1) The role of the the penalty term $R(X_{S})$ in $(4)$ should be explained even it is from a previous work.\\n\\n(2) The term $L(h)$ in $L(X|\\\\mathcal{H})$ is not defined in Section 2.2.\\n\\n(3) How is $\\\\mathcal{H}_{k}$ constructed in the algorithm? How large is the function class? \\n\\nTypos:  \\n\\n(1) Whether the term $-log P(X_{i}|X_{S})$ in (4) should be $-log P(X_{i}|f(X_{S}))$ or something else? \\n\\n(2) LHS of (5) should be $X_{j}^{(c)}$.\\n\\n(3) $\\\\lambda$ in Theorem 3.2. is not defined in the score function.\\n\\n(4) \"Theorem3.1 assumes Assumptions 1-4, Theorem 3.2 assumes Assumptions 1-5, and Theorem 3.3 additionally assumes Assumptions 6.\"\\n\\n(5) $X_{S} \\\\subseteq X\\\\setminus X_{i}$ in (4).\\n'},\n",
       " 'review_511': {'summary': 'This paper studies the problem of long-range time series forecasting problem and proposes a WITRAN model. The paper analyzes and compares previous forecasting methods from the perspective of information transmission process and design a water-wave information transmission mechanism, which simultaneously capture global and local correlations via a bi-granular information transmission. And a recurrent acceleration network is designed to reduce the computation complexity.',\n",
       "  'strengths': \"1) WITRAN is an ingeniously crafted framework, capable of simultaneously capturing two aspects of semantic information within long-range time series - global-local correlations and both long- and short-term periodic patterns. The WIT includes two innovative modules, namely, HVGSU and GSU, which augment forecasting accuracy while enhancing explainability. Additionally, the RAN segment is designed to markedly improve efficiency. Finally, the WIT and RAN segments are seamlessly integrated together. \\n\\n2) The paper presents an exhaustive theoretical substantiation of the RAN segment's operating efficiency, shedding light on its capacity to significantly boost model efficiency.\\n\\n3) WITRAN exhibits superior performance, as confirmed by a series of comprehensive experiments with equitable settings across all baselines. WITRAN outperforms SOTA methods in both long-range and ultra-long-range forecasting tasks. Moreover, the incorporation of RAN indeed enhances computational efficiency and reduces memory footprint, in alignment with theoretical proof.\",\n",
       "  'weaknesses': '1) It seems that the proposed model is suitable for the time series that naturally contains bi-granular periodicity, such as traffic flow with daily and weekly periodicity. So the generalization of the proposed model is unclear.\\n\\n2) In the experimental section, many Transformer-based methods are taken as baselines, but few RNN-based methods are not compared. Since the proposed model is RNN-based, so it is necessary to add more RNN-based baselines.\\n'},\n",
       " 'review_512': {'summary': 'The paper studies a Water-wave Information Transmission and Recurrent Acceleration Network (WITRAN) framework to model dependencies in a long historical time series. Inspired by Timesnet, the WITRAN introduces a water-wave information transmission strategy to model temporal information. This is implemented by the proposed Horizontal Vertical Gated Selective Unit (a kind of recurrent unit and  similar to GRU).',\n",
       "  'strengths': '1) This paper is well-written\\n2) Figures illustrate model details in a good way\\n3) This paper studies the single-channel case, though most existing papers consider evaluations on multivariate time series. This makes sense as this can better evaluate the ability to learn temporal dependencies in time series.\\n4) Advanced baselines such as MICN, timesnet, patchTST, and film are included.',\n",
       "  'weaknesses': '1) Although using the water-wave structure is new to me, I am still curious about why this design is needed in long-range time series forecasting. Especially, are there any special temporal structures that existing models in Figure a-g cannot handle?\\n2) The water-wave structure is a strategy to model time series dependencies. However, it is unclear how to decide the number of R and C and what are their effects on the final prediction. \\n3) In Figure 10 (appendix), the results of the proposed are much worse than other baselines: FiLM and Pyraformer. But you claimed that “our model WITRAN gives the best performance among different models” in Section J. Moreover, other plots in Figure 11-31 did not demonstrate the effectiveness of WITRAN. \\n4) The reference part is missing.'},\n",
       " 'review_513': {'summary': 'This paper focuses on the long-range time series forecasting problem. An interesting model, Water-wave Information Transmission and Recurrent Acceleration Network is proposed, which captures both short- and long-term recurrent patterns via bi-granular information transmission. The proposed model also captures global and local correlations using horizontal and vertical information transmission. This model is an interesting modification of the RNN network, and it significantly outperforms many transformer-based models.',\n",
       "  'strengths': 'S1. This paper reviews the shortcomings of transformer models and makes modifications to the RNN structure. \\n\\nS2. A bi-granular information transmission is proposed to capture short- and long-term recurrent patterns, which is easy to understand and does not require additional methods (e.g., FFT) to extract periodicity.\\n\\nS3. A recurrent acceleration network is proposed, which reduces the time complexity to O(√L) while maintaining the memory complexity at O(L).\\n',\n",
       "  'weaknesses': 'W1. Some previous RNN-based models, such as ConvLSTM [1]/ PredRNN [2]/ PredRNN++ [3], have yet to be compared.\\n\\n[1] Shi X, Chen Z, Wang H, et al. Convolutional LSTM network: A machine learning approach for precipitation nowcasting[J]. Advances in neural information processing systems, 2015, 28.  \\n[2] Wang Y, Long M, Wang J, et al. Predrnn: Recurrent neural networks for predictive learning using spatiotemporal lstms[J]. Advances in neural information processing systems, 2017, 30.  \\n[3] Wang Y, Gao Z, Long M, et al. Predrnn++: Towards a resolution of the deep-in-time dilemma in spatiotemporal predictive learning[C]//International Conference on Machine Learning. PMLR, 2018: 5123-5132.\\n\\nW2. Some minor problems:\\n1) It is recommended to enlarge Figure 1(i) and make horizontal lines clearer.  \\n2) It is recommended to unify TF_{en} and TFE_{de}.\\n'},\n",
       " 'review_514': {'summary': 'To capture semantic information and repetitive patterns concurrently, the authors propose WIT framework. By utilizing bi-granular information transmission and HVGSU, the framework can model the inherent repetitive pattern as well as correlation of time series. The author also use a generic RAN to reduce time complexity. Several experiments conducted by te authors demonstrate that their framework can outperform in time series forecasting.',\n",
       "  'strengths': 'S1: The logic and presentation of the essay is easy to follow.\\nS2: The problem they focus on is very essential as well as appealing.\\nS3: Experiments reveal the performance of the authors’ model outperforms existing SOTA baselines.\\n',\n",
       "  'weaknesses': 'W1: The authors may include more experiments such as robustness check to further evaluate the performance of the framework.\\nW2: There are some typos and minor errors that do not influence the understanding of this work, which should be carefully checked. For instance, line 29, semantic information include-> semantic information includes\\n'},\n",
       " 'review_515': {'summary': 'The authors propose an auto-encoding method for learning molecular embeddings from both 3D and 2D information jointly. The method is loosely related to diffusion methods in that embeddings of data augmentation trajectories are learned via a score-based reconstruction loss and contrastive loss. The embeddings give SOTA performance on a number of QM and activity prediction tasks.',\n",
       "  'strengths': '### Originality \\n\\nThe method is original in that it encodes both 3D and 2D molecular information via learning to embed data augmentation trajectories.\\n\\n### Quality\\n\\nThe results indicate that the resulting embeddings are SOTA.\\n\\n### Clarity \\n\\nThe paper could be made much clearer (see Weaknesses).\\n\\n### Significance\\n\\nOptimal molecular embeddings are a perennial desire for all kinds of downstream molecular tasks. The SOTA performance of these embeddings suggests that this method represents a significant contribution.',\n",
       "  'weaknesses': '- Section 2 Background is a meandering presentation of a number of related ideas, some of which are not immediately relevant for the main paper. Those should be moved to the appendix, and the remainder should be made much crisper so that it is clear to the reader how the remaining sections will proceed.\\n  - the unnumbered equation after Eq. 4 is missing an $e_m$.\\n- It is not at all clear what data augmentations are used in this paper. E.g. what are $\\\\mu_1$ and $\\\\mu_2$ in Eq. 6?\\n- The presentation of the MLE in Section 3.2 is unnecessarily confusing. There is no need to introduce energy-based models, Eq. 9 can be derived without the energy functions. Note that the energy functions are never referred to again. The only thing is the surrogate gaussian KDE, but again that does not need to be motivated by energy functions.\\n\\nTypos:\\n- The statement $E_θ(x0) = \\\\log q_θ(x_0)$ is incorrect since it is missing a $\\\\log Z_\\\\theta$.\\n- Most of the score expressions in section 3.2 are missing a $\\\\log$.'},\n",
       " 'review_516': {'summary': 'This paper proposes a new representation learning method for molecules using 2D and 3D structures. The joint distribution between original molecules and augmented molecules is decomposed into reconstructive and contrastive tasks. The proposed model, MolecularJAE, simultaneously tackles both tasks with the help of SE(3) equivariant GNN models. MolecularJAE is evaluated on quantum property prediction and molecular dynamics prediction and achieves a competitive result against baseline models.\\n',\n",
       "  'strengths': \"- Diffusion over two different modalities hasn't been explored as far as I know.\\n- The decomposition of joint distribution into reconstructive and contrastive tasks is new and interesting.\\n\",\n",
       "  'weaknesses': '- It is known that the 3D structure of a molecule follows certain physical rules. The diffusion process used in this paper does not account for the prior knowledge from the domain.\\n- The performance of the proposed model is worse than some recently proposed models, which hasn\\'t been included in the experiment section. For example, the performance of Equiformer[1] and PaiNN[2] on QM9 is better than the proposed model across almost all tasks.\\n- The presentation of this paper can be improved further. For example, Figure 1 does not provide any meaningful information to readers. Figure 2 is also difficult to digest. Polishing these figures with additional details and proper explanations would improve the accessibility of the manuscript.\\n- There are too many typos throughout the main text and appendix.\\n\\n[1] Liao, Yi-Lun, and Tess Smidt. \"Equiformer: Equivariant graph attention transformer for 3d atomistic graphs.\" ICLR 2023.\\n\\n[2] Schütt, Kristof, Oliver Unke, and Michael Gastegger. \"Equivariant message passing for the prediction of tensorial properties and molecular spectra.\" ICML 2021.\\n'},\n",
       " 'review_517': {'summary': 'The paper proposes MoleculeJAE, an auto-encoder for both 2D and 3D molecule diffusion trajectories. The model learns the trajectories jointly in a self-supervised manner. Empirically, MoleculeJAE achieves competitive results on property and force prediction benchmarks.',\n",
       "  'strengths': \"The joint diffusion of 2D and 3D is novel. It is widely concerned that point cloud diffusion is less aware of 2D information. I admire the authors' contribution to this problem. I would also thank the authors for providing a detailed theoretical analysis.\",\n",
       "  'weaknesses': '1. I did not really get the motivation of modeling diffusion trajectories. Personally, I think the intermediate states are less informative than x_0. Could you please further explain your idea, and provide some additional ablation results if possible, for it seems that the current ablation study shows that the role of the contrastive loss is not very significant in many cases? Thanks.\\n2. I believe the baselines of QM9 experiments are not state-of-the-art. Please consider this work: https://openreview.net/forum?id=tYIMtogyee\\n'},\n",
       " 'review_518': {'summary': \"The paper introduces a pretraining method for molecule joint auto-encoding (MoleculeJAE) for 2D molecular topology and 3D molecular geometry. Their approach adopts SE(3) symmetry and is trained by fitting the joint distribution of the trajectories from the forward process of the diffusion model.\\n\\nThe authors treat the 2D molecular structure and 3D geometry as continuous objects, which are perturbed by Gaussian noise in the diffusion process. Unlike traditional diffusion models that denoise data by marginal distribution modeling, their 'auto-encoding' approach focuses on learning the joint distribution of data pair $(x_0, x_t)$. The overall task is then optimized by two objective functions, including a reconstruction loss and a contrastive loss, as well as a surrogate model.\\n\\nExperimentally, MoleculeJAE is pre-trained on the PCQM4Mv2 dataset and is used to perform downstream tasks on QM9 and MD17 datasets. The experimental results are competitive on property prediction and dynamics prediction tasks.\\n\\nOverall, this work is well-motivated and novel, with a theoretical justification for their approach. This paper presents good quality work.\",\n",
       "  'strengths': 'First of all, this work is well-motivated, as jointly learning 2D and 3D molecular representations by diffusion models is still at the stage of development. MoleculeJAE can learn both 2D bond topology and 3D conformation geometry information and is designed to respect the SE(3) symmetry of molecule data and is trained by fitting the joint distribution of the data’s augmented trajectories extracted from the forward process of the diffusion model.  \\n\\nIt is also novel that the joint 2D and 3D learning of diffusion models is trained in a self-supervised learning manner and optimized by a contrastive learning objective function. MoleculeJAE unifies both contrastive and generative learning approaches from a trajectory perspective, providing a versatile and powerful molecular representation that can be applied to various downstream applications.\\n\\nUnlike traditional diffusion modeling, MoleculeJAE uses a contrastive learning paradigm to fit the trajectory of pairwise molecules, while also utilizing the reconstructive task to perform denoising for each individual molecule. By using contrastive learning, it allows the model to align the augmented views of the same data and simultaneously contrast the augmented views of different data. Also, ablation studies show the importance to have a contrastive loss in the task.\\n',\n",
       "  'weaknesses': 'For methodology, the authors treat the 2D graph topology as a continuous object that is perturbed by Gaussian noise. I understand it is easier and reasonable to put the three things, atom features, bonds, and coordinates, under a single SDE framework. However, following previous works [1][2], describing the 2D graph topology as a discrete object with a discrete diffusion process is more reasonable, and their models show superior results. \\nExperimentally, MoleculeJAE shows better results with only small margins. However, the authors do not compare the number of model parameters, the overall training time, and the error bars (standard deviation) with existing methods, so it is unclear to me how well MoleculeJAE surpasses those methods.\\n\\n[1] Vignac, Clement, et al. \"DiGress: Discrete Denoising diffusion for graph generation.\" arXiv preprint arXiv:2209.14734 (2022).\\n\\n[2] Hua, Chenqing, et al. \"MUDiff: Unified Diffusion for Complete Molecule Generation.\" arXiv preprint arXiv:2304.14621 (2023).'},\n",
       " 'review_519': {'summary': 'This paper proposes color equivariant convolutional networks (CE-CNNs), a novel convolutional neural network architecture that achieves equivariance to hue changes.&#x20;\\n\\nThey introduce color equivariant convolutions that apply a discrete set of hue rotations to the convolution filters during the forward pass. This makes the network output invariant to corresponding hue changes in the input image.\\nThey propose a group coset pooling layer that pools feature maps over the group of hue transformations to achieve invariance.\\nThey evaluate CE-CNNs on several image classification datasets, showing improved robustness to hue changes at test time compared to regular CNNs. The method also improves absolute classification performance in some cases.\\nOverall, the paper presents a novel and intuitive technique to build invariance to hue changes into CNNs. The evaluations demonstrate its advantages over standard networks, especially under shifted hue distributions between training and test.',\n",
       "  'strengths': 'This paper introduces a clever yet intuitive technique to make convolutional neural networks invariant to hue changes in the input image. The core idea is to apply discrete hue rotations to the convolution filters during the forward pass, essentially \"baking in\" robustness to color changes.\\n\\nThe paper is clearly written and easy to follow. The authors motivate the problem well, explain their proposed method succinctly, and provide thorough experimentation across image datasets. The visualizations offer useful insights, confirming that the networks learn consistent features across hues.\\n\\nOverall, I found this to be an original and significant contribution. Invariance to hue shifts is a practical problem, and this paper tackles it through an elegant approach that outperforms regular CNNs. The concept of encoding transformations into convolutions seems powerful. While not the flashiest technique, the method is thoughtful, principled, and achieves strong results. The paper is presented clearly and comprehensively, making the ideas accessible. In summary, this is a high quality paper with both theoretical and practical value.',\n",
       "  'weaknesses': '-   The method is demonstrated on image classification, but it\\'s unclear how well it would generalize to other tasks like detection or segmentation. Additional experiments on other applications could strengthen the claims.\\n-   The ablation study on number of hue rotations suggests performance varies across different shifts. It would be useful to dig deeper into why - is it an artifact of how shifts are applied? Better understanding this could improve results further.\\n-   The approach encodes discrete hue rotations. An interesting extension could be supporting continuous rotations for finer-grained equivariance.\\n-   The comparisons to \"grayscale\" networks should be interpreted carefully, as removing color information entirely handicaps models. Comparisons to networks pre-trained onImagenet may be more meaningful.\\n-   The Flowers-102 experiments indicate the method doesn\\'t help much on datasets without color bias. Analyzing when color equivariance helps or hurts could guide adoption.'},\n",
       " 'review_520': {'summary': 'Paper proposes color-equivariant CNN layers by imposing equivariance to H_n (a discrete subgroup of SO(3)) in the RGB space which is imposes hue equivariance. Implementation follows the framework of Group-equivariant CNNs. Experiments show marginal improvements over standard CNNs for in-distribution test data but significant improvements when test data is hue-shifted.',\n",
       "  'strengths': '1. Color equivariance in CNNs is a relatively less-studied but an important topic for robustness. The proposed idea of incorporating equivariance to hue transformations via rotations in the RGB space is novel. \\n2. Experiments are setup well clearly showing when color equivariance is helpful vs color invariance vs no symmetry. Proposed approach shows improves over CNN even when in in-distribution test data, but major improvements come when test data is hue-shifted.',\n",
       "  'weaknesses': '1. Definition of color equivariance considered in the paper seems to be restricted as it only considers the hue dimension. One of the motivations for incorporating color equivariance is for robustness to illumination changes which I do not think is guaranteed here. A general definition of color-equivariance should consider other dimensions. Maybe the claims are better justified if Hue-equivariance is emphasized in the title/introduction/method name, etc.\\n2. The definition of hue-equivariance is not precise in the paper. Ideally, it should include all rotations in the RGB space (i.e., SO(3)), but also consider the fact that many of these rotations take the color values out of the RGB space (unit cube). In general, this issue occurs for the discrete subgroup $H_n$ as well. Simply projecting the color values back into the RGB space does not work as it breaks the invertibility property of these transformations. \\n3. Experiments compare with a standard CNN (+grayscale) as baseline. Other baselines can be included, for example [1], that considers invariance to illumination color/intensity. \\n4. Experiments in the main paper only consider the group $H_3$ (i.e., 3 rotations in the RGB space), which seems limited in robustness, as shown in Figure 1 without jitter augmentations. \\n\\n\\nReferences:\\n\\n[1] Lengyel, Attila, et al. \"Zero-shot day-night domain adaptation with a physics prior.\"\\xa0_Proceedings of the IEEE/CVF International Conference on Computer Vision_. 2021.'},\n",
       " 'review_521': {'summary': 'The authors introduce a color equivariant convolutional neural network. To achieve this the authors represent the image in HSV format, and achieve hue equivariance using methods for rotational equivariance. This is possible since hue can be represented by an angle. The authors show that the proposed approach out performs standard CNNs and color invariant CNNs when there is a hue shift between the train and test set.',\n",
       "  'strengths': '* Originality: The presented method of building a color equivariant CNN appears to be original. \\n* Quality: The work appears to be of fairly good quality. \\n* Clarity: The paper is well written. \\n* Significance: The observation that color equivariance can be achieved by identifying hue with the rotation group is interesting. The results show the proposed approach leads to improved performance when there is a color based domain shift.',\n",
       "  'weaknesses': '* Quality: I have some questions about the mathematical presentation, and experiment design (see questions).\\n* Clarity: Some aspects were unclear to me, due to presentation or motivation (see questions)'},\n",
       " 'review_522': {'summary': 'This paper questions the importance of color variations for neural classifiers and proposes to use color-equivariant architectures in the case of unbalanced datasets.\\nTo demonstrate the validity of the presented approach, the authors conduct experiments both on synthetic controlled datasets and on common object recognition benchmarks.\\nAs the experiments show, the injection of color-equivariant layers leads to a slight improvement on almost all common benchmarks when the performance is measured on the original test set but the advantage of the presented method becomes more evident when the test data is corrupted with hue shifts.',\n",
       "  'strengths': 'This paper studies an interesting and underinvestigated question of the importance of color representation for neural networks.\\nThe submission is easy to read, and the motivation is well explained in the example of the Flowers dataset. \\nThe authors have conducted a significant number of experiments to support their claims.\\nAdditional strength is that the demonstrated performance improvement is achieved without increasing the number of trainable parameters (line 238).',\n",
       "  'weaknesses': '1. While the idea of extending equivariance from geometric to photometric transformations is definitely interesting, the submitted manuscript, unfortunately, focuses on the only type of such transformations, i.e. hue shifts. Despite the case of the Flowers dataset is a perfect fit for this transformation, the authors do not discuss other use cases when this type of equivariance may be interesting in practice and just mention \"accidental recording conditions\" (line 3). For other datasets, hue shifts seem less meaningful, and the better robustness of the proposed CE-ResNets to such shifts at test time is explained by the fact the architecture was just intentionally designed for this scenario. Taking this into account, I find the scope of the paper a bit limited.\\n\\n1. In addition to being limited in the number of considered photometric transformations, the paper also considers a single task of object recognition. I would encourage the authors to consider other tasks as well, e.g. unsupervised domain adaptation.\\n\\n1. While the authors claim their approach makes networks more robust to test time corruptions (Tab. 1), they do not demonstrate other baselines aiming to provide robust outputs, e.g. adversarially robust models.'},\n",
       " 'review_523': {'summary': 'This paper introduces a hybrid-grained feature interaction selection approach that targets both feature field and feature value for deep sparse networks and decomposes the selection space using tensor factorization and calculating the corresponding parameters on the fly. \\n',\n",
       "  'strengths': 'Extending the selection granularity of feature interactions from the field to the value level.\\n\\nIntroduce a hybrid-grained feature interaction selection space, which explicitly considers the relation between field-level and value-level. \\n\\nThe tensor decomposition and the sparsification are combined to perform selection on the shrinking space.\\n',\n",
       "  'weaknesses': '1.The evaluation datasets are pretty small (the feature number is around 11-26). For recommendation systems optimization work, it is usually better to show the results in large-scale datasets like industrial datasets to demonstrate the scalability and performance.\\n\\n\\n2.Missing several references:\\n\\nAutoFAS，\\n\\nNAS-CTR，\\n\\nAutoIAS,\\n\\nGAIN: A Gated Adaptive Feature Interaction Network for Click-Through Rate Prediction\\n\\nMaybe adding some discussions or comparisons to them is better. \\n\\n\\n\\n'},\n",
       " 'review_524': {'summary': 'This paper tackles the problem of modeling fine-grained feature interactions in high-dimensional sparse features.\\nA hybrid-grained feature interaction selection method is proposed, which operates on both field and value for deep sparse networks.\\nTo handle the increase in computation, a decomposed form of the selection space is done, which greatly reduces the computational requirements of modeling.\\nResults on deep sparse networks benchmarks show that the proposed method achieves SOTA results while being more computationally efficient.',\n",
       "  'strengths': '- Strong results in terms of performance on established benchmarks and computational efficiency, demonstrating the effectiveness of the proposed method.\\n- The proposed method seems generalizable and can be applied to other methods.\\n- All experimental parameters are provided, making reproduction straightforward.\\n- The writing is fairly clear and easy to understand.',\n",
       "  'weaknesses': '- Experimental results:\\n  - The proposed method is a simple tensor decomposition for improved efficiency and the additional consideration of more features. Such choices are generalizable to other architectures (as mentioned in lines 109-112) but this is not demonstrated in the paper. I would like to see the application of the proposed components to other existing approaches.\\n- Significance of results:\\n  - The AUC and Logloss scores differ by less than 0.001 between the proposed method and the previous SOTA. Is this significant? I suggest the authors add confidence intervals to Table 1 and 2 for easier comparison.'},\n",
       " 'review_525': {'summary': 'This work proposes a hybrid-grained feature interaction selection approach for deep sparse networks, which targets both feature field and feature value. The proposed approach uses a decomposed space that is calculated on the fly to explore the expansive space of feature interactions. The work also introduces a selection algorithm called OptFeature, which efficiently selects the feature interaction from both the feature field and the feature value simultaneously. The proposed approach is evaluated on three large real-world benchmark datasets, and the results demonstrate that the proposed approach performs well in terms of accuracy and efficiency. The work concludes that the proposed approach can effectively select feature interactions in deep sparse networks, and it has the potential to improve the performance of prediction tasks with high-dimensional sparse features.',\n",
       "  'strengths': '1. The hybrid-grained feature interaction selection approach goes beyond traditional field-level selection, and the decomposed space and sparsification-based selection algorithm make the work appear to be a cutting-edge method to some extent.\\n2. This work ran the repetitive experiments with different random seeds five times and reported the average value for each result, and provides information about the parameter setup, metrics, datasets, baseline and parameter setup, so the experimental results appear to be reliable.',\n",
       "  'weaknesses': '1. Novelty: The proposed approach that targets both feature field and feature value levels and introduced a decomposed space and a sparsification-based selection algorithm to explore the selection space, which appears to be a novel contribution to the field. But it does not provide a comprehensive review of related Feature Interaction Selection work in Section 2, and the novelty is not so obvious.\\n\\n2. Experiments: What GPU was used in this work? How many were used? Were all the experiments conducted on the same GPU? Why formulate the hybrid-grained feature interaction selection as a binary selection according to Equation 6? Taking either 0 or 1 doesn’t seem to reflect ‘hybrid’. \\n\\n3. Writing: the introduction does not summarize the main contributions of this work, so readers cannot intuitively get the advantages of this work. In addition, the content of Section 2.1 introducing Neural Architecture Search seems to be not very relevant to this paper. Furthermore, Section 3.3.2 does not explain how to determine the parameter α in Equation 6, which makes one wonder how to choose between value-grained and field-grained.\\n\\n\\n'},\n",
       " 'review_526': {'summary': 'The authors propose a novel feature selection algorithm, aiming to detect interactions between features at instance-level, contrary to the usual feature selection algorithms that selects the same features for every sample. Initially, the authors propose a highly memory-demanding approach, requiring an $m \\\\times m$ matrix, being m the number of different values the features can take. Later, a less memory-demanding approach is presented, using matrix decomposition. The experimental results are slightly better to the state-of-the-art.',\n",
       "  'strengths': '- **Quality:** Several DSN methods were included in the state-of-the-art section. The proposed algorithm is able to obtain very similar results.\\n- **Clarity:** The paper is easy to follow and to understand. The decisions made are clearly motivated.\\n- **Significance:** The idea of selecting, per each sample, the most important interactions between features is very interesting and it can provide a good explanation about the decision making.',\n",
       "  'weaknesses': \"- **Originality:** The algorithm is a combination of well-known techniques. The innovative part is focused on how to merge all of them.\\n- **Quality:** There exists other field of methods that also address feature interaction: the so-called *dynamic feature selection'. Techniques like L2X [1] are focused on the same goal, without the need of using DSNs, which highly reduces the memory consumption. Some information regarding these techniques should be included in the paper.\\n- **Clarity:** Fig. 3 is clearly misleading. Although it constantly suggest the proposed method outperforms the state-of-the-art, the granularity of the y-axis is almost non-existent. There are very little differences amongst all algorithms.\\n- **Significance:** I have concerns regarding two critical aspects of the experimental results:\\n    1. The experimental results show very little improvements against the baseline methods. An statistical analysis is mandatory, in order to establish whether the obtained results provide a real improvement over the state-of-the-art or not.\\n    2. Although I agree with the authors that feature interaction selection can provide insightful information regarding the decisions provided by the network, the authors do not mention anything related to this in the experimental section.\\n\\n[1] Chen, J., Song, L., Wainwright, M., & Jordan, M. (2018, July). Learning to explain: An information-theoretic perspective on model interpretation. In International Conference on Machine Learning (pp. 883-892). PMLR.\"},\n",
       " 'review_527': {'summary': 'The authors of the paper propose a time series forecasting architecture with a self-supervised method for basis learning, called BasisFormer. Their assumption is that the selection of basis for a time series is consistent across both historical and future sections of the time series. They introduce a Coef module that measures the similarity between the time series and the basis in the historical view via bidirectional cross-attention, and a Forecast module that consolidates vectors from the basis in the future view according to the similarity yielded by the Coef module. In their evaluation they demonstrate improvements in forecasting tasks.',\n",
       "  'strengths': '1. The paper is well-written with clear explanations of the proposed architecture.\\n\\n2. The empirical results, including the ones that were presented in the supplementary material, support the original claims across the manuscript.\\n',\n",
       "  'weaknesses': '1. In order to further validate the claims presented in this work, I would expect seeing another comparison to methods involve discretization of time-series, such as [Moskovitch, R. and Shahar, Y., 2015. Classification of multivariate time series via temporal abstraction and time intervals mining. Knowledge and Information Systems].'},\n",
       " 'review_528': {'summary': 'This paper proposed BasisFormer which is an end-to-end time series forecasting model that leverages learnable and interpretable bases. BasisFormer treats the historical and future sections of the time series as two distinct views and using contrastive learning. By making use of Coef module and Forecast module, the BasisFormer outperforms previous state-of-the-art methods for univariate and multivariate forecasting tasks.',\n",
       "  'strengths': '1. Contrastive learning objective is applied for basis learning which guarantees the consistency between the historical and future sections of the time series. And when applying the SSL module to other frameworks, there is a performance improvement of approximately 5%, which suggests the general application of the learnable basis.\\n\\n2. Based on the experiment results on six datasets, the proposed BasisFormer model outperforms previous SOTA methods on univariate and multivariate forecasting tasks.\\n\\n3. The network architecture of BasisFormer is carefully designed and well analyzed through ablation studies and model comparison. The paper is well written and easy to understand.\\n',\n",
       "  'weaknesses': 'In 4.3, the author analyzed the interpretability of the learned bases by visualizing the time series and the corresponding learned basis. An additional visualization of the attention distribution in BCAB module can be helpful for checking different weights assigned to each basis in different attention heads, and thus understanding the network behavior.'},\n",
       " 'review_529': {'summary': 'This paper studies basis learning for time series forecasting for which the past and future basis representations are aligned. Contrastive learning is used to build the time series basis and similarity between the past values and basis is used for time series prediction. The experiments on several time series forecasting datasets show improvement, especially for multivariate forecasting, when the input length (history) is short.\\n',\n",
       "  'strengths': '- The paper is overall well written\\n- The idea of using contrastive learning to learn basis is sound \\n- The proposed approach improves over baselines especially for multivariate case\\n',\n",
       "  'weaknesses': '- There is a strong emphasis on the consistency of the representations for past and future but this is directly experimented/evaluated \\n- Reproducibility is questionable without source code and scripts to run as the approach composed of several components and steps of training \\n- Proposed approach is particularly improves over baselines when the history to predict is shorter, however the motivation/need for a shorter history is not supported \\n'},\n",
       " 'review_530': {'summary': 'This paper addresses the problem of finding effective bases for time series forecasting models. Current methods are limited in their ability to satisfy the requirements of being tailored to specific time series data and exhibiting distinct correlation with each time series. To tackle this challenge, the authors propose BasisFormer, an end-to-end architecture that leverages learnable and interpretable bases. Bases are obtained through adaptive self-supervised learning, where historical and future time series sections are treated as distinct views and contrastive learning is used. The proposed architecture includes a Coef module that calculates similarity coefficients between time series and bases using bidirectional cross attention, and a Forecast module that selects and consolidates bases for accurate future predictions. Extensive experiments on six datasets demonstrate that BasisFormer outperforms previous methods for both univariate and multivariate forecasting tasks, achieving considerable improvements in performance.',\n",
       "  'strengths': 'This paper has studied a time series forecasting problem. The paper is well written. The significance of this work lies in addressing the limitations of existing methods in time series forecasting by proposing BasisFormer, an architecture that leverages learnable and interpretable bases. This approach allows for tailored modeling of specific time series data and distinct correlations with each time series, leading to improved forecasting accuracy.',\n",
       "  'weaknesses': \"However, I still have several concerns towards this paper. First, the illustration and motivation for the basis/bases is not very clear. What are the basis in essence? How can you define basis in time series? Are basis really needed for time series forecasting? What good effects can basis learning bring up? How to verify it? Second, in the main contribution, though the authors combine several techniques together, including self-supervised learning, contrastive learning, cross attention, basis selection. However, I don't find the necessity for each component. Third, the experimental results are less convincing. The proposed method adopts contrastive learning, but it does not compare the performance with other self-supervised learning methods, such as [1] [2]. Other works adopt periodic basis are also not discussed in related work [3].\\n\\n[1] Cost: contrastive learning of disentangled seasonal-trend representations for time series forecasting. ICLR 2022.\\n[2] Time-Series Representation Learning via Temporal and Contextual Contrasting. IJCAI 2021.\\n[3] DEPTS: Deep Expansion Learning for Periodic Time Series Forecasting. ICLR 2022.\"},\n",
       " 'review_531': {'summary': 'To be effective, a basis must be tailored to the specific set of time series data and exhibit distinct correlation with each time series within the set. As far as we know, the state-of-the-art methods are limited in their ability to satisfy both of these requirements simultaneously. To address this issue, the authors propose BasisFormer, an end-to-end time series forecasting architecture that leverages learnable and interpretable bases. Firstly, the authors acquire bases through adaptive self-supervised learning, which treats the historical and future sections of the time series as two distinct views and employs contrastive learning. Secondly, the authors design a Coef module that calculates the similarity coefficients between the time series and bases in the historical view via bidirectional cross-attention. Finally, the authors present a Forecast module that selects and consolidates the bases in the future view based on the similarity coefficients, resulting in accurate future predictions. ',\n",
       "  'strengths': '1. The authors acquire bases through adaptive self-supervised learning, which treats the historical and future sections of the time series as two distinct views and employs contrastive learning. \\n2. The authors design a Coef module that calculates the similarity coefficients between the time series and bases in the historical view via bidirectional cross-attention. \\n3. The authors present a Forecast module that selects and consolidates the bases in the future view based on the similarity coefficients, resulting in accurate future predictions. ',\n",
       "  'weaknesses': '1. The authors claim that this is a self-supervised learning model, and according to the reports of existing studies, the performance should be weaker than that of supervised models. I hope the authors can compare some time series prediction models based on self-supervised learning. Forgive me for being skeptical about the effect at the moment.\\n\\nminor comment:\\n\\n2. I would like the authors to be more clear about Eq. 7, why explainability is related to the smooth term, and to use the common l2-norm.\\n'},\n",
       " 'review_532': {'summary': 'The paper proposes a new implicit neural representation (INR)-based polychromatic x-ray CT reconstruction technique called Polyner. In normal CT reconstruction, the tissues of the body do not vary substantially in their attenuation coefficients, so the overall forward operator can be simply modeled as linear. This changes in the presence of metal implants, because the attenuation of metal implants depends on the energy of the input X-rays, giving a polychromatic attenuation response. Several methods have been proposed for polychromatic CT reconstruction, but these methods often manifest as inpainting methods that suffer from out-of-distribution generalization issues.\\n\\nThe present paper addresses this issue by using a NeRF-like model for estimating the attenuation coefficients in the body. The model is optimized by passing the predicted attenuations through a forward integral model and minimizing the distortion vs. the measurements. The forward model is adapted for metal vs. non-metal regions via mask.\\n\\nResults presented in the paper are promising: the proposed Polyner method is competitive with past methods on in-domain test datasets in terms of PSNR and SSIM metrics on the DeepLesion and XCOM datasets. Competing methods have wide variances in performance among the two datasets, whereas Polyner is more stable. On a new CT dataset consisting of a walnut scan with a metal paperclip, where Polyner further establishes is strong robustness. In ablations, the paper establishes the importance of decisions taken with respect to the forward model and loss functions.',\n",
       "  'strengths': '**Originality**\\n- The paper presents a novel approach for the metal artifact reduction problem. Although implicit neural representations have been used for previous CT reconstruction tasks, the metal artifact reduction problem is substantially different in terms of the physics under consideration and the artifacts that can manifest.\\n\\n**Quality**\\n- The paper includes all the expected experiments, examining multiple simulation datasets as well as new real-world data, providing strong experimental validation of the proposed method.\\n- Comparison methods seem up to date, including methods as recent as 2022.\\n\\n**Clarity**\\n- The paper is clear in its motivations for the metal artifact reduction problem and the justification for the INR approach.\\n\\n**Significance**\\n- Providing a robust reconstruction method for CT with metal artifacts is a long-standing goal of the CT field, and it seems that this paper makes a god contribution towards this goal.',\n",
       "  'weaknesses': '**Originality**\\n- The presence of previous INR-style methods in CT arguably reduces the originality of the current paper, but in my opinion not in a significant manner.'},\n",
       " 'review_533': {'summary': 'The paper with title: Unsupervised Polychromatic Neural Representation for CT Metal Artifact Reduction presents an Implicit neural representation-based method for CT metal artifacts reduction, outperforming existing supervised and unsupervised approaches.\\n',\n",
       "  'strengths': '1. This paper presents a novel INR-based method for CT metal artifacts reduction. \\n2. The authors present a non-linear forward model to model the metal artifacts, and leverages it as signal domain loss function.\\n3. I appreciate the real-scan results which demonstrate the results on prospective corrupted dataset.',\n",
       "  'weaknesses': '1. Regarding the results for the real-data - I noticed that for real-data, the gap or improvements of Polyner is not as significant as the simulated dataset, ACDNet is also doing a decent job, could you elaborate on this?\\n2. Regarding the forward model, from the ablation studies, including the non-linear components contribute to the improved performance, however, the forward model is still not perfect without considering some system attributes. Can you elaborate on this aspect?\\n3. lack of quantitative results on real-data.'},\n",
       " 'review_534': {'summary': 'This paper introduces Polyner, an extension of implicit neural representation to a nonlinear inverse problem with a forward model that simulates the polychromatic nonlinear CT acquisition process. This design allows Polyner to reduce metal artifacts without external training data and exhibits better generalization to out-of-domain (OOD) data. Experimental results showcase improvements of Polyner on OOD datasets and clinical data while being competitive with state-of-the-art supervised methods.',\n",
       "  'strengths': '1. The motivation is technically sound, and the proposed unsupervised method is interesting compared to the previous supervised paradigm. Taking into account the important knowledge of CT is reasonable. \\n\\n2. The performance on OOD dataset and clinical images demonstrates the OOD capacity, though the quantitative evaluation (see weakness) is unfair. The ablation study confirms the effectiveness of the polychromatic CT forward model and the proposed loss function.\\n\\n3. The paper is well-written and easy to follow. Experimental details are provided in supplementary materials with the open-sourced code. ',\n",
       "  'weaknesses': '1. While the author claims that \"Polyner is superior to its supervised counterparts,\" this is not sufficiently supported by the experimental results and may be caused by unfair comparison.  Directly generalizing pre-trained models to a different size (e.g., 256x256) for testing might not yield optimal results due to variations in noise levels and geometry settings.  A fair comparison should re-train or fine-tune these methods to fit the specific geometry settings. \\n\\n2. The suboptimal quantitative and visual results of ACDNet and DICDNet, in contrast to their original papers and CNNMAR, might be due to differences in geometry settings.  It is necessary to clarify whether the supervised models were fine-tuned on the IID setting of the DeepLesion dataset.  If not, please provide fine-tuned results (excluding OOD datasets) to ensure an accurate performance evaluation.\\n\\n3. The color representation of CT images impedes readability.  Presenting grayscale results with an appropriate window to facilitate evaluation is more reasonable.  The goal of MAR is to remove artifacts **and** preserve diagnosis ability. \\n\\n4. Please compare the proposed method with the state-of-the-art dual-domain methods published in 2022 or 2023.  Additionally, discuss the potential of the proposed method in enhancing traditional dual-domain methods.\\n\\n5.  Since the proposed method is case-specific and requires optimization for each slice, it is essential to compare iterative reconstruction methods optimized in a similar manner. Moreover, reporting the computational time for a single scan will provide meaningful comparisons.'},\n",
       " 'review_535': {'summary': 'The authors tackle a very relevant problem in computed tomography: metal artifact reduction. They recognize some severe gaps in conventional methods (both model-based and deep-learning based) and propose a theoretically sound approach to solve these gaps using implicit neural representations in a somewhat similar fashion as, for example, NeRP. However, to solve the problem at hand, the first derive a polychromatic (as opposed to standard monochromatic) forward model to model the nonlinear CT acquisition process. In combination with a newly developed loss function, they use this model to apply some constraints to the physical properties of polychromatic CT and incorporate the implicit neural representation reconstruction approach. The method is not pre-trained and optimized per scan. They perform better than model-based and supervised deep learning methods on three datasets.',\n",
       "  'strengths': 'I must say that reading this paper was a pleasure. Overall, the manuscript is written very clearly and easy to follow. The ideas are original, and motivated well, and the results are discussed and explained appropriately.\\nI think the idea builds nicely upon previous work, aims to tackle a very relevant problem in medical imaging, and applies to a wide range of medical imaging settings. Therefore, the clinical relevance of the work is significant. \\nSection 2.1 provides a clear and sound theoretical foundation to understand their approach.\\nAll ablation studies are supported by figures that show the importance of the components of the proposed architecture, and the other experiments are done on three different data sets.\\nIt is a great strength that the method outperforms or performs equally compared to supervised models without using any training data.\\n',\n",
       "  'weaknesses': 'I am quite familiar with INRs and methods such as NeRP, etc. I feel that the manuscript is complete and does not have severe weaknesses. There are, however, three things that I consider minor weaknesses. Firstly, the paper lacks an evaluation of a real-world patient data set. There are experiments on synthetically induced metal artifacts and the walnut scan. Still, in the end, the method should work on real patient data, and it would be better if the method were evaluated in that setting or if the authors would motivate why this was not done. Secondly, I think 2D fan beam CT is a bit old-fashioned. It would contribute to the strength of the paper – and its applicability in the real world – if the method would also work on cone-beam CT. Lastly, the speed of the approach limits the method significantly. 2 minutes for a 256x256 slice means about 4 minutes for a 512x512 slice. For brain CT, this would take 400 minutes, which is not clinically feasible. I suggest discussing potential methods to optimize the optimization process to make it more relevant for clinical application. '},\n",
       " 'review_536': {'summary': 'This paper proposed a challenging problem named Personalized Dictionary Learning (PerDL), which learned a shared global dictionary and individual local dictionary for heterogeneous datasets. \\n\\nIn order to investigate the feasibility of the problem, several definitions and assumptions are provided to make the theoretical guarantee. Under these conditions, a meta-algorithm called Personalized Matchina and Averaging (PerMA) is proposed to solve the problem. The convergence of PerMA is theoretically guaranteed. \\n\\nExperiments are conducted on synthetic, imbalanced digits reconstruction and video surveillance datasets, which show the effectiveness of PerMA. ',\n",
       "  'strengths': '(1). The problem is well-defined to ensure identifiability, feasibility, and convergence with the help of certain mild assumptions and definitions. This involves Assumptions 1 and 2, Definitions 1 and 2. This way, it is natural to investigate and derive a solution under the federated learning context.   \\n\\n(2). A federated meta-algorithm (PerMA) is proposed to solve the PerDL problem. In particular, Global Matching and Local Updates steps are designed in the federated setting. Global matching utilized a shortest path algorithm to tackle the non-convex and different initialization problems. Local updates employed a linearly-convergent algorithm. \\n\\n(3). With proper assumption and mild conditions, the convergence of PerMA is proved, being a theoretical contribution to ensure the feasibility of the PerDL problem. \\n\\n(4). Experiments on three settings verify the rationale of PerDL and the effectiveness of PerMA. ',\n",
       "  'weaknesses': 'Overall, the theory and method is good.   \\nThe experiment is a bit weak, considering only an independent strategy is adopted as the baseline.   \\nCan it be compared with other methods, such as personalized PCA? \\n'},\n",
       " 'review_537': {'summary': 'This paper studies the problem of personalized federated learning with each client conducting dictionary learning on heterogeneous tasks. This paper splits the learned dictionary into a global dictionary and local dictionaries. It provides the conditions that two types of dictionaries can be provably identified. It designs a federated meta-algorithm where clients only pass estimated global dictionaries to the center. It also provides the linear convergence for the federated learning procedure under some assumptions.',\n",
       "  'strengths': '1. The objective function is concise for the described personalized dictionary learning problem.\\n2. It gives conditions when global dictionaries and local dictionaries can be identified. The two conditions satisfy the intuition.\\n3. The algorithm finds the global dictionaries given initial client dictionaries by finding the shortest path based on DAG, which is an interesting solution.\\n4. The overall algorithm is theoretically guaranteed.\\n5. The writing of the paper is good. The description of the algorithm is clear.',\n",
       "  'weaknesses': 'The experiments are somewhat weak. Using each frame as a client is also strange in the third experiment.'},\n",
       " 'review_538': {'summary': 'This work tackles the problem of heterogeneity in federated learning through dictionary learning. The authors name this problem _Personalized Dictionary Learning_ (PerDL), which seeks to learn (linear) representations for the heterogeneous datasets from clients, which are supposed to share common characteristics. The insight of their approach is that PerDL will disentangle global/general and local/unique features from clients via DL. The authors provide a thorough analysis of convergence of their method, as well as a federated strategy for learning the dictionaries (PerMA).\\n\\n__Post-Rebuttal Acknowledgment__\\n\\nI have read the authors rebuttal, and other reviewers comments. In their rebuttal, the authors fully addressed my concerns, and provided important results and discussion, including further discussion on the ethical impacts of their work. Overall, I think the authors rebuttal greatly improves the quality of their submission. As a result, I increased my score to 6. Weak Accept.',\n",
       "  'strengths': '__Originality.__ The authors present an original and theoretically grounded work for dictionary learning in a federated setting.\\n\\n__Quality and Clarity.__ The paper is well written and clear. Assumptions are clearly stated and the concepts behind theorems are clearly defined. Analyzing the abstract alone, the federated aspect of this work is not clear (see W1 and S4 below).\\n\\n__Significance.__ While I consider the authors contribution novel, the fact that in the paper only qualitative results are shown, and that the authors do not draw comparisons with other SOTA methods hinders the significance of this work.',\n",
       "  'weaknesses': 'Below I list a series of weaknesses of the current paper. Please see my suggestions in the next section on how to improve these points.\\n\\n__Concerning Clarity__\\n\\n__W1.__ Even though it is clear from the introduction, the abstract does not mention federated learning at all.\\n\\n__Concerning the authors experiments__\\n\\n__W2.__ Sections 5.2 only contain qualitative results (i.e., Figures 3 and 4). This hinders the assessment of their method, especially in comparison to other strategies.\\n\\n__W3.__ The authors only provide comparisons with non-collaborative/non-federated approaches. A comparison with the methods of [Gkillas et al., 2022] and/or [Huang et al., 2022] would improve the impact of the authors results.\\n\\n__Concerning Ethical Considerations__\\n\\n__W4.__ Even though the authors method is not especifically tailored for video surveillance, I think that authors should provide a broader discussion on the ethical impacts of their experiment.\\n\\n__Post Rebuttal__\\n\\nIn their rebuttal, the authors correctly addressed all of the above weaknesses. As a result I raised my score from 3. Reject towards 6. Weak Accept.'},\n",
       " 'review_539': {'summary': 'This paper tackles the problem of personalized dictionary learning (PerDL) for heterogeneous datasets that share some commonality. The authors propose a federated meta-algorithm called PerMA that can provably recover both global and local dictionaries from heterogeneous datasets. They show the applications of PerDL in different learning tasks, such as training with imbalanced datasets and video surveillance.\\n\\n--post rebuttal\\nAfter reading the rebuttal, I would like to keep my score. \\n',\n",
       "  'strengths': '•\\tThe paper proposes a federated meta-algorithm called PerMA that can provably recover both global and local dictionaries from heterogeneous datasets.\\n•\\tThe paper provides theoretical guarantees on the identifiability, convergence, and robustness of PerMA, and demonstrates its applications in different learning tasks. The result on the Surveillance Video Dataset looks interesting.\\n',\n",
       "  'weaknesses': '•\\tThe paper does not compare PerMA with other existing methods for dictionary learning or federated learning, such as personalized PCA (PerPCA), which would be helpful to evaluate its performance and advantages.\\n•\\tIn Surveillance Video experiments, why there is only one original image and one local atom? The author is encouraged to give some explanation. Moreover, only one case study seems insufficient.\\n•\\tFederated Learning is a long studying problem so far, the author is needed to further highlight the difference between their proposed ``global matching and local update” with existing methods.\\n'},\n",
       " 'review_540': {'summary': 'This paper proposes to resolve the interference of model merging, a solution to combine multiple task-specific models into a single multitask model. It demonstrates two major sources of interference, including redundant parameter values and sign conflict and proposes solutions to resolve the interference. ',\n",
       "  'strengths': 'The paper demonstrates some interesting research insights and the solutions are simple and clear.',\n",
       "  'weaknesses': '1: I question the necessity of Section 7.3.  According to the network pruning literature, a high magnitude is always an implication of importance/sensitivity, and a widely used pruning metric. Flipping the sign of or pruning away the Top-k% parameters can cause significant performance drop is well-known to the literature. It seems to have weak connection with this paper’s main argument. \\n\\n2: I did not find the discussions regarding limitations and future work.\\n\\n3: More analysis on the experimental results are required. For example, what are the effects of the proposed on each task respectively? Why do some tasks perform better than others?  \\n'},\n",
       " 'review_541': {'summary': 'Merge mutiple **fine-tuned** neural networks, each from an unique task (dataset), into one neural network by weight averaging. Denate the weights of pretrained network as $\\\\theta_0$, fine-tuned network as $\\\\theta_{\\\\tau}$, the weight updating direction $\\\\tau = \\\\theta_{\\\\tau} - \\\\theta_0$ \\n\\nThe paper introduces two tricks 1) for each $\\\\tau$ only keep the top $k$% elements in $\\\\tau$ according to their magnitude. (keep the others as zero), 2) during the weight averaging, only retain the dominate direction (+1 or -1) for each elements. \\n\\nThe experiments shows the improvements of the proposed Ties-Merging method over other weight averaging methods, such as naive weight averaging, task arithmetic, and regmean. But Ties-Merging is still significantly lagging behind MultiTask training.\\n\\n',\n",
       "  'strengths': '- The writing is clear and easy to read. \\n- The introduced two tricks are resonable and easy to understand. \\n- Comparing with naive weight averaging, task arithmetic, Fisher averaging, and regmean, the proposed ties-merging performs very well. \\n\\n',\n",
       "  'weaknesses': '- Even though the proposed Weight Averaging method out-perform other weight averaging methods, it still legs behind MultiTask training. \\nFurthermore, considering both the training cost and inference time, it is hard to see the benefit of the proposed method over mutitask training. As to other baseline methods, such as naive weight averaging, Fisher averaging and regmean, they are designed to solve IID (one fine-tuning task instead of mutiple different tasks) not OOD. These two facts reduce the strongness of the experiments.  (But it is fine. Because the two introduced tricks are good enough). \\n\\n\\n\\n\\n\\n\\n'},\n",
       " 'review_542': {'summary': \"This paper delves into the challenge of integrating multiple task-specific fine-tuned models into a singular, multitask model, without necessitating additional training. The authors identified that current methodologies overlook the interference that occurs between parameters of different models. This interference can be attributed to two primary sources: redundant parameter values and conflicts in the sign of a given parameter's values across various models. To counteract these issues, the authors introduced a novel method, TIES, which incorporates three key steps: (1) resetting parameters that underwent minimal changes during fine-tuning, (2) resolving conflicts in sign, and (3) merging only those parameters that align with the final agreed-upon sign. The proposed method demonstrated SOTA performance across different settings. \",\n",
       "  'strengths': \"- The paper provides a comprehensive analysis of the sources of interference in existing model merging methods, specifically pinpointing redundancies in model parameters and disagreements between parameter signs. This thorough examination underpins the motivation for the proposed method. \\n- The proposed method demonstrates robust performance across a wide array of conditions, including various modalities, domains, task quantities, model sizes, architectures, and fine-tuning settings. This versatility underscores the method's adaptability and broad potential for application\\n- The informative and insightful Section 7, which delves into the significance of different components, particularly the estimation of correct signs during the merge process, serves as a valuable resource.\",\n",
       "  'weaknesses': '- The proposed method is quite heuristic and it would make the paper stronger if the authors can provide more theoretical analysis of the proposed method. \\n-  The author did not mention the limitations of their method and potential future work. The authors could further discuss them, which will provide a more balanced view of the method and give readers an idea of the potential directions for future research.\\n- The paper could be improved by discussing more real-world applications of the studied problem, integrating multiple task-specific fine-tuned models into a singular, multitask model, without necessitating additional training. Why is this problem important? This would help to demonstrate the practical value of the method and its potential impact in real-world scenarios.\\n-  It would be beneficial to include a sensitivity analysis of the hyperparameters used in the method. Although the authors provided a generic recipe of TIES with fixed hyperparameters, it would be good to see how sensitive the method is to different hyperparameters.\\n'},\n",
       " 'review_543': {'summary': 'The paper presents a novel method, TIES-MERGING, to merge models in the weight space for multitask learning. It observes an interference problem when linearly interpolating weights, and proposes a simple yet effective two-step solution: parameter trimming for small changes during fine-tuning and sign conflict resolution. The experiments in multitask shows that TIES improves performances, making it a notable (experimental) contribution to the literature of model merging.',\n",
       "  'strengths': '* The paper\\'s main strengths lie in its simplicity, as highlighted by its clear description and illustration.\\n* The paper successfully builds upon the \"task arithmetic\" task vector approach to report a new interference phenomenon, and then enhances performance with simple yet important modifications. Model merging is an important topic in multitask, and this paper fills a crucial gap in the current literature.\\n* The experimental framework is robust, with a focus on significant large-scale tasks across CV and NLP domains using recent architectures and fair benchmarks.',\n",
       "  'weaknesses': 'Despite its strengths, some areas require attention.\\n* The contributions, though valuable, are incremental, and the observed gains in multitask learning are consistent but arguably marginal, and the trimming/sign play only a marginal role in this gain.\\n* The experiments focus solely on models trained on different tasks. Yet, weight averaging is also useful to merge models trained on a single target task; on this model soups setup, I speculate that sign interference is less an issue, and that TIES would actually be detrimental as it would increase variance, thus limiting the benefits from combining multiple models, in particular under distribution shifts. As a minimum fix, the title should reflect this specificity, as the current one does not adequately reflect this scope limitation. A (naive) suggestion could be \"Resolving Multitask Interference When Merging Models\".\\n* Even whithin the multitask challenge, the experiments do not cover two important scenarios. First, multitask as better pretraining before fine-tuning on a target task (as in \"Fusing finetuned models for better pretraining\"). Second, multitask in the sequential patching scenario (as in \"Patching open-vocabulary models by interpolating weight\").\\n* Lack of analysis and clarity of the interpolating coefficient, for TIES and for the baselines. Specifically, without validation samples, could you clarify which values $\\\\lambda$ is used: it seems that it\\'s $\\\\lambda=1/|num tasks|$ for weight averaging, $\\\\lambda=0.4$ for task arithmetic (could you please point where you found this value), but $\\\\lambda=1$ for TIES. Therefore, is the difference between task arithmetic/weight averaging in Table 1 simply due to the use of different $\\\\lambda$? Thus (as further suggested from Table 3), scaling is an important factor, these different values of $\\\\lambda$ hidden the true impact of your core contributions.\\n* Similarly, the ablation study in Table 3 could be made clearer. It is not clear whether the ablations are done one at a time or sequentially all together. If the latter is true, then why do we recover 65.5 on T5-base (when all 4 components are removed), while weight averaging performs 65.9? Moreover, what does it mean to remove \"elect\" while keeping \"disjoint mean\"? what does it mean to remove \"scaling\" (is it $\\\\lambda=1/|num tasks|$ or something different)?'},\n",
       " 'review_544': {'summary': 'This paper identified two sources of performance degradation when merging fine-tuning models, (i) redundant parameter (ii) sing conflict and proposed TIES-MERGING to improve them.\\n',\n",
       "  'strengths': '1. The motivation to merge fine-gunning and performance is compelling.\\n2. Experiments were conducted with both NLP and vision, and the proposed method improved accuracy with both.\\n3. The proposed method is simple and computationally inexpensive, making it easy to reproduce.\\n',\n",
       "  'weaknesses': '1. There is no theoretical support for the proposed method.\\n2. In particular, the effect of sign conflict on performance is nontrivial and requires theoretical support.'},\n",
       " 'review_545': {'summary': 'The paper discusses the growing interest in accelerating optimization algorithms using machine-learned predictions. It highlights the work of Sakaue and Oki, who introduced a general framework for employing predictions to warm-start the L-convex function minimization method, demonstrating its effectiveness for various discrete optimization problems. Building on this, the paper presents a new framework that leverages predictions to accelerate M-convex function minimization with improved time complexity bounds, thereby extending the applicability of predictive techniques to a wider range of discrete optimization algorithms.',\n",
       "  'strengths': 'This paper is well-written, presenting intuitive results. It exhibits technical solidity, providing clear explanations of how the proposed algorithm enhances the existing worst-case time complexity.',\n",
       "  'weaknesses': '1. The main theoretical results appear to be straightforward. The computational time complexity relies on the distance between the initialization and the optimal solution, assuming a good initialization is provided. However, one limitation of this paper is the absence of an analysis regarding the methodology for obtaining such a good initialization.\\n2. The difficulty in deriving the corresponding theoretical results is not well elucidated in the paper. For instance, proving Theorem 3.1 hinges on Proposition 2.2, which is simply a direct application from existing works [44]. It would be more beneficial if the paper provided a clearer explanation of the technical challenges involved in obtaining the theoretical results.\\n3. This paper lacks numerical justifications for the proposed theoretical time complexity bound. \\n'},\n",
       " 'review_546': {'summary': 'This paper studies some classes of $M$-convex minimization problems, to which the recent framework of \"warm-starts with predictions\" is applied. The paper provides provable time complexity bounds on the standard greedy algorithm for $M$-convex minimization where the bounds are dependent on the $\\\\ell_1$-distance between the optimal solution and the predicted initial solution. The theoretical performance guarantees are promising and improve upon the existing methods that are not using predictions. At the same time, however, one would argue that the technical contributions of this paper are limited in that the results rely on and are deduced by applications of the existing results in the literature. Furthermore, one would be interested to see the numerical impact of the framework on more concrete problem settings, e.g., portfolio management and resource allocation, which were not tested in this paper.',\n",
       "  'strengths': '* The time complexity bounds provided in this paper are the first results that analyze the performance of the framework of warm-starts with predictions applied to $M$-convex function minimization.\\n\\n* The time complexity bounds improve upon the existing bounds for some classes of $M$-convex minimization problems when we may obtain an accurate prediction where the accuracy is measured by the $\\\\ell_1$-distance to the (unique) optimal solution.',\n",
       "  'weaknesses': '* \\u200bThe technical contributions of this paper are limited. The greedy algorithm and main results of this paper are built upon and follow from [(Shioura (2022), Corollary 4.2)](https://pubsonline.informs.org/doi/abs/10.1287/moor.2021.1180) which gives an upper bound on the number of required iterations for the greedy algorithm in terms of the proximity term. The rest of the results are basically about bounding $T_{\\\\text{init}}$, the time required to convert a prediction to a feasible solution, and $T_{\\\\text{loc}}$, the time bound for computing a locally steepest direction. Even these results follow from standard techniques in the literature.\\n\\n* This paper lacks computational demonstration. $M$-convex minimization has applications in resource allocation, equilibrium analysis, and portfolio management, but none of these problems were tested. In particular, one would be interested in how well the framework of this paper performs for the operations management models studied in [(Chen and Li, (2021))](https://pubsonline.informs.org/doi/abs/10.1287/opre.2020.2070). Furthermore, the numerical results reported in Section 6 do not consider the methods against which the theoretical complexity bounds are compared.'},\n",
       " 'review_547': {'summary': 'Extending the warm-starting techniques in L-convex function minimization by Sakaue and Oki (2022), the authors study the problem of acclerating M-convex function minimization with predictions. The idea is to start from a (possibly infeasible) predicted solution, project the rounded solution to the feasible region and then apply the standard M-convex function minimization greedy algorithm. In particular, the authors show that when applied to Laminar convex minimization, a special case of M-convex function minimization, their framework can achieve better time complexity than current worst-case time complexity provided that the prediction is accurate enough. Experiments on the staff-assignment problem confirm that the proposed framework can help reduce the number of iterations of the greedy algorithm.',\n",
       "  'strengths': 'The paper studies an interesting problem, and is written well in terms of structure, clarity in explanation and technical presentation. Theoretical results are justified by empirical experiments.',\n",
       "  'weaknesses': '1. The framework proposed in this paper for M-convex optimization is somewhat similar to the one in Sakaue and Oki (2022) for L-convex optimization. So novelty in the general framework is limited.\\n2. The authors provide comparision between their results and worst-case time complexity for laminar convex minimization. However, it seems like their complexity outperforms the worst-case only under the assumption of highly accurate predictions (small enough $\\\\ell_1$ norm prediction error), which does not necessarily hold in practice.'},\n",
       " 'review_548': {'summary': 'The goal of the work is to minimize M-convex functions with prediction. The work mainly focuses on a subclass of M-convex functions that use Laminar, Nested or Box constraints.',\n",
       "  'strengths': 'Minimizing M-convex functions is an important class of discrete optimization problems that has wide variety of applications. Using algorithms with prediction is an important area of research that can typically solve many problems in discrete convex analysis. Especially due to wide variety of application.\\n\\nSoundness. The work is technically sound that uses relevant algorithms produced in literature to solve a very important problem.\\n\\nPresentation. The paper is very well written that flows flawlessly with very minor concerns.\\n\\nContribution. The contribution is first of its kind to the class of problems that it is applied it. However, it must be noted that most of the major algorithms used in the paper are proposed in literature. The main contribution is modification of these classical algorithms to solve the bigger problem of minimizing M-convex functions with predictions.',\n",
       "  'weaknesses': 'I dont find many weaknesses in this work.'},\n",
       " 'review_549': {'summary': 'This paper applies the learning-augmented algorithms framework to a class of discrete optimization problems called M-convex. A function defined on an integer grid is M-convex if for every x, y it holds that f(x)+f(y) >= f(x-ei+ej)+f(y+ei-ej) for some base vectors ei, ej. The paper complements the line of research on improving running time of static algorithms using predictions, started by Dinitz et al. (NeurIPS’21), and is a natural followup to the Sakaue&Oki’s paper (NeurIPS’22) on another class, called L-convex.\\n\\nThe authors propose a general framework for solving M-convex optimization problems given a predicted optimal solution that is supposed to be close to the true one. Then, they give algorithms for specific subclasses of these problems, called Laminar, Nested, and Box (after the form of constraints allowed in each class). The running times they obtain are O(n*eta) for Laminar and Nested and O(n+log(n)*eta) for Box, where eta = ||x_opt - x_pred||_1 is the L1-error of the prediction.',\n",
       "  'strengths': 'There are nice algorithms in Sections 4.1 and 4.2 (for rounding to the nearest feasible solution and for finding the steepest descent in the laminar case).\\n\\nWith (very) accurate predictions, the algorithm for the special case of box constraints can go (a tiny bit) below a known lower bound for classic (prediction-less) algorithms, and it seems to be the first such example in the literature about learning-augmented static algorithms.\\n\\nThe paper is written with care and not hard to follow.',\n",
       "  'weaknesses': 'The algorithm/framework for general M-convex optimization is technically trivial. The algorithms for the laminar subclass are much more interesting, but I’m not convinced that this subclass is interesting enough on its own for the results to have substantial implications.\\n\\nInteresting technical ideas seem very much tailored to the specific setup, so it might be difficult for this paper to have a larger impact or inspire further research.\\n\\nThe experiments are very simplistic – on a toy problem with synthetic data and predictions. (Still it was somewhat surprising to learn that, for a concentrated enough distribution of instances, an integral solution learned from previous instances can be a better initialization than an optimal solution to the fractional relaxation.) If I consider this paper to be a pure theory paper (which for now I do), then such experiments are not an issue, but in that case the theoretical contributions of the paper might not be strong enough to pass the ICML bar.'},\n",
       " 'review_550': {'summary': 'In the vein of the seminal work by Sakaue and Oki for L-convex functions, this paper proposes a new method to accelerate M-convex function minimization using past predictions, a technique known as warm-start. \\n\\nThe contributions are as follows:\\n1) Present a framework to accelerate M-convex function minimization with past predictions\\n2) Applying this framework to the Laminar, Box and Nested classes of problems and improving time bounds using warm start for each of these problems',\n",
       "  'strengths': \"The results in the experiments section seems promising. Although I'm not an expert in discrete optimization, the problems tackled seemed of great importance.\",\n",
       "  'weaknesses': \"1) This paper is very theoretically dense and tries to tackle a lot of problems at once, the contributions are not clear. I think this paper would gain at focusing solely on the Laminar problem and possibly present the extension of your work in appendix. The demonstration would be clearer, and your paper more straight to the point.\\n\\n2) Although rigorously written, it feels like this paper is a re-adaptation of the work from Sakaue and Oki to the class of M-convex functions and is thus not particularly original. \\n\\n3) The results section is rather light compared to the extent of the theoretical claims on the Laminar, Box and Nested subproblems. I'd have preferred for each of the 3 classes of problems you mention, a first experiment on synthetic data with comparison between warm start and no warm-start. Then, a second experiment on real-world data to prove the superiority of your method. \"},\n",
       " 'review_551': {'summary': 'Since neural ordinary differential equation networks can show inherent robustness, in this work the authors try to perform an extensive study on different graph neural flows along with their stability on different stability notions like BIBO stability, Lyapunov stability, Structural stability and Conservative stability. The authors find that the graph neural flows using hamiltonian energy functions can achieve improved empirical adversarial robustness on using black box attacks like PGD and TDGIA. The authors show that designing graph neural flows which can ensure conservation stability along with Lyapunov stability can help in achieving improved adversarial robustness. As common in literature the authors generate a white box attack from a surrogate model and then transfer it to the black box model to testify the robustness of the black box model. Evaluation is done on node injection attacks as well as graph manipulation attacks, and significantly improved robustness is seen in both cases.',\n",
       "  'strengths': '* I think using graph neural flows to understand if we can achieve inherent robustness without the need for adversarial training is interesting.\\n* The way the authors have related different stability criteria with robustness is quite interesting.\\n* The results show significant improvements.\\n',\n",
       "  'weaknesses': '* There have been many instances where defences claiming to be robust have been later evaded using adaptive attacks [1]. Adversarial training has been the most successful defence strategy and the current successful defences use adversarial training to achieve robustness. Therefore, it is necessary that the robustness of the proposed method is evaluated properly. I think that the surrogate model-based black box attacks are not strong enough to get the worst-case robustness. Therefore, it is important that the evaluation on strong white-box attacks like PGD, PGD with max-margin loss / Carlini and Wagner attack [2] is used to testify robustness, and this evaluation should be carried out in a white-box setting. Further, it is important that the authors share a robust accuracy (both white box and black box) vs constraint threat model plot for the proposed approach, GAT and GAT trained using PGD-AT [3]. \\n\\n* Comparison is done only with models trained using standard training. It is important to include adversarially trained models as baselines. For instance, the authors should include a PGD-AT trained model as a baseline in all the tables.\\n\\n* In the case of GNNs it is important to ensure that the attack graph remains imperceptible and the attacked nodes in the case of node injection attacks cannot be pruned off. Therefore other than robust accuracy imperceptibility of the graph for a given threat model is also a very important metric to be considered. Similar to [], I request the authors to also include a comparison on the imperceptibility of the attack on the proposed Graph neural flow network and the baselines like GAT. It is important to ensure that the imperceptiblity of the proposed defence is either lower or equal to the baselines against the PGD and TDGIA attacks.\\n\\n* The authors should also look at these works [4,5] and try to compare their methods with them .\\n\\n[1] Athalye, Anish et al. “Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples.” International Conference on Machine Learning (2018).\\n[2] Carlini, Nicholas, and David Wagner. \"Towards evaluating the robustness of neural networks.\"\\n[3] Madry, Aleksander et al. “Towards Deep Learning Models Resistant to Adversarial Attacks.” \\n[4] Li, Jintang et al. “Spectral Adversarial Training for Robust Graph Neural Network.”\\n[5] Li, Jintang et al. “Spectral Adversarial Training for Robust Graph Neural Network.”\\n'},\n",
       " 'review_552': {'summary': 'This paper explores the robustness of Graph Neural Networks (GNNs) against adversarial attacks. Drawing inspiration from principles in physics, the authors propose a novel model called Hamiltonian Neural Flows for constructing GNN models. The effectiveness of the proposed method is evaluated on various benchmark datasets.\\n\\n',\n",
       "  'strengths': 'The problem addressed in this paper is both significant and intriguing, and the proposed method is well-supported by principles from physics.',\n",
       "  'weaknesses': 'I am a non-expert in physics-based methods, my evaluation is based on my understanding of GNN methods and educated guesses. I suggest AC to ignore my evaluation if there are expert reviewers in the field.\\n\\nHere are a couple of suggestions to improve the paper:\\n\\nIn my opinion, the comparison with existing baselines seems inadequate. The TDGIA paper was published in 2021, while MetaGIA was published in early 2022 or late 2021. It would be beneficial if the authors could include more recent graph attack papers and compare their proposed method against them.\\n\\nAdditionally, it would be interesting to see a comparison between the proposed method and the Graph Isomorphism Network (GIN).'},\n",
       " 'review_553': {'summary': 'This paper proposes a robust GNN model by leveraging the notion of Hamiltonian Energy Conservation. Specifically, authors first analyze the stabilities and limitations of several neural ODE-based GNNs, which motivate the proposed model HANG that is inspired by Hamiltonian classical mechanics. Experimental results indicate that HANG outperforms prior ODE-based GNNs against various adversarial attacks on several realistic graph datasets.',\n",
       "  'strengths': '- The paper is well written. All technical steps are easy to follow.\\n- Authors propose a novel approach to improve GNN robustness.\\n- Authors clearly motivate the proposed approach by analyzing the stability limitations of prior ODE-based GNNs.\\n- The proposed model has been evaluated against various adversarial attacks.',\n",
       "  'weaknesses': \"- The major issue of this work is that it only compares with a limited number of (and relatively weak) defense baselines. There are some recent methods such as [1, 2] showing better results than the baselines chosen in this paper. It would further improve the paper if authors could compare HANG with those methods.\\n- Figure 1 only shows the norm of node features become closer as time goes, which does not support authors' claim that node features gradually become similar (lines 182-183). Authors may want to show the norm of relative difference of node features is approaching to zero instead.\\n  \\n[1]: Geisler et al., “Robustness of Graph Neural Networks at Scale”, NeurIPS'21. \\\\\\n[2]: Deng et al., “GARNET: Reduced-Rank Topology Learning for Robust and Scalable Graph Neural Networks”, LoG'22.\\n\\nI'm willing to raise the score if my major concerns are addressed.\"},\n",
       " 'review_554': {'summary': 'Drawing inspiration from physics principles, the paper proposes the use of conservative Hamiltonian neural flows to construct GNNs that are robust against adversarial attacks. The adversarial robustness of different neural flow GNNs is empirically evaluated on several benchmark datasets, considering a variety of adversarial attacks.',\n",
       "  'strengths': 'This paper investigates the vulnerability of graph neural networks (GNNs) to adversarial perturbations that affect both node features and graph topology. The study focuses on GNNs derived from various neural flows and explores their connection to different stability notions.',\n",
       "  'weaknesses': 'The followings are four weaknesses.\\n\\n1. Paper\\'s writing quality is poor due to excessive amount of equations, formulas, and its explanation in a view of physics. The authors should use the adversarial research language to bring out the main insight for why this work is important for adversarial research.\\n\\n2. In addition, numerous words need to penetrate the core idea of equations rather than to revolve around technical terms.\\n\\n3. The reviewer did not see the connection bridging the gap between Hamiltonian mechanics and energy conservation.\\n\\n4. Is there any other simpler option that possess the notion of conservation other than Hamiltonian mechanics at all?  In addition, why is it important to conserve energy in a view of topological structure?\\n\\nOverall, the reviewer recommends the authors to answer these questions using insightful language at least to the reviewer, not using mathematical or physical language. The reviewer does not want a theoretical proof, only want really contributional insight; Why is it important to consider energy or conservation and why are \"energy and topology\" bridged? Why is the hamiltonian important? Please answer using adversarial language\\n\\n---\\n\\nThe authors\\' rebuttal has fully explained the connection between the energy conservation in the realm of the Hamiltonian and the adversarial robustness of GNNs using the adversarial research language. Thank the authors for their thorough commentary on the reviewer\\'s point.'},\n",
       " 'review_555': {'summary': 'This paper introduces QuIP, an algorithm for weight quantization in large language models, with theoretical guarantees. The experimental results demonstrate that QuIP achieves nearly lossless performance when using 3-bit quantization for models larger than 3B, and it shows good performance with 2-bit quantization for models larger than 7B.',\n",
       "  'strengths': 'First of all, QuIP is the first post-training quantization algorithm that compresses weights to 2 bits with reasonable loss of performance, significantly pushing the boundary of LLM on-device deployment and making larger LLMs available to ordinary users.\\n\\nSecond, the paper proposes LDLQ rounding method, which is both worst-case and average-case optimal in a family of adaptive rounding methods, i.e. iterative quantization through each column of weights. The family is carefully selected so that OPTQ (previously known as GPTQ) falls within this family.\\n\\nThird, solid proof is shown that LDLQ is optimal in its family assuming rounding to integers, while a rigid study, with counterexamples and more careful analysis is conducted in more realistic cases in Section 5.2.',\n",
       "  'weaknesses': 'The experiments are mostly conducted on OPT, which might not be the most standard model at the time of reviewing. Models like Llama, Falcon and MPT might be more popular LLMs. However, the reviewer understand the paper was submitted months ago and there might be limited time to conduct all the experiments. Also, the main experiments are conducted on decoder-only auto-regressive language models, while there are other models/domains of interest, for example, FastChat-T5 which is encoder-decoder architecture, Vision transformers, etc.'},\n",
       " 'review_556': {'summary': '- The authors coin a family of adaptive rounding methods for layer-wise quantization, establish that the state-of-the-art method GPTQ is optimal within this family, and prove quality guarantees.\\n- The paper further introduces incoherence preprocessing, together with a Kronecker-factor based inference scheme, which leads to significant accuracy improvements for very low bitwidth compression.',\n",
       "  'strengths': '- The paper introduces a non-obvious and useful optimization to GPTQ which fully eliminates the matrix inversion while obtaining equivalent results.\\n- The authors present what seem like the first theoretical guarantees for an adaptive layerwise rounding algorithm.\\n- The proposed incoherence preprocessing leads to greatly improved results for 2-bit compression. While the idea of multiplying with an orthogonal matrix to produce more uniform and thus easier to compress data is not new, I have not seen it applied in the context of LLM quantization before.\\n- The paper also studies the impact of some additional heuristics, like greedy post-processing passes on top of GPTQ. While those are mostly small tricks, it is good to have those implemented and evaluated.\\n- Code is provided for reproducabilty, including also a script to verify the equivalence of their GPTQ optimization.',\n",
       "  'weaknesses': \"- The method is only evaluated on OPT, which is not considered a great LLM anymore by today's standards; good results on e.g. LLaMa would be significantly stronger.\\n- There do not seem to be any runtime numbers for inference via the proposed efficient Kronecker-factored scheme. I think that the tripling of required FLOPs (2 additional o(n^2) matmuls if I understood this part correctly) may be challenging to implement in practice without significant overheads (both for low- and large-batch inference), which would limit the practicality of incoherence preprocessing.\\n- The algorithm family seems to be somewhat designed around how GPTQ works and the corresponding optimality is thus not exactly super surprising.\"},\n",
       " 'review_557': {'summary': 'The work presented in this paper introduces quantization with incoherence processing, which enables better quantization with fewer bits per parameter. The authors provide a theoretical analysis for adaptive rounding methods and present experimental results demonstrating performance of 2-bit quantization..To do this, the paper introduces the LDLQ adaptive rounding method and demonstrates its optimality compared to other rounding methods which specify linear feedback U for hessians, and rounding to integers (see Theorem 1). The authors define incoherence and demonstrate its effectiveness in achieving a theoretically superior asymptotic bound for LDLQ in terms of the spectrum of H. Additionally, the authors propose efficient pre and post incoherence processing techniques to transform W and H matrices, eliminating the need for nxn matrix multiplications.',\n",
       "  'strengths': \"The paper encompasses numerous interesting new concepts, theorems, and their corresponding proofs. The extensive experimentation serves to prove the authors' claims effectively. The writing is solid, making the paper relatively accessible despite the number of theorems and proofs. Proposed incoherence seems to improve baseline methods, for example OPTQ (table 6,7 appendix). The utilization of the incoherence technique has the potential to contribute significantly to achieve usable 2-bit quantization. They provided code, which is always a plus.\",\n",
       "  'weaknesses': '1) One significant drawback of the paper is that despite the aforementioned enhancements, the performance of 30-bit 2-bit quantization, although much better than 2 bit OPTQ, still falls short compared to 13b model 4-bit quantization with OPTQ(and even 4 bit RTN), making it practically unusable. This limitation diminishes the practical usability surrounding the work on 2 bit quantization.\\n\\n2) The concept of incoherence remains unclear until page 4 of the paper, which is problematic considering it is one of the main focal points. I believe the introduction should include a clear definition and intuitive explanation of what incoherence entails. Furthermore, I found it challenging to establish a connection between the intuition provided in line 22 and the definition presented in line 134.\\n\\n3) It is possible I missed, but it appears that there is no mention or measurement of inference speed presented in the paper.'},\n",
       " 'review_558': {'summary': 'This work proposes a unified framework for weight quantization with error feedback together with preprocessing and postprocessing transformation that makes the model more quantization-friendly. Authors derive theoretical bounds on the quantization error and investigate the failure cases of OPTQ quantization. The introduced LDLQ method with incoherence processing is evaluated on quantization of LLM for 2,3 and 4 bit quantization. ',\n",
       "  'strengths': '* Paper proposes a unified view on quantization with the objective of minimization of layer-wise MSE loss that involves well-known OPTQ as a particular case.\\n* Authors derive explicit average and worst-case bounds on quantization error. \\n* The introduced incoherence processing is well-motivated and supported by quantitative analysis.\\n* The demonstrated LDLQ failure case example despite being very different from typical cases occurring in practice is still interesting and shows potential limitations of the optimal quantization methods.\\n* Different variants of LDLQ achieve strong performance on quantization of models from OPT family at various bit widths considered. The most impressive result is that the model attains reasonable perplexity and zero-shot accuracy for 2 bit quantization, which is known to be very challenging and all the competitive methods experience massive performance drop. \\n* Overall, the work is well-structured and accompanied with thorough theoretical analysis and empirical study.\\n',\n",
       "  'weaknesses': '* Method is evaluated only on a single model LLM family. To be sure that the method achieves strong performance on LLM quantization in general one should consider at least one more family of LLM. \\n* Minor. $U^{\\\\prime}$ in formula (4) is not upper unit triangular but rather strictly upper triangular (I guess  $U^{\\\\prime}  + I$ is supposed to be upper unit triangular). \\n* Minor.  This will result in each of its eigenvalues being a random unit vector. I guess the authors meant eigenvectors instead of eigenvalues.'},\n",
       " 'review_559': {'summary': 'The paper proposes a unified framework for facial generative models that allows text/spatial/audio condition facial editing tasks. The results are reasonable and comparable to prior works. Based on the stable diffusion prior, this model can generalize well to different style domains.',\n",
       "  'strengths': '- The paper presents a unified framework that allows different face editing settings including face stylization, audio-driven animation, attribution editing, etc. The simultaneous style transfer and facial animation provides a one-stage solution to stylized facial animation, which avoids error accumulation and computation waste. More importantly, based on the SD prior, this model can generalize arbitrary style in the wild, such as anime, oil painting etc.\\n\\n- The technical contribution is moderate as most of the modules come from prior works. However, the whole system aims at addressing several face generative tasks in one model which is beneficial for many applications.\\n\\n- The paper organization and writing are easy to follow.',\n",
       "  'weaknesses': '- The paper would benefit from an analysis of the pros and cons of jointly training with different conditions using text and experiment results. This is one key to support the effectiveness of the unified framework design.\\n\\n- Some face generation+editing results in Figure A5 look odd. For example, the mask inpainted face has a different skin color compared to the neck in (a).\\n\\n- While MakeItTalk, Wav2Lip and PC-AVS are not SOTA methods of face animation, recent related works such as styleTalk, styletalk, AVCT etc. should be discussed and compared if available.'},\n",
       " 'review_560': {'summary': 'This paper presents a facial content generation framework named FaceComposer, which is based on a Latent Diffusion Model (LDM). The primary aim of this framework is to facilitate text-conditioned face synthesis/editing and animation. The conditions employed in this model encompass a variety of aspects, including mask, PNCC (Projected Normalized Coordinate Code), sketch, identity feature, and Text2Face embedding. To ensure the generation of dynamic content, the authors introduce a temporal self-attention module within the LDM during the training phase. The experimental results affirm the superiority of this framework, showcasing enhanced synthesis quality in both static and dynamic settings. This novel approach thus provides a robust solution to the challenges of face synthesis and animation.',\n",
       "  'strengths': '1. The concept underlying this paper is both straightforward and efficacious, offering a user-friendly yet potent solution to the problems at hand.\\n\\n2. The application of the Projected Normalized Coordinate Code (PNCC) as a condition in the diffusion model, particularly in the context of face animation, presents a unique and stimulating approach to this field of study.\\n\\n3. The collection of a new dataset comprising more than 500 hours of talking face videos is an important contribution. This sizable dataset is likely to have significant utility in the further exploration and development of this area.',\n",
       "  'weaknesses': \"1. Comparative Methods: Including the results from StyleTalk [20] in the comparison would be beneficial given its shared design principle of audio2PNCC for talking face generation. This comparison could provide a more comprehensive overview of how the proposed method performs against closely related approaches.\\n\\n2. Dataset Details: As Table 4 indicates, the release model of all comparison methods isn't trained on HDTF. This makes it difficult to ascertain whether the performance gap results from the FaceComposer itself or the additional training data sourced from Youtube, BBC, and so on. Conducting more ablation studies on the influence of the dataset would provide more clarity in this regard.\\n\\n3. Missing References: It appears that there are some relevant references missing from the current list. \\n\\n[a] DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion\\n\\n[b] Pretraining is all you need for image-to-image translation\"},\n",
       " 'review_561': {'summary': 'The paper presents an all-in-one pipeline that can perform face generation, editing and animation and can be driven by multiple signals such as audio, text and sketches. The proposed model is based on a Latent Diffusion Model (LDM) and works by decomposing images faces into several representations capturing identity (ArcFace embeddings), geometry (PNCCs), face shape (sketch embeddings) and text description (T2F embeddings). These embeddings are then used as conditions and guidance for the LDM, which is taken pre-trained and fine-tuned on a large dataset containing both images and videos. The model is able to train simultaneously with images and videos thanks to temporal attention modules inserted in the U-Net architecture. The model is evaluated on face generation, editing and animation and compared to SoTA methods for each task. Facial animation is performed using an audio-to-PNCC model, which predicts the 50 expression parameters and 3 jaw pose parameters from Wav2Vec embeddings.',\n",
       "  'strengths': 'The proposed framework is indeed flexible and can perform tasks that would normally require multiple modules. The advantage of a unified model apart from the simplicity is the computational efficiency (i.e. low latency), since it can perform several steps in parallel without stringing together multiple models.\\n\\nThe authors have collected a curated, extensive dataset of images and videos. They make sure that the dataset only contains high quality frames and highly correlated text-image pairs. The dataset will be made public and will undoubtedly be very useful for researchers in the field.\\n\\nThe authors include an ablation study showing the effect of training on only videos or only images and share their hypotheses into why the addition of video data results in slightly blurrier frames.\\n\\nThe lip movements appear to be synchronised with the audio and this is also visible in the SyncNet and LMD metrics.',\n",
       "  'weaknesses': 'The proposed framework does not present significant methodological novelty and it is not clear what the key contributions are besides the collection of multiple conditions and pretrained models to drive a unified framework. Temporal attention has been used before in [*] and [**] and the conditioning mechanism and guidance used in the paper are standard practice for most diffusion models. Make-a-Video [*] also is trained on both image and video data and has a similar approach but is missing from the references. The audio-to-PNCC network is based on StyleTalk but is only described in the supplementary material.\\n\\nFrom the supplementary video the performance of the model seems to degrade a lot when the masks are not used (identity feature + PNCCs). This setting is much more challenging and the proposed model seems to struggle to preserve the identity or produce natural head motion. Furthermore the visual quality also seems to degrade. The authors also do not mention if the results of Table 4 are measured when using masks or not. If masks are used then this is an unfair comparison against other methods such as PC-AVS that are truly one-shot and do not simply in-paint the mouth. This would also explain why the SSIM and CPBD are better.\\n\\nThe authors only have an ablation study examining how the use of images and videos during training affects the performance of the model. They have not performed ablation studies to explore how the performance improves with the addition of each condition. \\n\\nThe description of the user interface of the tool is not of particular interest for machine learning research. The authors should consider removing this section from the main paper and using the space to add experiments such as ablation studies or to describe some of the components in more detail.\\n\\n[*] Singer et.al. \"Make-A-Video: Text-to-Video Generation without Text-Video Data\"\\n[**] Ho et. al. \"Video Diffusion Models\"'},\n",
       " 'review_562': {'summary': 'The advancement of generative models has significant progress in automatic facial content creation. However, current models pose challenges due to their high customization and inefficiencies. To address this, a unified model called FaceComposer is proposed.\\n\\n- The model leverages images, videos, multi-modal face datasets. \\n- Better performance than SOTA. \\n- The user-friendly interface of FaceComposer enables easy face generation, editing, and animation.\\n',\n",
       "  'strengths': '- Well written text with nice figures and numerical results. \\n- Promising results supported by numerical results. \\n- Proposed method works in many styles\\n- Unified framework enables the proposed method to work on multiple tasks. \\n',\n",
       "  'weaknesses': '- The interface is confusing. \\n- Maybe adding human eval can make the work better. \\n\\n'},\n",
       " 'review_563': {'summary': 'The paper tries to solve famous problem of removing bias and noise during peer-review process. The authors address the problem in one-shot setting (without historical data) and propose a novel approach that allows to remove influence of bias and noise (under some assumptions on bias and noise) on the ranking of assessed elements (reviewed papers). The approach uses scoring adjustment (used for ranking) and requires additional signal (action) from each reviewer. \\nThe authors provide theoretical guarantees and small synthetic experiments.',\n",
       "  'strengths': '-\\tOverall good organization of the paper storyline (very good Intro!)\\n-\\tMore or less clear statements and easy to follow\\n-\\tSynthetic experiments',\n",
       "  'weaknesses': '-\\tSome drawbacks in clarity related to assumptions and limitations of the setup\\n-\\tSeem limited practical effect\\n-\\tThe contribution does not look very enough for NeurIPS\\n-\\tLack of comparison with alternative ways to improve scoring (e.g., non-1-shot ones, etc)'},\n",
       " 'review_564': {'summary': 'This paper aims to detect and correct bias in Peer Review. They propose a one-shot noise calibration process without any prior information. Experiments are conducted on the binary case to show the effectiveness of the proposed method.',\n",
       "  'strengths': '1. The studied problem is important.\\n2. Theoretical guarantee is provided for the proposed calibrated score.\\n3. The organization of this paper is clear.\\n',\n",
       "  'weaknesses': \"1. The rationality of the proposed surprisal scores needs further support. For example, in Figure 1, it seems that the left paper with lower negative reviewers’ prediction is the same as the right paper with higher negative reviewers’ prediction, while the left paper receives 1 accept and 2 reject while the right paper receives 2 accept and 1 reject. This result is confusing since the reviewers may give low P_0,1 simply due to the poor quality of the left paper.\\n2. The experiments are weak in demonstrating the generality of the proposed method. For example, in Sec 6, the authors only conduct experiments on the binary case, lacking the more general settings with more types of possible signals. \\n3. The theoretical guarantees lack a clear explanation. For example, in theorem 2, why there is 1/2 in the error probability (Pr[S(A) > S(B)|w1^A,w2^B]+1/2 Pr[S(A)=S(B)|w1^A，w1^B])? The guarantee of such an error probability may still remain a gap in the performance guarantee of the proposed method.\\n4. Some assumption or claims lacks further support and needs to offer more clarification or explanation. For example, in Sec 2.2, why “only consider the noise where M is invertible?” What will be the situation when M is non-invertible? Why can construct the vector q and the joint distribution matrix U from the prediction matrix P as stated in claim 1?  Is it universally applicable to assume that 'each individual receives the clean signal with probability 1-\\\\lambda’?\\n\"},\n",
       " 'review_565': {'summary': 'The paper considers the problem of comparing two papers based on noisy ratings, where the noise can be arbitrarily biased for different papers. The paper elicits from each reviewer both a rating and a distribution of predicted ratings from other reviewers’ (based on a Bayesian update of the common prior, known to the reviewers). The paper proposes a scoring method that recovers the correct comparison between papers from the noisy reports, which essentially corrects the reported ratings using the reported prediction distributions. The authors theoretically show a bound on the error probability of a comparison based on their scoring method, and experimentally evaluate the comparison accuracy. ',\n",
       "  'strengths': '- The problem considered by the paper, calibrating biased noise in a one-shot comparison between items, is conceptually interesting. The authors motivate this problem well in the peer review setting with examples of cases where multiple reviewers may have the same bias. \\n- The authors prove a theoretical bound on the convergence rate of their method’s error probability to 0. The experimental settings considered are thorough (and demonstrate aspects of the theoretical result). \\n',\n",
       "  'weaknesses': '- While the problem itself is interesting, the assumption that all agents share and know a common noisy prior is very strong; e.g., in the peer review examples in the introduction, while the noise may be biased in the same direction for all reviewers, the noisy prior may not even be similar for all reviewers. Given this assumption, I’m unsure about the significance of the proposed method, which essentially recovers this prior (as in past work) and uses it to standardize the reports.\\n- I found the clarity of the writing to be generally poor, leading to some significant confusion at points (particularly in Sections 1 and 2). For example, in Section 1, I did not understand the claim following Example 2 (that a higher noise level would result in a lower expected score).  In Section 2, it was difficult to follow which aspects are observable by agents and by the mechanism.\\n'},\n",
       " 'review_566': {'summary': 'This paper proposes a method to calculate peer-reviews scores for papers in the presence of systematically biased noise, such that the score of a paper with a higher expected score in a noise-free regime is higher than the score of a paper with a lower expected score in a noise-free regime with high probability (as the number of peer reviewers grows large). The method does not use reviewers\\' historical scores to compute their priors. Instead, the method asks reviewers to predict the scores of other reviewers (similar to the Bayesian truth serum). Numerical experiments confirm the theoretical results that the proposed score is better able to distinguish between \"good\" and \"bad\" papers under systematically biased noise compared to a baseline that just averages the uncalibrated peer review scores.\\n\\n**Post-rebuttal:** I am raising my presentation score to 4 (excellent).',\n",
       "  'strengths': 'The paper is clear and precise, and spends sufficient time setting up the problem and building intuition. The proposed method adapts a well-known idea (Bayesian truth serum) to the setting of systematically-biased noise in peer review in a principled manner; this is novel to the best of my knowledge. It is also non-trivial, and provides a useful way to construct peer-review scores without needing historical data for each peer reviewer.',\n",
       "  'weaknesses': 'The generality of the exposition also makes it a bit difficult to follow. I think just limiting the main body of the paper to the binary decision case (accept, reject) and adjusting the notation for this (eg. a for accept, r for reject) would make it easier to follow the main argument of the paper. The generalization to multi-valued decisions (eg. review scores) could be relegated to an appendix or to just one theorem.\\n\\nThe numerical experiments do not consider SP as a baseline (possible with some modifications since it cannot be directly applied). A naive application of SP would be the most related method in prior work for the problem considered in this paper. Hence, it would help to see how this would perform.'},\n",
       " 'review_567': {'summary': 'The paper tackles a problem in peer review where reviewers may provide noisy/biased ratings for papers. The paper investigate a \"one-shot\" scoring process inspired by the \"Surprisingly Popular\" method, that can rank papers by their true quality without any prior knowledge, even if different papers have different noise levels and biases.\\n\\nTheir method relies on eliciting reviewers’ predictions for a random reviewer’s signal and using this for calibration. Specifically, their model assumes that there is a prior distribution over the states (where each paper\\'s state in the \"clean\" setting is the distribution of reviewers’ signals)  and that reviewers are perfect Bayesians who can update their beliefs based on their private signals. In the \"noisy\" setting, reviewers can only observe noisy versions of their signals, determined by a random mapping that depends on the noise level and the bias vector.\\n\\nThen, the paper defines the true quality of a paper as the expected score in the clean setting, and aims to design a method that can rank papers by their true quality with high probability, even if they have different noises/biases. For this, they introduce a surprisal vector that measures how \"surprising\" a paper’s state is compared to the prior distribution, and is normalized by the correlation between reviewers’ signals. The key result is that the surprisal vector is noise-invariant, i.e., the surprisal vector is the same in the clean and the noisy setting, regardless of the noise model.  Then, by computing an empirical surprise-based score for each paper, the mechanism papers can be compared in a noise-invariant way and are consistent with their true qualities.',\n",
       "  'strengths': '- The paper is tackling an important problem, which is the question of how to de-bias and de-noise reviewers to obtain a clearer view of paper quality.\\n\\n- The observation that the surprisal vector is invariant under noise is insightful and interesting, as was the idea to look to the surprisingly popular mechanism.',\n",
       "  'weaknesses': '- The presentation of the paper could be improved. The intro feels a bit unfocused, there are a number of grammatical errors, and the paper is a bit notation heavy. It might help to move the notation table from the appendix to the main body, and also expand on the \"high level ideas\" to more provide a clearer overview of the proposed method. It took a couple reads to understand exactly what was being proposed. \\n\\n- The assumption of calibrated agent predictions is not clearly justifiable in a context where agent signals are assumed to be potentially biased.\\n\\n- In line 162, the result cited by Kong et al. (2018) is outdated, suggest updating with more recent results that improve on this:\\n\\nSchoenebeck, Grant, and Fang-Yi Yu. \"Two strongly truthful mechanisms for three heterogeneous agents answering one question.\" ACM Transactions on Economics and Computation 10.4 (2023): 1-26.\\n\\nSrinivasan, Siddarth, and Jamie Morgenstern. \"Auctions and prediction markets for scientific peer review.\" arXiv preprint arXiv:2109.00923 (2021).\\n\\n'},\n",
       " 'review_568': {'summary': 'This paper extends one of the promising uncertainty estimation method: Neural Process from unimodal to multimodal. This is motivated by the fact that: current techniques are predominantly designed for unimodal data, and directly applying them to multimodal information is ineffective. However, this extension poses several challenges: 1) how fuse information from different modalities effectively and efficiently; 2) the context memory of the original design grows in proportion to M - the number of modality, which is memory-consuming, and sets the question of how to maintain it small yet informative; 3) how to find an appropriate length-scale of the Radial Basis Function (RBF) that ensures a tight boundary between in-distribution and out-of-distribution data.\\nTo tackle these challenges, the paper introduces three solutions: 1) Dynamic Context Memory to choose the most informative samples in the context memory, 2) Multimodal Bayesian Aggregation, and 3) Adaptive RBF Attention. Empirical experiments show that the method can outperform other unimodal and multimodal baselines in terms of maintaining good accuracy and calibration at the presence of noise and in terms of out-of-distribution detection.',\n",
       "  'strengths': '1. originality: the first to extend Neural Process from unimodal to multimodal and effectively combine existing techniques to solve some of the challenges incurred.\\n2. clarity: in general, the paper articulates its ideas clearly, even though some parts remain difficult to understand or unclear in terms of details (see the weakness part)\\n3. significance: the proposed method shows promising results in terms of outperform most unimodal and multimodal baselines. ',\n",
       "  'weaknesses': \"**Clarity**: the clarity of the technical introduction (Sec. 3) and the experiment (Sec. 4) parts can be largely improved. \\n1. The method introduction part could be **challenging to comprehend for readers unfamiliar with the Neural Process and its technical details**. It lacks adequate contextual knowledge, such as an explanation for why the context memory is required, why it is used to store training samples rather than using a context feature. I think the Sec. 2 should be improved to be more comprehensive and general in introducing the Neural Process, to avoid the readers to revisit several referenced papers repeatedly.\\n1. The **math details can be overwhelming and at times confusin**g. For instance, when reviewing Sec 3.3, it necessitates frequent referral back to Section 3.2. It would be helpful if the semantic meaning of symbols is reintroduced when they appear, preventing the need for readers to revisit previous sections for notation understanding.\\n\\t1. **Derivation details**: The logic in some derivations is not easy to understand, e.g. Line 221 introduces the function $f(T_X^M)$ without any prior explanation. Also, there is no explanation on how equation (12) is derived, and why softmax is applied on a density function. These issues impede reading and understanding. The formula (4) and formula (6) are not consistent as their parameter notation is not the same on $\\\\omega$ and $\\\\psi$.\\n\\t2. The MNPs **pseudocode** lacks a high-level introduction and has heavy reference links, failing to provide clarifying information.\\n\\t3. **Captions**: Some table captions lack sufficient information. For instance, Table 4/5 does not clearly describe the dataset and settings used.\\n\\t4. **Experimental Setup**: The presentation of the experimental settings, such as how datasets e.g. Caltech101 were modified into multi-view datasets, is not clear.\\n\\n**Soundness**: Despite the multimodal setting, the experiments use only multi-view image data. The lack of experiments with multimodal combinations such as image + text impedes the proof of the model's effectiveness in various settings.\\n\"},\n",
       " 'review_569': {'summary': 'This paper proposes a new method for multimodal uncertainty estimation by extending neural processes. The authors summarize three challenges to do that and give solutions correspondingly. Experimental results show that the proposed method is more robust and outperforms existing baselines.\\n\\n---\\n\\nThanks for the clarification! My main concerns are addressed.',\n",
       "  'strengths': 'The proposed method (MNPs) can achieve good performance empirically.',\n",
       "  'weaknesses': '1. The motivation is not clear. Indeed, there is little discussion about neural processes with multimodal data, and extending unimodal neural processes to multimodal scenarios could be challenging. However, existing works discussed the multi-view data [16,21]. The reason why extending the neural processes for multimodal data (instead of extending/improving [16,21]) remains unclear.\\n\\n\\n2. Lack of understanding. I would like to suggest that the authors add some ablation studies. From current experiments, we can only see that proposed MNPs outperform baselines. However, why it can do that is not clear, e.g., why the unimodal method (DE) can achieve the best test accuracy.'},\n",
       " 'review_570': {'summary': 'This paper proposes a multimodal neural processes (neural network generaliation of Gaussian processes) model.\\n\\nThe overall approach has several novel elements:\\n* A way to maintain a dynamic context set throughout training (e.g a support set for few-shot learning, these context sets are needed for neural processes) \\n* A Bayesian aggregation scheme for combining multiple modalities\\n* An adaptive RBF attention mechanism as an alternative to (vanilla) dot product attention which the authors argue is overconfident on OOD samples.\\n\\nExperiments on a suite of datasets show that the proposed method is faster, more accurate and better calibrated, and better at detecting OOD samples than prior work.\\n',\n",
       "  'strengths': 'This reads like a polished piece of work with clear writing, extensive ablations (in the supplementary) and novel technical contributions.  Experimental results seem fairly convincing (that the proposed method is indeed better than prior similar works).  My caveat is that my familiarity with this part of the literature on Neural Processes is passing at best.',\n",
       "  'weaknesses': '\\nI have no major complaints about this paper, but some things to point out are:\\nIt is pretty unclear what are the actual multiple modalities in the datasets that are used for experiments (which makes these experiments not particularly compelling perhaps unless you are already familiar with this line of work).  I had to trace through a series of cited works to figure out that (likely) these different modalities are different features extracted e.g using different networks.\\nSection 3.2 could be written more clearly — I couldn’t figure out why there were multiple encoders until encountering Lemma 3.1 — it’d be much better to explain this up front.\\nA nit: it’s also not clear when reading section 3.1 how often the dynamic context memory is meant to be updated until I read the pseudocode much later (I’d recommend saying that it’s a per-minibatch update somewhere).\\n'},\n",
       " 'review_571': {'summary': 'This work proposes a confidence calibration algorithm for multimodal classification problems. The algorithm includes three key components: 1) dynamic context memory, 2) multimodal Bayesian aggregation, and 3) adaptive radial basis function. The algorithm is evaluated on multiple benchmarks using classification accuracy, calibration, and OOD performance. On multiple benchmarks, the proposed algorithm is able to obtain SOTA results.',\n",
       "  'strengths': '1, The targeted problem and challenges are explicitly stated. For each challenge, a technically reasonable solution is proposed.\\n2, The proposed algorithm is able to obtain strong empirical results, obtaining SOTA results on multiple benchmarks and different metrics.\\n3, Comprehensive ablation studies have been conducted to demonstrate each components.\\n4, As illustrated in Figure 2, the proposed adaptive RBF algorithm outperformed other attention mechanisms.',\n",
       "  'weaknesses': '1, Some notation definitions are confusing. Please refer to section \"Questions\" for details.\\n2, Because of the above notation section 3.2 is a bit hard to follow.\\n3, Ablation study is conducted for individual components. It would be interesting to design ablation studies and see how each component affects the end-to-end performance.\\n4, The component directly related to multimodality learning, i.e., multimodal Bayesian aggregation, is based on previously work [1]. It would be good if the authors can explain how the proposed MBA component is different from previous work, either in the revision or rebuttal. \\n\\n[1] M. Volpp, F. Flürenbrock, L. Grossberger, C. Daniel, and G. Neumann. Bayesian context aggregation for neural processes. In International Conference on Learning Representations, 2021.'},\n",
       " 'review_572': {'summary': 'The paper tackles the problem of uncertainty estimation specifically for multi-modal data, i.e., inputs consisting of different sources. Specifically, it improves the popular Neural Process (NP) in three aspects: dynamic context update, multi-modal Bayesian aggregation, and a novel attention mechanism based on the RBF kernel. The paper demonstrates superior test accuracy, uncertainty estimation (calibration and OOD detection), and robustness on multiple benchmarks compared to prior works. ',\n",
       "  'strengths': '* The paper studies the less well-studied area of uncertainty estimation for multi-modal data. This has practical implications as many real-world applications can be multi-modal.  \\n* The paper presents multiple metrics including accuracy, calibration, OOD detection, and robustness, which provide a holistic evaluation of the proposed method. \\n* The idea of dynamic context update is most interesting to me. Specifically, the method replaces uninformative context samples with informative ones where \"uninformative-ness\" is measured by attention weights and \"informative-ness\" is measured by difficulty of classification.  ',\n",
       "  'weaknesses': \"* While the paper presents three innovations and claims that they are all tailored to multi-modal data, only the Bayesian aggregation is inherently related to multi-modal inputs. The dynamic context update and the RBF context mechanism do not utilize the multi-modal characteristic. This makes the contributions and claims less coherent. \\n\\n* It seems the Bayesian aggregation mechanism is not ablated. It's not clear how much improvement it brings to the overall performance as it is the main mechanism responsible for tackling multi-modal inputs. Does the improved robustness come from the aggregation algorithm or the other two components? \\n\"},\n",
       " 'review_573': {'summary': 'This paper studies pre-training by using generated image from diffusion models. It presents StableRep that generate different images with the same caption by using stable diffusion models. The model is hence pre-trained by using the generated samples and contrastive loss. Extensive experiments demonstrate the effectiveness of the proposed method by using synthetic images only.',\n",
       "  'strengths': '1. This paper studies the pre-training by using synthetic data only. Experimental results show that pre-training by using synthetic data only outperforms the pre-training over real images.\\n2. This paper is generally clear and well-written.',\n",
       "  'weaknesses': 'The pre-training over generated images by using diffusion models have been studied in [24]. In [24], it seems direct pre-training on synthetic images could helps to improve the classification results without the proposed pre-training pipeline. As the comparison between the proposed method and the reported results in [24] is missing, it is difficult the determine the effectiveness of the proposed pre-training pipeline.'},\n",
       " 'review_574': {'summary': 'This paper investigates how synthetic data generated with the text-to-image diffusion model Stable Diffusion can be leveraged for representation learning.\\nTo this end, the paper analyzes established representation learning approaches such as SimCLR and CLIP, but trained on the synthetically generated data. Further, it introduces a novel method,\\ndubbed \"StableRep\", specifically designed for representation learning from a generative model, to generate multiple \"positive\" image instances for downstream representation learning.\\nExperiments demonstrate the potential of synthetic data for representation learning and mostly perform on-par with or better than when trained on real data only.',\n",
       "  'strengths': 'This is a well-written paper, which approaches a timely research question: To what extent can large-scale, generative models which have been trained on internet-scale data be leveraged for other tasks, by augmenting or replacing real data. The experiments are well-designed and hint at the potential of using synthetic data. StableRep is a nice method specificially designed for generative models that can generate multiple positive examples for a given prompt. The experiments are encouraging for future research in this area.',\n",
       "  'weaknesses': 'While experiments demonstrate potential, there remain a few unaddressed points: How does the choice of generative model influence the results for representation learning? In particular, Stable Diffusion is conditioned on CLIP text features, which themselves are pretrained through CLIP\\'s contrastive objective. There exist, however, other generative text-to-image variants that use non-contrastive features for conditioning, such as T5-representations (e.g., Imagen [https://github.com/deep-floyd/IF], IF [https://github.com/deep-floyd/IF]).\\nFurther, the paper does not discuss how the size of the pretraining dataset for both CLIP (for conditioning SD) and the training data for SD change performance of StableRep (the pretraining data is much larger than CC3M/12M). In addition, the possibility of data poisoning w.r.t to the results presented in Tab. 2 and Tab. 3 is not discussed (for example, SD\\'s training data might have contained examples from the linear probing datasets). The performance gap between CIFAR-10/100 and the other datasets remains unexplained.\\nl. 1014-107 need more detail on hyperparameter settings like number of steps, learning rate used, convergence of the model.\\n\\nFor further comments, please refer to the \"Questions\" section.'},\n",
       " 'review_575': {'summary': 'The authors presents a novel method for learning visual representations using synthetic data. The authors leverage text-to-image generative models (Stable Diffusion) to synthesize images from textual prompts, which are then used to train a self-supervised visual representation model. The synthetic data generation process is guided by a set of diverse and non-repetitive textual prompts, which helps in creating a wide variety of images. The authors demonstrate that their approach outperforms traditional self-supervised learning methods that rely on real images, especially when the amount of real data is limited. They also propose a multiple positive samples based contrastive learning approach called StableRep to utilize different synthetic images generated from a source text prompt, which outperforms training with simply real or synthetic images on a variety of downstream tasks. ',\n",
       "  'strengths': '1. **Important Problem:** The authors study a very important problem, how to utilize synthetic images for training vision and vision-language models. They also show success at this central problem (with caveats, see weaknesses). They are one of the first studies showing successful use of synthetic data from generative models on standard computer vision benchmarks.\\n\\n2. **Novel approach:** The multi-positive StableRep approach proposed by the authors for multi-caption invariance learning in self-supervised models is a novel idea and seems to work very well in practice leading to significant improvements over simply using synthetic images for training. \\n\\n3. **Ablations:** The authors perform extensive ablations on the role of guidance scale, and also include a study on how additional language supervision could be used to increase caption efficiency while training with multiple positive synthetic images. The results indicate that proposed approaches (StableRep and StableRep+) indeed are more efficient versus training on real images.',\n",
       "  'weaknesses': '1. **Limited motivation behind why synthetic images:** It is unclear to me as a reader why Synthetic Images are being used in Section 2.2 as training data for pre-training. It seems that there is no real benefit from using them on state-of-the-art contrastive models like BYOL and MoCo-V3 in terms of linear accuracy. Plus, the key issue for training is the lack of real world labelled data as mentioned by the authors\\' central question \"how can we collect such large amounts of varied data to train AI models?\" (L21). There is plenty of real-world unlabelled data that is available and can be used to train self-supervised models. The real benefit that synthetic images present is unlimited labelled data. However no fine-tuning comparisons or supervised learning comparisons are provided except for fine-tuning MAE, which could very well be explained by the stochasticity in model training (82.9% vs 82.6%). Section 2.2 does not do much to justify the usage of synthetic images for training in a manner that addresses the authors\\' central question, and follow up sections justify it for efficiency but not performance.\\n\\n2. **Limits of generative model:** While the authors include a limitation section, and mention briefly the issues that affect generative models like Stable Diffusion, there needs to be more rigorous evaluation of these issues. Conceptually, these methods suffer from issues like limited compositional understanding. There have been countless studies on the social biases reflected in these models. Very lately (after the NeurIPS deadline), there was an important work showing that models trained on data from generative models can suffer from model collapse, where tails of the original data distribution disappear from the subsequent trained model [1]. All these issues are quite major and should be part of this study, since it is one of the first to utilize synthetic data and show some improvements in results and could potentially effect future research in this area. In particular, the authors should include results on compositional benchmarks (like ARO, CREPE, Winoground, SugarCREPE etc) for their CLIP models trained with StableRep, discuss the fairness of the self-supervised models such as worst-class accuracy and geographic bias etc. \\n\\n### References \\n\\n1. Shumailov I, Shumaylov Z, Zhao Y, Gal Y, Papernot N, Anderson R. The Curse of Recursion: Training on Generated Data Makes Models Forget. arXiv preprint arXiv:2305.17493. 2023 May 27.'},\n",
       " 'review_576': {'summary': 'In this paper, the authors investigate the potential of learning visual representations using synthetic data generated by text-to-image models. The authors choose Stable Diffusion for exploration and extensive experiments demonstrate that self-supervised models trained on synthetic data can perform better or at par with training on real data. The authors also propose a multi-positive contrastive variant called StableRep to allow multiple images generated from the same text prompt as positives for each other.',\n",
       "  'strengths': '- The paper is well motivated. Given the recent progress of large-scale text-to-image generative models like Stable Diffusion, it is timing to investigate the effectiveness of these models in generating high-quality images to assist discriminative tasks.\\n\\n- The paper is generally well-written and easy to follow.\\n\\n- The experiments are extensive and the results seem promising.',\n",
       "  'weaknesses': '- The authors use large-scale image-text datasets like CC3M, CC12M, RedCaps for study. These datasets have well-collected image captions. Although the authors claim that the proposed method can reduce the reliance on collecting large-scale real images for learning representations, the cost of collecting these image captions is also somewhat expensive and should not be ignored. Thus, a more cost-effective and interesting setting should be to generate a synthetic ImageNet dataset using category labels as text prompts (e.g., a photo of [category]) since it does not require any human effects of collecting captions. Then self-supervised models could be pre-trained on the real ImageNet dataset as well as the synthetic ImageNet dataset for comparisons. I am curious about whether the self-supervised methods trained on synthetic ImageNet still have advantages over training on real ImageNet.\\n\\n- It seems that the synthetic data only have performance advantages for linear probing experiments. For few-shot experiments, self-supervised methods trained on synthetic data still have a large performance gap with training on real data, which limits the practical applications of using synthetic data to some extent.\\n\\n- The authors only evaluate the proposed method on classification downstream tasks. What about dense prediction downstream tasks like object detection or semantic segmentation? Will the synthetic data still have the advantages on these kinds of downstream tasks?\\n\\n- According to ablations in Sec. 4.2, generating multiple images per caption yields better performance. However, this may be due to simply increasing the number of views. To eliminate the interference of the number of views, the authors should also conduct an ablation by replacing multiple generated images per caption with the same number of cropped views per real image.'},\n",
       " 'review_577': {'summary': 'The paper investigates the potential of using synthetic images generated by text-to-image models to train self-supervised image embedding models. Methodologically, the authors propose StableRep, a multi-positive contrastive learning method that treats multiple images generated from the same text prompt as positive examples for each other. The paper demonstrates two key findings. First, when the generative model is appropriately configured, self-supervised methods trained on synthetic images can achieve comparable or superior performance to real image counterparts. Secondly, when language supervision is incorporated, synthetic data become more efficient. ',\n",
       "  'strengths': '1. **Interesting topic:** The paper investigates the potential of using synthetic images generated by text-to-image models as strong visual representation learners. This exploration addresses an important and timely question. \\n\\n2. **New contrastive learning method:** The proposed StableRep is new and tailored for synthetic data. \\n\\n3. **Comprehensive evaluation:** The paper evaluates the representations learned by StableRep on large-scale datasets and compares them with strong baselines. ',\n",
       "  'weaknesses': '1. **Potentially entangled comparison in terms of the amount of data:** The only concern I have for this paper is the claim of data amount. When claiming \"synthetic and real images of the same amount\", the authors refer to the amount of data for representation learning. However, Stable Diffusion is trained on LAION-2B. Therefore, 50M synthetic images may contain information from 2B images, making this comparison less meaningful. I\\'d like to see more discussion on this issue. '},\n",
       " 'review_578': {'summary': 'This paper introduces a novel tree fitting algorithm named HCCRootedTreeFit. First, the authors motivate the need for a better tree fitting algorithm by stating that current methods \"assume almost nothing about the underlying discrete point set, when, in fact, many real application data sets are close to hierarchical or nearly so\".\\n\\nBefore introducing their new method, the authors introduce new proxy measures of how tree-like a dataset is. These proxy measures are used later on in several bounds, including in their main theoretical result which guarantees the existence of a tree fitting method with some nice bound on the distortion.\\n\\nIn their theoretical analysis, the authors mention a connection between the tree fitting problem and hierarchical correlation clustering (HCC), along with an equivalence result between tree fitting algorithms and ultrametric fitting algorithms. Then, they introduce an adapted HCC problem formulation and three algorithms named HCCTriangle, HCCUltraFit and HCCRootedTreeFit. The first algorithm solves the adapted HCC problem. The second algorithm uses HCCTriangle to solve the ultrametric fitting problem. The last algorithm uses HCCUltraFit to solve the rooted tree fitting problem.\\n\\nIn the experiments, the HCCRootedTreeFit algorithm is tested versus various other methods from the literature. For these experiments the authors have used both common and synthetic datasets. They observe that their method underperforms on common datasets, but performs well on synthetic datasets with respect to the $\\\\ell_1$ norm. They attribute this observation to a lack of tree-like structure in the common datasets. They furthermore observe that their method underperforms with respect to the $\\\\ell_\\\\infty$ norm.',\n",
       "  'strengths': '1. The paper introduces interesting new notions of hyperbolicity and ultrametricity through their hyperbolicity and ultrametricity vectors. \\n2. The authors derive an interesting connection between the distortion bounds for tree fitting and ultrametric fitting algorithms.\\n3. The new notion of hyperbolicity is used to show that, contrary to common belief, the common datasets are not very tree-like.',\n",
       "  'weaknesses': \"The paper is very difficult to read. Due to the very large number of definitions and technical results, the paper reads more like a collection of statements than a paper. Much of the actual content seems to be put in the appendix, adding to the feeling that the paper is not at all self-contained. Moreover, the paper appears to use many tricks from different papers without any description of these tricks. For example, in line 233, the authors refer to some paper to obtain a tree fit without actually explaining the actual procedure. \\n\\nThe structure of the paper also makes it rather difficult to follow, with several forward- and backward references spread throughout the paper. As an example, Subsection 3.2 appears to state several results regarding algorithms that have not yet been introduced. Then, in the next subsection, these algorithms are introduced and following these algorithms, the authors quickly throw in a proof of a result from the previous Subsection. \\n\\nAnother issue with the paper is that they first formulate the tree (ultrametric) fitting problem, but then, after quickly mentioning a connection to hierarchical correlation clustering, seem to actually solve an adapted version of this HCC problem. However, the introduction of their adapted HCC problem is rather unclear and uses, for example, a 'number of disagreement edges' term that is not properly defined in the paper. Also, it is not really clear to me what the connection with this problem and the original problem is.\\n\\nDue to these issues I cannot adequately judge the validity of the many technical results of this paper.\\n\\nThere is also an issue regarding the newly proposed algorithm within the context of the experimental results. The authors show that their method underperforms on common datasets with respect to both the $\\\\ell_1$ norm and the $\\\\ell_\\\\infty$ norm. Moreover, the method is quite slow compared to two of the other methods. It therefore appears that this method is only useful in synthetic settings.\"},\n",
       " 'review_579': {'summary': 'The paper formulate the $l_p$ tree fitting problem introduces a new algorithm, HCCROOTEDTREEFIT, for building trees in hyperbolic space by investigating the relationship between hyperbolicity (ultrametricity) vectors and the error of tree (ultrametric) embedding, which outperforms previous methods both theoretically and empirically.,\\n\\n',\n",
       "  'strengths': '1) The authors have developed a novel approach to the tree-fitting problem that applies hyperbolic geometry and geometric group theory.\\n2) The developed algorithm, HCCROOTEDTREEFIT, delivers a tree metric with $l_1$ distortion bounded by polynomial function of the average hyperbolicity, while previous research delivers a tree metric with $l_{\\\\infty}$ distortion only.\\n3) Comparison not only on performance but also on speed are explored, which makes a more computational sense.\\n4) Repeated experiments are conducted and standard deviation was analyzed. ',\n",
       "  'weaknesses': 'The paper is not well self-contained, needing additional supplementary materials to be complete.\\n\\nTable captions are not very comprehensive, e.g., Table 3 and Table 5, which increase the difficulty to understand the major experimental results.\\n\\nThe results lack qualitative examples to show 1) how different the proposed tree-fitting method is compared with previous tree-fitting methods. 2) how different the synthetic datasets is to real datasets.'},\n",
       " 'review_580': {'summary': 'The authors consider the tree fitting problem for a given distance. The authors cast the tree fitting problem as finding the relation between the hyperbolicity vector and the error of tree embedding. The authors propose an algorithmic approach with provably tight $\\\\ell_1$ error. The authors also illustrate the advantage of the proposed approach on some “tree-like” datasets.',\n",
       "  'strengths': '+ By casting the fitting tree problem as finding the relation between the hyperbolicity vector and the error of tree embedding, the authors propose provably tight $\\\\ell_1$ error algorithmic approach.\\n+ The authors illustrate the advantage of the proposed approach on some “tree-like” datasets.\\n+ Overall, the presentation is good. (It may be better to elaborate more details on the proposed algorithmic approach in Section 3.3)',\n",
       "  'weaknesses': '+ At the heart of the proposed algorithmic approach (Section 3.3), although the authors summarize their proposed approach in several Algorithms, it is hard to get the ideas how the tree is constructed. It seems the authors focus more on analysis for the proposed algorithm.\\n+ It seems better to include discussions about other existing approaches of tree fitting for a given distance. Besides the provable analysis of the proposed algorithmic approach, it is not clear how the proposed approach addresses some limits of existing approaches on tree fitting for a given distance.'},\n",
       " 'review_581': {'summary': 'The paper introduces a new algorithm, HCCRootedTreeFit, for fitting tree metrics to a given distance matrix. The algorithm is designed to minimize the ℓ1 distortion of the fit. The authors provide a detailed explanation of the algorithm, its theoretical properties, and an extensive experimental evaluation. The results show that the algorithm performs optimally when datasets are close to tree-like and when distortion is measured in the ℓ1 sense. The paper suggests that commonly used datasets, especially in geometric graph neural nets, are not well-represented by trees, indicating the need for more refined geometric notions for learning tasks with these datasets.',\n",
       "  'strengths': ' The algorithm is theoretically sound, thoroughly evaluated, and performs optimally on tree-like datasets. The work provides valuable insights into dataset characteristics and has significant potential for practical applications, particularly in machine learning and data analysis.',\n",
       "  'weaknesses': \"The evaluation of the proposed algorithm is primarily focused on its performance on tree-like datasets. While this is certainly important, it would be beneficial to see how the algorithm performs on a broader range of datasets, particularly those that are not tree-like. This would provide a more comprehensive understanding of the algorithm's performance and its applicability to real-world problems.\"},\n",
       " 'review_582': {'summary': 'This paper proposed a VAE-based text-to-3D shape generation method. The authors designed an alignment-before-generation approach to narrow the gap between 3D shapes and the 2D or text condition. They first train a Shape-Image-Text-Aligned Variational Auto-Encoder to align the representations between the 3D shapes and the 2D or text inputs. Then, the use latent diffusion model to denoise the shape embeddings to match the conditions. The overall presentation is good and the experiments are extensive.',\n",
       "  'strengths': '1. The narratives are good and sound.\\n2. The SITA-VAE helps to align the representations between the three modalities.\\n3. The generation only requires some denoising steps on the latent embeddings.\\n4. The experiments are extensive and the authors provide sufficient visual demos and show the effectiveness of the method.',\n",
       "  'weaknesses': '1. It seems that shape-image-text align training requires a lot of paired shape-image-text data, which could be a huge challenge in the generalization to new categories.\\n2. The experimental implementation is not clear enough and could be improved.'},\n",
       " 'review_583': {'summary': \"This paper proposed a conditional generation model which aims to solve the alignment issue in image-to-shape or text-to-shape generation. The key idea is to learn a aligned representation among 3D shapes, images, and texts. To achieve that, the author proposes SITA-VAE with contrastive loss to force the shape's latents to be aligned with the pretrained vision-language model. After that, a LDM is trained to learn the diffusion process in the latent space. In the test time, it follows the previous works to use classifier-free guidance to perform conditional generation. The proposed method is evaluated on ShapeNet and Cartoon Monster 3D shapes.\",\n",
       "  'strengths': '* Propose to learn a aligned space for 3D shapes, images, and texts with 2D vision-language model. This essentially leverages the abundant 2D data into 3D modeling. The scarcity of paired data is one crucial reason why conditional 3D modeling does not perform as well as its 2D counterpart.\\n\\n* The conditional generation results look great and align with the inputs when compared with the baselines.\\n\\n* It is surprised that the aligned space does hurt the reconstruction results.',\n",
       "  'weaknesses': '* Novelty is somewhat limited. The first stage model is mostly based on 3DILG and the multi-modality conditional generation has been explored in previous work such as SDFusion. \\n\\n* Scalability is an issue as the model need paired 3D-image-text data to work.\\n\\n* Some parts of the writing and figure are misleading. The choices of the metric is problematic in Table 2.\\n\\nPlease see the \"Questions\" for the details.'},\n",
       " 'review_584': {'summary': \"This work is about 3D shape generative model focused on image-conditioned and text-conditioned generation. The authors aligned the latent space of a shape autoencoder to CLIP's image encoder and text encoder. Then generative diffusion models are trained on the aligned latent space. This enables shape generation given image or text as conditional input. The authors showed some good results in both tasks.\",\n",
       "  'strengths': 'The authors showed some good generation results for both the task of image-conditioned generation and text-conditioned generation. The writing is also clear and easy to follow.',\n",
       "  'weaknesses': '1. The autoencoder network (Fig 1 a) is similar to the network used in [63]. Thus the performance boost shown in Table 1 seems to be because of CLIP. This should be emphasized or ablated somewhere in the main paper.\\n2. Following the above comment (Table 1), the authors only compared with \"Learned queries\" results from [63]. According to [63], another design \"Point queries\" achieved better results than both this work and \"Learned queries\".\\n3. It would be better if the authors can show some visualization comparisons of the autoencoding results.\\n4. L136, the length is (1+L_i) instead of L_i. This is explained in later sections (L217) but is still causing confusion.\\n5. Another difference with respect to [63] is, when training the diffusion models, this work used a unet-style transformer [4] instead of a simple stacked self attention network.\\n6. Some pieces of writing can still be improved. For example, when talking about a design or an equation, we should mention why we are doing this or discuss some insights behind this.'},\n",
       " 'review_585': {'summary': 'This paper proposes a conditional 3D generation method by pre-aligning features of different modalities when training a 3D AE. After that, a latent diffusion model is applied to generate latent vectors for 3D decoder conditioned on text/image. The results quantitatively and qualitatively shows that the proposed method is able to achieve impressive results.\\n',\n",
       "  'strengths': '1. The results show that this method is able to achieve multiple tasks, which is good and important for a generation-related paper.\\n2. The main figure is easy to understand and follow, making this paper easier to read. \\n3. The core idea in this paper looks original.\\n',\n",
       "  'weaknesses': '1. No qualitative results show the diversity of the proposed method. Such a result is important to a generation-related paper.\\n2. The concept of pre-alignment is not very convincing. Other conditional generation methods are also aligning text/image to the shape latent space by either pulling their representations together or learning diffusion models. Further discussion on how this concept is better than others should be added.\\n'},\n",
       " 'review_586': {'summary': 'This paper proposes a way to cast a variety of classification tasks into a single text alignment task. The authors found out that using the text alignment task could generate better results on certain downstream tasks, compared to Flan-T5 and GPT-3.5.',\n",
       "  'strengths': 'The paper presents a novel approach by framing everything as an alignment task. The results are good, and I think the verifier results are interesting.',\n",
       "  'weaknesses': 'I understand that the text-alignment model is not well-suited for generative tasks. Therefore, I believe that the conclusion of the paper is a bit unfair to Flan T5 and Gpt-3, which can be used for generative tasks. It is well-known that sometimes specialized small models can be performed better than by much larger general models. Somehow, the proposed method sounds like another trade-off. I think the proposed method is reasonable, but I believe that further research into different trade-offs would be beneficial.\\n\\n'},\n",
       " 'review_587': {'summary': 'This paper leverages the fact that a lot of popular comparison based NLP tasks like entailment, paraphrase detection, semantic similarity judgement, multiple choice passage based QA etc. amount to learning a specific similarity function between two sets of sequences that is a proxy for “information alignment” between the two sets. Hence, this paper gathers together public datasets for many such tasks and with some light rule-based data augmentation results in 5.9 training examples from 28 datasets. Then a moderately sized RoBERTa model is finetuned on this big comparison-based dataset which is then compared to task specific models and larger models like FLAN T5 on many such datasets. This model has also been used as a metric for measuring factual consistency of NLG models like summarization models. The authors also use this model to detect questions that are unanswerable from the accompanying context to boost performance of systems on some QA datasets.\\n',\n",
       "  'strengths': '– The paper is well-motivated and the large aggregated dataset and the model trained on it will be useful to the community for further study.\\n\\n– This model outperforms larger general models like FLAN T5 and is competitive with task specific finetuned RoBERTa models on various semantic comparison tasks (some of them unseen during training) which shows the effectiveness of similarity between various such tasks.\\n\\n– The results on summarization evaluation are promising and the usage of this model for identifying unanswerable questions is interesting.\\n\\n– The ablation study shows an interesting trend indicating that various comparison-based datasets and tasks are very similar and compatible with each other. This raises interesting questions related to the nature of these tasks and datasets.\\n',\n",
       "  'weaknesses': '– No comparison is made against specialized task-specific models. While fine-tuning RoBERTa on task-specific datasets is informative, a deeper insight into how the proposed model fares in comparison to more focused task-specific models will strengthen the comparison.\\n\\n– While this paper focuses on comparison and understanding tasks, it is compared to larger generative models that are specially designed for natural language generation. While these models show impressive performance on these understanding/comparison tasks, a more informative comparison would be against larger encoder-based models that are specifically trained to do well on these datasets and benchmarks like SuperGLUE. \\n'},\n",
       " 'review_588': {'summary': 'This work proposed a text alignment model for a wide range of tasks that aims to measure the degree of alignment between their information. To be more specific, 5.9M examples from 28 datasets are used to fine-tune RoBERTa model. Experimental results show that the text alignment-enhanced model delivers comparable or superior performance compared to larger LMs, validating the effectiveness of the proposed method.',\n",
       "  'strengths': '1. 5.9M examples from 28 datasets are extracted for LMs fine-tuning, and the experimental result on in-domain datasets (Table 1) and zero-shot setup (Table 2) demonstrate the effectiveness of Alignment-RoBERTa.\\n2. Experimental code has been submitted, benefitting future pre-fine-tuning research.',\n",
       "  'weaknesses': '1. The previous pre-fine-tuning work proposed combining multiple losses with different weights [1], which diminishes the technical contribution of this work in terms of pre-fine-tuning.\\n2. Additional synthetic data is needed, increasing the complexity of the proposed pre-fine-tuning method. Also, the ablation study and corresponding are insufficient in terms of how much contribution synthetic data makes to the overall performance.\\n3. Experimental setup is not convincing because of the contamination of the training set (seen task) and test set (unseen task). Task clustering is needed to remove the concern.\\n\\n\\n[1] https://aclanthology.org/2021.emnlp-main.468.pdf'},\n",
       " 'review_589': {'summary': 'While next word prediction produces task-general models that can do a wide variety of tasks when prompted, it is not an efficient formulation in that it requires very large models. On the other hand, fine-tuned models achieve higher performance at smaller sizes but are specific to a few tasks. This paper proposes text alignment as a middle ground that encompasses a wide range of tasks while allowing for smaller models than next word prediction. Concretely, they convert 28 datasets (encompassing tasks like entailment, IR, QA, coref, and consistency) into the text alignment format and fine-tune RoBERTa on them. The resulting model outperforms much larger models (that are instruction-finetuned), as well as RoBERTa with task-specific fine-tuning.',\n",
       "  'strengths': '(1) The idea of using text alignment as a task-general interface is interesting and seems useful for producing useful task-general models at smaller sizes.\\n\\n(2) The experiments are extremely thorough, and the method performs well across the board.\\n\\n(3) The paper is well-written and clear.',\n",
       "  'weaknesses': 'While this section contains some suggested experiments, I support the acceptance of this paper regardless of whether or not they are run during the rebuttal period.\\n\\n(1) While the paper frames alignment as being more general than multi-task finetuning, they only evaluate the model on tasks seen during alignment finetuning. Indeed, as shown in the task ablations in Table 5, it seems that the model can only do tasks that are included during training. Therefore, I wonder how different the model is from simply doing multi-task fine-tuning, and what clear advantages are provided by using a unified interface. While already strong, I think the results would be even stronger if there were examples of the model doing unseen tasks.\\n\\n(2) Related to questions of how general alignment is, the tasks included in the training and evaluation feel very close to entailment, which might be a key factor in enabling them all to use the same interface without task-specific heads. Therefore, I wonder how performance would be affected if tasks very far from entailment were included. (For example, you could include POS tagging, where x_1 is the original sentence and x_2 is the sentence with some or all of the words replaced by their part of speech.)\\n\\n(3) Related to the above, while the paper claims that changing the interface from next word prediction to alignment allows for smaller models, I wonder if the smaller model sizes are simply a result of considering a narrower set of tasks than the instruction-finetuned models. I suspect that FLAN-T5 needs larger model sizes simply because it needs more capacity to do more tasks. One relevant ablation testing this question would be to take the same RoBERTa model and instruction-finetune it on the same 28 datasets as the alignment model.'},\n",
       " 'review_590': {'summary': 'The main focus of the paper is on the comparison between the posterior predictive distribution and the frequentist risk associated with the maximum a posteriori estimator for random features ridge regression model. The target function is assumed to be a sum of a linear model, a non-linear function given by a Gaussian process with specific kernel (see assumptions), and an iid noise model with mean zero, constant variance, and bounded fourth moment (see Eq. 1). The technical part starts with a review of frequentist risk and empirical estimator, given in Eq. (7). This is followed by a Bayesian model that assumes normal prior on the weights and likelihood model that conditions on the random features and weights of the linear model (see Section 2.2). The posterior distribution is the Gaussian centered at the maximum a posteriori estimator with covariance matrix given in Eq. (6). This is standard for the weight space derivation of Gaussian processes. The posterior predictive at an instance x is given in Eq. (8) and is just variance at that point. The expected posterior predictive (EPP) is given in Eq. (9) and is obtained by taking the expectation relative to the instance space. The paper then provides an asymptotic characterization of EPP relative to prior work by Mei & Montanari (2022) on frequentist risk. Numerical simulations illustrate the difference between the two concepts and show the lack of double-descent phenomena in the Bayesian setup.',\n",
       "  'strengths': 'It is a nicely presented work with an interesting insight into random features and the differences between Bayesian and frequentist notions of uncertainty. The theoretical result is cumbersome to parse but still provides an interesting illustration and side-by-side comparison with Mei & Montanari (2022). Numerical simulations also support the theoretical conclusions. The discussion is also valuable, pointing at some of the shortcomings and directions for future research.',\n",
       "  'weaknesses': 'The assumptions might be constraining the problem setting strongly but still the results provide an interesting insight on what happens asymptotically. '},\n",
       " 'review_591': {'summary': 'This paper considers the random feature model. Two objects are studied: (1) The posterior predictive distribution (in particular, the variance), and (2) The MAP estimator. This paper gives asymptotic formulas for these two quantities under the proportional regime. Comparison between these two quantities are made, in terms of both theory and experiments. Their results suggest that the posterior predictive summaries can be very different from that of the generalization error. ',\n",
       "  'strengths': 'This paper is among the few works that address the following problem: Are the Bayesian credible sets also valide confidence sets in the frequentist sense. This is true in the finite dimensional setting with n \\\\to \\\\infty, while unclear in the high-dimensional setting. They give precise expressions for the two targeted quantities: generalization error and posterior predictive variance. They give rigorous results to show that these two quantities agree and disagree in different regimes. The presentation is nice and clear. Extensive simulation is conducted to justify several unproven claims.   ',\n",
       "  'weaknesses': '1. Their setting is a little bit restrictive: Only one specific prior structure is considered. Having said that, I understand that choosing this prior is for getting a precise asymptotic expression for the quantities of interest. \\n2. Their theoretical results seem like direct consequences of [Mei and Montanari 2022], perhaps the authors should highlight their technical contributions comparing to previous works. This is my major concern, and I will raise my score if this question is well addressed. '},\n",
       " 'review_592': {'summary': 'The authors compare in this paper the asymptotic posterior variance of the predictive risk in the random feature model  associated with a Gaussian prior on the weights with the  asymptotic \\\\textit{frequentist risk} which had been derived by Mei and Montanari.  The asymptotic here is in terms of the dimension d of the covariates, in a context where the number of features $N$ and the number of observations $n$ are comparable with $d$. This regime is often studied to understand the phenomenon of double descent. \\nThey derive under the same assumptions as in Mei and Montanari the asymptotic behaviour of the posterior predictive risk and show that in the \"wide\" regime, i.e. when N/d converges to infinity with low signal noise ratio or when n/d goes to infinity both risks (under the optimal choice of the hyperparameter $\\\\lambda$ for the frequentist risk) have the same limit while when N/d goes to infinity and the \"SNR \" $\\\\rho$ is larger than some threshold then posterior variance is asymptotically larger than the frequentist risk which is 0. The authors then perform a simulation study to understand more precisely the role of $\\\\lambda$ and the different asymptotic regimes. ',\n",
       "  'strengths': 'The comparison of the frequentist and the Bayesian approaches in  the double descent  types of regimes is a very natural question and treating the random feature model seems like the obvious first choice to attack the problem. The results derived by the authors seem correct and the simulations shed light on the results. The proofs are a consequence of the proofs of Mei and Montanari, but remain technical (at least the proof of Proposition 1). \\n\\n The posterior variance , as studied by the authors is strongly related to the radius of credible regions therefore understanding if the posterior variance is similar to the frequentist risk is a first step to understand if credible balls are confidence balls, as hinted by the authors. As noted by the authors this is not a full statement on coverage of credible balls and higher order asymptotics is required  to understand the frequentist coverage  of credible balls. ',\n",
       "  'weaknesses': 'What I am not so clear about is what is the conclusion/ consequence of the results obtained in this paper. In particular, the \\\\textit{frequentist} risk of Montanari is not really frequentist and in my opinion, it  has already a Bayesian flavour. The risk $\\\\|f_d - \\\\hat f\\\\|_2^2$ (which is in fact a loss function) is viewed in Montanari as stochastic both in terms of the data $X,Y$ appearing in $\\\\hat f$ but also in $f_d$ (not to speak of the randomness $\\\\Theta$) and its asymptotic behaviour is under this regime. Hence, it would be interesting to have a proper discussion of the different notions of risk which are considered in the paper. I also think that the authors do not comment enough on why in some regimes the two risks are equivalent and not in others. Some description in terms on $\\\\tau$ (noise variance ) being large or small in the wide regime is provided but no real interpretation. \\n\\n\\n\\n That being said I still find the results interesting, but I am uncertain after reading as of to what ot make of them. '},\n",
       " 'review_593': {'summary': 'The authors study random feature (RF) regression in the high-dimensional setting. \\nThey focus on comparing the variance of the Bayesian posterior distributions (a measure of uncertaintiy in the Bayesian setting) to the variance of the maximum-a-posteriori estimator (a measure of uncertainty in the frequentist sense, and the generalisation error, already studied in previous work), motivated by previous work showing a discrepancy in the two quantities in the high-dimensional setting. They ask whether the two quantities have the same high-dimensional asymptotics.\\n\\nTha authors compute the high-dimensional asymptotic of the variance of the Bayesian posterior distribution. \\nThey find that it equals the variance of the maximum-a-posteriori estimator only in the region where the optimal L2 regularisation is not vanishing in the strongly overparametrised case, and that they always match in the large sample complexity regime, close to the classical low-dimensional limit.\\n\\nThe authors study numerically the fluctuations of the two observables studied, and conjecture that they are Gaussian distributed, and such distribution have non-overlapping support around the interpolation threshold.\\n\\nComment: \\nThe main proof seem a minor variation on reference \"Mei and Montanari, 2022\". \\nA reader familiar with that work (which I am not) should be able to easily tell whether the proof of the results of the authors is correct. \\n',\n",
       "  'strengths': '- The authors compare Bayesian and frequentist notions of variance-like observables, computing a novel characterisation for one such variable. They also provide interesting numerical observations of the flucuations of such variables, proposing a number of new conjectures.',\n",
       "  'weaknesses': '- The paper is not badly written overall, but many details (see list below) could be improved.\\n- The authors provide no code to reproduce their figures.'},\n",
       " 'review_594': {'summary': 'Convergence and implicit bias of non-linear networks is an important open question in deep learning theory.  The paper studies these questions in the case of regression with ReLU networks with a single teacher neuron. It proves that at a vanishing initialization scale the student neurons align with the teacher (or gets deactivated). It also shows an interesting counter example such that the implicit bias as initialization tends to zero need not be a minimum norm interpolator. ',\n",
       "  'strengths': 'a) Going beyond the orthogonal data, the paper proposes an interesting setting which helps analyse the case of correlated inputs. \\n\\nb) The geometric technique to study the convergence after the alignment phase is novel. \\n\\nc) The scenario proposed where the implicit bias as $\\\\lambda \\\\to 0$ is a rank minimizing one instead of a minimum norm interpolator is a very interesting contribution. ',\n",
       "  'weaknesses': 'a) The setting is simplified: there is only a single teacher neuron and all the labels are only positive. It directly that neurons (at least yardstick neurons) with negative last layer decreases in norm. The assumption that the inputs are correlated further ensures that they are deactivated. This makes the analysis easier.  \\n\\nb) The technical analysis follows the same strategy as Boursier et. al. Some aspects are easier as there is only one saddle to escape. '},\n",
       " 'review_595': {'summary': 'This paper studies how a two-layer ReLU network can fit a single neuron. The authors consider the case where all \\ntraining points are correlated with the teacher neuron and show that gradient flow from small initialization can \\nconverge to a zero-loss solution. \\nThey divide the training into two stages. In the first stage, the neurons are small and will align with the teacher \\nneuron or deactivate, depending on the sign of the output weight, and in the second stage, the aligned neurons will grow \\nand fit the target function. \\nIn addition, they show that as the initialization scale goes to $0$, gradient flow converges to a rank-$1$ solution. ',\n",
       "  'strengths': '* Overall, the presentation is clear, and the main text is relatively easy to follow (see the weakness part of the \\n  review for some minor issues.) \\n* The use of the yardsticks $\\\\omega_j$ is interesting.\\n* The geometric argument for the second phase seems novel and may be of independent interest. \\n* Theorem 8, which shows the set of balanced rank-1 interpolating networks and the set of minimum-norm interpolating \\n  networks can be the same or disjoint, depending on a certain quantity, is surprising. ',\n",
       "  'weaknesses': \"* The presentation is overall clear, but the notations are cumbersome. \\n  * For example, I don't think using $w$ and $\\\\omega$ simultaneously is a good idea, especially when they co-occur a lot \\n    and represent two closely related objects. \\n  * The detailed definitions of $\\\\delta$ and $S_l$ can be moved into the appendix, and define them informally in the \\n    main text and maybe briefly explain how small can $\\\\delta$ be and the intuition behind $S_l$. \\n* I personally don't like the $\\\\exp(-n)$ initialization scale, though I will accept it as it has been used in previous \\n  works. I think it is somewhat cheating because, with it, you can make sure the norm of the neurons is sufficiently small \\n  so that you can ignore them for any polynomially long time. \\n* The setting is quite restricted and unrealistic as it requires the angle of all inputs and the teacher vector to be \\n  smaller than $\\\\pi / 4$. \"},\n",
       " 'review_596': {'summary': 'The paper studies the problem of learning a single ReLU using a 2-layer ReLU network using gradient flow on both layers. The main assumption is that the data is correlated with the target neuron, while other milder assumptions are also used (e.g. specific initialization and spectral assumption on the data matrix). The main result is a two-phase convergence to a global minimum. Several experiments are also given.\\n',\n",
       "  'strengths': '- The main convergence result is novel AFAIK, and shows an interesting convergence dynamic, where in the first phase the learned weights either align with the target neuron or deactivate, and in the second phase converge to a global minimum. \\n- The connection between the global minima of the problem and the minimal norm solution in Section 7 is interesting and brings forward the question of whether minimizing the empirical loss results in a minimal norm solution, which was studied in previous works too (e.g. Vardi et al 2022).\\n- The experimental part shows empirically the behavior of the angles between the learned weights and the target neuron.\\n',\n",
       "  'weaknesses': '- The assumption that the data is correlated with the target neuron is pretty strong. The motivation for taking an angle of at most \\\\pi/4 between each data point and the target neuron is also not clear. What changes if the angle is larger\\\\smaller? I think the authors should elaborate more on this assumptions, and what breaks if it is not assumed. To compare, other papers about studying a single neuron usually consider a data distribution spread in all directions (e.g. Frei et al. 2020, Yehudai & Shamir 2020).\\n- The presentation of the main result is not clear. I think there should be a single Theorem stating the convergence result, with an explicit convergence rate. Currently, there is no single result just a lemma for each phase, and it is difficult to parse the main out-take of the paper. In such a paper, I think the convergence rate of the entire procedure is crucial to fully understand the quality of the result.\\n- The paper is very technical, and in my opinion, doesn’t provide enough intuition to understand the quantities that are used. For example, the definition of \\\\delta in line 238. Can’t \\\\delta be zero or at least exponentially small (if the angle between two data points is very close to \\\\pi/2).\\n- The result in Section 7 is interesting but not quite clear. What does the quantity M represents? What can we say about the dataset itself so that either option (i) or (ii) of Theorem 8 is applied?\\n- I think that claiming that the implicit bias for the problem studied here is to minimize the norm is a bit misleading. As I understand it, all the learned weights either align with the target neuron or deactivate, this means that the solution converges to a specific form of rank-1 matrix (where each row is either v^* or 0). \\n'},\n",
       " 'review_597': {'summary': 'The authors analyze the dynamics and implicit bias of gradient flow with the square loss when learning a single ReLU neuron using a one-hidden-layer ReLU network. They assume that the training data are correlated with the teacher neuron (the angles are smaller than $\\\\pi/4$), and that gradient flow starts from a small and balanced initialization. They give a non-asymptotic convergence analysis. In the limit where the initialization scale tends to zero, the resulting network has rank $1$. Namely, all non-zero neurons point in the direction of the teacher neuron. On the other hand, the resulting network might not have minimal Euclidean norm. Thus, there is an implicit bias for rank minimization but not for norm minimization.',\n",
       "  'strengths': 'Understanding convergence and implicit bias in overparameterized networks is an important question, that has attracted much interest in recent years. The paper gives a detailed analysis of the trajectory and implicit bias. The analysis is under strong assumptions (single-neuron teacher, correlated training data, small and balanced initialization, etc.), but these assumptions are present also in existing results, and the analysis of gradient flow is challenging even under such assumptions. Finally, the paper is well-written.',\n",
       "  'weaknesses': 'In Assumption 1: \\n- Item (iv): why is it a measure-zero event?\\n- Items (iv) and (v): I think that the assumptions should specify properties of the training data and the training algorithm. Then, the properties of the trajectory should be shown using these assumptions. Can you specify items (iv) and (v) as assumptions on the data+algorithm?\\n\\nOther than that, I don’t have major concerns. An obvious limitation is the strong assumptions, and specifically the assumption on the correlated training data, but as I already mentioned, I think that it is reasonable here.\\n'},\n",
       " 'review_598': {'summary': 'The authors used prior fitted networks to perform learning curve extrapolation. Crucially, they demonstrate that their method vastly outperforms approximate Bayesian inference via MCMC (both in terms of inference time and predictive log likelihood). Moreover, they demonstrate that the proposed approach outperforms heuristics for ending unpromising training runs commonly used in hyper-parameter optimization.',\n",
       "  'strengths': 'This paper prevents a super practical method that not only performs well *but* also runs fast, allowing it to be used in many real-time applications. The practicality of the method is extremely bolstered by the impressive suite of empirical experiments performed. Lastly, the paper was written well and was pretty easy to follow (though I have some comments).',\n",
       "  'weaknesses': \"The biggest weakness to me is that I don't think the authors spent time on the potential difficulty of using MCMC for this problem. Specifically, the prior, and the corresponding posterior, is constrained on some non-standard subset that prevents standard MCMC algorithms to be used. The geometry of this will heavily affect the performance of MCMC algorithms as samples that are proposed outside of the set will always be rejected requiring substantial tuning. That being said, I am a little concerned with the number of samples the chain was run: 4,000 samples seems too low for this problem.\"},\n",
       " 'review_599': {'summary': 'The authors propose applying prior-data fitted NNs to learning curve extrapolation.\\n\\nThe authors demonstrate that this approach outperforms MCMC inference and is substantially faster.\\n',\n",
       "  'strengths': 'The paper has a novel idea of applying approximate inference via meta-learning learning curves.\\n\\nThe method appears to work in experimental evaluation, but more experiments would make the paper stronger.\\n\\nThe manuscript (all but experimental section) is clear and relatively easy to follow.\\n\\nThe authors provide the code.\\n\\n',\n",
       "  'weaknesses': 'The paper contains only two experiments. One is based on synthetic data.\\n\\nTable 1 has no error bars. Table 1 indicates that while the performance of MCMC is stable across the hyperparameters, PFN score is dependent on the network size indicating it might not generalize well to other problems.\\n\\nWhile the difference in time is clearly significant, the differences in LL are rather small.\\n\\nWhile the idea of applying the described method in the considered context is novel, much of this work is a combination of previous work by Domhan 2015 and Muller 2022.\\n\\nThe experimental section could have been written in a more clear way.'},\n",
       " 'review_600': {'summary': 'The authors in this submission applied the prior-data fitted neural networks (PFNs) in the learning curve extrapolation task, for which the main goal is to predicit the performance of a machine learning model in later epochs, based on the information from earlier epochs. The target is modeled as a linear combination of basis growth curves, and the proposed LC-PFN algorithm aims to minimize the cross entropy loss as in PFN. The authors tested the proposed method across a few datasets and showed that PFN (i) achieves better prediction and (ii) is computationally efficient, when compared with its competitors.',\n",
       "  'strengths': '1. The idea of applying PFNs in the learning curve extrapolation task sounds reasonable, and is intuitively more efficient when compared with MCMC.\\n\\n2. The application of LC-PFN in early stopping could be valuable, as it can be helpful for the model selection step. The experiments in Section 4.3 also provide some promising results. ',\n",
       "  'weaknesses': \"1. In my opinion the selection for the 3 parametric basis curves seems a bit ad-hoc. It's not convinving whether they are sufficient to fit different learning curves. Furthermore, selection of hyperparemters in priors there also lacks details.\\n\\n2. The results could be more convincing if the authors can compare aganist more previous methods, instead of MCMC only. For instance, how about the one by Klein et al., 2017, which used Bayesian neural networks for learning curve prediction?\"},\n",
       " 'review_601': {'summary': 'The authors consider the task of learning curve extrapolation, i.e., the aim is to predict the performance of a given model wrt. e.g., accuracy/log-likelihood over time, given current observations.\\nTheir proposal primarily relies on Prior-data fitted networks (Müller et al., 2022) trained on samples from a prior set of curves adapted from their sole comparison method by Dunham et al. (2015). \\nCompared to this prior MCMC-based method (Dunham et al., 2015), the authors can show greatly improved performance in most setups as well as very strong improvements in runtime.\\n',\n",
       "  'strengths': '- The paper focuses on an important task in the AutoML literature that has so far not received a lot of attention.\\n- The authors evaluate their approach extensively on a varied set of experiments properly evaluating all their claims.\\n- The paper is overall well written with two minor deficiencies (see next section). \\n- The authors provide an extensive implementation of the model. However, it is also necessary as replicability would be difficult given the coarse level of detail in the written part.\\n- With respect to originality. The contribution is primarily in the application. The model itself relies on the PFN model by Mueller and the prior is an adaptation of Dunham et al.\\nThis can be seen as a weakness, yet given that the application of PFNs to this field is novel and the application is an important one with clear results, I see this only as a very minor weakness if at all.\\n- Concerning significance, I lack a deep understanding of the AutoML literature to properly judge the significance. But from what I know of the field, the results look very promising and should be of great interest to many readers.',\n",
       "  'weaknesses': '- It has two deficiencies in the writing/structure of the paper. \\n   1.  Its backbone is a prior-data fitted network. However, that model itself is only briefly introduced in a single paragraph with a figure that is barely understandable without reading the original paper.\\nThe paper requires a proper discussion of this approach in either the main text or the appendix. \\n   2. Training details and hyperparameters are barely discussed with many essentials missing, e.g., the reader has to guess the meaning of `nb_data`, `emsize`, `nlayers`. It is an easy guess, but a guess nevertheless. Adding the abbreviations to the paragraph in l157 would quickly fix this.\\n- As stated above, the novelty is almost solely in the application which could be considered a weakness. But in my opinion this is only a very minor weakness if at all.\\n- Table 3 lacks error bars.\\n\\n## Minor\\n- Figure 2 is missing details on the colors of the arrows \\n- The caption of Table two should be above\\n- Figure 3 contains an unexplained horizontal line\\n- l319-320 the sentence is broken (interesting appears twice)'},\n",
       " 'review_602': {'summary': 'I have reviewed the rebuttal, and I intend to maintain my decision. I appreciate the authors made the efforts to clarify most of my concerns. However, I believe it is essential to address the issue of hardware noise in the present study, a point that previous research seems to have overlooked. I strongly encourage the authors to delve deeper into this matter, as a robust algorithm should be capable of practical implementation on real quantum computers. I believe the issue of hardware noise is actually an inescapable and important challenge here.\\n\\nThis manuscript presents an innovative approach known as EMICoRe, which leverages the synergy between Bayesian optimization and prior knowledge of variational quantum eigensolvers (VQE) to enhance the efficiency of the optimization. The authors introduce a novel kernel specifically designed for Bayesian optimization and employ it within the EMICoRe framework. Additionally, the paper conducts numerical experiments to compare the proposed method with the state-of-the-art baselines, demonstrating its superior performance.',\n",
       "  'strengths': '- The manuscript introduces a novel optimization algorithm based on Bayesian optimization that incorporates the specific property of the VQE objective function into its design.\\n- The paper is well-organized and clearly written. The figures in the paper effectively illustrate the improved performance achieved by the proposed method in comparison to the baselines.\\n- The paper establishes the equivalence between two previously proposed VQE properties, providing a foundational basis for the subsequent analysis on VQE objective functions.',\n",
       "  'weaknesses': '- The numerical results presented in the paper indicate that the proposed method does not exhibit a clear advantage when the number of observed points is limited, as compared to the baselines.\\n- Although the proposed method exhibits improved performance compared to the baseline as the number of observed points increases, it still falls short of achieving the ideal ground state.\\n- The proposed method just considers the shot noise but ignores possible noise originating from the quantum circuit itself.'},\n",
       " 'review_603': {'summary': 'The authors propose a method for Bayesian Optimization for Variational Quantum Eigensolvers, which they call NFT with EMICoRe.  This method uses a novel VQE kernel, which constrains the function space of the Gaussian Process underlying the BO to include only valid VQE objective functions (using the representation in Prop. 2, derived from NFT).  The authors also propose a novel acquisition function for the EMICoRe method (Eq. 11), which optimizes over the expected maximum improvement over confident regions.  In their experimentation, the authors show that their VQE kernel is able to outperform other kernels in a BO setting, and that their NFT-EMICoRe approach is able to outperform other (non-BO) NFT approaches.',\n",
       "  'strengths': 'The paper tackles an important problem, the optimization of noisy VQE circuits, and offers a principled solution using BO combined with physical constraints, using state of the art methods (NFT).  The paper is well written, and the experimentation is well chosen to support the method.',\n",
       "  'weaknesses': 'The experimentation could be expanded.  Particularly, it would be interesting to see how the model performs on an actual quantum implementation.  Also, investigation of a broader ranger of Hamiltonians would be desirable (including ones motivated by practical problems).'},\n",
       " 'review_604': {'summary': 'In this work, the authors integrate a quantum kernel method with the EMICoRe architecture to further improve the NFT framework of Bayesian Optimization. The simulation results show the advantages of the proposed approach. ',\n",
       "  'strengths': '(1) The method of leveraging the quantum method for Bayesian Optimization is interesting. \\n\\n(2) The investigation of how to incorporate the quantum kernel method is significant. \\n\\n',\n",
       "  'weaknesses': '(1) Since no parametric circuits are implemented in the quantum kernel model shown in Eq. (9), the proposed VQE-kernel is nothing but a quantum kernel learning method, which has been comprehensively studied in previous work in Refs. [1-3]. In particular, Ref. [4] has exhibited the use of quantum kernel learning for improving the performance of Bayesian optimization. --- resolved\\n\\n(2) The circuit diagram for the quantum kernel learning is not provided such that the experiments cannot be easily reproduced. --- resolved\\n\\n(3) There are two main contributions to this work: the use of quantum kernel learning and an introduction to EMICoRe. Although the simulation results demonstrate the performance improvement, it is still unknown where the performance gains come from, and the quantum advantages of the quantum kernel are not analyzed at all. --- resolved\\n\\n[1] Havlíček, Vojtěch, et al. \"Supervised learning with quantum-enhanced feature spaces.\" Nature 567.7747 (2019): 209-212\\n\\n[2] Wang, Xinbiao, et al. \"Towards understanding the power of quantum kernels in the NISQ era.\" Quantum 5 (2021): 531\\n\\n[3] Blank, Carsten, et al. \"Quantum classifier with tailored quantum kernel.\" npj Quantum Information 6.1 (2020): 41\\n\\n[4] Rath, Yannic, Aldo Glielmo, and George H. Booth. \"A Bayesian inference framework for compression and prediction of quantum states.\" The Journal of Chemical Physics 153.12 (2020)'},\n",
       " 'review_605': {'summary': 'The paper introduces a new approach for BO of VQEs. BO can be a good match for this problem since it models the noise (measurement and circuit level) of quantum circuits. The main idea of the paper is to use a kernel that is adapted to the form of the VQE objective assumed when variational parameters are associated to single qubit gates. The paper also introduces EMICoRE and NFT-with-EMICoRE, acquisition function and parameter update strategies. Overall, the idea of using an adapted kernel for this task is well motivated, the paper is well written and presents numerical evaluation of their method. I think however that in the current state, the experimental evaluation is too limited to be convincing of the promise of this method with respect to other optimisation algorithms for VQEs.',\n",
       "  'strengths': 'The paper addresses an important problem in quantum computing. It is well written and accessible for both quantum computing and ML communities I think. It introduces the following technical innovations:\\n- Kernel adapted to VQEs: the kernel decomposition based on the form of the cost function of VQEs is a sound contribution.\\n- NFT-with-EMICoRE: a new BO algorithm that builds on NFT and a new acquisition function.\\n\\n',\n",
       "  'weaknesses': '1. Specific ansatz: the paper deals only with parametrised single qubit gates. While I believe this is not a theoretical limitation - as one can always decompose any unitary as a product of single qubit gates and CNOTs - it is not clear to me how practical is this parametrisation. The authors could add an explanation of whether this is a limitation for practitioner and what steps one needs to do to apply their algorithm to a generic parametrised quantum circuit\\n2. Limited experimental evaluation: the paper only discusses Q=3 and 5 qubit systems, while classically one could simulate easily bigger systems. Also the paper does not compare against other methods in the literature, it only compare against NFT. More benchmarking for larger systems and against other techniques would be required to assess the promise of the method. \\n3. Unclear benefit of the kernel: looking at figure 2, it is unclear that the red curve is better than blue curve - in fact on the left figure it looks to me that RBF is doing better.\\n4. Missing ablation for the EMICoRE acquisition function. One contribution of the paper is to introduce this new acquisition function, but ablations showing its importance are missing.\\n\\nMinor:\\n- $\\\\mu_X$ depends on y as well in section 2.1\\n- \"the the\" in line 308\\n- unclear what conjugacy means in line 97'},\n",
       " 'review_606': {'summary': 'The submission proposes an approach to improve model monitoring by rather evaluating changes in explanations instead of input features. The authors provide synthetic examples to justify their method and compare it empirically to existing strategies on tabular datasets. ',\n",
       "  'strengths': ' - The paper addresses an important topic as effective model monitoring based on unlabeled data only is a relevant problem.\\n - Although rather, simplistic the synthetic examples help to get a rough idea about the potential benefits of explanation monitoring.\\n - The authors provide code as well as tutorials on how to apply their method to ensure reproducibility.\\n',\n",
       "  'weaknesses': ' - The theoretical analysis is extremely limited such that the overall assumptions under which the proposed method can be expected to yield actual benefits are too vague. Also, the basic notations section seems a bit inflated. \\n - I think the novelty is limited as well. Monitoring feature attributions instead of input data is not new and is already offered by popular ML service providers. See for instance here the functionality implemented by Google (https://cloud.google.com/vertex-ai/docs/model-monitoring/monitor-explainable-ai). I would have also liked to see such an alternative approach to use explanations for monitoring somewhere included in the experiments.\\n - The conducted numerical experiments are not sufficient to demonstrate the benefits of the proposed approach. If only considering tabular data I think including more than 3 actual datasets and 4 prediction tasks is necessary to be convincing. This is especially true for methods where rigorous theoretical analysis is challenging. See also the question below for further suggestions. \\n - The evaluation section is hard to follow, and lacks formulation of insights derived from the experimental results, e.g., it is unclear what benefits can be derived from the feature importance in Figure 4. Given the lack of baselines and justification for those explanations, it is also not clear if they represent useful insights into the effect of a distribution shift on the model’s behavior.  Also, Table 1 comes out of nowhere and is not described sufficiently.\\n - Given the limited theoretical and empirical investigation the submission does in my opinion not make a significant contribution to the field.\\n'},\n",
       " 'review_607': {'summary': 'Detecting shifts in data distribution between training and deployment is critical for ensuring models function as intended and operate in their domain of applicability. However, detecting such shifts is challenging. In this paper, the authors propose an approach based on techniques from the explainability literature. They define the concept of explanation shift and introduce an Explanation Shift Detector. They validate their approach on a synthetic data and 4 tabular datasets, demonstrating improved performance over a range of baselines. ',\n",
       "  'strengths': 'The paper is well written, the introduction well motivated, and the formalism both precise and easy for the reader to follow. I found the method interesting, and the analysis of explanation shift detailed and informative. I think this work is a meaningful contribution to the literature.  \\n',\n",
       "  'weaknesses': 'The experiments were only conducted on several, relatively simple, tabular datasets. Demonstrating the method for another modality would strengthen the paper.\\n\\nPlease see Questions below. \\n'},\n",
       " 'review_608': {'summary': 'This paper uses explanation shift as a way to detect different types of distribution shift between the training set and unseen (test) data sets. The method is based on measuring the changes between the explanation provided by an explanation approach such as Shapley values, for the two data sets for a trained model. As such, the two data sets could be statistically similar but appear different from the model’s perspective. Overall, the proposed approach is novel and interesting but the paper needs to be improved. ',\n",
       "  'strengths': 'To the best of my knowledge, this is a novel approach that uses explanation to detection distribution shift. The proposed method is clear and the method seems to be effective in practice.',\n",
       "  'weaknesses': 'Section 4.1 provides examples where the proposed method works but simple distribution shift evaluation fails. But this does not provide any guarantee whether in general the proposed model is better or not. The same is true for Section 4.3. Section 4.2. provides a disposition but as mentioned by the authors, the prediction shift implies explanation shift, but the opposite is not true. Thus, no conclusion can be ae when there is an explanation shift.  \\n\\nEven though the authors compared their proposed model with the baselines on the synthetic data set in Section 5.1, they have not done it using any real data sets. The real data set is mainly used to study the sensitivity of the model on the parameters. \\n\\nThere is lack of consistency in notation used in the paper that makes it more difficult to follow. Notation changes from one section to another, and in some extreme cases from one example to another. Here are some instances:\\n1-\\tVal function is defined differently in Equation 1 and 2. \\n2-\\tEquation 3 is not clear and not explained either. What is the expected value is defined on? If it is X, why the notation differs from Equation 2?\\n3-\\tThere is a sign used in Example 4.2 which is not defined. \\n\\n\\nThe paper benefits from a round of proof-reading.\\nLine 143: out approach –> our approach\\nLine 182: a hard tasks --> a hard task (the sentence that includes this is also not clear and needs explanation)\\nLine 279: AppendixE.1 --> Appendix E.1\\n'},\n",
       " 'review_609': {'summary': 'This paper introduces a new concept called \"explanation shift\" for detecting shifts in data distributions with the changes of the attribution distributions on machine learning models. The authors argue that current methods for detecting shifts have limitations in identifying changes in model behavior. Explanation shift provides more sensitive and explainable indicators for these changes. The paper also compares the proposed method against other methods for detecting distribution shifts in both synthetic and real datasets.',\n",
       "  'strengths': '+ Leveraging the changes of explanations as a manner of detecting the distribution shift is a novel idea.\\n+ The authors provide a compreshensive analysis to show the connections between explanation shift and various distribution shifts, which could be helpful for readers to understand how to use explanation shift to detect distribution shift',\n",
       "  'weaknesses': '+ The overall presentation is not clear and many key terminologies and notations are not well explained or defined. For example, in Equation (3), what is $x^*$? What is the formal definition of $S(f_{\\\\theta},x)$? What are the definitions of \"sensitivity\" and \"accountability\" which are used as evaluation metrics in Experiments? The lack of clear presentations of these terms makes me extremely hard to understand the key information in this paper\\n+ Although the authors proposed a new concept called \"explanation shift\", the technical contribution is still very limited. First of all, the method proposed for detecting the explanation shift (i.e., Section 3) is very simple. But the authors failed to justify why this is an effective method from the theoretical perspective by comparing it against other methods. \\n+  Some key empirical studies are missing. In Section 5.3, the authors evaluate their methods on some real datasets to detect novel group distribution shift and geopolitical and temporal shift. However, the authors did not perform the same experiments by using baseline methods. Thus it is unclear whether those baseline methods can discover the same types of shifts or not. If yes, then what are the benefits of the proposed method? If not, why are those baseline methods unable to find out those shifts?'},\n",
       " 'review_610': {'summary': 'The paper proposes ESPL, a method for learning symbolic policies in environments with low-dimensional state spaces. ESPL uses a densely connected neural network structure (like DenseNet), where the activations in each layer are replaced with a hand-picked set of functions, such as multiplication, division, log and and exp. Second, ESPL uses the Gumbel-Softmax trick to learn a masking function with a minimal $L_0$ norm. This function ensures that the method learns compact symbolic policies by masking out redundant pathways in the neural network. ESPL is shown to be 100 to 1000 times more sample-efficient than a prior symbolic learning approach in single-task RL. The authors also propose a version that can be conditioned on task context for meta-RL.',\n",
       "  'strengths': '1. The proposed method is well motivated and clearly explained. $L_0$ regularization of the parameters of Bernoulli random variables is an elegant approach to learning compact symbolic expressions.\\n2. In single-task RL, ESPL outperforms a prior symbolic learning approach $DSP^0$ with between 100 and 1000 fewer training samples.\\n3. A task-conditioned version of ESPL called CSP outperforms prior (non-symbolic) approaches in a meta-learning setup. The authors point out that the symbolic policies are much faster to run than the baseline neural net policies.\\n4. Source code is included.',\n",
       "  'weaknesses': '1. The discovered symbolic policies in Table 1 seem to be somewhat more complex than the policies from $DSP^0$. It could be useful to additionally measure the complexity of the discovered policies for the various methods (if such measure exists).\\n2. It is not very clear how much effort went into hand-picking the activation functions in each layer of the network. Is it necessary to hand-design a different network for each experiment / environment?\\n\\nMinor:\\n* Missing space before `(` and `[`. This is repeated at least 10 times throughout the paper, e.g. lines 33 and 34.\\n* Line 109: repeat what ESPL stands for.\\n* Line 210: mixing up $t$ and $T$.\\n'},\n",
       " 'review_611': {'summary': 'The paper \"Efficient Symbolic Polmicy Learning via Gradient Descent\" proposes a new neural symbolic architecture for agents learned via reinforcement learning. Authors propose an architecture with an alternance of symbolic and linear layers. To finally obtain simple expressions, a probabilistic mask is learned altogether with parameters, enabling the production of sparse archiectures resulting in small expressions. The approach is experimented on classical RL settings, and also on meta-rl ones. ',\n",
       "  'strengths': '- Very interesting architecture\\n- Proposals look innovative\\n- Clever way to obtain sparsity\\n- Convincing experiments about efficiency ',\n",
       "  'weaknesses': '- I cannot understand, if the architecture is new, why authors did not experiment it on classical supervised learning (eg, on classification tasks) before such much more reinforcement learning setting. Is the architecture only new in the field of RL ? Is the main contribution of the paper the archiecture or its application to RL and meta-RL ?\\n- I feel that lacks important details about the used archiectures (for instances q is not defined, nothing is said about the choice of symbolic operators, nor about their numbers n and m, etc.)\\n- Not much results about explanability, which is one of the main goal of the proposal'},\n",
       " 'review_612': {'summary': 'This paper proposes to apply differentiable symbolic regression for policy learning. It shows promising results in multiple RL environments (including good average performance and learned interpretable symbolic policies). ',\n",
       "  'strengths': 'This paper shows promising results of differentiable symbolic regression in eight RL environments. The model design is intuitive and is shown to achieve good average performance, learn interpretable symbolic policies, and be less likely to overfit for OOD generalization in the meta-RL setting. The model is also more sample efficient than a previous neural symbolic regression model for policy learning. ',\n",
       "  'weaknesses': 'Nevertheless, the model is less novel as similar techniques have been explored in domains such as differentiable interpreters (e.g., Terpret [1] or DiffForth [2]) for program synthesis and Dart [3] for neural architecture search/pruning. \\n\\nThere are also concerns regarding the experiments:\\n* Symbolic methods are reported to perform better than neural ones even for single-task RL settings, which is counter-intuitive. There should not be overfitting problems in the naive setting, as far as I understand. Why would symbolic methods outperform neural ones? \\n  - I find this in appendix, lines 123-124, which seems relevant but could be unfair:\\n   > For all the environments, the proposed ESPL performs 3 independent training runs and selects the single best policy.\\n  - I also find that they may report averaged performance over multiple runs, which may not be necessary or standard for the single-task RL setting. \\n* Overall, the descriptions regarding evaluation procedures are vague, e.g.,\\n  - it\\'s unclear whether the final policies evaluated in Table 2 are symbolic or not; and\\n  - how to select policies in Table 1;\\n\\n\\n[1] Gaunt, Alexander L., et al. \"Terpret: A probabilistic programming language for program induction.\" arXiv preprint arXiv:1608.04428 (2016).\\n\\n[2] Bošnjak, Matko, et al. \"Programming with a differentiable forth interpreter.\" International conference on machine learning. PMLR, 2017.\\n\\n[3] Liu, Hanxiao, Karen Simonyan, and Yiming Yang. \"Darts: Differentiable architecture search.\" arXiv preprint arXiv:1806.09055 (2018).'},\n",
       " 'review_613': {'summary': '#  I have reviewed this draft once before. \\nThis paper proposes a meta-RL method to generate explainable symbolic policies. ESPL contains a symbolic network in the search space and a path selector to find the compact symbolic policy.\\n',\n",
       "  'strengths': 'I think there exists some novelty in ESPL because it contains symbolic + neural structures. Also, the symbolic policies induced by ESPL seem to be effective. The number of experiments is enough. The visualizations are cool.',\n",
       "  'weaknesses': \"Post rebuttal: I upgrade my score to a borderline accept because of the reasonable rebuttal.\\n\\nAlthough I originally leaned to accept this paper, I think the suggestions from the previous conference are not incorporated, and the draft is not improved much, so this time, I have to vote for rejection.\\n\\nThe major concerns are: \\n\\n(1) The proposed symbolic policy looks messy and it does not improve the interpretability much. Also, there could be many optimal policies.\\n\\n(2) The CatPole and other approaches have guaranteed optimal policy. The theoratcal analysis is missing. \\n\\n(3) The authors should try other discrete environments or complicated environments with rich semantics.\\n\\nI feel sorry for this paper. It was very close to acceptance last time but the AC insisted that the novelties were not enough. I don't think a resubmission without major modifications can get this paper in.\"},\n",
       " 'review_614': {'summary': 'The authors propose a Pruning at Initialization (PaI) method that considers the balance between the number of effective nodes and effective paths. This design principle is based on the observations on the NAS benchmark as well as layer-wise reshuffling. The pruning problem is nicely formulated as a multi-objective optimization problem. The experiment results show that the proposed method NPB outperforms the state-of-the-art method PHEW in some configurations.',\n",
       "  'strengths': '* A new Pruning at Initialization (PaI) method is developed considering both the number of effective nodes and the number of effective paths.\\n* A lot of analyses and experiments have been conducted to show the superiority and motivation of the proposed method. \\n* The pruning problem is formally transformed into a multi-objective optimization problem.\\n* In some settings, the proposed method NPB is shown to outperform the state-of-the-art method PHEW.',\n",
       "  'weaknesses': \"The motivation and technical details are not very clear in several places, as follows.\\n\\n**Overall:**\\n* The sweet spot of the proposed framework seems to be the extreme sparsity regime (> 99%).  I am really wondering if we need to prune a network to the extreme. My impression is that the sweet spot is a corner case.\\n\\n**Section 3.3:**\\n* Line 187: Why does reshuffling make subnetworks wider?\\n* Line 205: How is the hypothesis derived from reshuffling?  PaI actually does *not* involve reshuffling.  \\n\\n**Section 4.1:**\\n* Figure 4 (and Figure 1): It seems that, in typical architectures, the number of effective nodes and the number of effective paths are strongly correlated.  Then, why do we need to balance these two metrics?\\n* Line 223: Along the same lines, the strong correlation between the two metrics indicates that one of them is redundant. Thus, the overall claim cannot be supported by the observation.\\n* Figure 4 (and Figure 1): What's the meaning of each value in the x- or y-axis?  For example, what do you mean by $9.0$ in the x-axis?\\n\\n**Section 4.2:**\\n* Due to the strong correlation between the number of effective nodes and the number of effective paths, it may be unnatural to produce subnetworks with too many effective paths (or nodes) and too few effective nodes (or paths).\\n\\n**Section 4.3:**\\n* Even though it is reasonable to balance these two metrics, their ranges significantly differ. Actually, they have completely different scales (natures). This *incompatibility* between the two metrics would explain a very small value of $\\\\alpha$=0.01. Syntactically, Equation (4) does not achieve the balance, but mainly considers only $f_p$. Also, $\\\\alpha=0.01$ is indeed arbitrary and does not provide any insight on the optimal balance. \\n* Appendix G (Ablation Study): Figure 8 shows that the accuracy is not that sensitive to $\\\\alpha$. I am still very confused why the balance between the two metrics is indeed important. Figure 8 directly shows that the optimal balance may not be important.\\n\\n**Section 5.2:**\\n* It is not clear how the sparsity levels were chosen for the datasets in Figure 5. That is, how are the 12 settings chosen? I believe that a wider range of sparsity levels should be analyzed.\\n* In contrast to Figure 4 (and Figure 1), it is not clear why most of the circles are not placed on the diagonal. \\n* Line 316: Many cases of NPB do not lie in the so-called balancing regions. It would be better to mark the balancing regions in the figures.\\n\\nOverall, I believe the proposed framework is interesting and has some potential. However, the main contribution is neither well motivated nor rigorously presented. It seems that my concerns may not be sufficiently addressed by the rebuttal process. Therefore, I would like to give my rating as a reject.\\n\\n--\\n\\n**After Rebuttal**\\n\\nSome of the concerns and questions are resolved by the authors' rebuttal. However, the observational motivation and the need for careful optimization are not convincingly presented. Thus, I am a little reluctant to give a high score and would like to increase my rating to 5.\"},\n",
       " 'review_615': {'summary': 'Given the numerous pruning-at-initialization (PaI) methods, the performance of them are still far from satisfactory compared to the post-training pruning methods. In this work, the authors provide a novel perspective to understand the relationship between the performance and the architecture of the subnetworks generated by PaI methods. In particular, this work studies the topology of the subnetwork and observed a positive correlation between the PaI performance and the balance between the effective nodes and effective paths. Further, the authors propose a new PaI method, named Node-Path Balancing Pruner (NPB) to explicitly balance effective nodes and paths. The empirical results demonstrate the effectiveness of the proposed method.',\n",
       "  'strengths': '1. This paper studies the PaI methods from a novel perspective of model topology. This is a very interesting but also challenging perspective. \\n2. The figures and graphs in this paper are very delicately plotted and are of high quality. They help the readers better understand the methods proposed. \\n3. This work made enough literature review, which has covered the most important PaI literature.\\n4. This work is written in a very coherent manner, which shows clear the motivation, the method, the rationale behind the method, as well as the logic of the empirical studies. \\n5. The empirical results of the proposed method are indeed very impressive. ',\n",
       "  'weaknesses': 'I listed several weaknesses below from different perspectives. I will consider to raise my score if they are properly addressed.\\n* [Method] Based on my understanding of the NAS observation, the reason for balancing the effective nodes and the effective paths is to maximize the usage of the limited parameter quota. However, if this is true, wouldn\\'t directly cutting down the width of the network a perfect option for NPB? Correct me if I missed anything.\\n* [Method] Mathematically, the formulation of the optimization objective in Eq. (0) (between Line 243 and Line 244) and Eq. (4~5) are not standard. The to-be-optimized variables should be clearly stated beneath the maximization symbol.\\n* [Method] It is not very clear to me, how the optimization is carried out through the objective Eq. (4~5). Are there back-propagations involved? It seems not.\\n* [Experiments] For Fig. 5, the information conveyed is not as clear as I expected. Probably this is because the performance of each method in each setting is annotated with numbers. I would suggest the authors to plot a normal figure showing the performance change (y-axis) vs. the sparsity level (x-axis) as many pruning paper does (there are too many and thus I spare the references here). It can help the readers compare the final accuracy of different methods if they do not care the intermediate results too much (e.g. the effective paths/nodes).\\n* [Experiments] In the experiments, the $\\\\alpha$ is set to $0.01$. However, the word \"balanced\" claimed in the abstract seems a bit deceptive. To me, the value of $\\\\alpha$ is very crucial in the proposed method, but the authors fail to demonstrate its role through some ablation studies. I would suggest the authors either explain their choice of $\\\\alpha$ and/or conduct some ablation studies on $\\\\alpha$.\\n* [Experiments] In Fig. 5, will it be better to add a reference line such as $y = \\\\alpha x$ to help judge the balance of the nodes/paths? Correct me if I missed anything.\\n* [Experiments] This is not a must but I think the baselines compared in this paper are a bit old. Some methods like ProsPr (already cited in the paper) are recommended to be compared. The lack of this result will not change my evaluation on this paper.\\n* [Minor] Rephrase: \"An effective node/channel is one that at least one effective path goes through it\" ==> \"A node/channel is effective if at least one effective path goes through it\".'},\n",
       " 'review_616': {'summary': 'This paper posits that the performance of (neural network) pruning at Initialization methods depends on a balance between effective nodes and paths. With this framework, authors explain why randomly shuffled subnetworks are sometimes more effective than subnetworks found by pruning at initialization methods. Finally, using the Node-Path balancing principle, the authors propose a pruning at initialization scheme by solving a linear program that optimizes pruning mask to balance effective path and nods, which outperforms other pruning at initialization methods.  \\n\\n\\nEmpirical experiments are done on image datasets (CIFAR and TinyImagenet) with VGG and Resnet-20 models. Further empirical evidence for the node-path balancing principle is demonstrated through NAS benchmarks. ',\n",
       "  'strengths': '- The paper is well-written, and generally content is well-organized. \\n- The proposed node-path balancing principle is used to explain an existing phenomenon (random shuffling) as well as present a new pruning at initialization scheme, which is quite interesting. \\n- The convex program-based pruning method (NPB) outperforms other pruning at initialization methods and requires fewer FLOPs. PHEW is close in performance to NPB. However, the node-path balancing framework can also explain that, is interesting. \\n\\nOverall, the paper does a good job of introducing the node-path balancing principle and provides several empirical evidence in its support. ',\n",
       "  'weaknesses': \"\\n- The NAS experiments are interesting, but it wasn't clear to me to connect them with pruning at initialization or data-agnostic pruning, as NAS experiments are data-dependent. \\n- The term balance may be vaguely used. \\n   - The proposed principle states that at a particular sparsity, the best-performing subnetwork has to strike a balance between the effective nodes and paths. However, it does not predict the right balance.\\n    - It would be interesting to see if this balance depends on sparsity, model, and dataset or model and datasets only. Could the best-performing subnetwork network be maximizing average effective paths per node?\\n- The experiments are limited to image datasets and two neural network architectures. However, I appreciate the authors reporting results over three random seeds though.\"},\n",
       " 'review_617': {'summary': 'This paper examines Pruning at Initialization (PaI) methods using two novel metrics: the number of effective paths and the number of effective nodes. The authors find that layer reshuffling negatively impacts the performance of sparse neural networks obtained through PaI methods in the extreme sparsity regime. Based on the previous finding, authors present a novel data-agnostic PaI method, Node-Path Balancing Principle (NPB), which achieves the SOTA performance by effectively balancing the two proposed metrics.',\n",
       "  'strengths': '\\n- This paper provides a clear rationale for introducing the two proposed metrics; the authors empirically demonstrate the importance of the metrics via two experiments. First, experiments conducted on the NAS benchmark reveal a strong correlation between the two metrics and the final performance of sparse networks. Secondly, through layer shuffling experiments, the authors illustrate that simply increasing the number of effective nodes in the extreme sparsity regime is insufficient to prevent performance degradation due to the sharp decline in the number of effective paths.\\n- The proposed method demonstrates superior performance compared to the baselines, and the paper covers a fair amount of relevant previous studies.\\n- The paper is effectively structured and exhibits clear and concise writing\\n',\n",
       "  'weaknesses': '- While many previous PaI methods prioritize the weight magnitude as the importance metric, the main motivation behind NPB focuses on the topology of the sparse network. Thus, the ablation study with respect to different weight initialization would strengthen the paper. Further, is NPB robust to *weight reinitialization*?\\n- While the layer shuffling experiments are well-justified, it is confined to a single configuration (CIFAR-10, ResNet20). I wonder if similar observations can be made under different experimental settings. Also, does layer-wise shuffled NPB exhibit similar behavior as to layer-wise shuffled PHEW?\\n- There are two points in need of clarification. First, in lines 332-333, the term \"chunks\" is unclear, and it is not apparent how the parallel computation can be effectively achieved. Second, in the case of convolutional layers mentioned in lines 261-263, it is unclear whether equations 3-5 are still applicable when the mask vector is not boolean.\\n- Although the authors claim that NPB generally outperforms PHEW, the standard deviation with respect to random seeds should be included in the paper for fair comparison. For instance, the performance gain depicted in Fig. 7 seems marginal. Additionally, in lines 694-695, it is stated that NPB consistently outperforms the baselines regardless of the hyperparameter configuration. However, it should be noted that certain choices may lead to worse performance compared to the baselines (refer to Table 1).\\n\\nI am willing to raise my score if above concerns are well addressed during rebuttal.\\n'},\n",
       " 'review_618': {'summary': 'The authors perform a large-scale empirical analysis of models from the NAS-Bench-Macro benchmark which motivates to the development of (1) the node-path balancing principle and (2) Node-Path Balancing Pruner (NPB) -- a data-agnostic pruning-at-initialization (PAI) scheme. At a high level, the node-path balancing principle suggests that networks that have a good balance between the number of nodes and edges on a continuous/unbroken path from the neural network input to the neural network have a higher capacity for performance (i.e. classification accuracy). Their pruning algorithm, NPB, then solves a constrained optimization problem to strike this node-path balance for a given sparsity level. The driving factor for this research is to design advanced PAI algorithms for producing efficient models with better performance (i.e., classification accuracy) than existing PAI schemes.\\n\\n**Main contributions:**\\n\\n* Node-path balancing principle: Empirical analysis of NAS-Bench-Macro benchmark yields new perspective and principle for guiding design of pruning-at-initialization (PAI) schemes.\\n* NPB: A novel data-agnostic PAI scheme designed using the node-path balancing principle which outperforms existing PAI methods at lower FLOPs during inference.\\n\\n**Post-rebuttal revision:**\\n\\nFollowing the rebuttal, I feel that the authors have clarified my questions and concerns. Accordingly, I am increasing my rating to weak accept with the expectation that they will accommodate my requested minor revisions.\\n',\n",
       "  'strengths': '* Large scale analysis of NAS-Bench-Macro benchmark models suggesting connection between model performance and balance of effective nodes and paths.\\n* **NPB pruning-at-initialization algorithm**: Produces results comparable to state-of-the-art PAI scheme PHEW with fewer FLOPs during inference.\\n',\n",
       "  'weaknesses': '* **Looseness/inexactness of the node-path balancing principle**: I found the statement/rigor of this guiding principle (which was used to inform the design of NPB) to be very inexact. The motivating plots in Figure 4 suggest that there is nuance between this node-path balance and the resulting classification accuracy, but this was not further explored. Specifically, some networks with similar node-path balance in Figure 4 appear to have large variations in classification accuracy.\\n* **Lack of theory for node-path balancing principle**: Developing theory to study the principle would help design/inform a more exact guiding principle for PAI schemes.\\n* **Figure clarity**: It was not always evident what the takeaway is from certain figures and I feel that the presentation of certain figures could be improved. I found myself staring at some figures for a while trying to decipher what was important/meaningful as there is a lot of data. This isn’t to say there is not meaningful information in the figures but I feel like more careful curation/design of the figures could be enacted. For suggestions/specific figures, see comments under “Questions”.\\n'},\n",
       " 'review_619': {'summary': 'This paper proposes a pipeline and algorithms for machine learning prediction with abstention. The authors first propose the optimization framework to learn a model which allows abstention. They then consider different distributions and propose different algorithms for the learning process. Their theoretical analysis shows that the algorithms can achieve low error rate for misclassification and abstention.',\n",
       "  'strengths': '* The paper studies a variety of different contributions. The authors start with one-dimensional threshold scenario and shows the application of the abstention model. Then they provide algorithms for both known distribution and unknown distribution. The latter one is a more difficult setting and the authors provide a generalized algorithm for it based on the former one.\\n\\n* The paper provides comprehensive error bound for the algorithms. I am not an expert in theoretical ML analysis, but as far as I can tell, the theory part does not contain significant mistakes.',\n",
       "  'weaknesses': '* I do not see significant real-world application of the proposed abstention framework with adversarial resilience. The authors mention the case of predicting patient\\'s illness, in which case I understand why the abstention would be necessary. However, I do not see the necessity of caring about the adversarial resilience in such case - is it a (serious) threat that an adversary may launch a clean-label attack when people are training an illness classification task?\\n\\n* The authors also emphasize the \"sequential prediction\" in addition to the abstention framework and adversarial resilience in the context. I am not fully clear why this is also an important point to consider - can we also apply the proposed pipeline on a static dataset that does not contain a sequential order but also benefits from the abstention pipeline?\\n\\n* The paper does not contain empirical evaluation of the proposed algorithm, nor does it contain comparison with other works to show how good their bound is.'},\n",
       " 'review_620': {'summary': 'The paper presents a new protocol for beyond-worst-case sequential prediction, incorporating the option of abstention. It introduces two main algorithms: the first achieves an error rate of $O(d^2 \\\\log T)$ for classes with VC dimension $d$, while the second realizes an error of $O(\\\\sqrt{T})$ for a specific instance of classes with VC dimension $1$.',\n",
       "  'strengths': '1. An extensive literature search and insightful discussion of prior work spanning a variety of areas. This includes nuanced connection to topics such as beyond-worst-case sequential prediction, abstention-based learning, adversarially robust learning, adversarial examples, testable learning, etc.\\n\\n2. A new protocol of beyond-worst case sequential prediction with the option of abstention.',\n",
       "  'weaknesses': '1. Although the authors propose a new protocol, I struggle to identify novelty, as the primary difference appears to be the relatively straightforward inclusion of an additional abstention option.\\n\\n2. While new algorithms have been introduced, they are specifically tailored to special classes, thereby limiting the significance of the paper. Why that special case of VC dimension 1 classes is important?\\n\\n3. The proof techniques presented appear to lack significant novelty. What, then, is the underlying challenge?\\n\\n4. The phrase \"naturally be extended\" has been referenced multiple times throughout the paper, such as on lines 147-148, 366-367, and 370-371. Firstly, these extensions are not immediately evident, and as such, a more detailed discussion would be beneficial. Secondly, if these extensions are indeed straightforward, including them in the paper could greatly augment its significance.'},\n",
       " 'review_621': {'summary': 'This paper proposes a sequential prediction setting in which an adversary injects adversarial examples with clean labels, and the algorithm is allowed to abstain from predicting. This setting lies between the stochastic and the fully adversarial settings, which are known to be characterized by the VC and Littlestone dimensions of the hypothesis class.\\n\\nThe paper mainly proves the following two learning performance guarantees stated in terms of the VC dimension. (The algorithm incurs a unit loss whenever it outputs an incorrect label, or it abstains on a clean data poiunt.)\\n- An $O(d^2\\\\log T)$ upper bound on the number of mistakes, where $d$ is the VC dimension and $T$ is the time horizon. This result requires the access to the marginal data distribution.\\n- An $O(\\\\sqrt{T})$ error bound for the $d = 1$ case, without access to marginal distributions.',\n",
       "  'strengths': 'This paper defines a new setting of sequential prediction that models the power of abstention against clean-label attacks (e.g., adversarial examples). I found the setting well-motivated and the technical material beautifully presented. The authors identified various future directions of work on this model as well as potential connection to the learning theory literature.\\n\\nDespite the weaknesses discussed below, I (weakly) lean towards accepting this submission.',\n",
       "  'weaknesses': '- The error bounds are likely to be rather loose in terms of both $d$ and $T$.\\n- The assumption on having *perfect* access to the marginal data distribution is arguably too strong. While the approach should still work if the access to $\\\\mathcal{D}$ is replaced with (unlabeled) samples from $\\\\mathcal{D}$, the sample complexity would likely be $T^{\\\\Omega(d)}$; see questions below.'},\n",
       " 'review_622': {'summary': 'The authors study online learning under clean-label attacks. Since it is online learning, such attacks can be seen both as poisoning as well as evasion (adversarial examples). In this direction the authors propose the use of abstention when the classifier is not confident for a prediction and along these lines the main contribution is the introduction of a new loss function that penalizes abstention on non-adversarial examples but not on adversarial examples. The authors give an error (regret) bound of $O(d^2\\\\log T)$ ) for classes with VC dimension d for time horizon T, assuming access to the marginal distribution over the iid examples. This bound is off by a factor of $d$ from the situation where it is known that data are coming iid from some fixed distribution but at the same time the authors allow clean-label attacks which essentially alter the distribution. Finally, the authors also give a $O(\\\\sqrt{T})$ bound for concept classes of VC dimension 1 but without any access to the marginal distribution over the iid examples.\\n\\nAfter the rebuttal:\\n\\nWe had an interesting discussion during the rebuttal period and I am happy to see the authors will be integrating the feedback from the reviewers and improve the final version of the paper. Therefore I am increasing the score on soundness and presentation from 2 to 3 and the overall rating of the paper from 3 (reject) to 6 (weak accept). Thank you for a very interesting paper!',\n",
       "  'strengths': 'The paper is studying sequential prediction while the training examples can be poisoned in the sense that they are not drawn iid from some underlying distribution but otherwise respect the ground truth. This model of learning is somewhere between traditional machine learning where the learner has access to iid examples and online learning where the learners are studied under worst-case sequences of examples that are presented to the learners. The authors study the situation of sequential prediction, which is a term hardly found anywhere online and they never define in the text, but apparently has to do with the fact of studying machine learning algorithms that make predictions as they still learn from data (e.g., perceptron); the catch is to what extent the sequence of data can be adversarial and in this sense the authors allow perhaps the most adversarial of sequences. I believe this is an interesting problem though it is unclear how important this problem is, if it arises in the actual world, and where the motivation is coming from. The paper is sometimes well-written and sometimes not. Hence, there are issues both with the significance of the results and with the clarity.\\n\\nI like and appreciate the concluding section with ideas for future work and a clearly-separated paragraph on broader impact. However, the authors do not have a similarly marked paragraph listing the limitations of their work.',\n",
       "  'weaknesses': 'I think the paper has good potential, but it is not quite polished yet.\\n\\nSeveral definitions are missing or are confusing in the paper. Examples follow:\\n\\n- Sequential prediction is never defined as a concept.\\n\\n- Learning in the realizable case vs proper learning: in line 28 you define the hypothesis class $F$ and in lines 133-134 you indicate that labeling occurs according to some function in $F$. This is actually proper learning, which is a special case of learning in the realizable case.\\n\\n- In line 135 you forget to mention that you define what a version space is (and cite Mitchell) but you go ahead and use this notion in lines 255 and 269 (and perhaps elsewhere).\\n\\n- Littlestone dimension is mentioned but is never defined (not even in the appendix) and no example is actually given.\\n\\n- In lines 186-190: What is the relationship between $n$ and $T$? Does $n$ refer to unique examples, or does it allow potential repetitions and is thus the full number of draws from the (potentially adversarial) distribution?\\n\\n- One of the main contributions of the paper is the new loss function that penalizes the learning algorithm when when it abstains on non-adversarial data but does not penalize the learner on adversarial data. This is captured with the equation on display in line 152 where we see that the total error that the learner suffers over the sequence of the first T examples is decomposed to misclassification error and abstention error. Since the characteristic function (I assume that is what 1{$\\\\ldots$} is) is never defined, I understand from the misclassification error that the learning algorithm should receive a penalty of 1 every time it abstains since $\\\\hat{y}_t \\\\neq 1 - f^*(x_t)$. However, in Proposition 3.1 the learning algorithm abstains to predict in the disagreement region and the claim is that it has misclassification error equal to 0. However, I have no idea how this follows from the equation that is put on display in line 152.\\n\\n- In Protocol 1, two lines before the end you claim that the learner receives $x_t$ but earlier, in lines 143-144 it is clear that the learner receives $\\\\hat{x}_t$. \\n\\nNear the end the paper becomes more dense and while I appreciate that the authors are attempting to enhance the presentation by leaving the proofs in the appendix (thank you) there are still situations where there is ambiguity (e.g., in Theorem 5.1, is the \"corruption model with abstentions\" something new?)\\n\\nIn line 248 \"As we saw earlier...\" -> Perhaps explicitly number the particular example and refer to that with a number?\\n\\nAs a last remark, I am not sure if NeurIPS is the appropriate venue for this line of work. I do not believe it is.'},\n",
       " 'review_623': {'summary': \"The authors propose to generate adversarial attacks on different vision-language models (VLM) like BLIP, MiniGPT4, and UniDiffuser. The proposed method is simple and straightforward. To perturb the image, the authors propose to maximise the similarity (inner dot product) between the image-image / text-text / image-text features of CLIP. The attacked image is then transferred to the black box VLM models, which generates some text on these images. The similarity between the generated and the target text is calculated using unnormalised cosine similarity on the CLIP text encoder outputs. Maximising the similarity between the CLIP encodings of clean and target text and CLIP encodings of the clean and generated images of target text doesn't require any gradient approximation. But maximising the similarity between the target text encodings and generated text requires zero-order optimisation to get the gradients on the image. The authors demonstrate that the proposed attack completely fools the VLM models to generate text very similar to the target text.\",\n",
       "  'strengths': '* The proposed method is incredibly simple and, therefore highly valuable for the community\\n* The proposed method evaluates different types of VLM models, which makes the claims of the proposed method stronger.\\n* The problem identified is timely and highlights the importance of building robust VLM models in future.\\n',\n",
       "  'weaknesses': '* The proposed method shows the results of the PGD-100 attack, while in most of the black box attacks, it is observed that stronger attacks can overfit to the surrogate model resulting in worse transferability. Therefore, it would be good if the authors can also share the results on weaker attacks like PGD-10 and FGSM.\\n\\n* I think comparing the text quality using the CLIP score may not give the true picture. I would be nice if the authors can try some other metrics to compare the text quality.\\n\\n* For some of the approaches like LLaVA and MiniGPT-4 in Table-2, the results obtained using the proposed attacks like MF-it and MP-ii are very close (almost similar) to the clean image. Does this mean that the model is not able to get fooled? It would be nice if the authors can present results using some metrics which can quantify whether the model is fooled or not. This will help in getting a deeper understanding of the proposed method.\\n'},\n",
       " 'review_624': {'summary': 'This paper focuses on black-box targeted adversarial attacks on multimodal vision/language models via transfer. They observe particular vulnerability to transfer attacks because an adversarial image can be constructed in a fully-differentiable manner w.r.t. a model like CLIP and then transferred over to the black box target model. Their final approach involves matching the adversarial image features to both text and image features in the surrogate models used for training.',\n",
       "  'strengths': 'I think the combined method MF-it and MF-ii is clever, and I think the results are impressive. \\n\\nI find the paper clearly valuable and timely since models with these vulnerabilities are currently being deployed and their vulnerabilities could pose risks. I appreciate the discussion of this in the conclusion. \\n\\nI think that the experiments are compelling. I do not spot errors.',\n",
       "  'weaknesses': '(Minor) I find the figs to be generally cluttered. \\n\\nI would have liked to see experiments related to real-world concerns such as ones that were meant to illustrate real ways that these attacks could cause problems. For example, evading NSFW filters or making language models provide misinformation about an image that is used in a query.'},\n",
       " 'review_625': {'summary': 'The paper evaluates the pixel-space adversarial robustness of large vision-language models (VLMs), where the targeted attack has only black-box access to the large VLM systems. The paper introduces two adversarial strategies: transfer-based and query-based. The transfer-based strategy performs white-box attacks on surrogate models like CLIP and BLIP and transfers to large VLMs including MiniGPT-4 and LLaVA. The query-based strategy uses transfer-based priors to improve the efficacy of targeted evasion against these VLMs. The authors demonstrate the effectiveness of these strategies through comprehensive evaluations.\\n\\n',\n",
       "  'strengths': '1. The paper is well-presented with good motivation, and the authors provide a clear storyline with visual demonstrations to validate the proposed approach.\\n\\n2. It is novel to optimize the adversarial objective by matching image-image features (MF-ii) on large VLMs. The following Query-based attacking strategy (MF-tt) further enhances the effectiveness of the attack.\\n\\n3. The authors analyze the approach from multiple perspectives. The paper includes discussions on the influences of the perturbation, and the Grad-CAM interpretation visualizes the model decision well.',\n",
       "  'weaknesses': '1. The black-box setting is questionable. Although the adversary only has black-box access to the victim system $p_{\\\\theta}$, the transfer-based attack has white-box access to foundation components like CLIP. There is a high chance that the victim system shares mutual information (e.g., $p_{\\\\theta}$ contains CLIP / $p_{\\\\theta}$ trains on the same vision-language dataset / $p_{\\\\theta}$ has similar model architecture) with these white-box components. It will be beneficial if the authors elaborate more on the source of transferability.\\n\\n2. Although the Query-based attacking strategy (MF-tt) is feasible, the cost of such a process can be high. What is the forward inference cost (e.g., time of API call) per query, and how many queries are needed per attack? Authors should show the cost effectiveness of query attacks.\\n\\n3. The experiments mainly focus on imposing MF-ii as a prior for the following MF-tt queries. It will be constructive If authors demonstrate more on the sole use of MF-tt (which aligns with the black-box setting and is more computationally lightweight) without a strong MF-ii prior for the query attack.'},\n",
       " 'review_626': {'summary': 'This paper aims to assess the adversarial robustness of vision components in large vision-language models, which is an increasingly significant issue due to the prevalence of such models. The experiments conducted in this study are extensive, encompassing evaluations on UniDiffuser, BLIP, BILP-2, Img2Prompt, MiniGPT-4, and LLaVA. The research investigates transfer-based attacks and also employs black-box queries to enhance the effectiveness of the evaluation method.',\n",
       "  'strengths': 'The paper conducts extensive experiments on six prominent large vision-language models. By evaluating the adversarial robustness on these models, the study provides a comprehensive analysis that covers a wide range of architectures, ensuring the results are representative and applicable to the broader landscape of vision-language models.\\n\\nOne of the key strengths is that the paper demonstrates effective and realistic attacks specifically tailored for these models. By employing transfer-based attacks and utilizing black-box queries, the study goes beyond traditional methods to showcase the vulnerabilities and potential risks faced by large vision-language models in real-world scenarios.',\n",
       "  'weaknesses': 'This is an evaluation paper. It would be nice to see how baseline defense, such as adversarial training on CLIP [1], would help mitigate the adversarial vulnerability of the proposed attack.\\n\\nThe method focuses on the vision part, which is easier to attack, what about attacks on the language?\\n\\n[1] Mao et al. Understanding Zero-Shot Adversarial Robustness for Large-Scale Models. ICLR 2023.'},\n",
       " 'review_627': {'summary': 'The authors propose a class of neural processes that can be constructed to enforce invariance to particular properties like translation and rotation.',\n",
       "  'strengths': '- As far as I know, the proposed architecture and technique for enforcing invariances in Section 3 is novel.\\n- Improvements are shown over standard neural processes on a range of tasks\\n- The authors show both theoretically and empirically that the proposed architecture does indeed enforce the invariances described.',\n",
       "  'weaknesses': '- Choosing $g$ in Eq 5 to enforce a particular invariance seems difficult. The authors provide choices that enforce isotropy and translation invariance, but it would not be obvious how to enforce a different type of invariance.'},\n",
       " 'review_628': {'summary': 'The paper presents a novel approach for incorporating equivariance into conditional neural processes (CNPs) which can scale to high dimensions. Modelling equivariance is essential to improve the performance of CNPs. Unlike previous approaches that use convolution and become impractical with increased input dimensions, this work uses relational information and discards absolute information. As a result, this simple method can handle high-dimensional inputs. The authors also prove that their approach is context preserving which means they do not lose other information. Their empirical results demonstrate that the proposed method is comparable to convolutional CNPs, GNPs etc. on a diversified range of tasks.\\n',\n",
       "  'strengths': '**Strengths**\\n\\n1. This paper addresses the challenge of incorporating equivariance into Conditional Neural Processes (CNPs) for high-dimensional problems. The proposed models are shown to be translation-equivariant, allowing them to scale to higher dimensions and are comparable/outperform existing CNP and GNP models on a wide range of tasks.\\n2. The paper is well-structured and clearly presented, with a strong motivation for the research, precise technical statements, and comprehensive background. \\n3. The paper provides robust theoretical results, all of which are supported by proof. The empirical investigation is extensive, covering a diversified range of tasks. The authors demonstrate the effectiveness of their models through experiments on synthetic Gaussian and non-Gaussian regression tasks, Bayesian optimization, Lotka-Volterra models and reaction-diffusion models. ',\n",
       "  'weaknesses': \"**Weakness**\\n\\nGiven the extensive use of RGNP in the experiments and its significant role in the paper's findings, it would still be beneficial for the authors to provide a concise description or a mathematical formulation of the RGNP in the main text. Even though it is not difficult to extend the mathematical description of RCNP to RGNP.\"},\n",
       " 'review_629': {'summary': 'This work introduces a new member of the neural process model family that is designed for biasing the model towards representing equivariances in the data. It does this by including relational information among the context set, and between the predicted and context inputs in the encoder for a new input. Also, only the relational information is used for encoding and the absolute information is discarded. Experiments are given for a several types of equivariances/applications to show the method successfully models equivariances in the data.',\n",
       "  'strengths': 'Simple but effective technical idea with convincing experiments. For instance, I found Figure 1 very illuminating. The work shows promise for scaling GP-like models (or rather, emulating GP kernels) for distributions over functions to large data/dimensions.',\n",
       "  'weaknesses': 'The full RCNP variant has tractability issues, although it is shown that the simpler RCNP using the diagonal elements of the relational matrix performs satisfactorily.\\n\\nEquivariances other than translations and rigid transformations, and other variants of CNP are left to future work. Would it not be too much effort to examine a few of them in this paper?\\n'},\n",
       " 'review_630': {'summary': 'This paper is an extension of the conditional neural process. The primary contribution is to augment the conditional neural process with the relational structure. The developed model was examined in synthetic regression, Bayesian optimization, Lotka-Volterra simulation, and others.',\n",
       "  'strengths': '1. This paper is complete in organization and easy to understand.\\n2. The relational inductive biases mentioned in this work are crucial in some scenarios but were already studied in previous NP related work (See weakness).',\n",
       "  'weaknesses': '**1. Unclear Motivation.** The motivation for using relational inductive biases is not well clarified in the Introduction section, e.g., in which scenarios or datasets the relational information is required. Meanwhile, I am not sure of the definition of relational in this work, and it seems the concept is similar to that in Set Transformer .\\n\\n**2. Lack of Novelty.** The novelty of this work seems relatively limited. There have been extensive works to incorporate equivariance into neural process models, such as work in [1-4]. As for the use of relational inductive bias, especially when the input/output are high dimensional, this has appeared in work [5].\\n\\n**3. Incomplete Analysis.** In Table (1)/(2), the kl divergences are reported, but I did not find what it means in the results. Notably, most empirical analysis claims the proposed model outperforms others, but the reasons behind these observations, e.g., what kind of equivariance matters, are unclear.\\n\\n**4. Missing benchmarks and baselines.** Images naturally hold translation equivariance/invariance properties and are more appropriate for evaluation. This work fails to compare with other equivariant (C)NPs [1-4].\\n\\n \\n**5.** The contribution and the organization of the paper are mixed in Line 49-Line 56.\\n\\n**References:**\\n\\n[1] Kawano, M., Kumagai, W., Sannai, A., Iwasawa, Y., & Matsuo, Y. (2021). Group equivariant conditional neural processes. arXiv preprint arXiv:2102.08759.\\n\\n[2] Holderrieth, P., Hutchinson, M. J., & Teh, Y. W. (2021, July). Equivariant learning of stochastic fields: Gaussian processes and steerable conditional neural processes. In International Conference on Machine Learning (pp. 4297-4307). PMLR.\\n\\n[3] Markou, S., Requeima, J., Bruinsma, W., Vaughan, A., & Turner, R. E. (2021, October). Practical Conditional Neural Process Via Tractable Dependent Predictions. In International Conference on Learning Representations.\\n\\n[4] Foong, A., Bruinsma, W., Gordon, J., Dubois, Y., Requeima, J., & Turner, R. (2020). Meta-learning stationary stochastic process prediction with convolutional neural processes. Advances in Neural Information Processing Systems, 33, 8284-8295.\\n\\n[5] Wang, Q., & Van Hoof, H. (2022, June). Model-based meta reinforcement learning using graph structured surrogate models and amortized policy search. In International Conference on Machine Learning (pp. 23055-23077). PMLR.'},\n",
       " 'review_631': {'summary': 'This paper introduces a couple of ideas to improve the empirical performance of the TD3 algorithm on continuous-action RL problems.\\n\\nThe core contribution is to show that learning state and action embeddings that are designed to predict themselves in successive timestep can help achieve more reward. This is pretty nice because the representation learning process is done in conjunction with reward maximization and is shown to be useful and stable enough to enable faster learning in the same task.\\n\\nA few other contributions are presented which I list below:\\n\\n1- a normalization approach that scales the output of the embeddings, and which is compared against some of the existing normalization approaches such as batch and layer norm.\\n\\n2- checkpointing the policy during online RL, akin to supervised learning, so rather than using the latest learned policy one can continue learning by using the best-performing policy.\\n\\n3- clipping the value estimates during training to ensure that the estimates remain within a meaningful range.\\n\\n\\nVery nice empirical results are then provided, most notably on the Mujoco benchmark in online RL, where the proposed approach named TD7 is capable of beating competitive baselines such as TD3 and SAC.',\n",
       "  'strengths': 'The highlight of the paper is the impressive empirical results provided on the online RL experiments with the Mujoco baseline. I did my best to cross-check the performance of the baseline agents and it does seem like that TD7 is capable of beating TD3 and SAC (these are the two baselines I checked) on these benchmarks. I do see some discrepancy between SAC results reported here and those reported (for Hopper) in the original paper, but otherwise the results are consistent with published papers.',\n",
       "  'weaknesses': 'I did enjoy reading this paper, and I applaud authors for their successful implementation and empirical results. That said, I am not sure what the core message of the paper is. I think the contributions need to be motivated, framed, and highlighted better. For instance, is this paper primarily about the advantage of learning state and action embeddings in RL? If yes, existing work has already demonstrated that, so other than the fact that the empirical results are superior, what kind of statements can we make about this new approach to learning embeddings that we did not know previously? Is it better for transfer learning? Is it faster in terms of run time? Is it better motivated theoretically?\\n\\nJust to name a few papers, with the danger of missing other related and interesting work:\\n\\n- An approach very similar to the one presented here was presented earlier by Zhang et al: \"Learning Action Representations for Reinforcement Learning\"\\n\\n- Gelada et al also propose a very similar approach in \"Deepmdp: Learning continuous latent space models for representation learning\", and I am not clear in what sense SALE is doing something different than them.\\n\\n- Chandak et al show in \"Learning Action Representations for Reinforcement Learning\" that one can learn a low-dimensional representation for actions.\\n\\nThese are just a few examples to show that the idea of learning state and action representations is well-explored and to me this limits the novelty of the work.\\n\\n\\nMoving to the other contributions, and in terms of the normalization approach, I am not quite positive in what way this normalization is going to hedge against the issue of collapsing all states and actions to 0. To me it seems like that if the reward is not part of the process of learning the embeddings, and we use the kind of successive predictive loss in the embedding space, then trivially the 0 solution would be optimal with or without normalization.\\n\\n\\n\\nI found the checkpointing idea creative and interesting. That said, I have a few issues with it: 1- it seems like based on Figure 7 that checkpointing is rarely effective in the online case, and as the paper states, not applicable in the offline case. 2- it seems to me that when computing the goodness of a checkpointed policy, a potential issue is that during training we add some exploration noise to the action suggested by the network, so unless we do zero exploration, we need to account for the fact that we have not exactly executed the policy and therefore some off-policy learning is needed to compute the true goodness of the checkpointed policies. Do I get this right?\\n\\nThe clipping idea also makes sense, and it is interesting, but it is still a limited contribution.'},\n",
       " 'review_632': {'summary': 'This paper proposes TD7, an improved version of the popular TD3 algorithm with 4 additional techniques: state-action learned embeddings (SALE, the major one among the four), using policy checkpoints for stable evaluation, an existing prioritized experience replay method called LAP, an existing offline RL algorithm called TD3+BC. The four techniques strengthen vanilla TD3 algorithm from different aspects. TD7 is evaluated on MuJoCo and D4RL benchmarks for online and offline RL settings, significantly outperforming existing continuous control algorithms. Comprehensive ablation studies are also included.',\n",
       "  'strengths': '- This paper is well written and the content is clear.\\n- The proposed improvements (almost) make sense to me and well motivated or explained.\\n- The part of SALE (Section 4) is interesting to me, although SALE can be viewed as an improvement over OFENet. I think the detailed studies on useful techniques for stable representation learning could be inspiring to other similar problems in RL.\\n- This paper conduct ablation studies for most design choices to rule out the alternative choices empirically.\\n- The code implementation is neat and I assume it is easy to reproduce the experiments.',\n",
       "  'weaknesses': '- The proposed improvements are piecemeal, each of which is incremental or existing.\\n- A few additional hyperparameters (e.g., the dimensionality of $z^{s,a}$, the episode number to maintain the policy unchanged) are introduced, although the authors give recommended values.\\n- Although the paper has comprehensive empirical studies, intuitive explanations are lacked.'},\n",
       " 'review_633': {'summary': 'This work introduces a novel state-action representation learning framework SALE and two other techniques (e.g. checkpointing, a new type of Q value clipping) that substantially improve the data efficiency and final performance of TD3 in online and offline RL.',\n",
       "  'strengths': '1. The work studies joint state-action representation learning, which is under-studied with respect to state representation learning.\\n2. The method is very clear, and the authors provide extensive empirical analysis and ablation explaining their design choices.\\n3. Some techniques introduced in this work (checkpointing, Q clipping in Eq. 6) can be applied to most RL methods and are thus influential beyond representation learning.\\n',\n",
       "  'weaknesses': '**Core comments:**\\n1. I believe the paper would read more easily after reorganization.\\n    * Section 4.2 feels like an ablation study that should follow the core empirical results. Also, Section 4.2 references TD7 results, though TD7 is not introduced until section 5.\\n    * Section 5 begins by mentioning stability and extrapolation error jumped out at me; the intro and related work emphasize the representation learning side of this work much more, and extrapolation error is not mentioned in sections 1-4. I believe the paper would read better if the authors painted a clearer picture of what the stability side of the work entails in the introduction, and included transitions between section 4 and 5 that clearly indicate “we talked about one issue, and now we’re going to talk about another.”\\n    * Transition sentences before bolded subheadings (e.g. Normalizing embeddings, Fixed embeddings) would help in Section 4 – something to the effect of “We now discuss two important aspect of SALE…” \\n1. The checkpoint policy $\\\\pi_c$ denotes the policy is the largest minimum return during the assessment phase. During agent evaluation, you compute the return over N rollouts of $\\\\pi_c$ rather than $\\\\pi_t$, correct? If so, I’m a bit skeptical of the results; is it possible that the perceived benefits of checkpointing are simply due to the batched nature of training it requires? Suppose you run vanilla TD3 within the checkpointing framework but perform separate evaluations using the checkpoint policy *and* current policy. This experiment would be equivalent to vanilla TD3 with variable length batched updates. Does the batched updates alone improve performance?\\n\\n\\n**Minor comments:**\\n1. Figure 2 would be more readable with error bars rather than text to indicate the 95% confidence interval.'},\n",
       " 'review_634': {'summary': 'The paper introduces an approach dubbed SALE for learning embeddings that model the interaction between state and action in low-level state environments. The authors extensively study the design space of these embeddings and integrate SALE into the TD3 algorithm along with 3 other components to form a new algorithm, TD7. \\nThey perform an extensive empirical evaluation over the design space to discover the most significant contributors to final performance. The paper shows that TD7 outperforms existing continuous control algorithms on MuJoCo OpenAI gym tasks.',\n",
       "  'strengths': \"**Originality**\\nThe paper's originality lies in its comprehensive study of learning embeddings that model the interaction between state and action in low-level state environments. The experiments conducted provide evidence of the effectiveness of their approach in improving the performance of TD3.\\n\\n**Quality**\\nSee Weaknesses Section.\\n\\n**Clarity**\\nThe paper is well-written and organized, making it easy for readers to follow the authors' thought process and understand the methodology and results. \\n\\n**Significance**\\nThe authors demonstrate that their proposed method, when integrated into TD3 to form what they name TD7, performs significantly better than TD3 for the MuJoCo environments. This work brings to light the importance of learning the interaction between state and action information to improve performance in RL.\",\n",
       "  'weaknesses': \"While the paper presents a novel approach to learning embeddings for state and action information for RL, there are areas where it could be improved.\\n\\nFirstly, the evaluation of TD7 could be expanded to include more benchmarks. While the MuJoCo environments provide valuable data, including additional benchmarks such as Procgen or Brax could offer a more comprehensive understanding of the method's performance and any potential limitations.\\n\\nThese considerations, while not detracting from the originality and potential significance of the method, do highlight areas where further work could be beneficial.\"},\n",
       " 'review_635': {'summary': 'This paper proposes a new RL algorithm called TD7, which is based on TD3, and adopts additional techniques including (1) learning state-action representations, (2) LAP prioritized replay, (3) a behavior cloning term in the learning objective, and (4) checkpoints, where (3) and (4) are applied exclusively to the offline RL setting. They demonstrate the superior empirical performance of TD7 on the D4RL benchmark.',\n",
       "  'strengths': '1. The paper is well written and easy to follow.\\n2. Extensive experiments and ablation studies to evaluate the proposed methods.\\n3. The proposed method is shown to have strong empirical performance on established benchmarks.',\n",
       "  'weaknesses': \"1. **Limited contribution**: While I appreciate TD7 as a competent algorithm for both online and offline RL, I'm not so sure about the contribution of SALE especially regarding its applicability to other existing baselines. It doesn't seem conclusive to me that the proposed embedding is generally superior for RL agents. From the ablation studies it seems many independent design choices could significantly affect the final performance, which may also be algorithm dependent. \"},\n",
       " 'review_636': {'summary': 'This paper provides an asymptotic analysis of ensembles of ridge regressors using varying numbers of subsampled features. The authors consider a Gaussian data model with feature noise and readout noise in addition to label noise. Using the replica method from statistical physics, they obtain precise asymptotics of the limiting ensemble risk for any collection of subsampling operators. They specialize this result in the case of globally correlated isotropic data and numerically plot double descent curves for various non-overlapping ensemble strategies. They find that in poorly regularized regimes, increased heterogeneity of feature subset sizes leads to a significant decrease of worst-case generalization risk, in other words dampening the double descent peak, albeit typically at the expense of increased risk in other data aspect ratios. Departing from heterogeneity to consider instead homogeneous non-overlapping ensembles, the authors further demonstrate that in the presence of readout noise, there are regimes in the phase space of readout noise level and global feature correlation in which it is optimal to use an ensemble rather than a single learner, although without readout noise it is never optimal to ensemble.',\n",
       "  'strengths': 'The biggest strength of this paper in comparison to existing work on linear ensembles of random projections of features is that this analysis applies to arbitrary projection operators that need not be independent. In fact, for the specific cases the authors consider of non-overlapping feature subsets, which would correspond closely with distributed optimization practice (I recommend the authors emphasize this in their introduction), the projection operators are clearly very much not independent. Furthermore, the most general form of their results in Proposition 1 also makes no assumption on the relationship between the projection operators and the covariances, in contrast with most existing work which assumes them to also be independent.\\n\\nI am also not aware of any other work which explicitly considers heterogeneous linear ensembles, which is a novel contribution.',\n",
       "  'weaknesses': 'I think that the biggest weakness of this paper is the justification of the data model and of the advantage of using a (heterogenous) ensemble. I think that these could be improved by adding justifying and motivating comments throughout the paper, and if the authors would indicate how they would make such changes for the camera ready version, I would increase my score of the paper.\\n\\nData model:\\n- The features are corrupted with additional noise that is independent of the label, which is an interesting but highly non-standard assumption. Even more non-standard is the assumption that this noise is drawn independently in every forward pass. This assumption really should be motivated---should the reader be imagining this as something like noise due to dropout in a neural network?\\n- The model outputs are corrupted with readout noise independent across each member of the ensemble, again drawn independently each forward pass. This seems like an even stranger assumption to me; I could imagine some negligible computational noise, but I struggle to come up with a setting in which we would see the noise levels that are modeled in this paper. It is very important to motivate this, as the experiment in Figure 4 only justifies ensembles in settings where readout noise is high. Without good motivation, it seems like a strawman.\\n\\nEnsemble advantages:\\n- This is a complaint I have for many other papers that deal with double descent, but applies equally to this paper. The \"correct\" solution to double descent is to properly regularize, and other strategies such as the ensembling proposed here can be seen as \"hacks\" that can mitigate some of the worst double descent effects but are typically suboptimal. We see this in this case as well. E.g., consider Figure 3, where the heterogenous ensembles only improve risk in the under-regularized setting. In the setting with more appropriate regularization (c.iv-vi), where the risk is lower than in (c.i-iii) for most values of $\\\\alpha$, the heterogeneous ensemble is strictly worse than the homogeneous ensemble, which I am sure itself is strictly worse than the optimally tuned full ridge regressor. \\n- No comparisons are made to the full ridge regressor. Obviously, the ensemble would have to be worse, as ridge regression is typically the minimum mean squared error estimator in additive noise settings. However, this is a lost opportunity to demonstrate perhaps that bad double descent effects could be mitigated at a fraction of the computational cost (since the ensembles consider small subsets).\\n- Essentially, the risks are a linear combination of the individual risks of each ensemble member, plus some cross-terms. Thus in the limit of zero regularization, these ensembles would still have infinte double descent peaks, one for each different subsampling ratio. So to an extent, the authors already rely on regularization to help make the ensemble robust to double descent, although the benefits are realized for fairly small regularization already. Still, the authors should justify the need to regularize even with ensembles and discuss tuning.\\n- Related to the previous points, it\\'s not clear why worst case risk is an important metric, since tuning of regularization in some way or another seems necessary.\\n- Part of the issues of statistical performance may be due to the non-overlapping partition of features. In the related works, ensembles with optimality guarantees typically require many members with overlapping subsets of features, which the authors do not consider here. \\n\\nOthers:\\nOverall, I found the plots to be very busy and difficult to decipher. I give one suggestion on how to improve Figure 4 in Questions.'},\n",
       " 'review_637': {'summary': 'This article characterizes the asymptotic performance curve of a heterogeneous feature ensembling framework for ridge linear regression, in the limit of comparably large numbers of data samples and variables. For having different error peaks in a double-decent performance curve as a function of the data sample size, predictors built of heterogeneous feature sets give rise to an ensemble that is robust to the number of data samples, without a carefully tuned regularization parameter.',\n",
       "  'strengths': '* Clarity of the mathematical setup.\\n* Numerical validation of asymptotic results on finite data sets.\\n* Discussion of the theoretical implications of the analysis.',\n",
       "  'weaknesses': '* The analysis applies only to the square loss while recent related work addressed already a large family of convex losses.\\n* Even though the interest of heterogeneous feature ensembling is explained as mitigating the double-descent phenomenon, this problem can be in fact settled by optimizing the regularization parameter on a cross-validation set.\\n* There is no experiment on real data sets to see how well the observed consequences such as the mitigated double-descent curve apply to real data.'},\n",
       " 'review_638': {'summary': 'This paper introduces a theoretical investigation into ensembling methods applied to linear ridge regression with feature subsampling. It builds upon previous research in this area by extending the analysis to include scenarios with varying readout dimensionality.\\n\\nBy employing the replica method, the authors derive expressions for the average-case generalization error. These expressions capture the influence of both the data structure and the hyperparameters of the ensembling method employed.\\n\\nFurthermore, the paper focuses on a simplified scenario to examine how the degree of subsampling and heterogeneity affect the occurrence of the double descent phenomena in learning curves for generalization error. This analysis provides potential insights into the understanding of this well-known and recurring phenomenon in machine learning.',\n",
       "  'strengths': '- The paper is clearly written, and the experiments presented are of high quality.',\n",
       "  'weaknesses': \"- The authors use as proof technique for the main theorem the replica method, a heuristic method coming from statistical physics. While this method has been proven to be rigorous in certain contexts, its general correctness has not yet been formally established.  Unfortunately, the paper fails to acknowledge this limitation, which undermines the overall credibility of the research findings.\\n- In terms of technical results, the computation leading to preposition 1 appears to be a minor modification of the calculation presented in a previous work by Loureiro [2022]. However, unlike the present study, Loureiro's work accompanies the calculation with a rigorous proof. This discrepancy raises concerns about the rigour and robustness of the current paper's technical contributions.\\n\\n(Minor) Typos:\\n- Line 4: the the\\n- Line 53: studied studied\\n- Line 212: eta\"},\n",
       " 'review_639': {'summary': 'The authors provide theoretical results on generalization for ridge regression for the case of an ensemble of regression models trained on feature subsets, with noise, and correlation.\\n\\nThey relate this to the previously observed double-descent phenomena and characterize how the fraction of subsampled features, the regularization strength, and other properties affect the double descent phenomenon and where it occurs (i.e., how these impact generalization error).  \\n\\nFinding that double descent occurs at different places for different feature subset amounts, they also propose and analyze using a heterogenous ensemble of different feature subsampling sizes as a way to mitigate double descent without having to tune regularization or model architectures.\\n\\n\\n****Update****\\nRevised my score after the responses - see my response comment for rationale.\\n',\n",
       "  'strengths': 'The generalization bounds for the particular setting seem novel.  \\n\\nThe problem is a highly relevant one and the idea of using feature subset ensembles is interesting and potentially useful- as alluded to in the conclusion - as searching over many architecture and regularization settings for large neural nets may be prohibitive, so this kind of approach could provide an alternative for such cases with a fixed architecture, by creating a feature subsample ensemble instead - however this possibility is just alluded to and not tested, as only theoretical results for simple ridge regression problems are analyzed.\\n\\nThe authors provide thorough analyses of the results of the theorem for generalization error, to try to elucidate what different aspects of the ridge regression problem and choices for the modeling mean in terms of generalization error.',\n",
       "  'weaknesses': '1) The paper is hard to follow and extract any useful meaning or conclusions from.\\n\\na) Some terms are not defined or given adequate explanation.  As particular example - it would be helpful to explain what \"readout noise\" and readout dimensionality mean in this paper when first introduced - this was not clear to me and I found its use to be confusing in the theoretical setup section and even the related work.  It\\'s just mentioned without defining what it is or how it related to the model, and it would help to give an example of what it would correspond to.\\n\\nb) A lot of different parameters are introduced and hard to remember when trying to connect to the various results figures and analyses -  it may help to remind the reader and also include simple examples of models describing what the different parameters and values would correspond to.\\n\\nc) I feel the main results and conclusion need a simpler explanation and deciphering for the reader - as the various plots and analyses are still based on a large number of symbols / parameters that it\\'s hard to remember, and the reader would have to dig through the text each time to recall what they are.  Some simplified example and conclusion, as well as a table may help.  It\\'s hard to come away with any kind of recommendation or firm conclusion of what we could expect to work better in practice as well.\\n\\nd) \\n\\n2) It\\'s not clear how useful and impactful the results from the paper and the derived theorems are.  \\nIt seems the complicated expression derived is too complex to derive any useful properties, and requires knowing ground truth properties - so the benefit is not clear.\\n\\nEven in the simplified tractable case - it\\'s not clear what interpretation comes out of it.\\n\\nIn generally it\\'s not clear if any novel and useful findings have come out of this.\\n\\nI think a key part of the issue might be - after presenting each set of results / figures, some interpretations and conclusions and take-ways for the reader are needed and currently lacking - results are just presented with little explanation or analysis.\\n\\n\\n3) Related to the previous points, I feel having real data and model experiments and results could really strengthen this work and also more fully explore the idea and benefit proposed of using heterogenous feature sub-sampling ensembles.  \\n\\n\\n4) Novelty is also somewhat unclear.\\nObviously, heterogenous feature subsampling ensembles have been studied and applied in the past, and for some specific models there are theoretical results on generalization error as well, such as tree ensembles or even linear model ensembles with different kinds of approaches such as random subspace models.  \\nAdditionally, the authors point to some specific related work as well on theoretical study of generalization error as well.  However, clearly spelling out the differences in this work seems lacking.  For example, in related work - they mention other work also studying feature subsampling for ensembles and finding it provides an implicit regularization approach, in particular [20].  However, it\\'s not stated what differentiates this work from this prior work - what novel aspect does this provide?  It\\'s necessary to spell out what limitations of previous work this addresses and overcomes.\\n\\nI.e., overall it would help to clearly spell out how their work is different and novel with respect to prior work on feature-subsampling ensembles and what new conclusions and approaches result from it.\\n'},\n",
       " 'review_640': {'summary': 'The authors provide a theoretical analysis of the case of ensemble learning with linear ridge regression for the case where heterogeneous feature subsampling is used. The authors make a number simplifying assumptions about the distribution of the data (Gaussian distribution and noise, linear function), and using the replica trick from statistical physics derive generalization error for the L2-regularized least-squares solution. In simulations, the authors demonstrate that the derived solution coincides with numerically calculated generalization error, and based on analyzing learning curves provide a number of insights about the behavior of ensembled ridge regression, suggesting a novel way for mitigating the double descent phenomenon through the use of heterogenous feature subsampling in ensembling.',\n",
       "  'strengths': 'The work provides novel insights about how double-descent behaves based on noise, regularization, and subsampling and provides alternative strategies to regularization for avoiding the peak. These are quite central questions in modern machine learning theory and new ideas here can prove to be significant. The mathematical analysis seems rigorous and the replica trick used for the analysis appears to be a new type of tool for studying this phenomenon, though I do not have suitable mathematical background to follow all the proofs in detail. The basic setting and assumptions are clearly defined, related work seems to be covered well, and novelty of the contribution compared to related similar works is clearly established.',\n",
       "  'weaknesses': 'The work makes many simplifying assumptions that are unlikely to match most real-world learning problems (e.g. Gaussian data, linear teacher function), and analyzes may not be in practice tractable beyond the simpler cases such as analyzed in Section 2.3. with globally correlated data. It is not so clear whether the results would offer practical tools for an analyst wishing to apply heterogeneous feature-subsampled ridge ensembles in an optimal way, though results in the supplementary materials about CIFAR10 Classification Task suggest the results can have also practical relevance.\\n'},\n",
       " 'review_641': {'summary': 'The paper proposes Prune4ReL, which prunes a noisy training dataset such that the performance of a Re-labeling trained downstream model is maximized. \\nUnlike previous work, the paper targets pruning a *noisy* dataset and explicitly considers the learning algorithm of the downstream model. The proposed method is specifically tailored to Re-labeling, automatically cleaning the noisy training dataset.\\nThe utility function in Prune4ReL is inspired by the theory proposed in [1] and gracefully incorporated into the context of data pruning. \\nThe experimental results show that most prior work suffers under noisy datasets, while Prune4ReL remains robust to the noise in the training dataset, resulting in substantial improvements over baselines.\\n\\n[1] Theoretical Analysis of Self-Training with Deep Networks on Unlabeled Data, ICLR2021',\n",
       "  'strengths': 'The strength of the paper include\\n- Clear presentation and easy-to-follow writing\\n- The proposed method is theoretically-inspired and, maybe more importantly, easy to implement\\n- The evaluation, together with the analysis, is convincing.\\n- Include the analysis on why and how the baseline fail\\n\\nThe paper is well-organized, and the method and evaluation are solid.',\n",
       "  'weaknesses': \"The paper conducts a complete study on the proposed Prune4ReL, and the following weakness is relatively minor.\\n\\n- Prune4ReL outperforms the baselines by a large margin, but the gap between PruneReL and uniform sampling is small.\\n- Some notations are not clear.\\n  - Def. 3.1: the $x$ is not in the pixel space. Instead, it's in the embedding space. The author should state the dimension of $x$ at the beginning\\n  - in Thm 3.4, it should be $\\\\mathcal{S} \\\\subseteq \\\\tilde{D}$\"},\n",
       " 'review_642': {'summary': 'The paper proposes a novel data pruning algorithm, Prune4ReL, that maximizes the neighborhood confidence of the entire training examples, which is proportional to the likelihood of correct re-labeling. The paper demonstrates the effectiveness of Prune4ReL on four noisy datasets, where it outperforms baselines by a large margin.',\n",
       "  'strengths': 'The writing of this article is very clear and easy to follow up. Moreover, the methodology in this paper is also reasonable with necessary theoretical analysis. I enjoy this work very much! My only concern about this work is the experimental part.\\n\\n',\n",
       "  'weaknesses': '1. Recent works like [1,2,3] are missing in those selected baselines. \\n\\n2. Lack of results on ImageNet-1K, which is the most convincing part for us.\\n\\n[1] Moderate: Moderate coreset: A universal method of data selection for real-world data-efficient deep learning. ICLR-2023 \\n\\n[2] SSP: “Beyond neural scaling laws: beating power law scaling via data pruning. NeurIPS-2022 \\n\\n[3] CCS: Coverage-centric Coreset Selection for High Pruning Rates. ICLR-2023'},\n",
       " 'review_643': {'summary': 'This paper studies the task of data pruning, specifically in the setting of label noise. The authors propose a method to perform data pruning by maximizes the total neighborhood confidence of the training examples (which is equivalent to maximizing the relabeling accuracy). \\n\\nThe authors theoretically analyze this particular setting, bounding the error of a model trained on the subset that satisfies the expansion and separation assumptions from prior work. Their resulting bound is inversely proportional to the neighborhood confidence.\\n\\nTheir empirical results show mixed results in the comparison against existing methods; namely, in Table 1, the results are slightly better than existing baselines on a small number of tasks but predominantly match the performance of existing methods. In table 2, it also seems that the existing method Forget and kCenter seem to select similar or fewer noisy examples than the proposed method (except in the case of CIFAR-100N with 0.2 or 0.4).\\n',\n",
       "  'strengths': 'The authors present a theorem that shows that the error of a model trained on a subset of data is inversely related to the neighborhood confidence. They propose a method that maximizes the neighborhood confidence, which in turn minimizes this bound.\\n\\nThe authors show in Figure 3 that the test accuracy with SOP increases when using a subset produced by the proposed method. However, it is unclear why this is necessarily the case, since there are similar or fewer noisy examples selected by the Forget baseline method.\\n\\nThe authors provide ablation studies that study the effect of neighborhood threshold $\\\\tau$ and with different confidence metrics.\\n',\n",
       "  'weaknesses': 'The bolding strategies in Table 1 are a bit misleading; in many scenarios, a baseline achieves the same performance as the proposed method (and sometimes achieves a smaller variance), but the proposed method is still listed in bold. In fact, the reported method achieves the same performance across many of the tasks.\\n\\nSimilarly, the results in Table 2 show that the Forget baseline seems to select subsets with a smaller ratio of noisy examples when compared to the proposed method. However, in subsection 4.3, the authors claim that this method selects a high ratio of noisy examples.\\n'},\n",
       " 'review_644': {'summary': 'This paper studies data pruning in noisy label setting. Built on re-labeling models, it proposes Prune4ReL that finds a subset to maximize the re-labeling accuracy. In particular, it introduces neighborhood confidence as the criteria for selection, as well as a greedy algorithm to select the subset. Evaluation show its superiority over prior data pruning methods.',\n",
       "  'strengths': 'The target setting is interesting and well motivated. The proposed neighborhood confidence and Prune4ReL is sound with theoretical guarantee. In addition, the evaluations are comprehensive and experimental results look promising. ',\n",
       "  'weaknesses': 'I don\\'t see any major weakness, but I do have some comments:\\n\\n1. The proposed data pruning method does require model training as many sample selection methods for robust learning do; I think these methods should also be considered as baselines and compared, even though they are not specifically designed for data pruning. Currently, the authors only compare SmallLoss, which is quite outdated.\\n\\n2. There are some related work in robust learning field that also leverage neighborhood information, but the authors did not include and discuss them, eg, \"Learning with Neighbor Consistency for Noisy Labels\"'},\n",
       " 'review_645': {'summary': \"This paper focuses on the task of graph distillation (GD) from a fairness perspective. The authors found that current GD method amplifies bias in GNN training compared to training on original graphs. Since the distilled graphs do not contain node attributes, it's intractable to directly apply previous debiasing methods. To address this issue, the authors first made assumptions on the representation space of the distilled graph. Then they propose to measure the bias in the distilled graph representations using the least square distance between the distilled representations and the subgroup representations in the original graph. Technically a variance-based regularization is utilized to punish the model w.r.t. this measure. Extensive experiments demonstrate that the proposed method can benefit GNN training on distilled graphs with improved fairness.\",\n",
       "  'strengths': '1. This paper studies a novel topic and has its applicability in real-world scenarios. And it might bring in broader impact and more discussions on the characteristics and caveats of data distillation in other domains.\\n\\n2. The experiments are thorough.',\n",
       "  'weaknesses': \"1. The authors' design of the coherence loss in section 3.4 is confusing to me. Figure 2 shows that the intuition is to minimize the distance between z0 and z1 (as depicted by the red arcs in the figure), and this makes sense because fair representations should coincide in the attribute dimension. However, the definition in section 3.4 actually is the variance within group 0 or 1, and reducing this variance would only lead to more compact representations in each group, instead of bringing the two groups closer. Since the main contributions of this paper are based on this design, the authors should clarify this in a more rigorous manner.\\n\\n2. The empirical results on Pokec-z, German and Credit all show that the vanilla GD method can achieve comparable utilities with real graphs (within 5% accuracy gap) and worse fairness. Meanwhile, the results on Pokec-n and Recidivism show significantly worse utilities (up to 20% or 30% gap in accuracy), but better fairness. The improved fairness on these two datasets questions the motivation of this paper, that is the finding that the current GD method worsens GNN fairness. Also, I may wonder whether the authors have tuned the vanilla method right on these two datsets given such a large utility gap.\\n\\n3. There is not much logical connection between the theorems in sections 3.2 and the following part of the paper. Even if the span space does not match, or the barycenters are not consistent, it doesn't matter with the proposed method. The authors may need to justify the necessity of these theorems.\\n\\n4. Some typos. In the introduction part, the authors term the bias measurement as *consistency* (line 43), while it's *coherence* in other places. Line 143, it should be projection of z' instead of z. The defition of coherence loss in section 3.4 misses a superscript 2, since without this the formula is constant 0.\"},\n",
       " 'review_646': {'summary': 'This paper discovered the fairness problem in the distilled GNN methods and then introduce a fair graph distillation process to generate fair distilled graph data. To propose the algorithm, they also introduce a new bias metric, coherence, and propose a bi-level optimization framework, FGD, for fair graph distillation. Theoretical analysis are provided. Experimental results validate FGD’s effectiveness in mitigating bias while maintaining model utility across various GNN architectures and datasets.',\n",
       "  'strengths': '1.\\tGood presentation. This paper is easy and comfortable to read and follow.\\n2.\\tSolid theoretical analysis and experimental validation.\\n3.\\tThis paper is the first paper to solve the fairness problem in distilled GNN lines, which have good novelty and contribution.\\n',\n",
       "  'weaknesses': '1. Some terminology needs simple descirption. It is better to include some preliminary knowledge or terminology description to make paper more self-included.'},\n",
       " 'review_647': {'summary': 'This paper aim to address the issue of fairness in graph data distillation, a process that condenses large real graphs into smaller distilled versions for more manageable computation with GNNs. They proposed FGD by introducing a new bias metric called coherence and using a bi-level optimization algorithm, which has shown to provide improved performance-fairness trade-offs in numerous experiments.',\n",
       "  'strengths': \"1.\\tThis paper studies an interesting issue of fairness within distilled graphs, which arises due to the absence of sensitive features.\\n2.\\tThis paper devised a bias measurement named coherence specifically for distilled graphs, and suggests a framework utilizing this metric to facilitate the realization of fair graph distillation. The theoretical analysis in this paper is well founded.\\n3.\\tThe authors have conducted a thorough experimental analysis, and the presented results indicate that the proposed framework is adaptable to numerous renowned GNNs. This framework improves the trade-off between prediction performance and fairness across a range of datasets, signifying the framework's effectiveness and wide-ranging applicability.\\n\",\n",
       "  'weaknesses': '1.\\tAre there any fairness studies in dataset distillation in other fields such as computer vision and natural language processing? If so, there is a lack of discussion comparing the proposed framework with other similar works.\\n2.\\tThe time and space complexity are not mentioned.\\n3.\\tIn terms of methodology, this paper primarily uses strategies that were already developed before, and the unique contribution is the incorporation of a new loss term, Overall, the technical contribution of this work seems incremental.\\n4.\\tThe experimental part is inadequate, lacking integration of the proposed framework with large-scale and advanced GNNs, experiments in large datasets and the extra overhead of proposed framework.\\n\\n'},\n",
       " 'review_648': {'summary': 'This paper proposes fair graph distillation (FGD), as an advanced graph distillation approach to generate fair distilled graphs. FGD focuses on the group fairness issue in graph distillation methods and aims to generate fair distilled graphs with respect to sensitive attributes for nodes. This paper proposes a simple yet effective metric for measuring the bias in representation space, namely coherence, for distilled graphs, and a bi-level optimization framework to generate fair graph distillations iteratively. Experimental results illustrate that the proposed methods can achieve  performance-fairness trade-offs across various datasets and architectures. ',\n",
       "  'strengths': '- This paper considers group fairness issue, which is novel in graph distillation.\\n- The proposed metric for bias measurement is simple yet convincing.\\n- The theorems and algorithms introduced in paper is well presented.\\n- Experimental results show the effectiveness of FGD in debiasing distillation.',\n",
       "  'weaknesses': '- More baselines in graph distillation are needed. For example, *FairGNN* and *EDITS* are introduced as baselines in debiasing, while no graph distillation methods (such as [1]) are compared. \\n- Results in Table 1 shows that distilled graphs could achieve some improvements in debiasing, while the AUC performance drops significantly (e.g. from 94% to 70%), which is unacceptable for node classification.\\n\\n\\n[1] Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen. Dataset Condensation with Gradient Matching. In ICLR 2021'},\n",
       " 'review_649': {'summary': 'This paper considers the game played by content creators in recommendation systems, which they call the content creator competition game. This game is centrally defined by a rewarding function M, decided by the platform, which rewards content creators based on how users engage with their content. The paper focuses on how to design this rewarding function in order to maximize user welfare. \\n\\nThey show first that a practically-motivated class of rewarding functions, “Merit-based monotone mechanisms” (M3), lead to losses in user welfare by producing an equilibrium that caters to majority-group users, and fail to cater to minority-group users. Notably, the “necessary welfare loss” is only slightly suboptimal: such mechanisms can still capture a $K/(K+1)$ factor of the optimum, where $K$ is the parameter defining the top-K recommendation policy (though they do make the point that when $K$ is effectively 1 for users who care only about the top recommendation, this ratio can be 1/2). Also notably, they prove this result in a sub-class of creator competition games with the structure of a majority group and several minority groups, all with orthogonal interests (called TvN games - “trend versus niche”).\\n\\nNext, they introduce a class of rewarding functions called “backward rewarding mechanisms”, which keeps the merit-based property of M3 but drops the monotonicity assumption, trading it for a a set of functions f1,…fn specified by the platform that can be tuned to encourage diversity by making it costly for too many creators to be producing the same kind of content. They show that for TvN games, there exists a backward rewarding mechanism that admits the optimal welfare. They run some simulated experiments with user preferences that constitute a TvN game.',\n",
       "  'strengths': '- The paper aims to be general: they take almost an axiomatic approach and study an entire class of mechanisms (M3) defined by two main assumptions, which encompass multiple practical mechanisms. They also study an entire class of instances (TvN games).\\n\\n- They show clean equilibrium results for both classes of mechanisms\\n\\n- The new class of mechanisms they propose is conceptually interesting — it makes clear why the monotonicity assumption causes problems, and offers a tunable class of algorithms that can help improve user welfare, at least in theory (it remains to be seen whether there is adequate information available in practice to set the parameters of these mechanisms well).\\n\\n- The paper takes care to make abstract concepts understandable, giving examples and intuition to supplement the math',\n",
       "  'weaknesses': '1. I do not understand the “monotonicity” property conceptually (described on Lines 43-44 as “the sum of creators’ utilities increase whenever any creator increases her content relevance”). I may be misunderstanding something here, but I interpret this to mean “when one creator benefits, all creators benefit on average”. This doesn’t seem to necessarily reflect an environment in which content creators are competing: Under competition, it could be the case that when a given creator improves her content, it greatly increases her own utility but decreases all other creators’ utilities more in total?\\n\\n2. Although the paper makes some attempts to justify why the K/(K+1) loss of M3 mechanisms is bad, this doesn’t seem that bad to me, especially given that it emerges from a purely theoretical model in which many abstractions have been made. I felt that the paper oversold the magnitude of this loss in multiple places. It’s also not clear to me that the proposed fixed (BRM) doesn’t have similar loss in other natural sub-classes of games outside TvN games (as their positive results applies only to TvN games). To me, the combination of these two points weakened the motivation for the results sections later in the paper.\\n\\nSmall points about clarity:\\n- Line 34: what is a “reward signal”?\\n- Line 41: “and frame a class of prevailing rewarding mechanisms… Merit-based Monotone Mechanism”. It’s not clear what “prevailing” means here.\\n- In the explanation Lines 50-53, I’m missing a logical step: is “relevance quality” evaluated in terms of the *number* of users who find it relevant? Otherwise, I don’t see how this monotonicity property could cause concentration of creators around majority users’ preferences. '},\n",
       " 'review_650': {'summary': 'This paper studies the incentives in recommendation systems. Specifically, it studies how to design the platform\\'s reward mechanism to steer the creators\\' competition towards a desirable welfare outcome. Firstly, it shows a class of mechanisms called \"Merit-based Monotone Mechanisms\" lead to a constant fraction loss of the welfare. To overcome this loss, it introduces Backward Rewarding Mechanisms (BRMs) and shows that the competition games resulting from BRM induce the strategic creators’ behavior dynamics to optimize any given welfare metric.',\n",
       "  'strengths': 'The paper studies an interesting question in recommendation system. It shows an interesting bad effect of a wide class of mechanisms towards social welfare and then designs another mechanism to overcome the negative result. The theoretical results within the scope of the paper are complete. And there are also empirical experiments.',\n",
       "  'weaknesses': 'The applied value of the model in the paper is lack of justification.'},\n",
       " 'review_651': {'summary': \"The authors study strategic content creation in recommendation systems, focusing on the induced game's social welfare. The authors assume that the provider's rewards are entirely determined by the platform's payments, not clicks/engagements. This separation between the ranked results and the creators' incentives facilitates analyzing an expressive game in which the recommender system recommends a list of items (most prior work considers one item) with position bias. Notably, the authors assume that the rewarding mechanism is a mapping from a vector of relevance scores to reward vectors, i.e., $[0,1]^n \\\\rightarrow [0,1]^n$.\\n\\nThe paper considers two classes of merit-based mechanisms, monotone and BRM (and also the BRCM subclass). It showcases evidence against monotone mechanisms, highlighting that in a particular class of games (TvN), the POA of any monotone mechanism is at most $\\\\frac{K}{K+1}$, where $K$ is the length of the list, plus a small $\\\\frac{1}{n}$ factor. Later, for BRCM mechanisms, the authors show that the welfare function is the potential function; thus, the global optimum of the welfare is a PNE (despite the POA could still be  $<1$ for some mechanisms). \\n\\nFinally, the authors describe how to optimize over BRCM mechanisms in the presence of data, and conduct synthetic and semi-synthetic experiments to demonstrate their approach.\\n\",\n",
       "  'strengths': '1.\\tThe paper deals with a timely and important topic, and well-connects to previous literature.\\n2.\\tThe paper non-trivially extends previous literature, suggesting new theory and experimental validation.   \\n3.\\tThe optimization problem the paper suggests is exciting and new to this literature.\\n',\n",
       "  'weaknesses': \"1.\\tDue to the abundance of mathematical objects and notations, the paper is non-trivial to follow. Perhaps this is inevitable, but I see this as a weakness. \\n2.\\tThe case against monotonicity focuses on a relatively small class of TvN games tailored to the authors' argument. Arguing against monotonicity in (more) general games would be much more convincing. \\n3.\\tThe empirical evaluation lacks proper benchmarks.\\n\"},\n",
       " 'review_652': {'summary': \"The development of online media referral platforms has provided a source of income for media content creators, and the incentive strategies of the platforms may influence the creators' creative trends. The incentive model that tends to reward may also invariably encourage creators to over-serve the majority user group, and the niche groups will be increasingly underserved. In order to solve these problems, this paper designs a backward incentive mechanism, which induces creators' behavior through the game structure to dynamically optimize the creation model and maximize social welfare. And its advantages are verified by simulation experiments.\",\n",
       "  'strengths': \"To address the current problem that rewards mechanisms in online content recommendation platforms affect creators' production choices, the platform's content distribution and social welfare. In this paper, we design a reverse reward mechanism, which can guide content creators to optimize their creation strategies and provide locally optimal results for a given welfare metric. This avoids most creators to generate a large amount of homogeneous content that caters to the majority group for the sake of rewards.\\n1. originality\\nIn this paper, we provide a reverse reward mechanism to address the problem that current reward mechanisms may encourage creators to concentrate on the mass range, thus leaving niche users unserved. The superiority of this mechanism, which is performance-based but discards monotonicity, has been proven in empirical studies, and the approach in this paper is well original.\\n2. quality\\nThe research problem of this paper is apparent, the method is introduced in detail, the logic is clear and the experiment is reliable. This paper has good quality.\\n3. clarity \\nThis paper clearly defines the research problem, and introduces the effectiveness of the method from the theoretical and simulation experiments in detail. The overall clarity is good.\\n4. significance\\nIn this paper, it designs a reverse incentive strategy to cope with the incentive drift caused by the profit-oriented incentive strategy in online content recommendation platforms, so as to reduce the undesirable incentives that cause a large number of creators to ignore the niche groups and leave them unserved. The research in this paper has significant implications.\\n\",\n",
       "  'weaknesses': 'This paper’s related work on the content of the current study is weak, there are few references, and there are only a few works in the past five years, which is a bit difficult to explain the novelty of the current method.'},\n",
       " 'review_653': {'summary': 'This paper presents a novel approach for representing volumetric video using a dynamic codebook that incorporates the temporal correlation of features. This addresses the drawback of existing feature grid-based methods, which overlook this correlation.',\n",
       "  'strengths': '1. The proposed method uses a multidimensional feature space and a dynamic codebook to model the changing scene.\\n2. The paper presents model compression techniques, including pruning and weight clustering, which reduce the size of the model.',\n",
       "  'weaknesses': \"1. The article's novelty is limited as the introduction of the dynamic codebook approach appears to be primarily focused on engineering aspects. Additionally, the results from ablation experiments suggest that this approach is not particularly effective, and although a large number of model parameters are introduced, there is only a marginal improvement in video quality.\\n\\n2. It is impractical to manually adjust dynamic codebook parameters (such as k) for different videos in real-world applications.\\n\\n3. The paper lacks comparison results regarding training and rendering time.\"},\n",
       " 'review_654': {'summary': \"The authors of this paper propose  a dynamic codebook, which optimizes away codes of low importance to rendering the scene, clusters 70% of the least importance codes and optimizes the remaining codes for every time fragment. The process the authors introduce are intuitive and each step furthers compression or works towards reducing the distortion introduced in the compression process.\\n\\nI have read and acknowledged the author's rebuttal and will remain with my generally positive assessment.\",\n",
       "  'strengths': 'The introduction of a dynamic codebook is intuitive and handles a number of problems in the codebook creation process. First keeping highly important codes, clustering low important codes to a zero token, clustering remaining codes and then using gradient aware code optimization to further increase details for specific time fragments. \\n\\nThe authors demonstrate near state of the art PSNR on NHR and DyNeRF datasets ( < 0.25 dB PSNR difference) with substantially (more than 14x) smaller models.',\n",
       "  'weaknesses': \"As discussed by the authors, the dynamic codebook construction takes at least an hour for NHR and almost two hours for DyNeRF and substantially increases the total end to end time and rendering time.\\n\\nThe dynamic codebook introduces more hyperparameters to tune, what percentage of features to keep, drop, cluster and how many dynamic codewords get added. NHR and DyNeRF seem to differ substantially in these and it's unclear how much of this is based off of framerate, resolution, or complexity.\"},\n",
       " 'review_655': {'summary': 'The proposed method applies the codebook technique to explicit feature plane representation and a dynamic codebook is further proposed for dynamic scenes. Experimental results demonstrate the good performance of the proposed methods.',\n",
       "  'strengths': '1. The proposed method significantly reduces the model size while keeping a similar render quality with K-Planes [35] from both qualitative metrics and visualization.\\n2. The proposed dynamic codebook is easy to follow and the problem addressed is important and interesting.\\n',\n",
       "  'weaknesses': '1. Considering that previous work VQRF has introduced codebook to feature grid representation for reducing the model size with an excellent compression ratio, the proposed method here that introduces codebook to feature plane representation is reasonable but not of sufficient novelty.  \\n2. The main contribution of model size reduction comes from the codebook technique. The efficiency of the proposed dynamic codebook is somewhat limited.\\n3. There is no experimental comparison of the time cost. The influence of the optimization process caused by the dynamic codebook is unclear.\\n4. There lack some explanation and evaluation about some hyperparameters and settings. For example, In Sec 4, Line 235: \"We then retain the top 30% of codes with the highest importance score contributions and cluster the remaining codes into k codes\". The reason for the setting 30% and the influence of k can be provided for better demonstrating the efficiency of the proposed strategy.\\n'},\n",
       " 'review_656': {'summary': 'The paper addresses the challenge of representing high-fidelity volumetric videos with low storage cost. The authors proposed a novel neural representation called the dynamic codebook, which aims to reduce the spatial and temporal redundancy of feature grids inherent to scenes due to self-similarity. It achieves this by merging similar features for model compression and compensating for potential declines in rendering quality through a set of dynamic codes. The experimental results demonstrate that the dynamic codebook method achieves state-of-the-art rendering quality while achieving higher storage efficiency.\\n\\nThe contributions of the paper are twofold: \\n1. This paper proposes the dynamic codebook representation, which effectively reduces model size by minimizing feature redundancy in space and time while maintaining rendering quality in dynamic detailed regions. \\n2. Experimental results show that the proposed approach achieves rendering quality comparable to state-of-the-art methods while significantly improving storage efficiency.\\n',\n",
       "  'strengths': 'The paper introduces a novel approach that use the dynamic codebook to reduce the spatial and temporal redundancy.\\n\\nThe paper is well-structured, with clear section headings, and visual aids such as figures are effectively utilized to illustrate key points or enhance comprehension.\\n',\n",
       "  'weaknesses': 'Experimental details and results seem incompletely reported, so I have some confusion about this work. I defer some of my issues in \"Questions\".'},\n",
       " 'review_657': {'summary': 'A method for compressing Volumetric Videos is presented in this work. It is based on NeRF with a factored multi feature plane representation. The features of the model are compressed in two stages. In the first, a codebook for features is constructed based on the average contribution a feature has to the total reconstruction. Features are weighted based on their score contribution to the NeRF integral. Ones with low score contributions are merged into a zero code, the top 30% of codes are retained, and the rest are clustered using an exponential-moving average algorithm. In the second compression stage,  a small number of features per temporal segment are selected based on the accumulated gradients of back propagation on the codebook compressed model. These features are then optimized and added to the codebook, dynamically growing the codebook with time. The resulting method produces reconstruction quality and compression ratios comparable to SOTA while requiring only hours instead of days to train. ',\n",
       "  'strengths': 'A simple method that achieves SOTA accuracy and compression performance but is much more efficient. ',\n",
       "  'weaknesses': '- Writing could be a bit clearer\\n- Only evaluated on two scenes'},\n",
       " 'review_658': {'summary': 'This paper presents a novel motion generation pipeline that utilizes a 3-level hierarchical semantic graph. The entire reverse process of the motion diffusion model is divided into three stages: overall motion, local actions, and action specifics. The semantic graph is extracted through semantic role parsing and further enhanced using a Graph Attention Network. The obtained node features are subsequently input into a single transformer based on their semantic level.',\n",
       "  'strengths': '1. The proposed GraphMotion approach demonstrates excellent performance in terms of numerical metrics on two datasets, showing significant improvements compared to existing methods. Particularly noteworthy is the detailed comparison of GraphMotion at different diffusion steps with other state-of-the-art methods, which adds more persuasive evidence to the results.\\n\\n2. The motion refinement aspect is intriguing, as users are able to achieve a certain degree of motion editing by modifying the content of nodes. This adds an interesting and interactive element to the method.\\n\\n3. The motivation and objectives of the entire approach are well-explained, making it easy to understand the rationale behind the proposed method.',\n",
       "  'weaknesses': \"1. It is recommended that the authors conduct user studies to quantitatively compare their method with other existing works based on qualitative results. The current demo video lacks sufficient comparisons, and additional comparisons should be included to provide a comprehensive evaluation. Furthermore, it would be beneficial to showcase the qualitative results of motion refinement in the demo video to provide a more complete demonstration of the method's capabilities.\"},\n",
       " 'review_659': {'summary': 'This paper proposes a coarse-to-fine diffusion model coupled with a hierarchical semantic graphs to address the text-to-motion generation problem. To preserve the fine-grained control signals from captions, three-level textual features are extracted through GAT. Then, three diffusion models are adopted to recover the latent motion representations, which is decoded into motion sequences via VAE.',\n",
       "  'strengths': '1. Semantic graphs are introduced to model the coarse-to-fine textual descriptions.\\n2. Hierarchical diffusion model is technically sound to learn the latent motion distributions.\\n3. The experimental results outperforms sota methods.\\n4. Fine-grained controllability of the proposed model is interesting.',\n",
       "  'weaknesses': \"1. The motivation behind the imbalance problem needs to be more convincing. In line 31-33, deficience of the existing method boils down to imbalance and coarseness. I am curious about if there are some examples could prove that imbalance problem exists in the other methods.\\n2. Many descriptions in this paper are misleading or incorrect, and it needs further explaination. In line 176, the term ``codebook size'' is ambiguous because it is generallly associated with VQVAE. In line 180-181, the purpose of diffusion process should be learning a mapping from gaussian noise sampled from $\\\\mathcal{N}(0,1)$ to motion latent representation $z^m$, and the condition is the global motion node $V^m$. In line 183, $\\\\beta_t$ is not step size, it is the noise schedule.\"},\n",
       " 'review_660': {'summary': 'This work decomposes the motion description into three levels including motion, action and specifics, and proposes hierarchical semantic graphs to achieve fine-grained control of motion generation. \\nExperiments with the proposed method on HumanML3D and KIT datasets demonstrate better motion generation and more sensitive to subtle differences in texts than existing techniques.\\n',\n",
       "  'strengths': 'The motivation is clear, and the proposed solutions are to the raised issues. \\nThe results seem to be impressive and the experimental setup is somewhat reasonable.\\nThe ability to continuously refine the generated motion is meaningful and helpful to the community.',\n",
       "  'weaknesses': '1. The paper states several times that Transformer may overemphasize action names, but I think that the action level in the hierarchical semantic graph is also another kind of emphasis. Therefore, if possible, I hope the authors can experimentally demonstrate the \"overemphasis\" of the Transformer and prove that the hierarchical semantic graph does not have this problem.\\n2. Why is the last one in the action level of Figure 1 resumes instead of walking? How does it handle \"squats to picks\" and distinguish \"walks and walking\"? Also, the hierarchical semantic graph is built on a valid semantic parsing tool, and I\\'m not sure whether the tool will greatly affect the overall robustness of the model.\\n3. What are the results in the first row of Tables 3 and 4 in what configuration? By my understanding, these two rows should be the complete ablation of their respective parts, so they should be numerically different.\\n4. Is the modification in Figure 5 implemented in other latest works as well? Does it only modify the weights of the edges and can it modify the nodes?'},\n",
       " 'review_661': {'summary': 'The authors identify two major issues of text-to-motion generation as overemphasis on action names and the coarseness of sentence-level representations.\\nTo this end, hierarchical semantic graphs are adopted to factorize coarse sentences into fine-grained action concepts, thus refining the generated motion from coarse-to-fine.\\nFurthermore, the hierarchical design allows flexible control of the generation procedure.\\nExtensive experiments show the efficacy of the proposed method.',\n",
       "  'strengths': 'The proposed three tiers of node as motions, actions and specifics are interesting. \\n\\nThe hierarchical diffusion is well-designed in disentangling different level of granularity. Also, the experimental results show reasonable improvements with more and levels.\\n\\nThe performance is impressive.\\n\\nThe motion refinement application is attractive and promising.\\n\\nThe analysis on distribution of diffusion steps might be interesting in identifying the performance bottleneck among different semantic levels.\\n\\nExtensive ablation experiments provide a nice view of the effectiveness of different components.',\n",
       "  'weaknesses': 'Qualitative comparison of different hierarchies is missed. It would be helpful to visualize motion generated from different level of latent embeddings, since fundamentally human is the only gold standard to evaluate motion generation, given the rather close numeric metrics of different levels.\\n\\nThe ablation on the design of the semantic graph is missed.\\n\\nA more detailed description of the motion refining procedure, like a figure, an algorithm, or some equations might be added for better clarity.\\n\\n'},\n",
       " 'review_662': {'summary': 'This paper addresses the task of robust model reasoning and fitting in an unified optimization framework that can estimate the geometric model accurately without knowing the predefined model in advance while being robust to outliers as well as highly efficient. The authors propose a novel sparse subspace recovery theory and derive corresponding propositions, thus giving a general and unified formulation for robust model reasoning and fitting. They next introduced an alternating optimization strategy together with proximal approximation method to accurately estimate the sparse model parameters and outlier entries. Extensive experiments indicate that the proposed method outperforms the selected comparison methods.',\n",
       "  'strengths': 'This paper solved the geometric model estimation problem from a novel perspective, that is recovering the model parameters without knowing the model type, which is interesting and valuable. The writing is good. The authors have provided clear presentation to convey their core idea. The experiment part is reliable, which well verifies the advantages of the method.',\n",
       "  'weaknesses': '1:The authors designed an accelerated optimization approach and demonstrated its fast convergence in Fig. 2, claiming it an ‘optimal’ first order method. But there are no experimental proofs of the optimality in the paper. Authors should compare the performance of the algorithm before and after the acceleration.\\n\\n2:The authors mentioned their strength in efficiency, but the experiment results have not revealed this property.\\n\\n3:The authors propose a solution process similar to DPCP, and I think it should be added to the comparison algorithms as well.\\n\\n4:The experiments in the paper demonstrate the excellent performance of the DSP on 2D models and geometry models. I would like to know is the upper bound of the algorithm. Is it possible to design experiments (e.g., continuously increasing the dimension of the data space) to test the performance upper bound.\\n\\n5:During application test, the proposed method have successfully applied to multimodel fitting, as we can see. But why do the authors mention that they plan to integrate multimodel fitting and achieve a four-fold task in the future?\\n\\n6:The pose estimation or visual localization experiments are also necessary, since they are more common in this topic, comparing with multimodel fitting or Loop Closure Detection.\\n\\n7:Others:\\n Line 113, “to predefine” should be “predefining”\\n Line 159, “convert” should be “be converted”\\n'},\n",
       " 'review_663': {'summary': 'Considering that existing model estimation methods highly rely on the correct definition of model types, this paper introduces a unified optimization modeling DSP to simultaneously reason out the model type and estimate model parameters from contaminated data. For such purpose, the authors proposed Sparse Subspace Recovering (SSR) theory to modeling geometric model estimation task, that is to search a maximum of independent sparse bases under an over-embedded data space. The authors also introduced a fast and robust solver to estimate the sparse subspace parameters and error entries, and validated the advanced performance of their method on both unknown and known model estimation, and two applications.',\n",
       "  'strengths': '- This paper is well written and organized, and easy to follow.\\n- The motivation, theory, formulation and solution are good contributions for the model fitting topic.\\n- The authors solved the geometric model estimation problem from a novel perspective, that considers the model reasoning task additionally. Particularly, the authors introduced Sparse Subspace Recovering theory and formulated the unknown model fitting task into a continuous optimization objective, and explored efficient solution for it.\\n- The authors designed unknown model fitting experiments, and also evaluated their method on common exact model fitting task, which is reasonable and credible. The experiments are convincing, and the results show great superiority comparing to the SOTA.\\n',\n",
       "  'weaknesses': '- Line 74, the authors claimed that if the data are properly normalized, using algebraic error is good. But how to assure this property of input data?\\n- This paper proposes SSR theory, but the authors have not given mathematical explanation or proof.\\n- As for the solution, why not using ADMM to solve this problem, I think ADMM is a common choice for solving L1 norm problem with Lagrange multiplier, as sparse subspace clustering (SSC) used. Please explain.\\n- Line 52: How to understand ``insufficient information’’ that the GRIC used, which may cause wrong model selection for constrained motions. What are the advantages of this method comparing with those model selection criteria.\\n- If using DSP or SSR theory to estimate a Fundamental matrix F, how to use the rank 2 constraint of F? That is an intrinsic property of Fundamental matrix.\\n\\nTypos:\\n- Line 60, add citation for PSGM when it first appears.\\n- Lines 163 and 171, ``sparse independent hyperplanes``, I think it is better to use ``sparse intersected hyperplanes`` or ``sparse independent bases``.\\n- Line 170, $\\\\mathcal{R}$ should be $\\\\mathbb{R}$ to indicate the real number space.\\n- Line 226, $e_k$ --> $e^k$.\\n- Line 239, ``can successfully addressing`` --> can successfully address.\\n- Line 271, ``300 image pairs of each model`` --> ``300 image pairs for each model``.\\n\\n'},\n",
       " 'review_664': {'summary': 'This paper considers the robust model fitting problem in the presence of outliers, which is a fundamental problem in low-level CV. The aim is to simultaneously achieve outlier rejection, model selection, and model parameter estimation in a unified formulation. Toward this end, the authors propose to cast the joint outlier rejection, model selection, and model estimation problem into a sparse subspace recovery problem, which can cover the widely used projective transformation models for multi-view gemometry such as the fundamental, homography and affine models. The joint optimization formulation is solved by an alternating algorithm with the use of proximal approximation computation and acceleration. Experimental results on synthetic and real-word data have been provided to deminstrate the performance of the new method, including fundamental matrix and homography estimation, as well as a loop closure application.',\n",
       "  'strengths': 'This work is well motivated to joitnly achieve outlier rejection, model selection, and model estimation in a unified formulation. The proposed sparse subspace recovery formulation covers the widely used projective transformation models for multi-view gemometry, such as the fundamental, homography and affine models. The method has been evaluated on both synthetic and real-world data via various experiments.',\n",
       "  'weaknesses': '1. The formulation only applies to algebraic error model, i.e., model estimation with algebraic distance. While algebraic distance is convenient due to its linearity, geometric distance is geometrically or statistically meaningful and can yiled better performance in projective transformation estimation over the algebraic distance. This has been demonstrated in multi-view geomety.\\n\\n2. Wile the proposed method is well conceived, it would not outperform the simple method that first estimates the model parameters of each candidate models and then selects the best model in terms of the fitting error. Although the provided experiments show that it outperforms AIC, BIC, GRIC selection methods, in practical applications the model is typically selected in terms of a score of the estimated model computed based on the symmetric transfer errors when the ground-truth transformation is unknown. This selection method is typically used in practice.\\n\\n3. The proposed algorithm has several hyper-parameters, e.g., $\\\\gamma$, $\\\\lambda$, $r$, and $\\\\tau$. Its performance depends on the tunning of these hyper-parameters, which diminishes its potential advantage over the simple model selection method based on the symmetric transfer errors.'},\n",
       " 'review_665': {'summary': 'The paper studies the geometric model fitting problem with unknown model type and heavy outliers. It proposes a unified optimization model with dual sparsity constraints that combines the outlier rejection, true model reasoning and parameter selection. Moreover, a fast numerical algorithm is proposed to solve the approximate and dimension-reduced model via separability of the objective function. Numerical experiments on synthetic and real data sets are conducted to compare the performance of the proposed method with other related works. Overall, the paper is complete from theory, algorithm, to experiments with a section of broader impact.',\n",
       "  'strengths': '1. The proposed dual-sparsity optimization model has a certain novelty. \\n2. A variety of numerical results are presented to justify the proposed effectiveness.',\n",
       "  'weaknesses': '1. The existence and uniqueness of the proposed model are not discussed in detail. \\n2. The description of formulation for the proposed model is not fully concise and precise, especially the treatment of the rank-term. \\n3. Model sensitivity and robustness could be further discussed from the theoretical aspect.'},\n",
       " 'review_666': {'summary': 'This paper is about model fitting. The authors consider a scenario in which it is unknown whether correspondences between points in 2 images stem from 3D points that are (1) generally distributed, (2) lie on a plane, or (3) lie on a plane and the motion between the 2 images is not projective but affine. The latter implies that not a pinhole camera was used for projection but an affine camera. This can hold if, for instance, the distance between camera and scene is large compared to the depth variation within the scene.\\n\\nCase (1) amounts to the well-known fundamental matrix constraint x’^T*F*x=0 with (x, x’) being corresponding 2D homogeneous points. Here, F is a 3x3 matrix with rank(F)=2. For noise-free data, matrix F can be estimated from at least 8 point correspondences since F is determined only up to scale and each point-point correspondence yields a single equation.\\nCase (2) amounts to a 3x3 homography H. Differently from the F-matrix, homographies have full-rank, in general. As fundamental matrices, they are only determined up to scale. Since each point-point correspondence yields 2 equations, H can be determined from at least 4 correspondences.\\nFor a general affine transformation between the two images, case (3) implies that the last row of H equals [0,0,1]. There are no constraints on the remaining 6 entries, in general.\\n\\nThe authors show that by expressing cases (2) and (3) as fitting multiple subspaces, all three cases can be expressed by the same model. They propose a projected coordinate descent type of algorithm to estimate.\\n',\n",
       "  'strengths': 'To me, this interpretation of F/H-matrix geometry is new. I cannot say whether this naturally arises from classical theorems. The fact that all papers I am aware of fit either an F-matrix or a homography can be taken as evidence that at least this fact is not generally known.',\n",
       "  'weaknesses': '- proposition 2 is wrong\\nMatrix Psi has rank 2 which can be seen from the fact that the third row is linearity dependent on the first two. Hence, G_H=(9,7,2,3).\\n\\n'},\n",
       " 'review_667': {'summary': 'This paper shows an effect of deep neural networks when trained for classification tasks — the initial layers create linearly separable features, and the later layers collapse the features for the final prediction. This phenomenon is explored with extensive experiments. ',\n",
       "  'strengths': '- The paper explored a very interesting phenomenon of how the features are learned dynamically through layers.\\n\\n- The paper performed extensive experiments to show how this \"tunnel effect\" affects the model performance under different settings. \\n\\n- The experiments are well-designed, and the results are demonstrated well. \\n\\n\\n',\n",
       "  'weaknesses': '-  This is not the first/only paper that discovered some similar effects under a similar setting, therefore, a more comprehensive comparison with them in the related work section as well as a clarification on the contribution should be added. e.g. [1] examines the feature \"intrinsic dimension\", [2]  analyzes the generalization effects of feature neural collapse on in-domain and out-of-domain data.\\n\\n- The authors mentioned the network can be split into the extractor and the tunnel which compress the features, however, it can be difficult to systematically split the network, it seems the author also did not provide a systematically split of the network based on the numerical rank. \\n\\n\\n[1] Ansuini et. al. Intrinsic dimension of data representations in deep neural networks.\\n[2] Li et. al. Principled and Efficient Transfer Learning of Deep Models via Neural Collapse.\\n'},\n",
       " 'review_668': {'summary': 'This paper proposes the Tunnel Hypothesis: Training of deep networks splits layers into two distinct phases: (1) extractor phase and (2) tunnel phase. Extractor phase learns the linearly separable features whereas the tunnel phase compresses the representations. The authors provide evidence towards degrading effects of this tunnel effect on OOD (out-of-distribution) samples. Further, better understanding of continual learning may be possible due to the proposed hypothesis.',\n",
       "  'strengths': 'The paper has following strengths: \\n\\n1. The OOD representation section was very interesting.\\n\\n2. Applications to continual learning based on knowledge gained from the detailed analysis from this paper can also be useful.\\n\\n3. Overall, a lot of work has gone into this paper (many experiments).\\n',\n",
       "  'weaknesses': 'The paper has following weaknesses:\\n\\n1. Many of the observations are not particularly surprising. I think a lot depends on capacity of the network and the difficulty of the task at hand. It is not surprising that for a given task and a type of network, representations get learned up to a certain layer and then the remaining layers simply make the representations more compact. Indeed, if the task becomes more complex or more difficult, the tunnel length would reduce (since more layers would be spent trying to learn more complex features). This is clear from Table 1 where for ResNet-34, the tunnel length significantly reduces when going from CIFAR-10 to CIFAR-100 (from 20 to 29 layers). Thus, when the task became more difficult, more layers started getting used to learn better features. Similarly, for simple MLPs, we know that beyond a certain depth, depth does not help (this comes from many other studies, e.g., that analyze gradient properties, etc.: beyond a certain depth and without skip connections, adding more layers does not help due to vanishing gradients). The insight that “many later layers do not contribute significantly to accuracy” is also known and is precisely why “deep network pruning” literature is not able to prune later layers too significantly.\\n\\n2. In the introduction section, the authors claim that “they challenge the commonly held intuition that deeper layers are responsible for capturing more complex and task-specific features”. I do not see any evidence that they changed this commonly held view. In fact, many of their experiments reinforce exactly the common viewpoint. Specifically, the authors show that later layers hurt the OOD performance. This indicates that the later layers got specialized towards the within-distribution task which is why they hurt the OOD task. Hence, if the commonly held view is being reinforced with the evidence provided by the authors, there is nothing particularly surprising about the findings.\\n\\n3. I think the proposed work can have significant value in the field of continual learning and also multi-task/multi-modal learning if the observed insights can be used to guide novel architectural designs and/or loss functions. Unfortunately, the current work (despite a lot of hard work) only plays around with toy datasets in that problem space. If the authors can build further on the new insights and create new models/losses for the aforementioned areas, this can be an impactful work.\\n'},\n",
       " 'review_669': {'summary': 'The tunnel effect is described for deep overparameterized networks, whereby early layers form a linearly separable representation while later layers form a \"tunnel\" which passes this representation to the output without substantial change, other than compression (reducing its rank, a.k.a. discarding information). A large number of experiments show that this effect occurs in a variety of different models, datasets, and training times, and impacts out-of-distribution and continual learning settings. The effect implies that the capacity of a given architecture/dataset is fixed.',\n",
       "  'strengths': 'This paper provides a clear and comprehensive argument for both the existence of its hypothesis and its effects on several relevant subdomains of DNN research. The experiments are thorough, well organized, and address many potential concerns (such as consistency of the observations across different models and datasets). Some subtle details are handled correctly (e.g. use of unbiased CKA estimator in appendix E). The effect is convincing and could point to significant improvements in how transfer and continual learning is handled.',\n",
       "  'weaknesses': 'The procedure for computing the numerical rank should be given fully (e.g. the value of the threshold $\\\\sigma$ is not explicitly stated). In particular, figure 6 indicates some issues (see Questions below). Also, figure 6 is missing shading for the tunnel region after training, which would help readers reference other figures.\\n\\nThe difference in weights in figure 5 is not fully explained (e.g. $\\\\tau$ should be defined). Also, while the difference is normalized relative to $\\\\theta^0$ (the initial weight norm?, or is it the number of weights?), a better comparison would be relative to the norm of the mean change iterations/epochs, since the learning rate changes over training. As a result, the experiment cannot rule out the possibility that the tunnel is changing relative to other layers after the learning rate is reduced.\\n\\nOverall the evidence from CKA is lacking (figure 4) as it is only shown for a MLP. However, this is not a central piece of evidence.'},\n",
       " 'review_670': {'summary': 'The paper offers an empirical study of deep neural networks. The focus is on the role of intermediate layers in building a representation that is linearly separable and can eventually solve the task. The work highlights the fact that this linearly separable, low-rank representation emerges at a depth that is a fraction of the total depth (usually 1/3 to 2/3 for common image classification setups). Layers before such point are named \"the extractor\", and layers afterward \"the tunnel\". The authors further investigate the role of \"the tunnel effect\" on transfer learning and catastrophic forgetting. ',\n",
       "  'strengths': 'The main strength of the paper is the thoroughness of the empirical study. Although only pertaining to image classification (as mentioned by the authors), the study includes a wide range of benchmark datasets and architectures, and shows results with plots that are easy to parse.\\nConnecting the tunneling effect to practical recommendations for transfer learning is another interesting point. ',\n",
       "  'weaknesses': 'Although the authors put a strong emphasis on the novelty of their results, the fact that a linearly separable representation emerges well before the final layer is not completely novel. See e.g. [1] for an analysis using similar methods.\\nAlso, the reasons behind the so-called paradox that motivates the work are not completely clear. It\\'s not evident how the fact that capacity increases with depth, is at stake with the fact that there is an \"inductive bias\" toward simple solutions. \\nIn my view, the motivation paragraph in the introduction would need to be clarified, and the conclusion should clearly state how this paradox has been addressed by the paper.\\n\\n[1] Feature learning in deep classifiers through Intermediate Neural Collapse, Rangamani, Akshay; Lindegaard, Marius; Galanti, Tomer; Poggio, Tomaso.'},\n",
       " 'review_671': {'summary': 'The paper presents new and strong set of results on stability of (greedy version of) random forests. Theoretical (resp. numerical) evidence is provided to support stability for light-tail (and heavy-tail) assumptions on marginal distribution of squared response. New finite sample upper and lower bounds are provided for prediction intervals constructed from OOB effort of random forests. The paper can be regarded as a demonstrative work that justifies the merit of random forests for both point and interval prediction. \\n\\n\\n\\n',\n",
       "  'strengths': 'The style of results and overall content of paper are very appealing. I like the way in which stability and prediction interval results were informally stated first and then rigorously discussed later. A clear review of algorithmic stability concepts helped me understand the proof ideas.  \\n\\n',\n",
       "  'weaknesses': '-- I think the writing can be slightly improved by articulating the use of absolute stability results for bagged algorithms. \\n-- The transition from derandomized version of RF to finite-B case through the route of conditional stability analysis is a bit abrupt and needs more explanation, particularly with regard to concentration of measure. \\n-- The limitation/extension of theory to heavy-tailed case is interesting but some comments about the key bottlenecks in the proof technique that would need to be overcome to achieve such a generalization would make the contribution stronger. Also where does the theory break? The experimental results are not very clear in this regard. \\n-- On the prediction interval part, Table 1 can be enhanced and repositioned to include computational advantages as well. Finally, the discussion around “jackknife-after bootstrap-with-stability (JaBS)” is a bit hard to follow since the discussion on J+aB and J+aBS is intertwined with the intuition on how subsequent results in the paper build on stability results – it is desirable to streamline this discussion a bit. \\n-- please consider citing and discussing relevant work in OR on optimal classification/prescriptive trees by Bertsimas and co-authors as well as their work on Stable Classification. Your approach and focus is different, but given the stated goal of putting the stability of random forests on a stronger footing, it may be worthwhile to make a connection.  '},\n",
       " 'review_672': {'summary': 'In this paper the authors considers the issue of stability of the often used in practice Random Forest algorithm and provide theoretical bounds on the $\\\\varepsilon$-stability upto an order of $O_{\\\\mathbb{P}}(|Y|^2_{(n)}/n)$ (i.e. the largest in magnitude observation) when fitting the method with $n$-iid sample points $(X_i,Y_i)$. A light tailed assumption on $Y^2$ thereby yields suitable control over the asymptotic behavior of $|Y|^2_{(n)}/n$. Further, the stability results are used to derive $n$-dependent lower and upper bounds (under increasingly more assumptions) for the coverage probability of prediction intervals constructed from out-of-bag error of random forests. In comparison to many other results in the literature, this paper works with a practical version of random forests.',\n",
       "  'strengths': '1. In comparison to many other results in the literature, this paper works with a more practical version of random forests.',\n",
       "  'weaknesses': '1. It was not clear whether the stability bounds were optimal or could be improved.\\n2. The presentation usually benefits from working under a single set of assumptions instead of increasingly more assumptions (however this is a minor point).\\n'},\n",
       " 'review_673': {'summary': 'Random forests are one of the most used Machine Learning methods. Its standard variant (for regression) takes the following form. GIven a random sample $D=(X_i,Y_i)_{i\\\\leq n}$ of covariate/response pairs, one takes $B$ bootsrapped samples from $D$ and trains a tree regressor on each boostrapped sample (using one of many possible criteria). The estimated regression function $RF(x)$ is the average of the $B$ tree regressors on $x$. \\n\\nTheorem 1 of the present paper is a kind of stability property for $RF$ vis a vis its \"out-of-bag\" variant $RF^{\\\\backslash i}$. Here $i\\\\in [n]$ and $RF^{\\\\backslash i}$ is the version of $RF$ where bootstrapped samples not containing the $i$-th sample point are discarded. The paper then shows that one can use this stability property to build predictive intervals from the \"OOB residuals\" $|Y_i-RF^{\\\\backslash i}(X_i)|$. Theorem 2 proves that these intervals, after a slight enlargement, provide good coverage at near-nominal-levels, whereas Theorem 3  gives exact $1-\\\\alpha$ coverage in the limit, under suitable assumptions. \\n\\nOne of the main assumptions the authors impose for these last results is that the response variables be light-tailed. However, a small set of experiments suggests that similar properties would hold even for very heavy tailed covariates.\\n\\nThe present paper joins string of recent works dealing with uncertainty quantification for ML methods without resorting to a calibration sample (in which case one could use conformal prediction). The authors argue that main distinguishing feature of Theorems 2 and 3 is that their predictive intervals are much less demanding computationally. As computing the OOB predictors comes as a byproduct of the RF computations. By contrast, related work (eg. on jacknife type estimators) require the regression method to be rerun several times on leave-one-out samples. \\n\\nLet me also say a few words about proofs. The idea is to first explore the $B\\\\to +\\\\infty$ limit of $RF$ and $RF^{\\\\backslash i}$ and prove stability in that setting, via arguments from arXiv:2301.12600. ',\n",
       "  'strengths': 'As noted above, the paper obtains a lightweight method to compute (nearly-)valid prediction intervals from random forests, which are often used in practice. This means that the result is significant (though see the next field). It also seems to be original. The exposition is fairly clear. ',\n",
       "  'weaknesses': \"* Mathematically, it seems that much of the work behind the paper comes from arXiv:2301.12600 by Soloff, Barber and Willett. \\n* The nonasymptotic Theorem 2 is a bit unsatisfying in that both the interval length and the coverage are subject to errors that are hard to quantify in practice (still, since people will use RF anyway, it's nice to have some result of this kind). \\n* The results do not give a good bound on how large $B$ needs to be in order for the method to work well. This is clearly related not just to the maximum $Z_{(n)}$, but to how small an error one wants to allow when defining the interval.  \\n* One very minor comment: Theorem 3.4 from arXiv:2301.12600 (quoted in line 163) should be Theorem 9 (the numbering seems to have changed from v1). \"},\n",
       " 'review_674': {'summary': 'This work studies the random forests stablity for regression problem, and the authors presents theoretical analysis on the upper and lower boudns for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests. The theoretical guarantee is based on a light-tail assumption of the marginal distribution of the squared response. \\n\\n------------------after response---------------------------------\\n\\nAfter reading the authors\\' response, I do not think the authors answer my concerns, in particularly for the novelties and significances. \\n\\nAs a theoreical work, it is very important to evaluate from theoretical novelties and techniques, while I find some inremental results based on well-known techniques.\\n\\nI do not find any experiments, and I do not know why the authors could claim that \"Our work applies to many variants of random forests ... which makes it particularly relevant in theory and practice\".',\n",
       "  'strengths': '1) It is an interesting problem on the theoretical understanding of random forests.\\n\\n2) Some theoretical results on the convergence probability of prediction intervals constructed from the out-of-bag error of random forests. \\n\\n3) Limited theoretical techinical contributions',\n",
       "  'weaknesses': '1) The problem is not very clear. The authors should first present the studied problem, i.e. the original ranfom forests for regression, or randomf forest interval, or  prediction intervals constructed from the out-of-bag error of random forests. It is very confused to understand the main contributions in the current submission and relevant work. For completeness, it would be better to present the detailed algorithm, rather than finding some other research work for other readers.\\n\\n2) The main conclusions are not clear. The main contribution of this work is the stability of random forests in Theorem 1. Generally, a theoretical work concerns seriously the convergence rate of stability, and how tight of this rate. It would be better to present the specific expression for \\\\nu_{n,B}, and make necessary discussions. What\\'s factors affect the stability rate?\\n\\n3) Some important definitions and notions are missing. For example, where is the definition of \"light tail\"， whichi is the basic assumption in main theoretical results. How to characaterize light tail and its relevant factors.\\n\\n4) The authros should clearify the novelty and significance of the main results, for example, how about the theoretical new insghts on the technical proof in this work. As an pure theoretical problem, it is importnat to present some new technical proof, rather than simple extension of the current techiniques. What\\'s the siginificance of the main results, is it possible to present some pratical guidance and suggest some new algorithms.\\n\\n5) The authors should have a good background on the theoretical analysis on random forests, for example, \\nG. Biau, L. Devroye, G. Lugosi, Consistency of random forests and other averaging classifiers, JMLR 2008.\\nM. Denil, D. Matheson, N. De Freitas, Narrowing the gap: random forests in theory and in practice, ICLM2014.\\nW. Gao, F. Xu and Z.-H. Zhou. Towards convergence rate analysis of random forests for classification. AIJ, 2022.'},\n",
       " 'review_675': {'summary': 'This paper presents a new formulation of linear SEM by specifying a structure on the noise variables, which seems to impose zero-inflated distrbutions to achieve the \"few roots\" modelling goal. Identifiablity is given and guarantee for $L^0$ minimization estimator is provided for a special noise-free case. The minimization problem is further formulated into continuous optimization and numeric experiments are conducted.',\n",
       "  'strengths': '- The idea of the new formulation is interesting, based on the illustrative river pollution example.\\n- The experiments consider many different setups, also including real datasets. The proposed algorithm shows comparable performance in the simulation study, though not by much.',\n",
       "  'weaknesses': '- The motivation of the proposed formulation needs more elaboration, see questions. And the current definitions of \"few roots\" and \"negaligible noise\" in (6) are not formal or clear.\\n- Thm 3.2 only works for noise-free setting, thus there is no guarantee for consistency of $L^0$ minimization estimator for general model (4) beyond noise-free.\\n- Neither the related work and experiments discuss or compare with constraint-based methods, even the basic PC algorithm. Is it becaus we lose Markov property and faithfulness in this new formulation?'},\n",
       " 'review_676': {'summary': 'This paper considers learning of linear SEMs (weight matrix) under a data generation process that differs from the common formulation. It is assumed that each sample is generated from only few number of non-zero noise variables in which the set of noise variables is stochastic. The main theoretical result is identifiability of the weight matrix via an L0 norm objective. A relaxation of the objective with an L1 norm loss is used for extensive synthetic experiments and shown to be effective for learning the weight matrix under the proposed data generation mechanism.',\n",
       "  'strengths': '- Sparse root causes are an interesting concept to explore.\\n- Experiments on synthetic data demonstrate strong performance. Specifically, the proposed algorithm is fast and seems to scale up well, and when the assumptions are violated slightly, the algorithm still yields reasonable results.',\n",
       "  'weaknesses': '\\n- While the sparse root causes assumption is interesting, it is not well-motivated. For the pollution example, if I understand correctly, the top left and bottom left nodes do not really play “causal” roles in the sense that they are deterministic mediators in the system, and the whole causal system can be represented without using those nodes. In this sense, “few root nodes” become the effective causal nodes. Am I missing something? The numerical evaluations using real data also do not provide much help for motivation. \\n- NNZ is not a strong metric when SHD is already provided, and the only edge of the proposed algorithm in the real data experiments is this metric.\\n- Presentation can be improved. For instance, Theorem 2.1 formulation of the linear SEM is trivial. Similarly, having $N_c$ and $N_x$ separately is superfluous; having a single small variance, not necessarily isotropic noise suffices for the description.'},\n",
       " 'review_677': {'summary': 'This paper considers a new setting of linear DAG learning problem. Based on a linear transform of linear SEM, authors propose to study a new setting where there are few \"root causes\", with potential measurement noise in the data. Identifiability is proved and the true DAG is shown to be the global minimizer of the L0-norm of the vector of \"root causes\", under a specific distribution on the \"root cause\" variables. ',\n",
       "  'strengths': '- a new setting for the linear DAG learning problem\\n- useful identification result (Thm. 3.2) with a complete proof\\n\\n',\n",
       "  'weaknesses': '- the new setting and its motivating example are not sufficiently convincing. \\n- authors only consider specific distribution on the \"root causes\" variables, making  theoretic result somewhat limited\\n- some results are trivial from the literature (e.g., Thm 2.1) '},\n",
       " 'review_678': {'summary': 'The paper studies a new causal discovery method, in which it assumes that the DAG data is produced by few data-generating events whose effect percolates through the DAG. They propose a simple but effective method to learn the true DAG based on the few roots assumption. The proposed method outperforms baselines in various settings.',\n",
       "  'strengths': '1. The few roots assumption is reasonable. And the paper motivates it well.\\n2. The proposed solution is simple and effective.\\n3. The paper conducts experiments on both synthetic and real-world datasets, indicating the effectiveness of the proposed method.\\n',\n",
       "  'weaknesses': '1. It is not clear why the objective function Eq.(10) contains noise. It needs more clear explanation and derivation here.\\n2. I wonder whether the proposed method could find the root nodes at the same time rather than just learning the DAG.\\n3. The proposed method could not achieve the best results on real-world datasets. Hence, I doubt the few roots assumptions satisfy the real-world scenarios. BTW, it is better to say the network is a protein network rather than a gene network.\\n'},\n",
       " 'review_679': {'summary': 'This paper aims to deal with the temporal fluctuations and heterogeneity between variables, caused by unexpected noise, for better multivariate time-series forecasting. Specifically, the authors propose a linear complexity CrossGNN model, including Cross-Scale GNN which captures relationships inter- and intra- scales, and Cross-Variable GNN which captures the homogeneity and heterogeneity relationships between different variables. Experiments on 8 benchmark multivariate time-series datasets demonstrate the effectiveness of CrossGNN over some existing methods.',\n",
       "  'strengths': '1. The authors propose a GNN-based (CrossGNN) method with linear complexity for long-term time series forecasting.\\n2. The CrossGNN captures the relationships between both scales and variables.\\n3. The paper is easy to understand.',\n",
       "  'weaknesses': '1. The proposed CrossGNN does not compare with the SoTA methods, like RLinear, RMLP [1] and PatchTST [2]. I checked the results in this paper (Table 1 & Figure 4) and [1,2], and found that CrossGNN is worse than RLinear, RMLP and PatchTST.\\n\\n[1] Revisiting Long-term Time Series Forecasting: An Investigation on Linear Mapping\\n\\n[2] A Time Series is Worth 64 Words: Long-term Forecasting with Transformers\\n\\n2. It is unclear why the heterogeneity between variables is caused by unexpected noise.\\n3. In the top of Page 5, it is unclear why the production of two learnable vectors can diminish the effect of noise.\\n4. What is the meaning of \"C\" in Figure 2?'},\n",
       " 'review_680': {'summary': \"Overall Comment：\\nThis article addresses two issues in multi-variate time-series modeling: i) How to address signal noise in multivariate time series, and ii) How to address interactions between multiple variables to extract information. The article proposes two GNN models to solve these problems, including the Cross-Scale GNN model for addressing signal noise and the Cross-Variable GNN for addressing interactions between different signals.\\n\\nOverall, while some parts of the article are not very clear, such as, what is the meaning of  homogeneity and heterogeneity in time series, and the the ablation study can be improved, the article's innovative ideas are clear and worth being seen by more people. Compared to conventional baseline methods, this article has significant advantages.\\n\\nThe strengths of the article include:\\n\\n1. The paper conducts a large number of experiments, tested on 8 datasets. From the experimental results, the proposed method is effective and performs better than conventional MTS baseline methods.\\n2. The article is well written and easy to read, making it easy to understand the information that the author is trying to convey.\\n\\nThe weaknesses of the article include:\\n\\n1. The analysis of the ablation study needs to clarify that which module, the Cross-Scale GNN and Cross-Variable GNN, plays a larger role in the model in order to judge whether it is filtering signal noise that makes the proposed model perform better on each dataset or whether introducing interactions between multiple variables is the key factor.\\n2. Correspondingly, if the Cross-Scale GNN model for addressing signal noise plays a larger role, is the focus of the article on time series denoising or modeling time series with noise? The article should be compared with methods specifically designed for denoising time series, rather than just conventional time series modeling baselines.\\n3. What is the meaning of homogeneity and heterogeneity in time series signals? In Figure 1(d), only positive or negative correlations between variables are displayed, which is not related to homogeneity and heterogeneity relationships between variables.\",\n",
       "  'strengths': 'The strengths of the article include:\\n\\n1. The paper conducts a large number of experiments, tested on 8 datasets. From the experimental results, the proposed method is effective and performs better than conventional MTS baseline methods.\\n2. The article is well written and easy to read, making it easy to understand the information that the author is trying to convey.',\n",
       "  'weaknesses': 'The weaknesses of the article include:\\n\\n1. The analysis of the ablation study needs to clarify that which module, the Cross-Scale GNN and Cross-Variable GNN, plays a larger role in the model in order to judge whether it is filtering signal noise that makes the proposed model perform better on each dataset or whether introducing interactions between multiple variables is the key factor.\\n2. Correspondingly, if the Cross-Scale GNN model for addressing signal noise plays a larger role, is the focus of the article on time series denoising or modeling time series with noise? The article should be compared with methods specifically designed for denoising time series, rather than just conventional time series modeling baselines.\\n3. What is the meaning of homogeneity and heterogeneity in time series signals? In Figure 1(d), only positive or negative correlations between variables are displayed, which is not related to homogeneity and heterogeneity relationships between variables.'},\n",
       " 'review_681': {'summary': 'CrossGNN is a linear complexity GNN model designed for MTS forecasting, addressing two obstacles: self-attention mechanisms assigning high scores to outlier points and real-world data homogeneity and heterogeneity. By combining Adaptive Multi-Scale Identifier (AMSI), Cross-Scale GNN, and Cross-variable GNN, CrossGNN outperforms recent SOTA methods in real-world datasets.',\n",
       "  'strengths': '1. Despite considering the relationship between variables, unlike Transformer-based models, it has a low time complexity O(L).\\n2. The paper also includes a comprehensive set of ablation studies and the performance in forecasting is SOTA.\\n',\n",
       "  'weaknesses': '1. The authors mentioned that noise can disturb attention mechanism in transformer. However, the noise ratio is less than 2\\\\% as shown in Figure 1 (b) and I do not think this would be significant. Also, those outliers can be removed by using outlier detection techniques before training. \\n2. It is necessary to add an explanation or experiments to assure that the self-attention mechanism really adversely affects performance by assigning outlier points as high scores.\\n3. Technical novelty is a bit weak. Concepts of cross-scale and cross-variable are already introduced concepts in TimesNet and Crossformer. Also, many papers have already used GNN to deal with cross-variable interaction. What is the main difference except the input?'},\n",
       " 'review_682': {'summary': 'This work first analyzes real-world datasets for multivariate time series forecasting and finds out two problems that are not well handled by previous works: 1) unexpected noise; 2) heterogeneity between variables. A GNN-based model, named CrossGNN, is proposed to fill the gap. CrossGNN consists of three components: 1)Adaptive Multi-Scale Identifier identifies potential periods with FFT and aggregates time series at different scales to construct a mult-scale view of the data; 2)Cross-Scale GNN constructs a graph among scales and uses GNN to capture cross-scale dependency; 3)Cross-Variable GNN captures homogeneous and heterogeneous dependency among variables. Correlation graphs used in Cross-Scale and Cross-Variable GNNs are restricted to be sparse, so the complexity is linear to the input length. Experiments on 8 real-world datasets demonstrate the effectiveness of the proposed model.',\n",
       "  'strengths': '- This work is well-structured and easy to follow.\\n- The studied problem, noise in datasets, is an important and practical problem for MTS forecasting.\\n- Three components in CrossGNN are well-motivated and reasonable. The linear complexity is also an advantage.\\n- Robustness analysis of noise in section 4.3 is interesting.',\n",
       "  'weaknesses': '- My main concern is that graphs used in Cross-Scale and Cross-Variable GNNs are static for each dataset. These graphs are constructed by shared learnable vectors with filtering, so they are static and the same for different inputs. This leads to 1) the dependency structure of time steps being fully determined by the positions in the series; 2) the dependency structure of variables being the same for different inputs in a dataset. \\n- Some recent works (e.g. PatchTST[1], Crossformer[2]) that explicitly model the cross-variable dependency should be compared in the main experiment.\\n\\n[1]Yuqi Nie, Nam H. Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. A time series is worth 64 words: Long-term forecasting with transformers. In International Conference on Learning Representations, 2023.\\n\\n[2]Yunhao Zhang and Junchi Yan. Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting. In International Conference on Learning Representations, 2023.'},\n",
       " 'review_683': {'summary': 'This work addresses the problem of proximity bias and confidence calibration by performing a comprehensive empirical study of various pretrained ImageNet models. The empirical findings provide insights on persistence of proximity bias even after performing calibration using existing post-hoc calibration algorithms. To mitiagte proximity bias and improve confidence calibration based on sample proximity, the paper proposes PROCAL algorithm that can be used as a plug-and-play method combined with existing calibration approaches. Further, proximity-informed expected calibration error metric is introduced to quantify the effectiveness of calibration algorithms in mitigating proximity bias. ',\n",
       "  'strengths': '- A comprehensive study of pretrained ImageNet models involving various neural network architectures on their model calibration and proximity bias evaluation. The empirical study is performed on image classification tasks (under balanced, long-tail, and distribution-shift settings) and text classification tasks. \\n- Experimental evaluation if thorough using various calibration metrics. \\n- The paper provides many interesting observations from the empirical study related to proximity bias and model calibration, which is an important area of study under long-tailed data distribution settings.',\n",
       "  'weaknesses': '- The presentation of experimental results and writeup of Experiments Section 6 can be improvised, the findings for many of the questions are pointed to the Appendix without any brief details in the manuscript. I understand this is due to page limitation, but I would suggest the authors to focus on the results that are presented in main manuscript, or include the brief info in the manuscript at least.\\n'},\n",
       " 'review_684': {'summary': 'The article focuses on the problem of uncertainty quantification in classification.\\nCalibration provides some guarantees on the estimated class probabilities on average. However, subgroups can still be miscalibrated. The article first aims to characterize these subgroup miscalibrations through proximity levels of the samples. It claims that a classifier, even calibrated, tends to be underconfident on high-proximity samples and overconfident on low-proximity samples. To measure this effect, it defines a proximity-informed ECE. Then, it proposes a recalibration framework based on this proximity-informed measure. Finally, it benchmarks the proposed method on numerous datasets and models.',\n",
       "  'strengths': '* The problem is well presented and motivated. Figure 1 is pedagogical and helps the comprehension of the problem.\\n* The idea of characterizing subgroup miscalibrations through proximity is interesting, and refining uncertainty estimates is a good direction.\\n* The proposed framework is versatile: it can work as a stand-alone or combined with standard calibration techniques. It provides two versions: binning-based and continuous.\\n* The experimental study is substantial.\\n  * Datasets are large-scale, numerous, and multimodal: ImageNet, Yahoo-Topics, iNaturalist, ImageNet-LT, MultiNLI, ImageNet-C.\\n  * The article studies numerous models, e.g. 504 pre-trained models on ImageNet.\\n  * It compares many standard calibration methods, both scaling-based and histogram-based: temperature scaling, ensemble temperature scaling, parameterized temperature scaling, histogram binning, isotonic regression, and multi-isotonic regression.\\n* The experimental study provides substantial evidence.\\n  * It reveals proximity bias in most of the 504 pre-trained networks on ImageNet (72% according to a Wilcoxon rank-sum test).\\n  * The proposed method consistently improves over standard calibration methods.\\n  * The time overhead of the method is small, with an increase of 1.17% in inference runtime.\\n* Completeness of the study: It reveals the proximity bias, proposes a metric to measure it, a recalibration procedure to address it, and substantial experiments showing consistent improvements.',\n",
       "  'weaknesses': 'No major weaknesses.'},\n",
       " 'review_685': {'summary': 'This paper studies the prevalence of proximity bias in calibration, i.e. the rate of miscalibration on samples that are far away from their nearest neighbors in the data (\"low proximity\"). The authors empirically show that this type of miscalibration is present across many models, and propose a new post-training calibration procedure for mitigating it. Their approach shows significant empirical improvements over standard post-training calibration approaches.',\n",
       "  'strengths': '- **Originality:** The empirical investigation and proposed methodology in the paper is quite novel, as I am not aware of prior work that has studied this type of bias in calibration (although others have studied subgroup calibration). \\n- **Quality:** The claims in the paper are technically sound, and the experiments exploring proximity bias are extensive (more than 500 pretrained models considered, and various calibration baselines).\\n- **Clarity:** Overall, the paper is well-written and well-organized, with motivating experiments and intuitive definitions. However, I believe the presentation of the calibration algorithm in the paper could be improved (detailed further in weaknesses).\\n- **Significance:** The idea of low proximity samples introduced and analyzed by the authors seems quite significant, as these samples can correspond to underrepresented populations in the data.',\n",
       "  'weaknesses': '- **Algorithm Details:** The weakest part of the paper in my view is the lack of detail in Section 5.1. This part of the paper would be significantly improved by including something akin to the pseudo-code algorithm in the appendix. There are several questions that arise when reading this part: what does one do after estimating the posterior probability conditional on prediction and proximity (in the algorithm I can see that this is just the output on the test point)? Do we compute proximity only with respect to the test data? What type of KDE is used (i.e. kernel, bandwidth, etc.)? \\n- **Implementation Details:** In addition to algorithm details, some parts of the experimental setup could also be made clearer. How are ECE and ACE computed (i.e. binning scheme)? Do you set aside calibration data for the scaling methods (TS, ETS, PTS, PTSK) in addition to the set aside data for ProCal?'},\n",
       " 'review_686': {'summary': \"This paper quantifies and proposes a mitigation for a phenomenon in DNN training, where more 'unusual' examples (here defined as having a higher average distance to its K=10 nearest neighbors) are generally more miscalibrated across a range of models and tasks. The authors propose a new proximity-aware calibration metric, PIECE, and demonstrate that it can capture calibration issues that are not necessarily captured by the standard ECE metric (and, in fact, always P>= ECE). Additionally, the authors propose a mitigation, ProCal. This mitigation is presented in two variations, one for continuous and one for discrete confidence. These work by adjusting the uncalibrated probability score based on the model's miscalibration on examples with that average distance.\",\n",
       "  'strengths': \"The paper is very clearly written, with a logical flow and good explanations of all steps taken. I particularly enjoyed the motivation via experiments on existing models leading to theory-driven proposals leading to further experimental verification. I also appreciated the through ablation study and the extra attention given to OOD examples.\\n\\nIn addition, the original miscalibration problem that the paper brings up seems to me to be important and relevant, and is well-motivated. As I am not an expert in miscalibration mitigation techniques I cannot fully comment on the novelty aspect of the work, though I have not seen this 'atypicality' concern brought up explicitly before; it also dovetails neatly with other research in atypical examples.\\n\\nThe proposed metric and mitigations, while very simple, are logical and effective, which I hope will lead to their adoption.\\n\\n\",\n",
       "  'weaknesses': 'I felt that the \\'atypical\\' (high $D(X)$) examples could have been better characterized. In particular, the authors relate these examples to underrepresented categories in datasets (eg, Black people in health datasets), but this is not necessarily so. It does not seem incredible to have a scenario where a data is divided into two clusters, where the smallest cluster is nevertheless very tight, and so has a smaller average $D(X)$.\\n\\nIt is not really clear what the ProCAL method refers to. It seems like it mostly splits into two methods each of which have their own name. Maybe it would be better to call them ProCAL-C and ProCAL-D  (for continuous and discrete)?\\n\\nThe analysis of ProCAL effectiveness seems a little sparse in claiming \"our method consistently improves the calibration\"... My interpretation of the data would be that ProCAL is very helpful in conjunction with raw confidence as well as some of the other methods with higher PIECE scores (TS variants), but not as effective for methods such as IR and MIR, where it seems to hurt as much as help. I don\\'t think that this disqualifies the paper, but a more thorough explanation and analysis of this would be appropriate.\\n\\n(minor) in section 3.1, what is the sensitivity of two points having the \\'same\\' confidence?\\n(minor) It is not clear why the definition of D(X) contains an exponent, rather than the simple average of the ten smallest distances.\\n'},\n",
       " 'review_687': {'summary': 'This paper proposes to use reinforcement learning (RL) to improve adaptive sampling effectiveness in Monte Carlo ray tracing.  Another key contribution they claim is the use of a latent space representation to encode temporal information, which improves the reuse of spatiotemporal pixel information across frames.  The impact of this work is to improve quality of real-time path tracing results with respect to noise and temporal stability.',\n",
       "  'strengths': 'The paper is well written, and provides a clear preliminary of the necessary background on adaptive sampling and denoising, as well as reviewing current SOTA approaches which are compared with their method.  The usage of the \"spatiotemporal\" latent \\nspace, which is claimed to encode temporal information more effectively than previous works, is an insightful idea.  The RL-based, learned importance sampler is also an interesting approach that addresses limitations of prior works.  Qualitatively and quantitatively, their method outperforms other methods by a significant margin.',\n",
       "  'weaknesses': 'Evaluation of the method is limited to only a small number of scenes.  It would be nice to see a larger scale evaluation, though it is understandable that training/evaluation data is laborious to assemble.\\n\\nPossible lack of theoretical novelty -- the method is validated with empirical results which are quite promising, but there is little discussion or analysis of the stability / robustness of the method.\\n\\nAdditional images for qualitative comparison could be helpful for visualizing some of the key concepts discussed in the paper.  For example, visualizing qualitative differences between various sample counts, or dedicated visualizations of the estimated sample maps and/or RL state.'},\n",
       " 'review_688': {'summary': 'This paper tackles the issue of Monte-Carlo path tracing which is an important field for computer graphics and rendering. The paper first analyzes the current state of the art and identifies mainly two flaws which are addressed thereafter: First, the authors introduce a spatio temporal latent space serving as input to the denoising autoencoder which outputs the final image frames as well as (as a feedback) to the importance sampling network which outputs a distribution for rays per pixel. Second, as opposed to previous work, this distribution is not sampled from a sampling heatmap as in previous works but since this is problematic during training due to a coarse numerical estimation of the output gradient with respect to the gradient. Instead an RL based method for importance sampling is used during training which removes this need for a numerical estimation of the gradient. The resulting model seems to yield higher PSNR values than previous works.   However I am very unfamiliar with this topic so I cannot really estimate how thorough the evaluation is done.',\n",
       "  'strengths': \"* The paper seems to identify limitations and flaws in current methods which are then overcome by simple solutions which can furthermore be trained in combination in and end-to-end manner. However since I don't know all the related work, I could've missed sth.\\n* The proposed results seem to yield better results (measured by PSNR) at the cost of slightly higher inference times \",\n",
       "  'weaknesses': \"* For Table 1, there is no information regarding the dataset and resolution of the images/videos used to assess the presented values. This is confusing, because the PSNR values are shown for 4 spp, resulting in an inference time of 22.5 ms which is faster than base. However, in Fig. 3, the average inference time for the proposed method  is much higher . Can the authors clarify this?\\n* The results are not presented as a function of image resolution (or number of pixels in the image). It would be interesting and important (e.g. to estimate the method's rea-world applicability) to report that, since nowadays most images/video to be rendered are of high spatial resolution.\\n* training datasets are nowhere listed? Is the method trained on all three presented datasets jointly or independently for each of them?\\n* Writing down the final objective function for the overall model would be good, since it would give the reader a final overview and summarize all the different aspects of the method. \"},\n",
       " 'review_689': {'summary': 'This paper proposes two techniques to improve the performance of Monte-Carlo patch tracing on real-time image rendering: 1) keep all previously sampled values to improve spatial-temporal information reuse; 2) use reinforcement learning to optimize the sampling importance network, avoiding the explicit numerically approximated gradients.',\n",
       "  'strengths': 'The problem is clearly illustrated and the motivation is easy to understand. The experiments are adequate to demonstrate the arguments of this paper.',\n",
       "  'weaknesses': \"1. Line71 describes some methods that improve the spatiotemporal reuse by storing not only the averaged pxiel values. But there are no further discussion about their difference to the proposed method.\\n\\n2. Although a well-trained RL framework performs good during inference, the training of a RL framework is usually unstable. The authors are suggested to add more details about the training techniques.\\n\\n\\n\\n------------Post Rebutal-----------\\n\\nI have carefully read other reviewers' comments and the authors' responses. Although I think this paper proposed a good method for the defined problem, other reviewers argue that most of the techniques used in this paper have been discussed in previous papers, which heavily weakens the novelty of this paper. Since I am not familiar with this topic, I adjust my score for the concern of the novelty.\"},\n",
       " 'review_690': {'summary': 'Ray tracing faces the difficulties of being applied practical real-time applications due to high levels of noise when sample counts are low. Sample counts are often limited to as low as 4 when considering real-time applications (~30ms latency). As such, the paper proposes an end-to-end training of a RL-based sampling importance network, a latent space encoder network, and a denoiser network. As a result, the proposed framework achieves strong performance on several benchmarks when considering performance and latency trade off.',\n",
       "  'strengths': '- The paper is well-written and easy to follow\\n- The proposed framework demonstrates strong performance in terms of performance and latency trade off.',\n",
       "  'weaknesses': '- What is the exact novelty in comparison to previous works? The proposed framework seems to be combination of RL-based adaptive sampling [22], the use of sampling importance network [23], spatiotemporal reservoir (spatiotemporal latent space) [25,27], and the use of denoisers [10], except for minute details, such as not feeding the output of a denoiser to the sampling importance network?\\n\\n- Without detailed discussions on the major differences between the proposed method and previous works and/or combination of previous works, it is difficult to assess the novelty and contribution of the proposed method.\\n\\n- How does the memory consumption compare between the proposed method and previous works?\\n\\n- Is the inference time in Table referring to the latency of the whole framework, including the inference of networks?'},\n",
       " 'review_691': {'summary': 'This paper considers the spiked Wigner problem with inhomogeneous noise, i.e. the inverse problem of estimating a rank-matrix through an inhomogeneous noise channel. This problem naturally arises in many applications and a universality result makes the problem considered quite general with regards to the noise distribution.\\n\\nThe authors have made several contributions in this paper:\\n1. They have derived the AMP recursions to solve the spiked Wigner problem.\\n2. The most interesting property of AMP-like methods is that their behavior can be characterized exactly through a set of low-dimensional state evolution equations. This paper obtains the state evolution for the AMP recursion that solves the problem considered.\\n3. The authors analyze the AMP algorithm with identity denoisers and show that it corresponds to an spectral method for a specific matrix. More interestingly, the authors conjecture that this linear version of AMP detects a spike in the same region as the general AMP.',\n",
       "  'strengths': '- The paper considers an interesting problem with many applications. \\n- The authors derive an AMP method to solve this problem.\\n- The authors obtain the state evolution of this AMP recursion, thus fully characterizing the macroscopic behavior of the AMP recursion at **each** iteration of the algorithm and **not** just the fixed points. This result gives us a **theoretical** way of obtaining the estimation error of the AMP method using very general metrics\\n- The authors show that when the Bayes optimal denoisers are used (i.e. the mean of the posterior) the fixed point equations exactly match the Bayes optimal fixed point equation of another recent work.\\n- Finally, the authors analyze the linear version of the AMP algorithm and show it is equivalent to spectral method for a specific matrix.\\n\\nTo summarize, the authors look at the spiked Wigner problem with inhomogeneous noise, derive an AMP method to solve it, and fully characterize the theoretical behavior of the AMP method in a certain high-dimensional asymptotics. This is in contrast to many other methods that are used in practice, but have no theoretical guarantees or guarantees of the form of high-probability upper bounds on the error in certain metrics. AMP methods, allow us to obtain the **exact** error in many **different error metrics** in a certain **high-dimensional limit**.',\n",
       "  'weaknesses': 'The weaknesses that come to my mind are mostly the usual weaknesses of the AMP algorithms:\\n- The AMP algorithms are often described as not very useful to solve problems in practice due to their instability often requiring a lot of tweaks such as damping to make them converge. I do not see much comments in this work regarding the stability of the AMP method described. This is in part due to generality of the algorithm (described using general denoisers) and in fact for the linear case the authors show a condition for convergence, however no mention of convergence or potential issues in the general case is mentioned. I should admit however that for example Bayes optimality of the AMP method with Bayes optimal denoisers makes this method interesting in practice for this problem.\\n- That being said, AMP having theoretical guarantees would still be very valuable as a theoretical tool. However, obtaining the errors through the state evolution equations are often very nontrivial due to the need to calculate expectations in a recursive formula that often need MCMC methods and are sometimes computationally not much better than running AMP for several instances of the problem and estimating the final error.\\n- As mentioned above, the AMP results only hold in a certain asymptotic regime. However in practice, very good match is observed even for moderately sized problems as the authors also mention.\\n\\n## Minor comments\\nI believe the work is hard to follow for someone who is even familiar with the problem considered but not familiar with the AMP literature. It assumes the readers are knowledgeable in this area and very familiar with previous works which makes it hard to follow.'},\n",
       " 'review_692': {'summary': 'The paper provides an analysis of an AMP algorithm for the spiked Wigner model with inhomogeneous noise. The paper builds on the matrix AMP framework to derive the state evolution equations for the considered AMP recursion for the studied model. The paper further shows that if the denoising functions are the Bayes one, then the fixed point equation of the state evolution of the AMP algorithm is the same as the one satisfied by the Bayes optimal estimator.\\n\\nThe paper also leverages the developed machinery to study the properties of a spectral algorithm which is motivated by considering the the identity denoising functions. It is conjectured that this spectral algorithm exhibits optimal phase transition.',\n",
       "  'strengths': 'I find the paper to be generally well-written and it is not hard to follow. The problem that is considered is interesting and the presented results generalize previously known results for the spiked Wigner model with homogenous noise to the non-homogenous case.',\n",
       "  'weaknesses': 'Minor comments:\\n- Page 1: Please state whether $\\\\tilde{\\\\Delta}$ and/or $g$ are assumed to be known. From Eq.(3) it seems that we do assume that $\\\\Delta$ is known.\\n- Page 2, line 82: The notation for $f_t:\\\\mathbb{R}^N\\\\times \\\\mathbb{N} \\\\to\\\\mathbb{R}^N$ is confusing/informal because from the displayed equation, it seems that $f_t$ takes input from $\\\\mathbb{R}^N$. Is $t$ supposed to be the input integer in $\\\\mathbb{N}$?\\n- Page 2, line 83: If $f_t^a$ are general Lipschitz functions, it is not clear to me why $f_t$ is linear.\\n- Page 3, line 112: It seems to me that if we replace the second moment assumption by finite $k$-th moment, we are strengthening the assumption, not weakening it.'},\n",
       " 'review_693': {'summary': 'This paper studies the (symmetric) rank-1 matrix estimation problem with inhomogeneous noise. Here inhomogeneous noise refers to a symmetric noise matrix that is block-wise constant where the number of blocks is a constant relative to the dimension. \\nThis paper proposes an approximate message passing (AMP) algorithm and shows the corresponding state evolution result. \\nAnother piece of contribution is the design of a spectral algorithm that outputs the principal eigenvector of a rescaled and recentered matrix. \\nNumerics suggest that this outperforms the naive estimator of the principal eigenvector of the data matrix per se. ',\n",
       "  'strengths': 'The most interesting (at least to me) part of the paper is Section 3 where a nonstandard spectral algorithm is introduced and analyzed to some extent. \\nAs the authors commented, this estimator outperforms (at least numerically) the naive one corresponding to the original matrix Y. \\n\\nAnother satisfactory aspect of the result is the coincidence between the fixed point of AMP and that of the Bayes-optimal estimator (i.e., E[x^* | Y]), though this is not surprising. ',\n",
       "  'weaknesses': '1. The majority of the paper is devoted to AMP and its state evolution whose proof is a rather standard reduction to the matrix-valued AMP by Javanmard--Montanari. I didn\\'t check the details carefully since everything goes as expected. But it\\'s still good to see things written down formally. \\n\\n2. Section 3 is interesting at a heuristic level. However, I have a doubt regarding the authors\\' claim. \\n\\nIn line 131, it is claimed that \"we rigorously show that with SNR<1 our proposed spectral method fails to recover the signal\". I don\\'t think the analysis in Section 3 constitutes a proof of this claim. \\nIt was shown that the trivial fixed point of an AMP with linear denoiser is attractive when SNR<1. I agree with this, but this does not imply that the asymptotic overlap of the spectral estimator is 0 when SNR<1. \\nThe iterate of the linearized AMP converges (in constant number of steps) to the principal eigenvector (i.e., the spectral estimator) only when a spectral gap is present. \\nWhen SNR<1, there is no spectral gap and it is unclear how the iterate of linearized AMP is related to the principal eigenvector. \\nIt may converge to some other vector, depending on the initialization. \\nIn fact, rigorously speaking, I think it\\'s fundamentally unlikely to prove subcritical behaviour by exploiting linearized AMP. \\nThe analysis only proves the attraction of 0 when SNR<1, which is an *evidence* that the phase transition threshold is 1.\\nHowever, this implies neither \"spectral fails when SNR<1\" nor \"spectral works when SNR>1\". \\n\\n3. If I understand correctly, the Delta matrix is assumed to be *known*. A very important aspect that was not discussed at all (correct me if I\\'m wrong) is what happens when Delta is unknown which appears (to me) to be a slightly more realistic assumption. \\nIn that case the Bayes-AMP is no longer a practical algorithm (even with warm start) and the spectral algorithm is also not computable. \\nIn fact, is it fair to say that the proposed spectral algorithm outperforms the naive one *because* it uses Delta information?\\nCan the price of lacking the knowledge of Delta be quantified?\\nI know this may go beyond the scope of the present paper. \\nBut it seems to be an interesting nontrivial point that\\'s worth mentioning/discussing. '},\n",
       " 'review_694': {'summary': 'This paper considers approximate message passing algorithms for reconstructing a rank-1 signal when corrupted by a symmetric matrix of noise with a block-variance structure; it is assumed the signal _x^*_ has iid coordinates generated from a prior distribution.  One then forms the matrix $Y = x^* (x^*)^T/\\\\sqrt{N} + A \\\\odot \\\\sqrt{\\\\Delta}$, where $\\\\Delta$ is a blockwise constant, positive matrix.  The matrix $A$ is a symmetric gaussian matrix with iid off-diagonal entries of size $N \\\\times N$.   \\n\\nThe number of blocks $q$ appears to bounded independent of matrix size, and it is assumed one has access to the scale matrix Delta.\\n\\nThe first algorithm is a proper generalization of an AMP recursion for the case of a rank-1 signal with Wigner noise.  The state evolution is shown to converge (Theorem 1.2 -- using a modification of existing techniques) and correspond to the solution of the Bayes optimal estimator (Theorem 1.4).  \\n\\nThe spectral method designs a linear recurrence which is (locally? and conditionally?) optimal, in that it also recovers the same estimator by computing a principal eigenvector of an associated matrix.  ',\n",
       "  'strengths': '1) The mathematical content is sound.  The main content (theorem 1.2) is proven in the supplemental material.  This adds an algorithmic aspect to a model which has attracted recent information theoretic attention.\\n2) The paper presents an algorithm which is optimal for the problem posed.  The algorithm is part of a larger well-studied class.\\n3) The performance of the algorithm is illustrated numerically in a simple case.\\n4) A linear method is presented, which may reproduce the more complicated general AMP performance for the hidden spike.',\n",
       "  'weaknesses': '0) The article does not provide any broader context for the technical results it develops; all but the first few pages are technicalities related to AMP theory.  It is targeted at experts in approximate message passing, and it does not develop much of the information-theoretic aspects of the model (which I gather are proven in Guionnet et al).  There is no conclusion.  There is nothing in the way of practical considerations or relations to application (although I would say this alone is forgivable, if the paper were otherwise immaculate).  Much of the main text is occupied by technicalities related to the formulation of the main theorem and in summoning relevant AMP theory from Javanmard and Montanari as well as Deshpande et al.  \\n1) The main theorem (1.2) is an adaptation of an existing result.  Moreover, approximate message passing algorithms are well studied and many theorems exist for them.  The presence of non-iid noise makes it somewhat unique, but I think it is fair to say that this is not a big extension of existing theorems.  (In particular, there is a change of variables to connect the homogeneous and inhomogeneous cases).\\n2) The spectral method, which is introduced, is largely left half-baked.  There is a conjecture (1.6) related to it, and there is a 1 page description of how the method is developed.  There is an equation (42) showing that the overlap evolution is unstable when a certain Perron-Frobenius eigenvalue is larger than 1.  But finally, the main points here are left as conjectures.'},\n",
       " 'review_695': {'summary': 'This paper presents Hierarchical Multi-Agent Skill Discovery (HMASD) that can discover both team and individual skills in MARL. The authors formulate multi-agent skill discovery as an inference problem in probabilistic graphical models. The model consists of a skill coordinator that reasons about team and individual skills, a skill discoverer that maps skills into actual execution, and a skill discriminator that encourages the learning of diverse and distinguishable skills. The proposed method is evaluated on sparse reward multiagent benchmark including SMAC and overcooked and is shown to achieve superior performance comparing to baselines. Ablation studies are also done to verify the effectiveness of each proposed components.',\n",
       "  'strengths': '- The proposed method is intersting.\\n- The paper is nicely structured.',\n",
       "  'weaknesses': 'There is a bit limited given only training curves are shown. More fine-grained experiments like visualization of learned skills, progression of skill learning, etc., may provide more insight into the effectiveness of the proposed method. Overall the experiment is on a low side and see more detailed comments in the questions section.'},\n",
       " 'review_696': {'summary': 'This paper focuses on applying unsupervised skill learning to multi-agent reinforcement learning. For this purpose, the authors proposed a two-level hierarchical algorithm for discovering both team and individual skills in MARL, where individual skills refers to the abilities of individual agents and team skills refer to the ability of agents to work together as a whole. To this end, they embed the multi-agent skill discovery problem into a probabilistic graphical model and formulate it as an inference problem. Finally, they show that the proposed method achieves superior performance on sparse reward MARL benchmarks. ',\n",
       "  'strengths': '1. The problem this paper considers is rather important and it is a promising way to learn a set of skills and combine them properly to tackle complex tasks.\\n2. The literature review is sufficient in Appendix B.\\n3. The proposed method of decomposing the team skill into different individual skills for agents and ensuring that the joint behavior of all agents can form the team tactic is well-motivated with the football example.\\n4. The proposed method is novel as this work is the first attempt to model both team skills and individual skills with the probabilistic graphical model in MARL.\\n5. The empirical evaluation, especially Figure 4, is of high quality and quite interesting. \\n6. The results on SMAC with sparse rewards and Overcooked are significant.\\n7. The paper is generally well-written.',\n",
       "  'weaknesses': 'The reviewer is concerned about the training of the proposed method. (1) Too many components that require function approximation may bring instability into the MARL training process.  (2) In Figure 3 of Appendix E, the proposed method seems to be very sensitive to hyperparameters. '},\n",
       " 'review_697': {'summary': 'This paper proposed HMASD, a two-level hierarchical algorithm for discovering both team and individual skills in MARL. The high-level policy based on the transformer structure generates team skills and individual skills in an autoregressive manner, and the low-level policies output primitive actions according to individual skills and local observations. The authors formulate multi-agent skill discovery as an inference problem by augmenting the basic probabilistic graphical model. Experimental results show that HMASD can outperform other baselines in sparse reward multi-agent tasks.',\n",
       "  'strengths': '1. The paper is well-organized and well-motivated. The authors explain their formalism extremely well throughout, including in their methods section.\\n2. The authors design a toy game *Alice_and_Bob* to demonstrate how their method works, which improves the soundness of their method.\\n3. Some MARL work related to skill discovery or exploration is fully mentioned in the appendix.\\n4. The authors conduct solid experiments in some popular benchmarks, and carry out sufficient ablation experiments.',\n",
       "  'weaknesses': '1. Some important baselines are missing in the experiment section, such as HSD and CMAE.\\n2. Some curves are stopped while learning does not seem to have converged in Figure 6 & 7.\\n3. Due to the introduction of more hyperparameters (8 new hyperparameters can be seen from Table 3), HMASD needs more hyperparameter tuning.'},\n",
       " 'review_698': {'summary': 'The paper proposes a two level hierarchical model for cooperative multi-agent RL. The key idea is to use variational inference based skill discovery over joint and individual policies. Intuitively, the objective can described as follows: i) find individual options, that are diverse (in terms of state visitations), ii) find joint options that are diverse (in terms of joint state visitation) iii) maximise the reward.\\nThe experimental results on several cooperative domains are presented and the method performs better than well established baselines.',\n",
       "  'strengths': '- The paper presents a technically solid, novel algorithm.\\n- The experiments are convincing and demonstrate that the method indeed discovers helpful joint and individual skills and combines them to into a reward-maximising policy\\n',\n",
       "  'weaknesses': '- My main concern is that most of the improvement comes from implicit exploration bonus that arises from skill discovery objective, rather than from decomposition of the main task into subs tasks. It would be more convincing to have some sort of exploration bonus baseline. For example, adding a reward for individuals visiting new states and population visiting new joint states. For example, one could derive them via \"Exploration by random network distillation\" (https://arxiv.org/abs/1810.12894) method, one RND trained on individual states and another on the joint and summing up the reward.\\n\\n- There is no discussion on limitations.\\n\\n- Minor issue. The notation is a bit overloaded and makes things slightly confusing:\\n - line 143-145. $Z \\\\in \\\\mathcal{Z}$ and $z \\\\in \\\\mathcal{X}$ is confusing\\n - line 157-159. p and q seem to be referring to two distributions each \\n\\n\\n'},\n",
       " 'review_699': {'summary': 'This paper introduces a framework that concurrently learns the individual skills for each agent and the team skill for the entire team, amalgamating these skills to perform multi-agent tasks. The discovery of skills is grounded in a probabilistic graphical model and employs variational inference tools for scalable optimization, extending unsupervised skill discovery in single-agent RL. The proposed algorithm exhibits superior performance on sparse reward multi-agent benchmarks when compared to robust MARL baselines.',\n",
       "  'strengths': \"(a) The paper is effectively articulated, with clear exposition of the intuitions underlying each aspect of the algorithm design.\\n\\n(b) The empirical results provide substantial support for the paper's technical contributions.\\n\\n(c) The extension of unsupervised skill discovery from single-agent to multi-agent RL is a considerable achievement, offering a promising direction for future research.\",\n",
       "  'weaknesses': \"(a) The algorithm might face limitations in practical applications due to: (1) the high-level policy necessitating input that comprises the global state and all agents' observations, and (2) the multi-agent options designed for the entire team, which lack flexibility as coordination among agents often manifests within sub-teams.\\n\\n(b) The algorithm framework is complex, encompassing multiple components and hyperparameters. The fine-tuning efforts, particularly for coordinating the training of neural networks across different scenarios, could be resource-intensive.\\n\\n(c) The paper omits important details in certain areas and requires more clarity. My queries and suggestions follow.\"},\n",
       " 'review_700': {'summary': \"The paper deals with the challenge of utilizing small LMs in knowledge intensive tasks. As recent LLMs have shown promising capabilities in tasks that require reasoning, however, deployment of such model can remain limited due to cost or data limitations. Thus, the authors turn to face the challenge of reasoning distillation to other LMs, mainly smaller LMs that might be more feasible for deployment. However, small LLMs are limited by their inferior limited capacity of knowledge and understanding, therefore an external source of relevant context could be utilized for bridging this gap.\\n\\nThe authors present Knowledge augmented reasoning distillation (KARD) that fine-tunes smaller LMs to generate rationals, with the aid of a LLM with high reasoning capabilities, and to augment its knowledge with relevant contexts from an external knowledge base, to answer complex questions. KARD utilized baseline approaches to tackle knowledge intensive tasks, such as CoT prompting to the LLM and fine-tuning a neural document re-ranker to retrieve high quality contexts during inference when access to a large LLM is unavailable.\\n\\nThe authors test their system on two knowledge intensive benchmarks that require some level of reasoning using one of multiple sources and/or steps (MedQA-USMLE and StrategyQA). The evaluations show that using KARD with a 250M parameter model shows superior performance compared to fine tuned models, knowledge augmented and in few-shot settings. Furthermore, the authors analyze how model size, training set size and reranker setup affects the performance of KARD.\\n\\nThe main contributions of the paper are: (1) novel method that combines reasoning distillation with knowledge augmentation using neural rerankers. (2) analysis showing that small LM (250M) are not sufficient for knowledge intensive tasks in domain specific cases. (3) KARD's performance vs. various baselines and technique is superior.\",\n",
       "  'strengths': \"- The challenge presented is of high importance for real-world applications and has high value. \\n- Experimental setup, baselines chosen and evaluation results of KARD on MedQA-USMLE and StrategyQA are convincing and significant with clear accuracy improvement of smaller LMs (and also larger) compared to the different baselines. Proving the paper's main claim.\\n- Improving the neural re-ranker using the LLM's rationals aids KARD to find relevant contexts during inference, and beyond naive approaches like BM25. \\n- Well written with clear problem presentation, concept explanations, mathematical notations and definitions. It is easy to follow the concepts in the paper. \",\n",
       "  'weaknesses': \"- Limited evaluation on different datasets (only 2) and models (T5/Flan-T5). In addition, performance of KARD methods vs. reasoning distillation in the StrategyQA task is limited compared to MedQA. The authors address this in the limitations section.\\n- A generic external knowledge base (wikipedia) that might not be suitable for medical-oriented tasks such as MedQA for example. We can further see evidence to this looking at the KARD (silver knowledge, oracle) evaluation where the gap between that model and with the best KARD is smaller vs. the large LLM (chatGPT). \\n- Somewhat limited development (or naive approach) of the main contribution of the paper, that is the combination of neural ranker with reasoning distillation. To the authors credit they have addressed this in the paper. The authors address this in the limitations section.\\n- Authors have addressed but did not evaluate a joint objective functions of neural ranker + distillation.\\n- Despite authors addressing many of the paper's limitations, I find it significantly hinders the reliability of work done in the paper.\\n \"},\n",
       " 'review_701': {'summary': 'In this paper, we propose the KARD model for small model Q&A through knowledge distillation + KB retrieval. The authors show experimentally that the model can outperform other models of 3B using only 250M parameters.',\n",
       "  'strengths': '1. a model of LLM knowledge distillation + KB retrieval is proposed.\\n2. KARD outperforms other fine-tuning models.\\n3. a neural reranker based on similarity of rationales and passages is proposed.\\n4. the paper is easy to read.',\n",
       "  'weaknesses': '1. a problem of the paper is the experimental design. In Table 1, the authors do not compare other knowledge-augmented LMs. this leads to experimental comparisons that are inadequate and unfair.\\n2. The finding of the paper-enhancing model effectiveness through KB retrieval-is not that surprising. This leads to a possible lack of innovation throughout the paper.\\n3. for MedQA-USMLE, using wikipedia as KB may not be as effective as using specialized medical KB.'},\n",
       " 'review_702': {'summary': 'This paper proposes a retrieval-augmented knowledge distillation approach for QA tasks. This approach, KARD, extends reasoning distillation, which uses an LLM such as GPT-3.5 as a teacher model and distills a student model by learning from question and rationale pairs (generative loss). KARD has a retriever that obtains relevant documents based on the rationale. The retrieved documents are used for training a student model. In addition, a reranker is independently trained to select more relevant documents.\\n\\nThis approach is evaluated on two QA datasets: one from the biomedical domain, MedQA-USMLE, and StrategyQA, which covers more general and popular entities. EN Wikipedia is used as a knowledge base throughout experiments. The proposed approach, KARD (reasoning distillation+reranker), is compared with prompting approaches (e.g., few-shor, CoT) and other finetuning-based approaches (e.g., standard FT and knowledge-augmented FT). KARD outperforms all baselines by various margins depending on the datasets and model sizes. In addition, the authors provide analyses on several factors such as the number of rationales. \\n',\n",
       "  'strengths': '- This work proposes KARD, which integrates retrieval and reranking modules into the distillation framework.  \\n- The experimental results support the effectiveness of this approach particularly on the QA task from the medical domain. \\n- Overall, this paper is well-written and easy to follow. The detailed analysis on model configurations is provided.\\n',\n",
       "  'weaknesses': '- Although this approach outperforms all the baselines, its gains become marginal with large model sizes, specifically in the cases of MedQA-USMLE and StrategyQA. On the other hand, KARD demonstrates a performance comparable to that of the oracle, ChatGPT, on StrategyQA, but lags significantly behind on MedQA-USMLE. The inconsistency in these results presents a challenge in interpretation.'},\n",
       " 'review_703': {'summary': 'The paper focuses on distilling the chain-of-thought reasoning capability from large LMs to small LMs in knowledge-intensive tasks. Since small LMs do not encode sufficient knowledge required for reasoning, the paper proposes to augment small models with a knowledge retriever that obtains relevant documents for a given task. Experiments show that the proposed method leads to more successful knowledge distillation, especially when the LM size is smaller.',\n",
       "  'strengths': '1.\\tThe proposed idea is well-motivated and sound.\\n2.\\tSufficient experiments and detailed analysis are provided to demonstrate the effectiveness of the method.\\n',\n",
       "  'weaknesses': 'One concern I have is the consequence of using multiple rationales to train the small LM, since this would misguide the model to learn that the answer prediction does not rely on the rationale. This may further lead to shortcut reasoning. I would suggest using simulation-based metrics to evaluate the faithfulness of the rationales to see if this is the case. Or you can randomly corrupt the generated rationales and see if the answer prediction is affected.'},\n",
       " 'review_704': {'summary': 'The authors propose a form of knowledge distillation for a retriever-reader architecture. It uses rationales to guide the neural reranker to retrieve more relevant passages for reasoning, instead of passing the query to the retriever and retrieving the most similar passages. The paper includes an interesting set of ablations as well as some quantitative analysis and limitations. The generative process is as follows: at training time, a rationale is generated using a LLM. Successively, the rationale is passed to the retriever and it retrieves the top-k passages that are most similar to it Finally, a small LM is fine-tuned with the rationale, retrieved passages and question.\\n\\nAt inference time, the question is passed to the retriever, and top-k passages relevant to the question are retrieved (with BM25 plus a neural reranker which helps correct the initial ranking that is closer to the question than to the rationale). Then, a rationale is generated conditional con the reranked passages and input query.',\n",
       "  'strengths': \"Originality and significance: the authors' contribution is a nice application of both distillation and retrieval or knowledge augmentation for LMs.\\nClarity: the paper is well written and it is clear and easy to read.\",\n",
       "  'weaknesses': 'From the experiments section, it is not clear what type of retriever the baseline methods that include knowledge augmentation, is it a dense retriever or BM25? If it is the former, which specific encoder/decoder are used and in which task they are fine-tuned on? \\nHere, I am assuming that the retriever is with BM25 in the baselines:\\n\\nSuch comparisons to more than one neural retrieval augmented language models are important to paint a full picture of the contribution. One possibility is to use NQ, TriviaQA, other Q&A evaluation datasets or the KILT datasets to understand whether both the retrieved passages and the rationale augmentation is useful for smaller LMs for simpler Q&A tasks besides the reasoning Q&A used in the paper. \\n\\nAlternatively, comparisons to other retrieval-augmented language models using the same benchmarks included in the paper can also help to quantitatively assess its performance grounding the claims that the cited paper mentions (i.e. that these models are not good for complex reasoning tasks). --> This experiment has been done during the rebuttal'},\n",
       " 'review_705': {'summary': \"I think the main contributions of this paper are as follows:\\n\\n- Proposes a new decision-making framework called robust Bayesian satisficing (RBS) which combines robust satisficing with Bayesian optimization. RBS aims to achieve a satisfactory solution under distributional shifts by observing a predefined satisfactory threshold. This is different from distributionally robust optimization which requires an ambiguity set and stochastic optimization which optimizes for a given reference distribution.\\n\\n- Defines two regret measures to evaluate the performance of RBS algorithms: lenient regret and robust satisficing regret. Lenient regret measures the cumulative loss of an algorithm's chosen actions with respect to an aspiration level. Robust satisficing regret measures the loss with respect to the robust satisficing benchmark which is the aspiration level minus the fragility (a measure of suboptimality per unit distribution shift). The paper shows the connection between these two regret measures.\\n\\n- Proposes an RBS algorithm called Robust Bayesian Optimistic Satisficing (RoBOS) which uses Gaussian processes to model the objective function. RoBOS only requires an aspiration level as input and does not need an ambiguity set. RoBOS chooses actions to minimize the estimated fragility which is an optimistic estimate of the true fragility.\\n\\n- Proves that RoBOS achieves sublinear robust satisficing regret and lenient regret under certain assumptions. The regret bounds depend on the maximum information gain and the sum of distribution shifts.\\n\\n- Demonstrates the effectiveness of RoBOS on synthetic problems and compares it with other robust Bayesian optimization algorithms.\",\n",
       "  'strengths': 'Robust Bayesian satisficing is a novel framework that combines robustness to distributional shifts with satisficing behavior. This provides an alternative to existing paradigms like distributionally robust optimization and stochastic optimization. RBS does not require precise knowledge of the ambiguity set and can handle unknown distribution shifts. Also, the paper provides theoretical guarantees on the regret of RoBOS under some assumptions. The robust satisficing regret and lenient regret of RoBOS grow sublinearly with time. The regret bounds show the dependence on maximum information gain and the sum of distribution shifts, providing insight into how RoBOS handles distributional shifts. In addition, the experimental results verify the theoretical findings on the sublinearity of the regret bounds. Finally, the paper is well-written, clear, and easy to follow.',\n",
       "  'weaknesses': '- Some assumptions seem to be strong for this problem. For example, the bounds require the sum of distribution shifts to be sublinear in time which may not always hold in practice. It would be good to discuss how the algorithm behaves when these assumptions are violated.\\n\\n- The experiments are limited to synthetic problems. It would be good to evaluate RoBOS on some real-world benchmark problems to demonstrate its effectiveness in practical settings. Comparisons with more algorithms on these problems would also strengthen the experimental evaluation. There are many datasets for distributional shifts that the author can leverage to verify their algorithm.\\n\\n- Although as defined in the conclusion as a future direction, it would be beneficial to discuss the effects of continuous context in this problem, since the focus is on deterministic contexts in this paper. Analyzing RoBOS when contexts are stochastically generated would provide greater insight into how it handles uncertainty.'},\n",
       " 'review_706': {'summary': 'This paper studies robust satisficing in contextual Bayesian optimization under distribution shift in the distributions of the context. \\nThey show that under some assumptions their algorithm achieves sublinear lenient regret and under some relaxed assumptions they achieve sublinear robust satisficing regret. \\n\\nThey compare their method agains distributionally robust optimization approach [10] for contextual Bayesian optimization.',\n",
       "  'strengths': 'I have my reservations against points that I mentioned below, but I believe this research direction is valuable and interesting.',\n",
       "  'weaknesses': 'The writing of the paper can be improved. The clarity and coherence of the writing could be enhanced. There are instances where the ideas are not effectively communicated, leading to confusion for the reader. Furthermore, the structure of the paper could benefit from more logical organization and smoother transitions between sections. Additionally, some grammatical and punctuation errors need to be addressed, as they can detract from the overall quality of the paper. A revision focusing on refining the writing style and ensuring a more polished presentation would greatly strengthen the paper.'},\n",
       " 'review_707': {'summary': 'This paper studies a contextual Bayesian optimization problem when the true and reference distributions of the context can be different due to distribution shifts. The authors propose an algorithm called robust Bayesian satisficing algorithm (RoBOS) based on the idea of robust saisificing (RS). Through theoretical analysis and empirical results, the authors demonstrate their results on two notions of regret: lenient regret and robust satisficing regret. For the theoretical part, the authors have a thorough analysis and show that RoBOS achieves with high probability $\\\\tilde{\\\\mathcal{O}}(\\\\gamma_T \\\\sqrt{T})$ robust satisficing regret and  $\\\\tilde{\\\\mathcal{O}}(\\\\gamma_T \\\\sqrt{T} + \\\\sum_{t=1}^T \\\\epsilon_t)$ lenient regret, where $\\\\gamma_T$ is the maximum information gain and $\\\\epsilon_t$ is the amount of distribution shift in round $t$. For the empirical part, the authors propose two synthetic benchmarks and one real-world benchmark, and for all cases, they demonstrate RoBOS outperforms distributionally robust BO (DRBO).',\n",
       "  'strengths': 'Distribution shift is an important challenge in Bayesian Optimization, and it is great authors propose a new algorithm that attempts to address these issues, it also brings in some new interesting future research questions. The proposed question and results are new, to my best knowledge. I also like the algorithm, which naturally combines the empirical fragility and common algorithms in the contextual Bayesian optimization setting.  The paper is well-written in most parts except for a few minor parts.\\n\\n',\n",
       "  'weaknesses': 'My biggest concern is the two regrets defined in the paper: the lenient regret and the robust satisficing regret, which depends explicitly on the threshold $\\\\tau$. In particular, previous papers in robust satisficing [1] also did the analysis using common performance measures such as average performance. The authors also lack justification for their proposed new notion: robust satisficing regret, beyond matching the definition of robust satisficing which might favor RoBOS. In addition, think the theoretical analysis employed is standard in the literature.\\n\\nI think the following issues need to be addressed:\\n1. Could you also demonstrate (theoretically or empirically) the performance of RoBOS if the goal is to maximize the reward?  \\n2. How sensitive is the choice of $\\\\epsilon$ in DRBO/ WRBO versus the choice of $\\\\tau$ in RoBOS? \\nIn the literature, e.g., Figure 1 of [1], they measured the performance of the robust satisficing model over a sequence of $\\\\tau$ and solve the distributional robust optimization model over a sequence of radius of $r$, then they compared the efficient frontier on both average performance and CVaR. This might be a way to further justify the effectiveness of RoBOS.\\n\\nReference:\\n\\n[1] Daniel Zhuoyu Long, Melvyn Sim, and Minglong Zhou. Robust satisficing. Operations Research, 71(1):61–82, 2023.\\n'},\n",
       " 'review_708': {'summary': \"The paper proposes robust Bayesian satisficing, a new setting of BO that is similar to distributionally robust BO. Robust Bayesian satisficing aims to achieve a 'good enough' expected value given by some threshold $\\\\tau$ and relaxed by the distribution distance between a reference and a true distribution. The paper proposes 2 new notions of regret, design an algorithm with regret bounds, and empirically compare this algorithm to DRBO and other suitable baselines.\",\n",
       "  'strengths': \"1. Robust satisficing as a new optimization objective for BO is interesting and presents an alternative 'good enough' objective along with a relaxation based on distribution distance that is sensible. It enables distributionally robust BO in another way that does not involve uncertainty sets. \\n2. The new regret definitions make sense, and the proposed algorithm is supported by theoretical guarantees on its performance via regret bounds.\\n3. The empirical evaluations present support the claim that the proposed algorithm performs well with the proposed regret definitions.\\n4. Overall I believe that this work has relevance to the community, subject to the issues raised in the Weaknesses section being addressed properly.\",\n",
       "  'weaknesses': \"Technical concerns:\\n1. How is the threshold $\\\\tau$ to be selected in a real world problem? The paper states that it 'can be expressed as a percentage of the SO solution', but when $f$ is unknown, the expected value of the SO solution is unknown as well. From Algorithm 1, $\\\\tau$ is an input prior to any BO rounds. This is an important question to answer, since one of the claimed advantages over DRBO is that there is no need to pick uncertainty sets which may be unknown a priori. But now you have to pick $\\\\tau$ which is also unknown a priori, so it seems that you have replaced one hyperparameter for another. In order to satisfy Assumption 1, it is claimed that $\\\\tau$ can be dynamically selected, but that makes the regret and thus the regret bounds not well-defined, since the regret is a function of a constant $\\\\tau$.  If $\\\\tau$ is to be dynamically selected and learned, then the algorithm and regret bounds should be explicitly written to take this into consideration, instead of claiming in a footnote that it 'can be straightforwardly adapted to work with dynamic thresholds'.\\n2. The experiments in the main paper are simple synthetic benchmarks which by themselves are not comprehensive enough an empirical evaluation. I see that you have an interesting real world benchmark on insulin dose allocation in the appendix, why is it hidden there without a reference from the main paper? Why aren't WRBO and SO tested on that benchmark?\\n\\nClarity issues:\\n1. The equation below line 102 defining $\\\\kappa_{\\\\tau, t}$ and the preceding sentence does not quite make sense. It seems to me that you do not need that sentence and equation, simply define fragility as in Eq. (1), and then the following sentence makes clear what $x_t^*$ and $\\\\kappa_{\\\\tau, t}$ are.\\n2. In all the figures, heatmaps are uninterpretable without a colorbar indicating the values that each color corresponds to.\\n3. Lemma 1 uses the maximum information gain $\\\\gamma$ before it is defined, and includes a definition for determinant when determinant is not used there.\"},\n",
       " 'review_709': {'summary': 'This paper presents a transformer-based architecture (DyGFormer) for dynamic graph learning, based on a node co-occurrence encoding scheme and patching. Further, they present DyGLib a library for uniform evaluation of dynamic graph learning techniques. Extensive experimental evaluations over diverse datasets show that DyGFormer performs well.',\n",
       "  'strengths': \"**Originality.** While the transformer architecture is well-known, it's application to dynamic graph learning, and the proposed co-occurrence encoding and patching schemes are novel. Various libraries / frameworks (as discussed in 108) exist for dynamic graph learning, so DyGLib is not novel in that regard, but a fresh rigorous and extensible evaluation is appreciated.\\n\\n**Quality / Clarity.** The paper is well-written and easy to follow. The DyGLib codebase is high-quality and well-documented. At a glance, it looks easy to use. Also, the appendix is thorough and well-put-together.\\n\\n**Significance.** Dynamic graph learning is an important research problem. This work not only presents a good solution but also paves the way for rigorous future work.\",\n",
       "  'weaknesses': 'While DyGFormer outperforms the baselines in avg. rank, there is a problematic trend that on some datasets DyGFormer can be much worse than the best or second best baseline in terms of absolute performance points (Table 1). This needs some analysis. What characteristics of these datasets make DyGFormer a bad choice against the baselines? What aspects of DyGFormer and the baselines could be causing their poor and better performance respectively? Why does DyGFormer\\'s superiority falter when going from \"rnd\" to \"hist\" to \"ind\"?'},\n",
       " 'review_710': {'summary': 'This paper propose DyGFormer, a new Transformer-based architecture for dynamic graph learning, whose novelty mainly includes a neighbor co-occurrence encoding scheme and a patching technique. Moreover, it introduce DyGLib, a unified library to promote reproducible, scalable, and credible dynamic graph learning research. In experiments ,the DyGFormer achieves sota performance on most of the datasets.',\n",
       "  'strengths': '1. The paper is clearly written and easy to follow.\\n2. I think this unified library is high-quality, meaningful and urgently needed, which can well promote the development of dynamic graphs\\n',\n",
       "  'weaknesses': '1. In DyGFormer , I think the introduction of transformer is not so novel. which has similarity with the attention mechanism of TGAT and TGN.\\n2. PINT[1], a work in NeurIPS 2022, is a new and sota model in the area of dynamic graph. Why this paper has not mention it?\\n\\n[1] Souza A, Mesquita D, Kaski S, et al. Provably expressive temporal graph networks[J]. Advances in Neural Information Processing Systems, 2022, 35: 32257-32269.'},\n",
       " 'review_711': {'summary': \"This paper proposes a new dynamic graph learning architecture and implemented it as part of a new unified graph library with extensive experiment results to verify the effectiveness of the proposed algorithms.\\n \\nThe author proposes a new Transformer-based architecture DyGFormer for dynamic graph learning. The architecture is designed to overcome some of the limitations of previous methods by:\\n- Leveraging a neighbor co-occurrence encoding scheme, which captures the frequency of appearances of each neighbor in the sequences of source and destination nodes. This explicitly explores the correlations between nodes.\\n- Utilizing a patching technique, which allows splitting each source/destination node’s sequence into multiple patches, enabling the capture of long-term temporal dependencies and reducing the computational complexity to a level that doesn't depend on the input sequence length.\\n\\nThe author also developed a library called DyGLib as a unified library specifically tailored to continuous-time dynamic graph learning. Its key features include:\\n- Standardized training pipelines to facilitate reproducibility and consistency across different methods.\\n- Extensible coding interfaces for better adaptability and scalability and integrates with 13 graph datasets and 9 graph algorithms\",\n",
       "  'strengths': 'The paper presents an extensive and technically rigorous evaluation. The authors benchmark their model on 13 dynamic graph datasets against nine state-of-the-art dynamic graph learning models, providing thorough evidence for their conclusions. The comprehensive ablation study further supports the effectiveness of the proposed components.\\n\\nThe proposed DyGFormer architecture performs favorably in comparison to other dynamic graph learning models, with only a few exceptions.\\n\\nDyGFormer handles long-term node interactions efficiently, thanks to the novel integration of neighborhood co-occurrence encoding and the patching technique.',\n",
       "  'weaknesses': \"The paper lacks a comprehensive technical discussion motivating the design of the proposed model. The co-occurrence matrix is said to model node correlations better than other models, but it's not entirely clear why explicit modeling of correlations leads to superior performance. Node proximity and similar neighbors are features that even basic models like the Graph Convolutional Network (GCN) can capture without explicit modeling.\\n\\nThe paper's presentation could be improved. The title, for instance, may overpromise what the paper actually delivers - I was expecting a unified learning algorithm along with a software tool. However, on closer reading, it appears that the main contribution is from DyGFormer, while DyGLib, though useful, doesn't seem to bring much novelty or be absolutely essential to the paper's contributions. The preliminaries section seems unfinished, and the section on DyGLib includes several unsupported claims and lacks novelty.\"},\n",
       " 'review_712': {'summary': 'In this paper, the authors considered the dynamic graph representation learning (a.k.a. dynamic network embedding) problem and proposed a novel transformer-based architecture - DyGFormer, with several original designs (e.g., a neighbor co-occurrence encoding scheme, a patching technique, etc.) Moreover, the authors also implemented a unified continuous-time dynamic graph learning library, which include several baselines, widely-used datasets, and a common evaluation pipeline. Exhaustive experiments with various settings of dynamic link prediction and dynamic node classification were also conducted to validate the effectiveness of the proposed method.',\n",
       "  'strengths': '(S1) The overall presentation of this paper is clear, which makes it easy to grasp the key ideas.\\n\\n(S2) There are some original designs (e.g., neighbor co-occurrence encoding scheme and patching of historical neighbor sequence) in the proposed method.\\n\\n(S3) The authors conducted many experiments on 13 datasets for both dynamic link prediction and dynamic node classification with various settings.\\n\\n(S4) The authors also implemented a unified library including some typical baselines and a common evaluation pipeline for various task settings (e.g., transductive and inductive dynamic link prediction and node classification), with the code provided for review.',\n",
       "  'weaknesses': \"(W1) Some statements are with too many citations (e.g., 'continuous-time methods [27, 53, 62, 44, 35, 9, 55, 58, 57, 24, 34, 12]', 'graph convolutions [53, 62, 44, 35, 9, 57]', etc,) which are hard to check their sources. Some references are also repeated in successive sentences (e.g., 'only a few libraries are specifically designed for dynamic graphs [18, 45, 71]. DynamicGEM [18] is a library for dynamic graph embedding methods'). It is better to ensure that there are at most 5 references for each statement. Some of the references can also be replaced with concrete examples or methods introduced in this paper. Furthermore, references of some important statements are also missing, e.g., 'unlike most previous methods that need to retrieve nodes' historical interactions from multiple hops' but what do 'previous methods' refer to?\\n\\n(W2) Some problem statements regarding model optimization are unclear. Concretely, the formal definition of training loss is not given. In general, we can divided existing dynamic graph representation techniques into the task-dependent and task-independent methods, which are respectively trained via (i) supervised losses related to and (ii) unsupervised losses regardless of the downstream task. It is unclear that the proposed method is task-dependent or task-independent. In the baselines, DyRep and TGAT are task-independent while CAW is task-dependent (with a loss designed for dynamic link prediction), as I can check. From my perspective, it is unfair to compare both types of method in a common experiment setting, where task-dependent methods are expected to have better performance than task-independent approaches, due to the incorporation of supervised information related to the downstream task. For task-independent methods, the authors should also clarify the downstream module (e.g., logistic regression, SVM, MLP, etc.) to support a concrete task. More importantly, the evaluation pipeline of a unified library should also cover both the settings.\\n  \\n(W3) Although the authors gave toy examples for some procedures of the proposed method (e.g., the computation of neighbor co-occurrence encoding), several details still need further clarification (e.g., how to pad a derived patch, etc.) It is recommended summarizing the overall procedure to derive all the encoding and patches in terms of pseudo-code (even in supplementary material).\\n  \\n(W4) In related research, inductive dynamic link prediction includes the prediction of links between (i) one old (i.e., previously observed) node and one new (i.e., previously unobserved) node as well as between (ii) two new nodes. It is unclear that the inductive setting in this paper refers to both cases or just the latter case.\\n  \\n(W5) Although the authors included 7 baselines in experiments, most of them are based on time-encoded deep sequential models (e.g., with RNN and attention). In addition, there are some other related approaches based on temporal point process (e.g., HTNE [1] and TREND [2]) and neural ordinary differential equation (e.g., GSNOP [3]) that are not considered in experiments. A unified library should cover various types of method.\\n- [1] Zuo, Yuan, et al. Embedding temporal network via neighborhood formation. KDD 2018.\\n- [2] Wen, Zhihao, and Yuan Fang. Trend: Temporal event and node dynamics for graph representation learning. Web Conference 2022.\\n- [3] Luo, Linhao, Gholamreza Haffari, and Shirui Pan. Graph sequential neural ode process for link prediction on dynamic and sparse graphs. WSDM 2023.\\n  \\n(W6) In supplementary material, although the authors gave some details regarding the datasets, the source information (i.e., where can we download these datasets) is missing. In Table 4 of supplementary material, what does 'duration' means? Does it means the time granularity? Consistent with the statistics of 'duration', what is the total number of time steps for each dataset? From my perspective, the scale of a dynamic graph is related to the (i) number of nodes $N$ and (ii) number of time steps $T$. As I can check, all the datasets are with $N<20,000$, which cannot be considered as large datasets. Can the proposed method be scaled up to larger datasets? Or are there any possible solutions to addressing the scalability issue (perhaps as one future research direction)?\\n  \\n(W7) It seems that the authors upload the paper to ArXiv before the formal submission to NeurIPS. Several month ago, google scholar and github recommended the ArXiv version of this paper to me. As a result, I have already known the names and institutions of the anonymous authors, which breaks the double-blind policy.\"},\n",
       " 'review_713': {'summary': 'This paper studies the problem of continuous-time dynamic graph learning. The authors proposed a Transformer-based architecture DyGFormer to learn the dynamic edge representation, which mainly consists of a neighbor co-occurrence encoding scheme to count the co-occurrence of nodes, a patching technique to split the node’s sequence into multiple patches, and a Transformer as the backbone.  The authors also propose a dynamic graph learning library DyGLib, and re-report the important baselines’ performance based on DyGLib. Experimental results conducted on 13 benchmark datasets verify the effectiveness of the proposed method. ',\n",
       "  'strengths': '1.\\tThe authors propose a co-occurrence encoding scheme and a patching technique to capture the correlation between sequences and the long histories of sequences respectively.  As far as I know, it is less studied than learning the dynamic link representations direct from the sequences of nodes’ first-hop interactions under the dynamic graph learning problem, especially how to model the long histories of the interaction sequence.\\n2.\\tThe authors conduct extensive experiments on 13 benchmark datasets to verify the effectiveness of the proposed two-component. Besides the proposed method, the authors also re-implemented the important baselines in the area, and point out that some findings of baselines are not in line with previous reports because of their varied pipelines and problematic implementations, which may benefit future research in the continuous-time dynamic graph learning community.\\n3.\\tThe authors propose a continuous-time dynamic graph learning problem. This library provides a unified pipeline to train and evaluate different baselines. I think this library can provide a tool for researchers in the community to conveniently evaluate different methods in a unified setting.\\n',\n",
       "  'weaknesses': '1.\\tIn the problem formalization of section 3, the authors define the target of the dynamic graph learning problem as learning the time-aware representations for each node. But the DyGFormer actually learns the dynamic link representations but not the node representations. Or more accurately, the DyGFormer learns the contextual node representation $h^t_{u|(u,v)}$ but not $h^t_u$, where the node representation $h^t_{u|(u,v)}$ relies on the other node v. It will be better to add some discussion for this in the paper.\\n2.\\tIn section 5.2, the authors say that “some of our findings of baselines differ from previous reports”, but the authors do not point out which baselines’ performance improves. I suggest the authors explicitly list which baselines’ performance improves.\\n'},\n",
       " 'review_714': {'summary': \"The authors propose a unified framework called State2Explanation (S2E) that combines learning a joint embedding model between state-action pairs and concept-based explanations. The authors draw inspiration from the Protégé Effect, which suggests that explaining knowledge reinforces self-learning. They propose that concept-based explanations can benefit both the RL agent and the end-user by improving the agent's learning rate and the end-user's understanding of the agent's decision making. The S2E framework is designed to inform reward shaping during an agent's training and provide explanations to end-users at deployment for improved task performance.Results on Connect 4 and Lunar Lander demonstrate the success of S2E in providing a dual benefit.\",\n",
       "  'strengths': \"The paper introduces a novel framework S2E. The authors suggest that explaining knowledge to the agent can improve its learning rate, while providing explanations to end-users can enhance their understanding of the agent's decision making. The framework is supposed to be useful in providing explanations understandable in various applications.\",\n",
       "  'weaknesses': 'There are no significant weaknesses from my point of view, while there are some improvements can be made. Although the paper mentions experimental validations in the Connect 4 and Lunar Lander domains, the proposed method should be tested on more complex tasks to test its effectness. The authors should also consider how concepts can be better selected beyond expert-defined thresholding.'},\n",
       " 'review_715': {'summary': 'The paper proposes a framework to incorporate explanation concepts to sequential decision tasks. The framework can be applied both to the training of the agent by improving RL and to provide explanations to end-users during deployment. The framework is tested using two simple games, Connect 4 and Lunar Lander, where it shows it help improve training performance and user performance.',\n",
       "  'strengths': 'The main strengths of the paper are:\\n\\n1. It provides an unified framework for explanations which can be used both for training and deploying.\\n2. The explanation framework is based on user-understandable concepts and terms.\\n3. The paper provides a sound theoretical and empirical analysis of the proposed framework.\\n4. The paper performs user testing and subsequent data analysis in a methodologically sound manner, rare in NeurIPs papers.\\n',\n",
       "  'weaknesses': 'The main weaknesses of the paper are:\\n\\n1. The paper condenses two much information in very little space, including impossible to read figures. It is very hard to read.\\n2. The paper fails to discuss how difficult will be to create frameworks for more complex scenarios where there are more and more complex concepts. For instance, consider a system making decisions about buying and selling stocks.\\n3. Because of 2, the ideas presented in the paper may never be applicable to real-world problems.\\n4. It provides a very brief description of how the concepts are actually created, stored, and verified. \\n5. The paper does not discuss situations where the explanation is wrong or inadequate for a situation (for instance, there is a better move), and how that impacts training and user performance.'},\n",
       " 'review_716': {'summary': 'Inspired by the Protege effect, learning and developing explanations should provide a dual benefit, both to the readers of the explanations, and to the developers of the explanations. Based on this idea, the paper proposes State2Explanation, an algorithm to learn joint embeddings between state-action pairs and concept-based explanations. This allows for reward shaping, which benefits the explanation developer, while also providing explanations. These claims are validated for agents in two different reinforcement learning settings: Connect 4 and Lunar Lander.',\n",
       "  'strengths': '1. Provides concrete desiderata for a concept is, including the need for generalizibility and its relationship to the task goal \\n2. Reward shaping through explanations is potentially novel, and explores use cases of explanations beyond explainability\\n3. Thorough evaluation investigates the impact of various additions to the model, making it clear what the impact of Information Filtering (InF) and Temporal Group (TeG) are\\n4. User study demonstrates real-world viability model through a human explainability lense\\n',\n",
       "  'weaknesses': '1. Concepts for domains are dependent on expert knowledge for state-action pairs, making it unclear how easy it would be to generalize beyond well-studied games. This is especially the case when state-actions pairs tend to get very large. \\n2. An additional baseline would make it clearer what the impact of each study condition was in Section 6. In particular, a baseline with no intervention/information would make it clear how much the rise in performance is due to the additional practice attained from the PreTest when completing the PostTest. \\n3. If concepts for Lunar Lander are derived from the existing domain reward function, then claiming that $M_{LL}$ \"informs reward shaping comparable to expert-defined dense reward functions\" seems to follow from the definition of the concepts rather than an indicator of the performance of the algorithm. \\n'},\n",
       " 'review_717': {'summary': 'The paper proposes State2Explanation, a framework for training RL agents in such a way that both the human and agent benefit, the Protégé Effect as the authors state. The basic idea is to learn a joint embedding space with \"temporal\" concepts that actively helps the agent train better by shaping their rewards. At test time, these explanations are provided to humans to also help train them.',\n",
       "  'strengths': \"A strength of the paper is I feel the motivation. Explainability in RL is harder than supervised learning due to the temporal added component, so approaching this problem is well motivated.\\n\\nIn addition, the interplay between agent and human is also very exciting, I love the idea of the two helping and playing off each other. I feel this is a great way to impose human understandable concepts onto an RL agent's policy.\\n\\nI also appreciate the rigour in the user study (although I need some clarifications in the rebuttal), it's clear to me the authors tried here.\",\n",
       "  'weaknesses': 'What I always look for in a paper is a single nice idea, and I am not certain this paper really contains one, let me explain by iterating your claimed contributions.\\n\\nRegarding the desiderata: (1) the idea that a \\'concept should be grounded in human domain knowledge\\' is not a new idea I feel. The original T-CAV paper noted this by e.g. using zebra stripes to explain zebra classifications, rather than e.g. logit values. Simple saying the same thing is true in a sequential setting doesn\\'t seem that original to me. I\\'m not aware of a great many people suggesting q-values are a good explanation. (2) The idea that a concept should relate to the task goal is an interesting one, and could be useful in certain context, but I feel it doesn\\'t generalize well. For example, if I\\'m in a self-driving car going from a => b, and halfway through the journey the car brakes to avoid hitting a pedestrian, your framework seems to posit the explanation should be \"I avoiding killing the human so I could still get to point b\". I feel that\\'s a questionable belief system here we are teaching the agent. (3) is a nice idea, but I don\\'t feel it\\'s particularly surprising, the idea that explanations should be robust and generalisable is well agreed upon.\\n\\nThe framework you propose does seem quite interesting to me, but reward feedback loops are not my area of expertise, so I defer to my colleges to evaluate the novelty of such a framework.\\n\\nSection 5.2: I am slightly concerned that the explanations are not always matching in Figure 3, does that mean that this method will inevitably give \"wrong\" explanations? Also, I don\\'t know what i, j, and k are in the figure? Now I personally believe it matters more that it just helps people in a user study, which you show it does, so that\\'s great and I feel makes up for this.\\n\\nSection 5.3: If I understand this correctly, your method doesn\\'t seem to show much difference here at all, and in fact Fig 4a seems to show the baseline outperforming it?\\n\\nUser Evaluation: I appreciate the attention to detail here, but a lot of details are missing or (I feel) badly explained. I don\\'t really understand how people\\'s performance could get worse in group $E_{A}$, all they are being shown is the action as an explanation, so the idea their ATS would get worse seems extremely odd to me, and makes me feel I am misunderstanding something here. I tried to explore the appendix to understand what was happening, but didn\\'t have much luck.\\n\\nI think there\\'s some citations that you might also like to be aware of regarding human friendly concepts in sequential settings.\\n\\nJi, Ying, Yu Wang, and Jien Kato. \"Spatial-temporal Concept based Explanation of 3D ConvNets.\" Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.\\n\\nKenny, Eoin M., Mycal Tucker, and Julie Shah. \"Towards interpretable deep reinforcement learning with human-friendly prototypes.\" The Eleventh International Conference on Learning Representations. 2023.'},\n",
       " 'review_718': {'summary': 'The paper proposes a new kernel correction method to address the issue of incomplete data. Existing approaches aim to recover the distance matrix of complete data, starting from that of the incomplete data. In contrast, the proposed method (Section 3.2) formulates the problem as finding a positive semi-definite matrix that is closest to kernel matrix of incomplete data. The optimisation is solved using a iterative approach.\\nThe paper further extends the approach to (kernel) affinity learning problems to propose 3 further algorithms, and finally, experimentally shows that the proposed methods outperform existing distance completion methods in the setting of kernel spectral clustering.',\n",
       "  'strengths': '- The proposed approach is technically sound, and based on a rather intuitively simple idea of projecting onto the space of positive semi-definite matrices.\\n- Extensions to affinity learning are proposed\\n- The experiments show clear improvement over existing approaches for completing distance matrices',\n",
       "  'weaknesses': 'Literature:\\nThe paper focus only on kernel spectral clustering and affinity learning, and hence, misses the broad and older literature on kernel methods for supervised learning. A quick search of Google scholar reveals a considerable literature on this topic. Few papers are noted but the literature is quite large, and it is not clear why the paper does not compare with such approaches.\\n- Smola, Alex J., S. V. N. Vishwanathan, and Thomas Hofmann. \"Kernel methods for missing variables.\" International Workshop on Artificial Intelligence and Statistics. PMLR, 2005.\\n- Dick, U., Haider, P., & Scheffer, T. (2008, July). Learning from incomplete data with infinite imputations. In Proceedings of the 25th international conference on Machine learning (pp. 232-239).\\n- Liu, X., Zhu, X., Li, M., Wang, L., Zhu, E., Liu, T., ... & Gao, W. (2019). Multiple kernel $ k $ k-means with incomplete kernels. IEEE transactions on pattern analysis and machine intelligence, 42(5), 1191-1204.\\nThe paper needs to positioned well in context of this literature, and the proposed algorithm should be compared with existing kernel completion methods.\\n\\nWeak theory, and insufficient experiments on different missing data:\\nTheorem 1 is rather weak since it only guarantees that if the incomplete kernel matrix was derived from a some true psd matrix, then the returned projection is closer to ground truth that the incomplete kernel matrix. However, the algorithm/theorem does not guarantee that the output kernel matrix is significantly better than the given incomplete one. A general guarantee cannot be provided without assumptions. \\nHowever, the work would significantly improve if there is a guarantee on recovery of ground truth kernel assuming that incomplete kernel matrix is obtained from data with features missing uniformly at random (setting considered in experiments)\\n\\nOn a similar note, the experiments only assume that features/values a missing at random. However, in practice, data is often systematically missing (some features tend to have higher missing values rate; there is often correlation between missing entries). Extensive experiments are needed to demonstrate that the proposed methods are robust to different types of missing entries, other than uniformly random.'},\n",
       " 'review_719': {'summary': \"The authors introduce an imputation-free framework for correcting a kernel obtained from incomplete data. They propose the corrected kernel to be a PSD matrix with bounded elements that is closest to the initial kernel (calculated from incomplete data) in Frobenius norm. They show that the corrected kernel is guaranteed to be closer to the ground truth than the initial kernel. In the case of the Gaussian kernel, Dykstra's projection algorithm is presented to obtain the corrected kernel. They then extend the existing self-expressive affinity learning framework by incorporating the proximal p-norm (0 < p < 1) and the Schatten p-norm (½ < p < 1) penalties on the affinity matrix. An algorithm (KSL-Pp) based on augmented Lagrangian and ADMM is proposed for the proximal p-norm penalty. Another algorithm (KSL-Sp) based on gradient descent is proposed for the Schatten p-norm penalty. Finally, the authors combine the kernel correction and the self-expressive affinity learning frameworks to jointly learn the corrected kernel and the affinity matrix. An algorithm (AKLSR) based on augmented Lagrangian and ADDM is proposed to solve the joint optimization problem.\\n\\nFor numerical experiments, they perform a comparative analysis on synthetic and image datasets and show their proposed method produces a more accurate Gaussian kernel than the existing techniques. The performance of spectral clustering improves when their proposed corrected kernel is used against the corrected kernels obtained by competing techniques. For self expressive affinity learning, they show that more accurate affinity can be estimated when their proposed corrected kernel is used against the corrected kernels obtained by other techniques.\",\n",
       "  'strengths': \"Significance: The Gaussian kernel plays a central role in several tasks including clustering, dimensionality reduction, graph neural networks etc. A comparative analysis on image datasets is provided that showed improved quality of the corrected kernel using the proposed approach against those obtained by existing techniques. The same is also reflected in the improved performance of spectral clustering and the improved quality of self-expressive affinity matrices based on their proposed corrected kernel. On a high level, these improvements could be helpful in downstream applications.\\n\\nQuality: The authors adapted Dykstra's projection algorithm which comes with linear convergence guarantees, to correct the Gaussian kernel obtained from incomplete data.\",\n",
       "  'weaknesses': 'Quality / clarity:\\nThe authors extended the existing self-expressive affinity learning framework by incorporating p-norm based penalties (0 < p < 1). However, it is not clear how p-norm based penalties are more effective than the conventional 1-norm, Frobenius norm and nuclear norm based penalties. The provided empirical analysis seems insufficient to reach any conclusion.\\n\\nThe authors also proposed an algorithm that jointly optimizes the corrected kernel and the self-expressive affinity matrices using ADMM. However, there seems to be some issue in the formulation (see questions), and no empirical analysis is provided. This gives the sense that the paper is incomplete: the authors propose Adaptive Kernel Self-expressive Learning in 4.2 to tie between the kernel correction in section 3 and the self expressive affinity in 4.1, however do not include any simulations for this approach. Without demonstrating its efficacy, the inclusion of the proposed algorithm AKLSR seems unnecessary, and then the paper is essentially two unrelated approaches (kernel correction, self expressive learning) grouped together.   \\n\\nMissing references:\\n* Gilbert, A. C., & Jain, L. (2017, October). If it ain\\'t broke, don\\'t fix it: Sparse metric repair. In 2017 55th Annual Allerton Conference on Communication, Control, and Computing\\n* Shahid, N., Kalofolias, V., Bresson, X., Bronstein, M., & Vandergheynst, P. (2015). Robust principal component analysis on graphs. In Proceedings of the IEEE International Conference on Computer Vision \\n* Biswas, Arijit, and David W. Jacobs. \"An Efficient Algorithm for Learning Distances that Obey the Triangle Inequality.\" BMVC. 2015.'},\n",
       " 'review_720': {'summary': 'This paper studies the spectral clustering problem when there is missing data. The paper proposes a new algorithm for correcting the computed kernel matrix by projecting the matrix to the nearest symmetric PSD matrix, and using this corrected kernel for clustering. The paper also combines the new kernel correction algorithm with affinity learning to develop a new technique for learning affinity matrices for incomplete data.\\n\\nExperimental evaluations show that the newly developed techniques outperform alternative methods for handing incomplete data with respect to standard clustering metrics.',\n",
       "  'strengths': 'The newly proposed algorithm for kernel correction is novel and interesting. It has potential applications and could inspire future research directions. The algorithm is conceptually quite simple and captures the theoretical intuition quite naturally. The experimental results suggest that the new algorithm outperforms alternative methods.',\n",
       "  'weaknesses': 'The running time of the kernel correction algorithm is quite slow - it requires computing the spectral decomposition of the kernel matrix at every iteration. It is good that the authors discuss this limitation in the paper, although it is a weakness of the algorithm. Improving the running time could be a future research direction.\\n\\nIt would be interesting to compare experimentally the benefit that kernel correction brings over simply doing nothing to correct the missing data (or doing something very naive to construct the k-NN graph for example).'},\n",
       " 'review_721': {'summary': 'This paper proposes an imputation-free framework with two novel approaches to improve spectral clustering on incomplete data. Firstly, the authors introduce a new kernel correction method that enhances the quality of the kernel matrix estimated on incomplete data with a theoretical guarantee, benefiting classical spectral clustering on pre-defined kernels. Secondly, they develop a new affinity learning method that equips the self-expressive framework with ℓp-norm to construct an intrinsic affinity matrix with adaptive extensions. \\n\\n\\n',\n",
       "  'strengths': 'The originality of this paper is satisfying, which proposes an imputation-free framework with two novel approaches to improve spectral clustering on incomplete data and the significance is OK.\\n\\nThe quality and clarity of this paper are satisfying based on the clear presentation of the imputation-free framework with two novel approaches.',\n",
       "  'weaknesses': '1. The authors propose an imputation-free framework with two novel approaches to improve spectral clustering on incomplete data. However, the advantages of the proposed method in dealing with incomplete data are not clearly stated based on Section 3, i.e., considering how to recover the missing data. Thus, the authors are expected to analyze the merits of the proposed method in dealing with the incomplete data.\\n\\n2. In section 3.1, the authors give different methods to provide a calibrated distance matrix with benefits for distance-based kernels and are not a universal solution for dealing with incomplete data in spectral clustering tasks. However, these separated methods may make the novelty of this paper separated and not focused. I think the authors can better stating the revisiting distance calibration methods in this part.\\n\\n3. The adopted datasets in the paper are almost with small scales in the experiments. The authors can add one or more multi-view datasets with large scales for validating the clustering performance.\\n\\n4. The improvements of the proposed method compared with other methods are not significant in the experiments, i.e., the RE_K of KC is just 0.217 on USPS.\\n\\n5. The authors can add one or more recent methods for comparison in the experiment, which make the comparson of experimental results more comprehensively.'},\n",
       " 'review_722': {'summary': \"The paper studies the classical regret-minimization problem in the stochastic multi-armed bandit framework. In particular, the manuscript's focus is on randomized algorithms with an aim to develop one with closed-form arm-selection probabilities at each step. Data collected by such algorithms can be used for offline policy evaluation. The manuscript proposes an algorithm called KL-MS for bounded-support distributions, that achieves KL-style regret guarantees. It is asymptotically optimal (in the instance-dependent stochastic sense) for bernoulli bandits, and order optimal for more general bounded-support distributions. It also enjoys an optimal worst-case regret guarantee. The paper also presents numerical study comparing the offline evaluation when the data is collected using the proposed KL-MS and Thompson Sampling with Monte-carlo on bernoulli bandits.\\n\\n\\n\\n\",\n",
       "  'strengths': 'The paper is written well and easy-to-read. I particularly enjoyed the various remarks and discussions after the results, providing insights into the results and comparing the analysis to existing ones. While in some settings randomness should also be treated as a resource (and hence be used with care), there are indeed benefits to using randomized algorithms in other settings. For example, as highlighted in the paper, the data collected by randomized algorithms can be used for offline evaluation. The paper develops an algorithm that simultaneously satisfies different desirable properties, while being optimal (or close-to-optimal) in a non-parametric setting of bounded-support distributions.\\n\\n',\n",
       "  'weaknesses': '1. The plots in the appendix are not very clear. The text along the vertical lines is overlapping and unreadable. It would be good to spread-out the fugures and probably figures in a vector form for clearer display. \\n\\n2. In view of the recent results on fragility of optimized bandit algorithm, I believe that the MAB results should be studied and stated beyond the expected regret. See for instance \"Fan, Lin, and Peter W. Glynn. \"The fragility of optimized bandit algorithms.\" arXiv preprint arXiv:2109.13595 (2021).\"\\n'},\n",
       " 'review_723': {'summary': 'The submission considers the vanilla setting of stochastic K-armed bandits and studies a strategy introduced by Maillard (2013), which relies on exponential weights and outputs at each round probabilities of taking each action. This is often convenient in offline policy evaluation, when estimates based on inverse propensity weighting [IPW] are constructed. Distribution-dependent and distribution-free regret bounds are provided, either in a general non-parametric model of all probability distributions over [0,1], or in the much specific model of Bernoulli distributions. The general distribution-dependent regret bounds asymptotically match the gap-based bounds of UCB (Theorem 1 and Remark 2) and is actually optimal in the Bernoulli model (Theorem 5). The general distribution-free bound improves on the one for UCB by featuring a \\\\sqrt{\\\\mu^\\\\star (1-\\\\mu^\\\\star)} term (Theorem 3). Another main result is formed by Figure 1 and Table 1: there are actually few randomized strategies (Thompson sampling, MED) and none of them exhibits closed-form expressions for probabilities of plays. \\n\\nThis shows that the core result of this article is: a strategy for the vanilla case of stochastic K-armed bandits, with decent (though not optimal) distribution-dependent and distribution-free regret bounds, and based on determining actual probabilities of playing arms, which is useful for offline policy evaluation.\\n',\n",
       "  'strengths': \"The idea of constraining the strategy to output probability distributions while getting decent bounds is nice and may turn useful---I have witnessed several recent articles critically using IPW in bandit contexts. By 'decent bounds', I mean bounds that are as good as, or slightly better than, UCB, but not optimal (as IMED and recent versions of KL-UCB achieve).\\n\\nThe exposition is clear and I enjoyed reading the main body of the submission. \\n\",\n",
       "  'weaknesses': \"1.\\nExponential weights are actually difficult to compute in practice with a good accuracy, at least for suboptimal arms that are played often. Perhaps this case does not arise (suboptimal arms are played only logarithmically many times and the probabilities are easy to compute with a good accuracy), but the accuracy in the computation should be commented, especially given the critiques against Thompson sampling on these issues on page 2. \\n\\n2. \\nThe comparison to previous works could be clarified and reorganized in pages 4--5. In particular, it would have been better to recall first the typical (e.g., for UCB) as well as the optimal distribution-dependent and distribution-free regret bounds, in the Bernoulli model and in the model P(0,1) of all distributions over [0,1], when no constraint of outputting probability distributions is imposed. The sub-UCB criterion could be omitted, I don't think it adds anything. The literature review seems a bit outdated. In particular, a new reference is critically missing: https://www.jmlr.org/papers/volume23/20-717/20-717.pdf / it shows that in the model P(0,1) there exists a strategy called KL-UCB-switch that achieves simultaneously the optimal distribution-dependent and the optimal distribution-free bounds. \\n\\n3.\\nThe regret bounds are unprecise: (i) they involve O(...) terms and (ii) even the main terms are difficult to read because of +/- c \\\\Delta_a terms in the kl, (iii) not mentioning the additive T \\\\Delta term, where \\\\Delta is a parameter that must then be << \\\\ln T / T and therefore should vanish. Even worse, Lemma 9 and Theorem 5 are proved by taking \\\\Delta = 0 in the bound of Theorem 1, while Theorem 1 assumes \\\\Delta > 0.\\n\\n4.\\nThe proof sketches are too vague: pages 8-9 merely indicate a proof structure in terms of decompositions of events and other immediate considerations, but the actual boundings of the probabilities of interest is not explained in the main body (but is detailed in the extremely long appendix). At least two or three salient (new?) ingredients of these proofs should have been given in the main body. What I read on pages 8-9 is too high level and actually takes almost 2 pages without learning anything specific to the reader. I regretfully couldn't check the proofs and get a sense of their correctness, but I don't feel guilty for this, as nothing or almost helped me doing this in the main body. Better editorial choices could have been made as far as proof sketches are concerned. \\n\\n\\nOther comments / remarks / typos along the text:\\n- Lines 9-10: I wouldn't insist on the distribution-dependent optimality for Bernoulli distributions (which is a minor point) but rather on getting decent (better than UCB) bounds \\n- Line 28: also Garivier and Cappé 2011 \\n- Footnote 1: yes, but for known L and U \\n- Caption of Figure 1: difficult to understand in itself, I have to read lines 770--773 in appendix to understand (these explanations should thus be moved in the main body)\\n- Line 48: the empirical averages \\\\mu_{t,a} were not formally defined \\n- Lines 54-55: sounds like an overstatement; the submission proposes decent but not optimal distribution-dependent and distribution-free regret bounds \\n- Table 1: Tsallis-INF is among the few strategies that output distributions, so it should not have been excluded on the ground of a minor issue given its non-optimal bound for Bernoulli distribution; this Table 1 is generally not helpful given that it contains too many strategies that do not output distributions\\n- Lines 65-67: I would be less enthusiastic; getting rid of the \\\\sqrt{\\\\ln K} is uneasy but was achieved for some algorithms that are optimal from the distribution-dependent viewpoint (see https://www.jmlr.org/papers/volume23/20-717/20-717.pdf) though I appreciate as well the \\\\sqrt{\\\\mu^*(1-\\\\mu^*)} term, which indeed may be smaller than \\\\sqrt{\\\\ln K} in some situations \\n- Line 69: drop 'with'\\n- Line 82: OK for this definition in case of absolute continuity, otherwise, = +\\\\infty\\n- Lines 108-109: syntax issue\\n- Line 119: > b, not \\\\geq b; this quantity is called K_inf \\n- Lines 154-155: some strategies like KL-UCB-switch (see https://www.jmlr.org/papers/volume23/20-717/20-717.pdf) would be sub-UCB and enjoy a \\\\sqrt{KT} distribution-free regret bound---I thus disagree with the statement made here \\n- Lines 205-206: same kind of comments \\n- Lines 239-241: there is no such issue if the Bernoullization trick of lines 115-119 is implemented \\n- Line 258: rather (6) instead of (8)\\n\"},\n",
       " 'review_724': {'summary': 'This paper considers a classic bandit problem, where the algorithm should explicitly output the random distribution of the next pulling arm (as a comparason, in classic case, the algortihm only needs to generate one arm from this random distribution and outputs that arm). Existing results only work on the case that the random rewards are unbounded and subgaussian. In this paper, the authors extend the existing works to the case that the rewards are bounded in $[0,1]$, design a KL-MS algorithm (using a KL-divergence approach). They show that the regret upper bound of KL-MS is near optimal. They also use some experiments to show that the performance of KL-MS (in outputing the random distribution precisely) outperforms existing baselines. ',\n",
       "  'strengths': 'The regret bound in this paper is nearly tight.\\nThe writting is clear for me to understand.',\n",
       "  'weaknesses': 'My first concern is about the model setting, i.e., why we require to know the exact random distribution of pulling the arm? Though there is an example of estimating the average reward, I do not think this is a well-motivated one. Can you provide more examples about the why we require that distribution in reality? Besides, why not just use a UCB-type algorithm, which can easily give you the exact probability distribution, as long as tight analysis? I know that there are works, e.g., MOSS, to achieve the tight $O(\\\\sqrt{KT})$ regret upper bound, but not very sure whether there are UCB algorithms that achieve $O(\\\\sqrt{\\\\mu(1-\\\\mu)KT})$ regret upper bound (though I think after using some variance-based concentration, the steps are straightforward). \\n\\nMy second question is about the experiments of this paper (in appendix H). I do not see any comparason about the regrets between different algorithms, and I am wondering the regret performances of KL-MS.\\n\\nFinally, do you think the idea (of either MS or KL-MS) could be applied to infinite-arm case (e.g., linear bandits), for example, return a distribution supported on an infinite set?'},\n",
       " 'review_725': {'summary': \"In this paper, the author analyzes the MED algorithm proposed by Honda \\\\& Takemura (2011) for Bernoulli distributions in the context of general bounded distributions, and under the name KL-Maillard Sampling. This work is a follow-up of a previous work that proposed Maillard Sampling for sub-gaussian distributions. \\n\\nKL-MS is a bandit algorithm that samples an arm at each time step with probability $p(t) \\\\propto \\\\exp(-N_a(t) \\\\text{kl}(\\\\mu_{t-1,a}, \\\\mu_{t-1, \\\\text{max}}))$, where kl is the KL divergence corresponding to Bernoulli distributions. The interest of this simple strategy is that one can explicitly compute the probability to pull each arm, which is useful for instance in the context of off-policy evaluation.\\n\\nContrarily to the initial work of Honda &  Takemura that focused on instance-dependent bounds, and in the spirit of the previous MS paper, the authors provide both optimal instance-dependent and minimax bounds for the algorithm for Bernoulli distributions. The same guarantees naturally hold for general bounded distributions, losing the optimality for problem-dependent guarantees compared to the original MED algorithm using the ``tight'' divergence. It is also proved that the worst-case guarantees scale in the standard deviation of the best arm, which is on par with what is known from the sub-gaussian case.\",\n",
       "  'strengths': '* The paper is well-written, clear, and easy to follow. Furthermore, it seems technically sound, and the proofs are carefully detailed. The literature review is well-covered regarding the scope of the paper.\\n \\n*  The analysis of asymptotic optimality of MED for the Bernoulli case is largely simplified compared to the original proof of Honda \\\\& Takemura (2011). Furthermore, the worst case optimality is a novel result compared to this work. Compared to the previous MS paper, it is also interesting that the optimal minimax ratio is achieved without tweaking the algorithm. To prove these results, the the authors perfectly used the analysis tricks introduced recently in the TS literature (e.g all the cited works from Jin et al.).\\n  \\n* The main novel element/insight of the paper compared to its two major inspirations is the refined analysis of the \"under-exploration\" term (F3) in the regret analysis, that lead to the $\\\\log(K)$ vs. $\\\\log(T)$ improvement of the minimax ratio of MS without having to change the algorithm, making MS+ obsolete. The changes in the proof for this are rather substantial so the contribution is valuable. \\n\\n* Maybe the most surprising result in the paper is the minimax bound scaling with the variance term $\\\\mu_1(1-\\\\mu_1)$. Therefore I would have appreciated some explanation in the main text as to where Theorem 4 comes from. If I understand correctly, it follows from a tighter version of Pinsker\\'s inequality (Lemma 28) which is worth highlighting. While interesting, this trick could certainly be applied to the analysis of other bandit algorithms (as done for KL-UCB in an Appendix), so the result cannot really be interpreted as an indicator of the superior performance of KL-MS.\\n',\n",
       "  'weaknesses': '* I am a bit uncomfortable with the re-branding of MED as KL-MS. This was understandable for the initial MS paper since Honda & Takemura tackled bounded distributions, but here the algorithm exactly matches MED for Bernoulli distributions. Furthermore, it is folklore that for algorithms using divergences the Bernoulli divergence can be used for general bounded distributions. Hence, there is no real reason for this re-branding in my opinion. However, I insist on the fact that I find the novel elements of analysis intereting.\\n\\n* Regarding the analysis, it seems that it differs from the original paper only from term (F3). The way the authors handle this term is very interesting and a valuable contribution in itself, but this should be better highlighted in the paper. However, even this part seems largely inspired by recent papers from Jian et al. for the analysis of Thompson Sampling, so I wonder if there is a really novel theoretical contribution in the paper. \\n\\n* Minor: the authors should cite a recent follow-up of Honda and co-authors on the MED algorithm: https://arxiv.org/abs/2303.06058 \\nThis do not alter the contribution of this paper since the authors focus on problem-dependent guarantees of MED for a broader class of distributions, but answer some of the questions presented in the conclusion of the paper.'},\n",
       " 'review_726': {'summary': 'In this paper, the authors explore the mechanics of Chain-of-Thought (CoT), a method that has successfully enabled language models to handle complex reasoning tasks by decomposing them into simpler steps.\\nThe study aims to understand the underlying mechanics of CoT by investigating its impact on the ability of transformers to in-context learn a simple yet general family of compositional functions: multi-layer perceptrons (MLPs).\\nThe authors reveal that the success of CoT can be attributed to two distinct phases: focusing on data related to each step of the composition and in-context learning the single-step composition function. \\nThey provide experimental and theoretical evidence that demonstrates how CoT significantly reduces the sample complexity of in-context learning (ICL) and facilitates the learning of complex functions that non-CoT methods struggle with.',\n",
       "  'strengths': '1. This work explores CoT in the learning of MLPs thatis a novel perspective. Such a simplicity can also help to dig the into inner machenism of CoT and ICL.\\n2. This work experimentally compare three schemes (ICL, CoT-I, and CoT-I/O), providing valuable insights into their differences and the benefits of CoT prompting.\\n3. The paper provides a formalized theorem that explains how a transformer architecture can realize the CoT process for MLPs.',\n",
       "  'weaknesses': '1. The Chain-of-Thought (CoT) implementation presented in this study appears to be limited in terms of reasoning steps, which may not be fully consistent with the original motivation behind proposing CoT as a method for complex reasoning tasks.\\n\\nIn most existing work, CoT has the potential to assist in various complex reasoning tasks as it provides the model with step-by-step guidance on solving the input. \\nEach reasoning step should include both the intermediate state and the process through which this state is generated from the previous one. \\nThis is typically implemented using natural language descriptions or formal language expressions.\\n\\nHowever, the CoT implementation in this paper focuses on the intermediate states in MLPs and does not provide information on how each intermediate state is produced. \\nBy only presenting intermediate states rather than complete reasoning steps, the CoT explored in this study primarily reflects the capability of state transition rather than reasoning.\\n\\n2. The study appears to have limited analysis on generalization capabilities, which is a fundamental aspect of in-context learning (ICL).\\n\\nThis study assumes that there is no distribution shift between the training and test datasets. \\nHowever, a fundamental aspect of in-context learning (ICL) is the ability to learn new tasks from in-context examples. \\nConsequently, it is crucial to examine the performance in a generalization setting. \\nFor example, [1], which shares a similar philosophy with this work, extensively discussed the behavior of ICL on out-of-distribution prompts.\\n\\n[1] Shivam Garg, Dimitris Tsipras, Percy S Liang, and Gregory Valiant. What can transformers learn in-context? a case study of simple function classes.\\n'},\n",
       " 'review_727': {'summary': 'This paper aims to demystify the mechanism lying in the in-context learning (ICL) and chain-of-thought (CoT). It reveals how CoT significantly reduces the sample complexity of ICL. It uses a two-layer MLP, and a backbone GPT-2 model for exploration.   The experimental results reveal some interesting findings, e.g., the in-context samples needed is linearly dependent on the input dimension. The paper also provides theoretical analysis of probable approximation of MLPs via chain-of-thought.',\n",
       "  'strengths': '- The paper provides both experimental and theoretical evidence to support its claims about how CoT works.\\n- The findings about the relations between the in-context samples needed and the input MLP dimension are interesting and insightful.',\n",
       "  'weaknesses': '- Lack of clarity: Some parts of the paper may be unclear or difficult to follow, which could make it challenging for readers to understand the key findings and contributions of the study. Some of the concepts are not explained very well in the beginning (e.g, what is compositional learning? What is MLPs in-context), thus making the paper abstruse.\\n- The main contribution of the paper is not clear. The paper claims to dissect the mechanism of CoT'},\n",
       " 'review_728': {'summary': 'The paper proposes to study chain-of-thought (prompting) in the setting of learning MLPs. The authors build on top of recent work studying in-context learning linear regression tasks in the light of gradient descent and extent their setting to learning non-linear functions. In order to study chain-of-thought prompting they either provide features / hidden activations from the \"teacher\" MLP the student (CoT-I setting) or make the Transformer produce its own input by \"looping\" (CoT-I/O  setting). \\nThey provide theoretical results and empirical evidence that the Transformer is more sample efficient due to CoT by leveraging the given inputs and/or can remember weights coming from the family of teachers to allow for the self-production of features due to looping. \\n',\n",
       "  'strengths': 'I like the abstraction of CoT presented in the paper. The experiments are convincing and supported by the theoretical results. Although this setting is quite simple, it nicely extends the recent studies of gradient descent on linear regression. The results and the line of thinking is very intuitive, I like the ideas and the empirical execution of the paper. ',\n",
       "  'weaknesses': 'Although I am very familiar with the setup of the paper, I still had problems understanding it. The presentation can be made much clearer. \\nPlease work on your presentation and think about how to structure the paper in a clearer and structured way. It is a bit confusing that you have 1.5 empirical sections and the paper is very dense. I think it would benefit the paper if the authors work on restructuring the presentation given the (hopefully available) extra page if accepted. \\n\\nIt would be nice to clearly explain what is meant with \"learning an MLP\". This differs from classic student teacher frameworks since you are not learning and also don\\'t have to learn (in the CoT-I setting as far as I understand) the weight of the MLPs but solely rely on gradient descent on a linear regression task which acts on the given features in-context. Given these features in-context, it feels quite obvious that the CoT setting is indeed outperforming classic in-context learning. Nevertheless, I think it is still quite interesting. \\n\\nAlso it would be helpful to clearly state your abstraction/hypotheses that in LLMs the additional data needed to outperform plain ICL are \"features\" of the data motivating your MLP abstraction. This only became clear to me after reading a few times. \\n\\nIn the CoT-I/O setting, please explain why you are not using MLPs but linear deep nets as the teacher.  Although the presented experiments make sense, the training of Transformers is usually done differently as TFs are not trained to do CoT-I or CoT-I/O. Please comment on this.\\n\\nThere are a couple of ablations / interesting experiments I would like to see.'},\n",
       " 'review_729': {'summary': 'This paper investigates how the transformer-based model can compositionally learn some complex functions (e.g., an MLP) by breaking them down to some atom problems (e.g., linear mapping). Such an ability is also the crux of the success of Chain-of-thought (CoT) in-context learning (ICL) methods in large language models. Hence this paper bridges the gap between these two fields by theoretically analyzing the sample complexity of different methods and the accelerating effect of CoT in pertaining. Although I believe the contribution of the paper is solid, novel, and helpful to the field, there are plenty of problems that make the paper hard to follow. I wish the authors could polish the paper and tackle some of my concerns to make the paper stronger. Hence at this stage, I would only give a borderline rejection. I would be very happy to increase my score during the rebuttal phase.',\n",
       "  'strengths': 'See the summary part.',\n",
       "  'weaknesses': '1. I find the paper hard to follow, maybe because the theoretical part, which I believe is the most important contribution, is too abstract. It is not easy to get intuition from current section 3.2, so maybe explaining how theorem 1 is formulated is helpful. \\n\\n2. The experimental parts are not well organized. First, it appears almost everywhere (in section 2,3,4), which breaks the flow of the paper significantly. Also, some of the subfigures in Fig3,4,5 contain similar information. So it would be good to re-organize these results to make the paper easier to follow.\\n\\n3. In section 4.3, the paper switches from the ICL setting to the pertaining setting. It is beneficial to clearly explain what’s the difference between them and why we need experiments in this setting.'},\n",
       " 'review_730': {'summary': 'The paper presents a large scale medical imaging dataset consisting of 1.3M medical images from 55 publicly available datasets along with a new contrastive learning framework based on graph matching. Specifically, the model is firstly pre-trained on the collected dataset, and then finetuned towards different downstream tasks, improvement is observed a cross different datasets and settings.',\n",
       "  'strengths': '+ A large scale *medical* dataset for pre-training purposes\\n\\n+ Well-written and easy to follow\\n\\n+ Extensive experiments and good results',\n",
       "  'weaknesses': '- The paper did not provide enough details regarding the proposed datasets, especially in terms of the usage of the dataset, which, in my humble opinion, is pretty important to provide guidance on training medical models on large-scale datasets, e.g., 1. how are 3D data used, are they sliced into 2D data firstly? 2. The data comes from different datasets and maybe in different modalities, any balancing strategy during pre-training? 3. Any augmentations besides multi-crop? (e.g., flip, rotate, color jittering etc). In short, I expect the author provide more details regarding how they utilize the dataset\\n\\n- I appreciate the author provided dataset statistics details in the supplementary, yet I am curious how are these datasets selected and have the author tried any filtering/curation? As data curation has been considered very important in modern large-scale model training [1], it would be great to have some insights in the medical area.\\n\\n\\n[1] DataComp: In search of the next generation of multimodal datasets\\n'},\n",
       " 'review_731': {'summary': 'The paper proposes a set of networks called LVM-Med which are trained on large-scale medical datasets. The authors collected more than a million medical images from more than 50 publicly available datasets of diverse modalities and structures of interest (e.g. CT, MRI, Ultrasound...). In the work, several self-supervised algorithms are benchmarked on the large dataset. Furthermore, this work proposes a self-supervised contrastive learning algorithm based on a second-order graph-matching formulation.',\n",
       "  'strengths': '- the paper combines an incredibly large number of medical image modalities and images\\n\\n- I like the formulation of contrastive learning as a graph matching objective \\n\\n- the method section is comprehensive and the contributions are formalized',\n",
       "  'weaknesses': '1) Some aspects of the experimentation are unclear to me. From how I understand the text, the authors aim to compare to a large number of other datasets, baselines (\"In 2D settings, we also compare with 2D supervised architectures, such as U-Net, U-Net++, Attention U-Net, etc.\"), and tasks across 2D and 3D. What I do not understand is how the authors choose their baselines and what they present in the tables. For example, in Table 2. for the Drive segmentation dataset, the authors report 2D supervised Methods (e.g., UNet) with Dice scores ranging from 59 to 65. Clearly, this is not a performance on par with scores reported in other works. From the literature, the state of the art in supervised DRIVE segmentation should be way higher. A fully supervised segmentation baseline on the DRIVE dataset should have 80+ Dice (https://paperswithcode.com/sota/retinal-vessel-segmentation-on-drive). Similarly, the IoU performance of BRATS baselines should be higher https://arxiv.org/pdf/1811.02629.pdf\\n\\nPotentially I misunderstand what kind of comparisons the authors provide here. Can the authors please explain the choice of their baselines and their experimental settings? \\n\\n2) The clarity of the writing in some sections should be improved, e.g., in the experimentation.\\n\\n3) The reproducibility of the results and methods is a concern. I have not seen the code. Furthermore, the sheer amount of computing required  makes reproducibility challenging.'},\n",
       " 'review_732': {'summary': 'This paper collects a large medical imaging dataset, and it also shows that a self-supervised learning technique based on second-order graph-matching enhances performance in various downstream medical imaging tasks compared to other supervised learning methods and foundation models trained on image-text instances. The evaluation also considers two different architectures: ResNet-50 and ViT backbones.',\n",
       "  'strengths': '- Creating such a large medical imaging dataset is a commendable feat, and is needed by the community.\\n- The proposed self-supervised task is interesting.\\n- The evaluation results are comprehensive and thorough.',\n",
       "  'weaknesses': 'None to report.'},\n",
       " 'review_733': {'summary': 'This paper proposes a self-supervised pre-training strategy for medical imaging using a graph matching approach. Each unlabeled image is transformed via a pair of data augmentations and then processed via an encoder network. The augmented pair of images become vertices in a pair of graphs, with vertex features being the encoder outputs and edge connections selected via k-nn. A graph convolutional network is trained for vertex-to-vertex matching of the extracted pair of graphs. The training objective incorporates global and local similarity learning over spatial features along with a second-order edge similarity cost. Due to the combinatorial nature of the objective, gradients for backpropagation are approximated via Implicit MLE. Pre-training is performed over a large scale dataset comprising 55 publicly available datasets and used for multiple downstream fine-tuning tasks including segmentation, detection and classification.',\n",
       "  'strengths': 'The proposed graph matching technique for self-supervised learning is a novel and significant contribution. Abundant experiments demonstrate the generalizability over downstream tasks, with error bars also included. ',\n",
       "  'weaknesses': 'Some related works on graph matching in computer vision are missing in Section 2.3. \\n\\nDoi et al. Detecting Object-Level Scene Changes in Images with Viewpoint Differences Using Graph Matching 2022\\n\\nBian et al. Unsupervised Domain Adaptation for Point Cloud Semantic Segmentation via Graph Matching 2022\\n\\nWu et al. Unsupervised Visible-Infrared Person Re-Identification via Progressive Graph Matching and Alternate Learning 2023\\n\\nLiu et al. Self-supervised Learning of Visual Graph Matching 2022\\n\\nPeng et al. GATE: Graph CCA for Temporal SElf-supervised Learning for Label-efficient fMRI Analysis 2022\\n\\nThe authors should discuss and contrast with the graph matching objectives and applications in these works to highlight their novelty in self-supervised learning. \\n\\n\\nIntroduction can also be improved to better highlight the contributions. Rather than starting with discussing image-text datasets, the story should highlight the value of self-supervised learning in medical imaging and related works > proposed self-supervised learning method via graph matching > large-scale dataset collected for implementing this method > experiments on downstream tasks. \\n'},\n",
       " 'review_734': {'summary': 'This research paper focuses on LVM-Med, a self-supervised learning (SSL) technique designed for medical imaging tasks. Based on a second-order graph matching strategy, LVM-Med is trained on a large-scale medical imaging dataset. The researchers found that the method significantly improves performance on a variety of downstream medical imaging tasks compared to other supervised learning methods and foundation models trained on large quantities of image-text data. These findings were consistent across two different architectures: ResNet-50 and Vision Transformer (ViT).',\n",
       "  'strengths': \"- The LVM-Med method was evaluated on various tasks, including segmentation, object detection, and image classification. The results were compared to foundational models like Clip, Align, Flava, and SAM. It performed particularly well on eight medical segmentation tasks, outperforming both 2D SSL methods trained on the same dataset and foundational models.\\n- The training of LVM-Med on a large-scale medical imaging dataset indicates its capacity to handle and learn from large amounts of data, which is often a requirement in the field of medical imaging.\\n- The LVM-Med model outperforms both supervised learning methods and foundation models trained on hundreds of millions of image-text instances. This includes a variety of popular models such as Clip, Align, Flava, and SAM.\\n- The results show that LVM-Med performs well in in-out-distribution settings, implying a certain level of robustness and generalizability.\\n- LVM-Med provides benefits in both end-to-end and prompt-based segmentation tasks. This flexibility can be particularly useful in real-world applications, where various segmentation scenarios may be encountered.\\n- The authors also conducted an ablation study, experimenting with variations in LVM-Med's configuration to assess the importance of various components in the overall performance. It was concluded that all factors contribute to the final performance, with the second-order graph matching and Gumbel noise being the most significant.\",\n",
       "  'weaknesses': \"- Only 2D backbone is conducted: The LVM-Med model focuses primarily on 2D backbone. Author should provide more discussion about the challenge for applying this framework in 3D backbone.\\n- The LVM-Med model is trained on a large-scale dataset, how can author endure the testing dataset is not leaky in training set. Moreover, the use of a single dataset could potentially limit its generalizability. Ensuring robust performance across diverse datasets from different sources is critical.\\n- The model's performance benefits seem to be tied to its training on a large-scale medical imaging dataset. If such a dataset is not available, the performance of the model might be significantly diminished.\"},\n",
       " 'review_735': {'summary': \"In this paper, the authors propose a method to infer an agent’s internal model in a Partially Observable Markov Decision Process (POMDP) when the agent’s actions are non observable. Using local linearization, the authors show how a closed form approximation of the likelihood function for state trajectories can be constructed to subsequently yield maximum likelihood estimates. They also show that when there are confounding factors that can lead to the same behavior, the proposed method is able to disambiguate the factors better compared to the baseline.\\n\\n**After author's rebuttal:** I appreciate the authors offering clarifications. My main concern was around the significance of the contribution, which I based on the references discussed in the paper since I haven't been working on this specific area myself. However, looking at the other reviews and the author's comments, it appears the paper does more than just relaxing a simple assumption or two. I also mentioned that if the inference mechanism is aware of the generative model, one would expect better estimation in general. I make this comment from a Bayesian perspective so if the observations are from a Gaussian distribution and we model it as such, we expect to learn the sensible parameters with enough data as opposed to an unaware model that assumes, say, a Laplace distribution. I would need to think more as to why this might not hold here, as I am still inclined to believe it does. In any case, based on the discussion of the contributions, I am changing my rating from 4 to 5.\",\n",
       "  'strengths': 'The paper does a good job at laying down the groundwork for the problem, going over previous work and pointing at the potential shortcomings of existing methods. The motivating example in Fig. 1 works well and the paper’s structure follows naturally. The experiments are well-designed and the results are clearly discussed establishing the technique’s superior performance over the baseline.',\n",
       "  'weaknesses': 'However, in my opinion, the contribution lacks significance for acceptance at the venue. The problem formulation is slightly more general than existing work but only marginally so. The linearization to get approximate likelihood is clean but not novel. The results are not surprising since a technique that is aware of the generative assumptions is expected to lead to better posterior estimates. The disambiguation behavior follows from better estimation. '},\n",
       " 'review_736': {'summary': 'This paper presents the new formalization of inverse optimal control on partially-overevable Markov decision processes. The authors argue that most existing works on inverse control or inverse reinforcement learning focus on fully-observable Markov decision processes. Their approach extends iterative linear quadratic Gaussian (iLQG) and Maximum causal entropy (MCE) reinforcement learning, introducing local mineralization to achieve tractable likelihood. The method is evaluated through simulations.\\n',\n",
       "  'strengths': '+ The formulation and derivation of the method are solid and well-motivated.\\n\\n*Weaknesses\\n\\n\\n\\n\\n*Limitations\\n',\n",
       "  'weaknesses': '- The derived method seems natural, making it challenging to identify the novelty of the proposal.\\n- The evaluation lacks sufficient quantitative and qualitative analysis, as it only covers simple settings and compares with the MCE approach ~~without using the proposed method~~.\\n'},\n",
       " 'review_737': {'summary': 'This paper is a strong contribution on the Inverse Optimal Control problem when actions cannot be observed. It is particularly interesting their modelling of the agent and the “researcher” observer. The mathematical depth is good and sound. The results may be enough for a theoretical paper. However, there are too many unknowns to be ready for acceptance, particularly some definitions like partial observability related to noise. Another issue is the clarity regarding the baseline used, is it self-programmed?, is it taken from previous literature?. It seems that it does not work for any of the problems tested.',\n",
       "  'strengths': '-\\tThe mathematical depth is good.\\n-\\tInverse optimal control plus noise estimation is relevant for many applications; especially for motor control research.\\n-\\tResults may be enough for a theoretical paper.\\n',\n",
       "  'weaknesses': '-\\tNarrative: While the contribution looks very promising, the explanation of the contribution in the introduction is not enough clear to understand what is the main focus of the paper. Furthermore, there is a need to jump forward and backward in the text to fully understand the details of the approach. Particularly, it is sometimes complicated to see if the authors are talking about the agent or the observer (“researcher”). Another example: I had to read the whole article to understand the title.\\n-\\tThe partial-observability may be controversial as it is defined. The idea of tracking the belief of the agent is interesting, but why not using directly the observed state? So then is it the noise that the algorithm is tackling as partial observability. Thus, then the complexity depends on the type of noise.\\n-\\tFollowing the previous comment, while the method may be used for any parameter estimation (as authors state) why only estimating the observation/motor noise? Btw, observation noise of the agent or the observer? From the text I assumed that the authors were doing system identification at the same time. But they are estimating the noise.\\n-\\tBaseline explanation needs further description for the sake of clarity.\\n'},\n",
       " 'review_738': {'summary': \"This paper introduces a probabilistic approach to inverse optimal control for partially-observable stochastic non-linear systems with unobserved action signals. It derives an approximate likelihood function for the model parameters by linearizing the system around the observed trajectories and tracking the agent's belief distribution. This method is demonstrated to accurately infer the parameters better than the baseline maximum causal entropy (MCE) approach on two classic control tasks and two human behavioral tasks. Additionally, it shows the ability to disentangle the influences of perceptual uncertainty and behavioral costs on information-seeking behavior sources of information-seeking behavior.\",\n",
       "  'strengths': '- The introduction gives a clear background, which is helpful for someone like me who is less familiar with this field. It provides a clear understanding of the research question and the existing approaches.\\n- This paper proposes a new probabilistic approach for inverse optimal control in stochastic non-linear systems with missing control signals and partial observability, which outperforms the baseline MCE model and also provides an interpretable representation of the parameter space.\\n- The proposed method is evaluated on different tasks, including two human behavioral tasks, which might inspire further investigation on how the method can be applied to neuroscience and cognitive science studies.',\n",
       "  'weaknesses': \"A more comprehensive investigation into the method's robustness under various conditions would strengthen the paper's contributions.\"},\n",
       " 'review_739': {'summary': \"This paper targets for solving the inverse optimal control problem for partially-observable stochastic non-linear dynamics with no observation of the action. To estimate the parameters of the cost function in a stochastic non-linear system, the author first derives a likelihood function for the model parameters. They then approximate this likelihood by locally linearizing the system using a combination of iterative linear quadratic Gaussian (iLQG) and Extended Kalman filter (EKF) techniques. The proposed inverse method makes explicit assumptions about the dynamics of the control tasks, the agent's belief in a stochastic environment, and the structure of the cost function. The authors evaluate their approach on four simulation environments where structured noise is added to the dynamics of the environment to introduce stochasticity into the system dynamics. In comparison to the baseline, the proposed approach demonstrates better uncertainty estimation.\",\n",
       "  'strengths': 'In general, I find this paper easy to follow and variables in the equations are well defined. The derivations are nicely structured. The details are well documented in the Appendix and the assumptions and limitations are explicitly considered. \\n',\n",
       "  'weaknesses': 'I suggest the author clearly define their contribution in this paper, as the likelihood formulation of the inverse optimal control problem has been derived in another work, \\\\textit{Inverse Optimal Control Adapted to the Noise Characteristics of the Human Sensorimotor System}. To enhance clarity, I recommend placing the likelihood formulation in the background section.\\n\\nClaiming that their approach can disentangle perceptual uncertainty and behavior costs might be too bold for two reasons: firstly, the author demonstrates this claim in a single simulation environment only, and secondly, the structure of perception uncertainty and behavior cost function is known. However, in reality, obtaining the structure of these elements is difficult.\\n\\nMy major concern pertains to the number of assumptions made in different aspects of the system to obtain the proposed closed-form solution. For instance, all noises added in the experiments are assumed to be Gaussian distributed. These assumptions render the proposed approach challenging to apply in real-world scenarios, and the experiments were solely conducted in simulations. In addition, potential solutions to these assumptions i.e. addressing multi-modals belief utilizing SMC, are only briefly mentioned in the conclusion section. \\n'},\n",
       " 'review_740': {'summary': 'The authors propose an inverse optimal control method to handle the challenging case of inferring an internal model in a non-linear partially observable system, when the action sequence is not observed. Quantitative evaluation of the proposed method was shown for some classic control problems. The authors also demonstrated through an example the potential of their method in disentangling perceptual factors and behavioral costs.',\n",
       "  'strengths': 'The written language is easy to understand, and well organized. This work is a novel combination of ideas from some well-established techniques. The method should be of particular interest since intended actions of other agents are often only partially observable.\\u2028\\u2028\\n\\nThe value of the method is highlighted by a comparison with an alternative method that mistakenly attributes perceptual uncertainty to subjective preferences. The authors’ IOC is able to correctly infer that much of the action in this task is driven by exploration rather than exploitation.\\n',\n",
       "  'weaknesses': 'It would be helpful to highlight more strongly that they can distinguish preferences from uncertainty. The authors rightly mention this virtue in the title, so I think it deserves more attention in the text. On the other hand, for that section, I would say that stronger evidence is needed, for example on a more complex task than the light and dark one. Uncertainty and cost are sometimes nonidentifiable: It could be too costly to correct a certain mistake, or it could be too uncertain to justify an optimal action, and these effects can be indistinguishable from the outside. However, when the uncertainty is dynamic while the cost function is static, these factors are dissociable. This should be addressed by the authors.'},\n",
       " 'review_741': {'summary': 'The paper introduces a new approach to inverse optimal control which is able to deal with partially observable systems in which action signals are not known. Most existing approaches only work in fully observable systems where actions are known. The paper introduces a probabilistic formulation for inverse optimal control and uses maximum likelihood to estimate the costs and parameters of the system. To make the likelihood tractable, they use local linearization similar to iLQG. The paper tests the approach on 4 tasks and shows improved performance over a maximum causal entropy-based baseline. \\n',\n",
       "  'strengths': 'I am not familiar with this area of research and most of the concepts in the paper are new to me but I was still able to follow most of concepts introduced in the paper hence I think the writing is mostly coherent and fairly easy to follow. \\n',\n",
       "  'weaknesses': \"I don't have any weaknesses to point, I mainly have questions which I will write below.\\n\"},\n",
       " 'review_742': {'summary': 'This paper proposes an algorithm for inverse optimal control for agents operating in a partially observable Markov decision process, using only state trajectories. Given state trajectory data, dynamics model and observation model, the algorithm estimates the parameters by three steps: first, a policy is estimated using iLQG; second, the belief dynamics is estimated with EKF; finally, filtering is done by linearizing belief propagation. The likelihood is then maximized by back-propagation. The authors tested the proposed algorithm on several synthetic problems and compare it with a baseline based on maximum causal entropy. The results show that the proposed approach can better estimate the unknown parameters from behaviors than the baseline.',\n",
       "  'strengths': 'The problem studied here is relevant to community. I think especially that the authors consider the case without action information, which makes the setup more practical. The writing of the paper is easy to follow. The introduction is well motivated and the related work discussion is informative. The proposed idea is clean and is new to my knowledge. The authors discuss in details about the limitation of this work.',\n",
       "  'weaknesses': 'While the writing is easy to follow, it is unclear what the assumption is being made to use the proposed method. From Algorithm 1, the authors assume knowledge of the dynamics, observation models, and state trajectory, but the steps of Algorithm 1 requires more information than that, e.g., the cost is needed in iLQG. In addition, it is also unclear how the proposed algorithm actually operates; the authors describes how filtering and approximate likelihood (given all the parameters) is computed in details, but do not mention how the unknown parameters are actually estimated (the authors mention \"using gradient-based optimization\" with automatic differentiation, but it is unclear what the computational graph entails). As a result, while I get the high level idea, I do not think I fully understand the working details of the proposed scheme, and therefore it is hard to give it an accurate evaluation. I think the authors should compare more with recent IOC or IRL works, in the experiments, and consider more realistic datasets (rather than synthetic ones).  In addition, it would be more informative if the authors can better highlight their contribution in terms of the specific problem difficulties here (e.g., due to missing action).  Lastly, the proposed method is limited to low dim problems as the authors also point out.'},\n",
       " 'review_743': {'summary': 'To better adapt models to test distributions without changing model parameters, this paper utilizes the strategy that trains a data adaptor which can adjust the test data to fit the deployed models. To avoid the potential corruption of data features caused by the data adaptor, the proposed method treats the test-time adaptation process as a semi-supervised learning process. Specifically, the test data points are split into two subsets, including a high confidence set to perform regular cross entropy minimization and a low confidence set (as unlabeled set) to perform mutual information maximization.',\n",
       "  'strengths': '1. This paper studies a realistic problem in test time adaptation, i.e., the unreliable nature of the pseudo-labels assigned to the test data. \\n\\n2. This paper proposes solves the low-quality issue of pseudo-labels by transforming the adaptation process as a semi-supervised learning process, in which the data adaptor model is less impacted by the mislabeled data points.\\n\\n3. The proposed method uses ZOO framework to estimate the gradients of the parameters and can efficiently the problem with a few queries.\\n',\n",
       "  'weaknesses': '1. The Pseudo-Label-Robust Data Adaptation module is the key contribution of this paper, but the design of this part is too simple. The problem here is actually noisy label learning problem and treating it as semi-supervised learning is a common strategy. \\n\\n2. The reliable pseudo-label selection process in Subsection 3.3 utilizes fixed threshold or ratio to select data points, which maybe not robust in real-world settings.\\n\\n3. The experiments on large scale datasets are not presented in the paper. Moreover, the parameter analyses in terms of $\\\\tau$ and $\\\\rho$ are needed.'},\n",
       " 'review_744': {'summary': 'This paper proposes usage of zeroth order optimization (ZOO) for test-time adaptation (TTA) to ease several practical issues regarding accessing model parameters during TTA. Since the ZOO with pseudo label, which is a standard method in TTA, might cause the unreliable gradient, the paper proposes a sample selection method using the confidence of the prediction and class balance, and use only reliable sample to compute pseudo-label loss. The unreliable sample is used to compute another unsupervised loss to facilitate better adaptation. They show its effectiveness, CIFAR10-C and CIFAR100-C. No theory is provided.',\n",
       "  'strengths': '1. The paper is generally well written and easy to follow. \\n2. The usage of zeroth-order optimization in TTA is well motivated and interesting new problem. \\n3. The proposed sample selection approach based on the confidence and class balance seems not to be revolutionary but sensible.',\n",
       "  'weaknesses': \"1. The experiment is limited to the CIFAR10-C and CIFAR100-C. As usual, I recommend adding experiments on ImageNet-C and some domain adaptation datasets. \\n\\n2. The technical novelty is not high. Besides, I found that the effectiveness of the selection method proposed in this paper is not fully validated. For example, the paper does not provide ablation about the sensitivity about the threshold parameter. I'm also curious why we should not compute information maximization loss for reliable samples. Besides, the necessity of information maximization loss is not experimentally validated. \\n\\n3. The selection of the information maximization loss is not well described. Why did you choose the specific loss function? \\n\\n4. Several details are unclear for me. Including, \\n \\n- What the difference between SODA-R and SODA-FO? \\n- I'm confused by the table 5, since it says that SODA-O as a variant of SODA under *online* settings but seems to repeat the optimization multiple epochs. Do you repeat the optimization after you reach all test dataset? In the case, I have to say that it is not usual online setup. \\n\\n5. No theoretical results.\"},\n",
       " 'review_745': {'summary': 'In this work, the authors aim to adapt unlabelled test data to a deployed model without access to its parameters and inner structures during the testing process. Specifically, the authors utilize a data adaptor during testing to map test data into the deployed model, which gradients are estimated via ZOO. Experiments are conducted on CIFAR-10C and CIFAR-100C to verify the effectiveness of the proposed method.',\n",
       "  'strengths': '1. This paper is well-written and easy-to-follow. \\n\\n2. The code is available with the submission which improves the reproducibility index of the paper.\\n',\n",
       "  'weaknesses': '1. Experiments are not convincing. The authors only use CIFAR-10C and CIFAR-100C to verify the effectiveness of their algorithm. I suggest more datasets with various types of distribution shift should be included such as Office-31, Office-Home, PAC, etc.\\n\\n2. The necessity of ZOO is not clear. I can understand parameters of the deployed model are inaccessible, but why the data adaptor you generate during testing is still a black box? If the parameters of the data adaptor are known, why do not you simply fix the parameters of the deployed model as constants, and use FOO to calculate gradients of the data adaptor?\\n\\n3. More baselines should be considered. There already exist some TTA algorithms that do not requiring access to parameters of the deployed model, such as T3A [1].\\n\\n[1] Iwasawa Y, Matsuo Y. Test-time classifier adjustment module for model-agnostic domain generalization[J]. Advances in Neural Information Processing Systems, 2021, 34: 2427-2440.'},\n",
       " 'review_746': {'summary': \"This paper proposes SODA, a test-time data adaptor with the black-box source model leveraging Zeroth-Order Optimization for the adaptor, which involves a random perturbation on the adaptor model's parameters. It also considers the scenario, namely SODA-R when the gradient information is available and online setting SODA-O. The proposed method outperforms existing benchmarks, including BETA and DINE. The experiment is comprehensive with CIFAR10-C/CIFAR100-C. However, having more benchmark dataset experiments is better for achieving better confidence with the proposed framework for practical application.\",\n",
       "  'strengths': 'Test-time adaptor problem is well-motivated, and leveraging the adaptor could potentially save the training cost in practice.\\nUnder the limited available information scenario, the authors claim that they successfully tackle the problem better than other benchmarks, such as BETA and DINE. I value the simplicity of the approach only with two components; 1) mutual information maximization and 2) cross-entropy loss with pseudo labels by achieving a better performance. As a black-box scenario, overcoming the lack of gradient is another main ingredient of this paper, and it outperforms other benchmarks in CIFAR10-C/CIFAR100-C. Application of Zeroth-Order Optimization is another key ingredient, but the simplicity is better appealing to me.',\n",
       "  'weaknesses': \"1. I would like to understand the relationship between the model perturbation and the data augmentation in the proposed framework. See the more detailed question in the Questions section.\\n2. A good combination of the choice $\\\\sigma, \\\\alpha, \\\\tau$ seems to be critical. I see this discussion at C3 in the Appendix, but I suggest that the authors make this more explicit in the main paper. If those parameters are dataset/or task-dependent, it's not yet applicable in practice.\\n3. Why $\\\\sigma=0.5$ generally achieve a better performance? And a better performance with $\\\\alpha=0.0001$ implies that the mutual information term is the most critical. A further ablation study of each loss term would be necessary.\\n\\nMinor Comments:\\n- L61: SOTA $\\\\to$ SODA?\"},\n",
       " 'review_747': {'summary': 'An operation of consolidation on SCMs is defined and its merits laid out in numerous examples. The operation amalgamates variables while preserving aspects of the causal structure. As opposed to the similar operation of marginalization that comes from probability theory and is well-known in causal abstraction, the consolidation operation is capable of representing interventions on those variables that were abstracted since the consolidated variable is of a special kind. It also accommodates compressions since other compatible functions can be assigned to the consolidated variable; this also opens the possibility of widening the domains of the original variables.',\n",
       "  'strengths': 'The problem is relatively well-situated within the literature, I believe the results to be sound, and the examples are good.',\n",
       "  'weaknesses': 'I am not convinced of the utility of the approach. What open problems does this contribute to solving?'},\n",
       " 'review_748': {'summary': 'This work introduced a concept of consolidating causal mechanisms to transform large-scale Structural causal  models (SCMs) while preserving consistent interventional behaviour. The author shows consolidation is powerful for simplifying SCM, disscuss the complexity and give a perspective on generalization.',\n",
       "  'strengths': 'The author builds a solid framework of consolidating causal mechanisms. The expression of notations is adeque. The spirit of compression the causal equation is interesting and straight-forward.',\n",
       "  'weaknesses': '1. The author should spend more efforts to describe the compression of causal equations clearly, as this is the key contribution of this work.\\n2. The author did not propose a concrete algorithm to compress the causal equation.'},\n",
       " 'review_749': {'summary': 'The paper presents a framework for causal reasoning that supports the simplification of large structural causal models (SCMs).  One key operation that supports this simplification is consolidation of a SCM such that only a subset of endogenous variables are explicitly modelled, but in such a way that all possible interventions are still supported. Another key operation is the partitioning of an SCM into sub-models, in such a way that endogenous variables from one sub-SCM act as exogenous variables in another. \\n\\nPotential reductions in complexity are then discussed by the use of these operations and associated constraints. For instance, replacing equations within SCMs with computationally simpler expressions,  and dropping equations which do not relate to variables of interest. Throughout there is a focus on retaining information about the effects of interventions. The paper concludes with two examples: one on modelling tool wear on a milling machine and another, more complex example, exploring planning policies for a simple platformer game. \\n',\n",
       "  'strengths': '* The paper very clearly presents its contribution and relates this well to existing work, justifying the relevance of the contribution to the field.\\n* The paper builds its arguments formally, and with intuition, and presents meaningful relevant results and constraints.\\n* The examples illustrate well the benefits of the proposed framework.\\n* The contributions appear meaningful to me and likely to be of relevance to other researchers, particularly those concerned with large scale causal modelling.\\n\\n',\n",
       "  'weaknesses': '* At times the arguments are a little vague or the explanations incomplete.\\n* Although mostly clear, the formal notation sometimes leaves a little to be desired.\\n* There are a few places where the authors appear to make errors or omissions in their explanations.\\n\\nIssues with understanding:\\n1. In definition 1, the set of possible interventions is a little unclear. There appears to be 1 possible intervention, $I_i$ per endogenous variable, $X_i$. Or can there be multiple potential, but mutually exclusive, interventions per endogenous variable? What exactly is $I_i$?\\n2. On line 94 $f_i(\\\\textbf{x}, x_0)$ is used to indicate the structural equation for variable $X_i$ under the intervention that $X_j$ is set to value $x_0$, but this seems a little under-defined to me.\\n3. On line 98, the authors state that $\\\\mathcal{M}$ entails infinitely many intervened distributions, but this seems to conflict with earlier notation (see 1.).\\n4. Definition 2 could do with an explanation of $P^{\\\\textbf{I}}_{\\\\textbf{E}}$. I am assuming this means the distribution of target variables in $\\\\textbf{E}$ under some intervention $\\\\textbf{I}$ but I can\\'t see this stated anywhere.\\n5. The notation $\\\\rho(\\\\textbf{U},\\\\textbf{I})$ first introduced in Definition 2 does not refer to the subset of variables $\\\\textbf{E}$ to which it refers. This would be good practice anyway, but becomes more problematic when partially consolidated SCMs are considered (Def 5) as the variables of interest $\\\\textbf{E}$ are augmented with additional variables that act as exogenous variables in other sub-SCMs.\\n6. The caption for Figure 2 (right) states that the dotted line indicates explicit computation for $X_2$ but it isn\\'t clear what is meant by this.\\n7. In section 3, in a number of places (lines 159, 165, 187), there appears to be repeated errors in the notation, e.g. $\\\\textbf{V} \\\\in \\\\textbf{A}$. I think that $\\\\textbf{V}$ is the complete set of endogenous elements while $\\\\textbf{A}$ is a subset of $\\\\textbf{V}$\\n8. In lines 175-183, the partitioning of an SCM appears to  require that exogenous variables $\\\\textbf{U}_i$ of a sub SCM must be endogenous variables of another sub-SCM in the same partitioned SCM. But could they be truly exogenous variables of the whole system? Also, there appears to be notational irregularities in this paragraph relating to what is a sub-SCM and what is a partitioned SCM.\\n9. Things get a bit messy around definition 5 with respect to $\\\\textbf{E}$ and $\\\\textbf{E}\\'$. The distinction between these two sets of variables could be clearer. For instance, if I am considering partially consolideted SCM $\\\\mathcal{M}_{\\\\mathcal{A},\\\\textbf{E}\\'}$ then how do I know what the set $\\\\textbf{E}$ is that is used to define $\\\\textbf{E}\\'$.\\n10. In section 4, there is a chain of inference on lines 234-235 that is difficult to follow (what is the scope of the universal and existential quantifiers?) and some entity $D$ appears without being defined.\\n11. I got a little lost in section 4.1. In particular, the discussion of conditional branching and stacking was a little vague.\\n\\n## Post rebuttal\\n\\nAfter reading the rebuttal and individual responses to the above points, I am raising my recommendation to \"accept\".'},\n",
       " 'review_750': {'summary': 'The authors propose a thrust score which measures if a pre-trained language (PTLM) model has the knowledge to perform the task. They then go on to use this score to choose when they should use external knowledge (when the thrust score is less). The main crux of the thrust score is knowledge representation. The authors argue that if the PTLM places a sample close to related samples, then it has sufficient knowledge about the sample.\\n\\nI feel the thrust score is very good contribution. The adaptive lookup for knowledge experiments are useful, though there might be other ways to use this thrust score.',\n",
       "  'strengths': '1. The authors propose a thrust score which is a measure of a pre-trained language models knowledge of the instance. These are based on the distance of a sample to the centroid of a cluster. The clusters are task examples. There can even be mulitple clusters within a class in a classification task. This is measured from representations in the last hidden layer (last decoder layer in T5).\\n\\n2. Given the authors have a thrust score, they proceed to lookup external knowledge only when the model does not have internal knowledge to predict on a sample. The hypothesis is that looking up external knowledge all the time is wasteful and some times even counter productive because of noisy external knowledge.\\n\\n3. Overall I think the thrust score is a very useful contribution.\\n\\n4. The ablations - checking which layer to use for representations, comparison with BM25, comparison with full knowledge usage are meaningful.',\n",
       "  'weaknesses': '1. The adaptive knowledge injection (while useful and demonstrates that the thrust score is effective) could have benefited with knoweldge probing experiments rather than just QA, MC etc. The performance on (triples) tail prediction task, or even knowledge probing like in the below work, can add be even more interesting.\\n\\nOnoe, Y., Zhang, M.J., Padmanabhan, S., Durrett, G. and Choi, E., 2023. Can LMs learn new entities from descriptions? Challenges in propagating injected knowledge. arXiv preprint arXiv:2305.01651.\\n\\n2. Some of the claims like below seem a bit subjective and can be avoided. Atleast from the abstract.\\n\\n\"we can achieve significantly higher cost-efficiency with Thrust score as the retrieval indicator than the naive usage of external knowledge on 88% of the evaluated tasks with 26% average performance improvement.\"\\n\\n3. The results could be presented a bit better. For example, figure 4 seems unnecessarily complicated.\\n\\nIt\\'s ofcourse the author prerogative, but it took me a while to get used to the thrust, propulsion terminology.'},\n",
       " 'review_751': {'summary': 'The paper addresses the limitations of large-scale pre-trained language models (PTLMs) in effectively utilizing external knowledge. It proposes the instance-level adaptive propulsion of external knowledge (IAPEK) as a solution to leverage external knowledge only when necessary. The paper introduces a novel metric called \"Thrust\" to measure the knowledgeability of PTLM models at the instance level, using the representation distribution of a small number of seen instances. Extensive experiments demonstrate that Thrust is an effective measurement of PTLM models\\' instance-level knowledgeability. The paper shows that using the Thrust score as a retrieval indicator achieves significantly higher cost-efficiency compared to naive usage of external knowledge, resulting in a 26% average performance improvement on 88% of the evaluated tasks. These findings contribute to the understanding and real-world application of knowledge-enhanced language models, particularly in scenarios with limited knowledge-seeking budgets due to computation latency or costs.\\n\\n\\n\\n\\n',\n",
       "  'strengths': '1、The authors clearly highlight the limitations of implicit knowledge in pre-trained language models (PTLMs), such as being opaque, static, and inefficient. This acknowledgment sets the stage for proposing a novel approach to address these limitations.\\n\\n2、The authors introduce the concept of Instance-level Adaptive Propulsion of External Knowledge (IAPEK) as a solution to address the limitations mentioned earlier. ',\n",
       "  'weaknesses': '1、The methods and experiments are described in an informal and obscure manner, lacking motivation for the specific choices made and failing to compare them with alternative approaches. Moreover, this paper lacks the experimental comparison and discussion with ChatGPT and other instruction fine-tuning large models\\n\\n2.  A major weakness of this work is its lack of reproducibility. The paper fails to provide clarity on whether the external knowledge used is published or not, and it does not explain how one can obtain it. \\n'},\n",
       " 'review_752': {'summary': 'This work proposes methods IAPEK and Thrust to make instance-level decisions about when to utilize external knowledge for question answering. IAPEK is instance-level adaptive propulsion of external knowledge, essentially the use of external knowledge only when it is necessary beyond the base model. Thrust is a heuristic scoring method to decide which questions to use external knowledge on, based on various notions of distance from existing clusters of points. Intuitions for Thrust score are outlined in S2.2. The work demonstrates that Thrust outperforms two baseline methods (random and BM25) at overall accuracy when used to select which instances require external knowledge under a fixed budget. They also demonstrate that using IAPEK with Thrust performs nearly as well as using external knowledge in every case, with a lower computational budget.',\n",
       "  'strengths': '- The work makes useful statements about the complex nature of retrieval based QA -- both in terms of efficiency and the counterintuitive finding that external knowledge does not always help\\n- Thrust seems to outperform baselines at selecting instances that require external knowledge\\n- In general, IAPEK seems to improve efficiency without too much loss of performance compared to always using external knowledge',\n",
       "  'weaknesses': '- The Thrust score does not have theoretical grounding, or sufficient ablations to justify design decisions. These are not both necessary, but more justification (either theoretical or experimental) for specific design decisions would be very useful. A description of intuitions is given at line 105, but no experimental examples are given to demonstrate that these cases are relevant. One useful aspect would be comparing to simpler scores. Only random and BM25 are used as baselines, but what about simpler notions of distance, that either do not involve complex clustering, or do not involve the \"mean vector\" idea for Thrust? Something simpler like distance from existing points may perform worse, but there it is not clear given the current results included in the paper. Perhaps some of the complexity of Thrust is not required. \\n- More broadly, it would be useful to show, even for a subset of datasets, the full set of possibilities between: {no EK, IAPEK default, BM25, Thrust, distance from overall centroid, full EK}\\n- It is not completely clear what aspects factor into the performance of IAPEK/Thrust. Particularly, the authors mention that external knowledge can sometimes hurt performance, in which case perhaps Thrust is helping less with efficiency, and more with preventing such examples from seeing external knowledge that would reduce performance. One useful aspect would be a more comprehensive version of Table 3 with numbers, to answer the question \"how often does thrust outperform full EK?\"\\n- Continuing from the point above, it is not clear from the paper whether the justification of Thrust is improving efficiency (i.e. full EK always helps but is expensive) or performance (i.e. there are some examples that do better without EK, and Thrust helps identify these)'},\n",
       " 'review_753': {'summary': 'LLM’s parametric memory may be inaccurate or outdated and thus retrieving additional information to LLMs can help but it’s costly and may be noisy.\\nSo this paper proposes Thrust to measure the instance-level parametric memory and can help determine whether to use a retrieval module for enhancing LLMs, which is more cost-efficiency.\\nBy dynamically using external knowledge, the proposed IAPEK can achieve consistent gains over a large amount of tasks and LLMs.\\n',\n",
       "  'strengths': '1. The task is important and motivation is well elaborated.\\n2. Thrust is quite data-efficient to construct, which is valuable in practice.\\n3. Comprehensive evaluations are conducted and valid points are made.\\n',\n",
       "  'weaknesses': '1. LLMs used in this paper are not that strong and may not well utilize external knowledge, as pointed by you. I would recommend adding models like FLAN-T5 or other instruction-tuned models that can follow instructions to use external information for QA.'},\n",
       " 'review_754': {'summary': 'This work looks at treating the meta-continual learning problem as instead a sequence modeling problem. Instead of traditional approaches that train a model with an inner loop and then compute a meta-gradient in the outer loop, they replace the inner loop with just inference in a sequence model. The meta gradient step is replaced by a normal gradient step that is taken based on the sequence seen by the model. In order to make this approach work, the paper uses transformers that (1) use causal attention (ie the information transfer only happens forward in time) (2) make use of kernel-based transformers to address the quadratic memory usage of traditional transformers. They test their approach on 4 classification datasets and 3 regression problems.',\n",
       "  'strengths': '- The results show that there is potential for this approach of treating meta-continual learning as sequence modeling. The performance is generally competitive or superior to prior approaches.\\n    \\n- The presented method is memory efficient and fast compared to previous MCL approaches, at least when dealing with typical MCL benchmarks.\\n    \\n- The paper is well presented and readable, with helpful figures.',\n",
       "  'weaknesses': '- The paper does mention that their model tends to overfit on the CIFAR-100 dataset. The paper hypothesizes that this is because task diversity is lower, but this is not verified experimentally.\\n- The novelty is a bit limited, as the paper simply applies transformers to this task of MCL, but still good enough.'},\n",
       " 'review_755': {'summary': 'This paper applies transformers and their efficient variants as sequence models to the problem of meta-continual learning. More specifically, instead of running gradient descent on a stream of training data, this paper trains transformers to do in-context continual learning over the data stream. It then compares these transformer-based approaches to three other MCL baselines on regression and image classification tasks.',\n",
       "  'strengths': 'Originality: There have been many works on using sequence models for meta learning, and many works on meta-continual learning. However, to my knowledge this is the first paper where sequence model based meta-learning is tested for continual learning capability.\\nQuality: code included, good reproducibility; rich content in the Appendix, many details and analysis.\\nClarity: well-written and easy to follow. Many schematic illustrations that make the core ideas clear.\\nSignificance: in the long run, being able to leverage data and compute to learn a CL algorithm instead of human-engineering one is an important topic.',\n",
       "  'weaknesses': 'The main weakness is that the experiments have not convincingly demonstrated the proposed method is practically useful as a continual learning method. \\n\\nOne reason is its scalability to longer sequences. If I understand correctly, during the meta-test, almost all methods are evaluated on episodes of only 20 x 5 = 100 examples. The only experiment that’s slightly longer is Table 2 with 100 x 5 = 500 examples, and only one baseline was included. In comparison, OML showed it can scale to 1000 examples and ANML to 9000 steps. But frankly even these are too short to be useful for continual learning, which is supposed to handle much longer streams than normal deep learning settings. How would this method fare if at test time the episodes are much longer?\\n\\nThe second reason is its generalization ability to out-of-distribution data during meta-test. All evaluations in this work assume the same distribution and the same episode length for meta-train and meta-test. However, in real CL applications, one can’t know beforehand the distribution of future data and how long the stream would be. One advantage of SGD-based continual-meta learning approach is that the inner loop uses SGD for optimization, so even if the meta-test data is OOD, SGD can still learn. Can transformers still learn new data if they are OOD?\\n\\nThe third reason is that it’s not compared to any competitive conventional CL baselines. Even if the authors only intend to show competitiveness among MCL approaches, it’s still good to have other types of CL approaches for reference. In addition, there are other meta-learning methods that could be competitive baselines but not referenced, for example [1, 2]. Although these meta-learning methods are not particularly designed for continual learning, they have both demonstrated continual learning capabilities. In particular, [1] proposed an optimization-based approach that can extend to arbitrarily long inner-loops and trained a continual learning optimizer with it; [2] notably also applies a transformer as a meta learner over episodes for in-context RL.\\n\\n[1] Meta-Learning with Warped Gradient Descent https://arxiv.org/pdf/1909.00025.pdf \\n[2] In-context Reinforcement Learning with Algorithm Distillation https://openreview.net/forum?id=hy0a5MMPUv'},\n",
       " 'review_756': {'summary': 'The paper redefines Meta-Continual Learning (MCL) as a sequence learning problem. Following this definition, the paper proposes a Transformer-based meta continual learner. The method is evaluated on several classification and regression tasks.',\n",
       "  'strengths': 'Overall, I think the paper is well written and does a good job justifying the approach.\\nThe idea of casting MCL as a sequence learning problem is novel (at least in CL) and interesting.',\n",
       "  'weaknesses': 'baselines: the paper mentions that Prototypical Networks could be used in MCL. It would be interesting to compare against them.\\nIn general, the baselines are a bit limited. It would be interesting to compare against other methods that keep all the data in memory, like Transformers do.\\n\\nminor comments:\\n- line 40-41 claims that sequence learning exploits in-context learning (ICL). However, ICL is a property of large pretrained models, I don’t think it applies to this setting\\n'},\n",
       " 'review_757': {'summary': \"The paper proposes to formulate continual learning as a sequence modeling problem. This new formulation views the model's learning process with continual session data as the forward pass of a sequence model, such as a Transformer, rather than relying on backpropagation. Specifically, keys and values within the Transformer can be interpreted as the internal state of a memory module in continual learning. To optimize the sequence model's parameters for continual learning problems, meta-continual learning is employed. This involves meta-learning the Transformer model using episodic learning. To address the computational and memory costs associated with long sequence modeling, efficient transformers, including the Linear Transformer and Performer, are utilized. The proposed approach's effectiveness is substantiated through performance evaluations across multiple benchmark datasets.\",\n",
       "  'strengths': '* Formulating continual learning as the problem of sequence modeling is very novel to me, and the author provides a very detailed explanation of why that two problems can be connected with each other under the framework of meta-continual learning. For example, the similarities between the inner loops of the two problem formulations are illustrated clearly in Algorithm 1 and 2. Furthermore, the paper conceptually outlines the connection between dynamic-architecture CL approaches and standard Transformers.\\n\\n* The introduction is written in a very clear manner, making it easy for readers to grasp the central ideas and the contributions of the study.',\n",
       "  'weaknesses': '* The paper doesn\\'t adequately distinguish between continual learning and meta-continual learning. While the text mentions that meta-continual learning aims to automatically learn how to continue learning as opposed to standard continual learning by manual design, it fails to mention the necessity of a large-scale offline dataset to create a meta-training dataset. In contrast, standard continual learning does not require such an offline dataset for training.\\n\\n* The explanation of meta-continual learning lacks clarity. I recommend that the authors define and explain terms such as episodes, meta-train, and meta-test more explicitly. Particularly, the concepts of a support set and query set, which are typically used under the meta-learning framework, are not mentioned in this paper.\\n\\n* An important baseline in meta-continual learning, \"Wandering within a world: Online contextualized few-shot learning,\" presented at ICLR 2021, is overlooked in the related work section.\\n\\n* While the text acknowledges the limitations of SGD-based meta-continual learning, such as the high cost of second-order gradients and scalability issues, it doesn\\'t reference previous work on efficient meta-learning approaches. e.g. [1].  I would suggest the authors incorporate references to efficient meta-learning techniques and add a dedicated section comparing them to transformers in terms of computational and memory costs.\\n\\n    [1] Large-Scale Meta-Learning with Continual Trajectory Shifting. ICML 2021\\n\\n\\n* The presentation of the experiment results could be improved. A central challenge of continual learning is the balance between catastrophic forgetting and rapid adaptation to new knowledge. However, Table 1 doesn\\'t illustrate the proposed method\\'s effectiveness related to these two criteria. Therefore, I suggest the authors represent the experiment results using a plot charting the number of continual sessions against average accuracy. Such a plot is typically employed in previous works.'},\n",
       " 'review_758': {'summary': 'The authors assert that there is a gap between traditional recommender systems trained on offline (historical) preference data and conversational assistants that aim to elicit user feedback about their *current* preferences. The authors assert that conversational assistant training relies on reinforcement learning-based frameworks and suffer from data insufficiency. They propose the CORE method for learning a conversational recommender system based on the idea of maximizing \"certainty gain\" by using a pre-trained recommender system as a scoring model for an online decision tree process. Experiments across a wide range of datasets demonstrates consistent improvements over reinforcement learning methods for learning conversational recommenders.',\n",
       "  'strengths': '- The problem formulation makes sense and the authors organize the methodology in 3.1 and 3.2 in an intuitive manner. However, as mentioned in the weaknesses section there could be improvements in clarity.\\n- It is important that the authors extend attribute certainty gain computation to continuous attributes (Lemma 1) as this is a realistic setting for many attributes of interest in real-world situations (see prices, interest rates, or other continuous values).\\n- As a general extension of the above, the authors carefully consider multiple cases that bring the problem setting closer to real-world user interactions and preference considerations (neutral responses, attribute dependence). They extend the derivation of certainty gain across these situations.\\n- Experiments across a variety of datasets and base recommender systems demonstrate that CORE performs better in most cases compared to CRM and EAR baselines.',\n",
       "  'weaknesses': '- The authors should clarify the reasoning for the statement on lines (135-136) that \"if [the queried item is in the target set], the sesion is done and therefore the certainty gain is the summation of all relevance scores in V_{k-1}\". Why is this the certainty gain? It is rooted in the definition in (1) that the certainty gain of a target item sets all items to \"checked for certainty\" but it is unclear what the basis is for this or whether it\\'s a choice made to simplify the modeling.\\n- The authors omit discussion of a large area of conversational recommendation focusing on eliciting user feedback via critiques of surfaced attributes [including 1-4]. This area is directly related to the \"attribute query\" in the online-checking framework of CORE, and merits discussion in the literature review.\\n- The reference to ChatGPT-3.5-turbo seems gratuitous, as there is little mention of it in the main paper other than a statement on (254) that a pre-trained language model can be used as the Psi_{CO} component.\\n- The experimental analysis seems relatively sparse. It would be good to see a deeper analysis (case studies, for example, or human evaluations) in the main paper body. It would also help to see a discussion of the limitations, edge cases, or remaining challenges in the space and what other challenging experimental settings were considered.\\n\\n\\nReferences:\\n[1] Antognini, D. \"Interacting with Explanations through Critiquing\" (2021)\\n[2] Antognini, D. \"Positive and Negative Critiquing for VAE-based Recommenders\" (2022)\\n[3] Li, S. \"Self-Supervised Bot Play for Conversational Recommendation with Rationales\" (2022)\\n[4] Wu, G. \"Deep language-based critiquing for recommender system\" (2019)'},\n",
       " 'review_759': {'summary': 'In this paper,  the authors propose a learning framework called CORE that can incorporate a conversational agent into any recommendation platform, to complementarily check estimated offline relevance scores in each online user session. Experiments results on comprehensive benchmark datasets show that CORE outperforms existing reinforcement learning-based and statistics-based approaches in querying items and attributes/attribute values. \\n\\n',\n",
       "  'strengths': \"1. The proposed offline-training and online-checking paradigm bridges a conversational agent and recommender systems via a unified uncertainty minimization framework. It's effective and efficient, and flexible to handle recommendations in both cold-start and hot-start settings. \\n\\n2. Various large-scale benchmark datasets are used in experiments, and the results are convincing. \\n\\n\\n\",\n",
       "  'weaknesses': \"\\n1. Are the comparison results in Tables 1, 2, 3 and 4 statistically significant? It'd be great if t-test results could be provided. \\n\\n2. The central idea in this paper is to bring a conversational agent for recommendation systems. If possible, it'd be great to conduct an experiment on a real online platform to have user sessions to show the superiority of the proposed algorithm.  \"},\n",
       " 'review_760': {'summary': 'In this paper, a conversational part of a recommender system is proposed. It is assumed that a recommendation model is available that assigns scores to user-item pairs (which estimate the probabilities of acceptance of the corresponding recommendations), items have a number of important attributes (numerical and categorical), and each user has preferences over the values of these attributes. A conversational model should sequentially decide (based on the recommendation scores) whether to ask the current user about the preferenced values of one attribute, or to try recommending an item, which can be accepted or rejected by the user. The goals are to maximize the rate of successful dialogs which accepted recommendations and to minimize the average number of rounds until the user accepts a recommendation.\\n\\nIn the current paper, authors propose a simple greedy algorithm that chooses an action that minimizes the expected sum of estimated recommendation scores of the unchecked items, that is, items that are still can be chosen by the user in the light of the obtained information so far.\\n\\nAuthors compare their algorithm with two previous baselines based on RL (CRM and EAR) and conclude that the proposed method outperforms RL-based approaches.',\n",
       "  'strengths': '-\\tPaper is mostly well-written, the algorithmic ideas and propositions are clear.\\n-\\tThe idea of expected uncertainty minimization is reasonable',\n",
       "  'weaknesses': '1.\\tThe main questionable point is the contribution of the paper. I have the following doubts:\\n\\n-\\tPapers on conversational RS referenced in related work are very old, I do not see any works dated by 21-23 years. Expected gain maximization resembles expected improvement criterion, one of the most widely-used Bayesian optimization algorithms (see \"Efficient global optimization of expensive black-box functions.\" by Jones et al.) Both algorithms are based on the estimation of the expected gain using the posterior distribution. I think, corresponding references are needed here.\\n\\n-\\tMotivation behind the proposed method in comparison with RL-based approaches is not convincing for me. Problem setting does inherently lead to RL approaches: it includes actions, states, rewards, and requires a policy for an optimal trajectory. Why a simple definite empirical greedy algorithm should outperform RL-based models?\\n\\n2.\\tTheoretical part is not perfect. \\n\\nIn problem setting, it would be useful to state explicitly what assumptions underly the proposed method. For example, it in implicitly assumed that there is a unique item the user needs (therefore the sum of probabilities over items equals 1, see Eq. 5). Another example is that information on user preferences on an attribute carries binary information on user preferences on items, what underlies their division on “cheched” and “unchecked”.  The motivation behind the approach is based on these assumptions, which are rather controversial in practical cases considered in experiments.\\n\\nTheoretical results are very simple. Claimed propositions are self-evident, but do not carry much understanding on the specific properties, novelty, and contribution of the proposed EG maximization technique.\\n\\nThere are some inaccuracies in equations. For example:\\n\\n-\\tEquation for the action space at line 175 looks formally incorrect. As $W_x$ is different for different $x$, we cannot obtain $A$ as a set product.\\n-\\tEq. 10 Is not formally accurate: the argmax operator should be applied to a function.\\n\\n\\n3.\\tExperiments and practice.\\n\\nThe baselines are rather old (CRM and EAR). What about CRIF from “Learning to Infer User Implicit Preference in Conversational Recommendation”?\\n\\nThere is no discussion on the possibility of efficient implementation of the proposed algorithm. How the calculation of uncertainty gains can be implemented in practice? Naïve summation over all items with the given attribute (see, e.g., eqs. 7-8) for each possible attribute values (see eq. 7) looks impractical in real-time conversational recommender systems.\\n\\n'},\n",
       " 'review_761': {'summary': 'The paper is about conversational recommender systems (CRS), which are systems that can interact with users through natural language and provide personalized recommendations. The paper addresses the challenge of incorporating a conversational agent into any existing recommender system in a plug-and-play fashion, without requiring reinforcement learning or data collection. The paper proposes CORE, a novel offline-training and online-checking framework that bridges a conversational agent and a recommender system via a unified uncertainty minimization objective. The paper claims that CORE can benefit any recommendation platform and can handle different types of data, attributes, and queries. The paper reports that CORE outperforms existing methods in both hot-start and cold-start recommendation settings, and can communicate as a human if empowered by a pre-trained language model.',\n",
       "  'strengths': '1) Originality: The paper proposes a novel offline-training and online-checking framework, CORE, that bridges a conversational agent and a recommender system via a unified uncertainty minimization objective. This approach is original in its ability to incorporate a conversational agent into any existing recommender system in a plug-and-play fashion, without requiring reinforcement learning or data collection.\\n2) Quality: The paper develops a new human-AI recommendation simulator and conducts extensive experiments on eight industrial datasets with nine popular recommendation approaches. The results show that CORE outperforms existing methods in both hot-start and cold-start recommendation settings.\\n3) Significance: The proposed CORE framework has the potential to benefit any recommendation platform and can handle different types of data, attributes, and queries. This makes it a significant contribution to the field of conversational recommender systems.',\n",
       "  'weaknesses': '1) The introduction does not provide enough background and motivation for the problem of conversational recommender systems. It should explain why this problem is important and challenging, and what are the existing gaps and limitations in the literature. A possible way to improve it is to cite more relevant works and compare them with the proposed approach.\\n2) The proposed approach in Section 3 is not clearly explained and justified. It does not provide enough details and intuition for how the uncertainty minimization framework works, how the expected certainty gain is derived, how the online decision tree algorithm is implemented, and how the dependence among attributes is considered. It also does not discuss the advantages and disadvantages of the proposed approach compared to other methods. A possible way to improve it is to provide more examples, figures, pseudocode, and analysis to illustrate the proposed approach.\\n3) The experimental setup in Section 4 is not comprehensive and fair. It does not describe how the datasets are preprocessed, how the hyperparameters are tuned, how the baselines are implemented, and how the evaluation metrics are calculated. \\n4) The experimental results in Section 4 are not convincing and insightful. They do not show the statistical significance of the performance differences, the impact of different factors/hyperparameters, or the qualitative analysis of the generated conversations. They also do not discuss the limitations and challenges of the proposed approach, such as scalability, robustness, diversity, etc. \\n5) The references in Section 6 are incomplete and inconsistent. Some references are missing important information such as authors, titles, venues, pages, etc., or have different formats or styles.'},\n",
       " 'review_762': {'summary': 'The paper proposes a novel framework called CORE that bridges conversational agents and recommender systems via an uncertainty minimization principle. The framework treats a recommender system as an offline relevance score estimator and a conversational agent as an online relevance score checker. The conversational agent can query either items or attributes (or attribute values) to reduce the uncertainty of the user’s preference and find a target item. The paper shows that CORE can be applied to various recommendation platforms and datasets, and can outperform existing reinforcement learning-based or statistical methods in both hot-start and cold-start settings. The paper also demonstrates how to empower the conversational agent with a pre-trained language model to communicate more naturally with the user. ',\n",
       "  'strengths': '1.\\tThe paper presents a comprehensive study of the core task of conversational recommendation by considering the complex situations that arise in conversational contexts.\\n2.\\tThe authors conduct an extensive experimental analysis and exploration.\\n3.\\tThe proposed method achieves lower complexity and latency compared to existing state-of-the-art approaches.\\n',\n",
       "  'weaknesses': '1.\\tThe innovations and core contributions of the paper are questionable. Most conversational recommendation papers consist of offline and online components, but CORE does not appear to have any notable novel features despite considering more complex interaction settings. The improvements in these scenarios do not seem to be sufficient to warrant acceptance of this paper.\\n2.\\tThe formatting and organization of the paper could be improved to facilitate readability, with inconsistencies in notation and an excessive number of annotations. The description in Section 3 is too verbose, with the core method not being highlighted adequately. A concise explanation of Algorithm 1 would suffice to clarify the scenario.\\n3.\\tThe core of CORE still relies on an offline recommendation system, and even the online decision making depends on scores from the offline recommendation system. The key challenge of conversational recommendation is determining how to make dynamic decisions based on user interests and conversation context. Existing reinforcement learning-based methods evidently consider more factors, whereas the proposed heuristic method in this paper depends on recommendation scores that themselves have uncertainty in dynamic interactions. The methodological foundations of CORE appear weak and unconvincing.\\n'},\n",
       " 'review_763': {'summary': 'This paper proposes a method that combines offline recommendation learning with online decision tree learning to enable recommendation in a conversational format with a few rounds of interaction. The proposed approach is evaluated on multiple datasets and in various validation settings to assess its effectiveness.',\n",
       "  'strengths': 'This paper proposes a novel framework called CORE for uncertainty reduction. CORE improves the performance of recommender systems by revealing user preferences through querying attributes and attribute values.\\n\\nThe paper evaluates the performance of CORE using multiple datasets and different recommendation methods. The experimental results demonstrate that CORE improves the success rate of recommendations.',\n",
       "  'weaknesses': \"(1) This paper heavily relies on decision trees, and there is a significant design cost involved in creating those decision trees. Decision trees are domain-specific and lack clear design guidelines, and the paper does not discuss this aspect or provide any discussion on it in relation to each experimental dataset. Therefore, the weakness lies in the inability to evaluate this aspect.\\n\\n\\n(2) The reliance on metadata such as price, location, and hotel rank in decision trees makes the approach simplistic. In conversational recommender systems, it is important to consider finer item characteristics that can be obtained from diverse evaluations in user reviews while engaging in conversational interactions with AI. Furthermore, in conversational recommender systems, it is crucial to incorporate language models (LM) to capture linguistic variations and users' intuitive expressions in order to reflect them in the recommendations. However, this aspect is not well addressed in the paper (though it states a little in Section 4).\\n\\n\\n(3) The evaluation setup of this paper raises some concerns. While the main evaluation metric is the number of turns, the criteria used to determine correctness seem to be based solely on whether an item was checked or not. In the case of hotels, for example, it is important to consider whether a reservation was actually made, and relying solely on item checking may lead to an inflated number of correct predictions.\\nAnd, while evaluations are performed on different datasets, there is a lack of detailed explanations about the specifics of the conversations and the actual recommendations made in each dataset. Without this information, it becomes difficult to fully understand the effectiveness and characteristics of the proposed method.\\nFurthermore, the experimental results of this paper do not include comparisons with other methods or existing approaches. It is important to compare the proposed method with other recommendation techniques in order to clearly demonstrate its advantages and improvements.\\nMoreover, it appears that there is a lack of qualitative evaluation. While the paper utilizes multiple experimental datasets for validation, it is difficult to grasp the nature of the interactions and how satisfactory item recommendations are achieved in each dataset. Given that the conversation is a crucial aspect, the absence of information on the nature of the conversations makes it challenging to form a clear picture of the system's performance.\"},\n",
       " 'review_764': {'summary': 'This paper targets learning turbulence closure models for RANS simulations via neural networks. The paper proposes to use a neural SDE on the latent space of a transformer to predict different samples from the distribution of the next state, and then compute an average over these. This process is unrolled and trained for a sequence of multiple steps.',\n",
       "  'strengths': \"Overall, this is a good idea, and I'm not aware of a an NSDE being previously used in this form. Thus, I see the general direction of the paper and the promising approach as strong points.\",\n",
       "  'weaknesses': 'On the other hand, the paper targets a single, two dimensional Kolmogorov flow secnario as the only test case. In addition, only a single deterministic NN is compared to (plus an implicit LES solver). For this single data set, the paper is lacking a stable evaluation: multiple, differentily initialized models evaluated across multiple tests to obtain a stable result are not evaluated. In addition, NeurIPS is a very broad ML venue. Turbulence is definitively an exciting topic here, but even more important would be a broader evaluation, ideally with substantially different secnarios to show that the method has merit beyond turbulence. In its current form, I don\\'t think that the results are sufficient for a NeurIPS paper.\\n\\nI see two ways to improve this aspect of the submission: either the authors focus their writing on the turbulence secnario (cf. below), and present multiple scenarios in this context, or non-turbulence cases are included to broaden the scope. A more stable evaluation with multiple models and tests should be included either way. This potentially also could help to show the benefits of the method more clearly. Right now the gains in terms of accuracy and the differences in the TKE spectrum seem to be mild. Additional cases could show areas where the approach gives larger improvements.\\n\\nIn addition, I would also recommend that the authors include additional learned baselines. This is less crucial, but would nonetheless help to put the work into the context of previous methods at NeurIPS, ICLR & co.\\n\\nI also do want to mention two weak points in the writing. One is that I found the motivation (esp. L44) quite unintuitive: the \"inductive bias of the LES field\" is not very clear, and the summary implies this is \"simply\" a matter of choosing the right architecture. Things get clearer afterwards, but reading the paper front to back, I think this summarizing question is not helping a reader.\\n\\nThe conclusions are also not a good fit with the rest of the paper: suddently, a transition is is made to generic chaotic systems. The whole previous paper targets a single specific scenario in the form of Kolmogorov turbulence, and presents a single set of results. Hence, this outlook is not supported by the content of the paper. I can understand that the authors have hopes that their method will at some point in the future generalize to other cases, but it should be made clear that this is an outlook. Rather, references to specific works where the authors see potential would be interesting to give here.\\n\\nOverall, I want to encourage the authors to continue their direction of work. Nonetheless, I find it difficult to directly argue for accepting this paper in its current form.'},\n",
       " 'review_765': {'summary': 'This submission proposed a data-driven method to learn a.closure model to simulate the results from DNS. The key part is a latent stochastic process by Neural SDE. And finally compute the Monte-Carlo approximation.',\n",
       "  'strengths': '1. The model treats the DNS as a stochastic process, instead of a deterministic process as in many previous works.\\n\\n2. Empirical results indicate it performs well on Kolmogorov flow.',\n",
       "  'weaknesses': '1. The number of datasets is small.\\n2. It lacks recent deep learning-based methods as baselines.'},\n",
       " 'review_766': {'summary': 'This paper introduces a data-driven method for approximating the closure term in Large Eddy Simulation (LES). The closure term represents the unresolved scaling effect caused by reducing the computational grid through downsampling. In comparison to the traditional physically-informed approach, the learned closure term has the ability to automatically capture relevant features without the need for specific domain expertise or manual design. The model improves temporal resolution by employing latent space evolution with stochastic propagation. The proposed model demonstrates competitive performance compared to the Filtered DNS reference across different wave numbers, and significantly outperforms the baseline model.',\n",
       "  'strengths': '- The proposed method outperforms several baselines in terms of the squared error and the accuracy of turbulent kinetic energy spectrum.\\n- The latent space evolution implements the procedure to solve the SDE equation, which introduces the domain specific inductive bias into the model.',\n",
       "  'weaknesses': \"- The model's training solely relies on a single reconstruction loss, which is atypical for stochastic latent variables. The absence of prior regularization with respect to latent space implies that the stochastic component added at each temporal step acts more like a sparsity regularization, as the model is trained to minimize the stochastic effect rather than explicitly capturing the physical dynamics. Apart from prediction accuracy, there is a lack of additional benchmarks to demonstrate the advantages of the stochasticity, such as prediction diversity.\\n\\n- When comparing the proposed niLES with deterministic Neural Network-based models, it should be noted that niLES introduces additional parameters $h_{\\\\phi}$ and $g_{\\\\theta}$ as well as more computational routes, potentially leading to an unfair comparison. The authors should showcase the model's performance while varying the magnitude of the Wiener process in Equation 15 and compare it to the scenario where the noise magnitude is zero.\\n\\n- The current evaluation protocol does not adequately assess the scalability of the model, particularly with respect to wave numbers. To address this limitation, the authors should exclude a certain range of wave numbers as test cases, enabling a more comprehensive evaluation of the model's scalability.\"},\n",
       " 'review_767': {'summary': 'The authors introduce a neural SDE model for LES flow fields. The model structure is motivated by the ideal LES approach and the model learns a data-driven closure term. The learned latent representation captures the variability and fine-scale structure of the fully-resolved DNS solution that is lost by the LES filter.',\n",
       "  'strengths': 'The paper is excellently motivated, presented and embedded into the theory. Stochastic modeling for turbulence as presented in this paper is an important direction to explore and therefore the paper would be valuable contribution to the field.',\n",
       "  'weaknesses': '1. The authors seem to use the term \"closure model\" more loosely than usual in the introduction. Out of the citations for data-driven closure models in line 39, only [45] defines a closure model as the term is used in the context of RANS and LES.\\n1. Lines 177-182 are slightly misleading as they can be understood to suggest that the model would learn possible DNS realizations as $Z_t$ instead of an opaque latent representation. (Actually, lines 211-213 clarify this but could be moved forward/merged into the first paragraph)\\n1. A figure showing the flow (and predictions) after, for example, 200, 400, etc. steps would help the reader appreciate how chaotic the flow is and how much the velocity field evolves over 800 steps.\\n1. A figure comparing the DNS and filtered data would also be helpful for the reader to understand the effect of LES filtering better.'},\n",
       " 'review_768': {'summary': 'The paper investigated effects of weight decay in the scenario of federated learning, especially for the stage of local updates. It was found that even subtle changes of weight decay values might lead to drastic performance drop and the observations motivated the authors to conduct convergence analysis considering the factor of weight decay. The proposed method, FedNAR, was supported by both theoretical analysis and empirical results, and demonstrated advantages when incorporated into various FL backbone algorithms.',\n",
       "  'strengths': '- The paper is clearly written and well organized. In addition, the idea was motivated and inspired by an empirical study of weight decay in Section 3, which made the paper more sound.\\n- The authors investigated the influence of changes in weight decay of local updates, which was overlooked previously and found that the model performance was sensitive to the selection of weight decay values.\\n- A theoretical analysis of convergence with weight decay was presented in the paper, and supported the proposed FedNAR method',\n",
       "  'weaknesses': \"- It seemed that FedNAR worked well on most of federated learning backbone algorithms except for some adaptive methods such as FedAvgM and FedAdam. The accuracy was even worse after applying FedNAR to these methods. Can the authors expand on this phenomenon and provide some insights? Do adaptive methods themselves have the ability to adjust update trajectories so that adaptive weight decay might not work as expected?\\n- Experiments were still at a small scale and can be further improved. Currently the authors only chose one dataset CIFAR10 for image classification and one dataset Shakespeare for next-character prediction, which was not sufficiently. More large scale datasets such as ImageNet and practical ones with more realistic splits like CelebA (as suggested in the LEAF benchmark), or Apple's FLAIR dataset. Besides, details of the model architecture for each task were not clear. The selection of model structures might also affect the final performance and should be analyzed as well.\"},\n",
       " 'review_769': {'summary': 'This paper first describes an important and challenge problem in Federated Learning, that the performance of FL is very sensitive to the choice of weight decay hyper-parameter for local optimization. The authors produced data to demonstrated the sensitivity of the weight decay hyper-parameter.\\n\\nThis paper first outlined a general analysis framework for any client-side learning rate and weight-decay adjustment scheme, then proposed a adaptive weight decay scheme which adjust the hyper-parameter inversely proportional to the magnitude of the sum of the local gradient and the decayed-parameters. The authors provided analysis and performance guarantees for their proposed adaptive decay method. The authors conducted experiments to demonstrate the applicability of their method as a \"plug-in\" for different types of FL methods.',\n",
       "  'strengths': '1. hyper-parameter sensitivity is often a over-looked issue in FL. Existing methods addressed this problem by a hyper-parameter optimization problem, which is costly. This methods directly make the weight decay parameter and adaptive, eliminate the need for search.\\n\\n2. The authors have shown the robustness of their method as a plug-in on various FL methods, and the robustness to the initialization of the decay value, which is critical to make it actually useful.',\n",
       "  'weaknesses': 'In the experiments, the authors ran 5 local epochs for each algorithm. When the FL training process starts from random initialization, often single local epoch produces the best results because it limits the client drift away from the server model. I would like to see how does the proposed method perform under single local epoch.  '},\n",
       " 'review_770': {'summary': \"The study discusses the role of weight decay in enhancing generalization performance in deep neural network optimization and in avoiding overfitting in Federated Learning (FL). The authors highlight the influence of weight decay value on FL algorithms' convergence. To mitigate this issue, Federated optimization with Normalized Annealing Regularization (FedNAR), is introduced, which modulates each update's magnitude through co-clipping of the gradient and weight decay. The algorithm shows improved accuracy in experiments on diverse vision and language datasets with various federated optimization algorithms. \",\n",
       "  'strengths': \"- The motivation of the paper and the corresponding solution is straight-forward.\\n- The article is clearly articulated and readily understandable.\\n- This paper theoretically analyzes the impact of local training's weight decay on the convergence of federated learning.\\n- Experiments on both image and text datasets validate the effectiveness of the proposed method.\",\n",
       "  'weaknesses': '- To further validate the effectiveness of the proposed method, it would be beneficial to conduct experiments on more challenging datasets such as CIFAR100 and Tiny-ImageNet. Additionally, tests on more realistic benchmarks, like LEAF, that encompass feature disparity or imbalanced data, would provide even stronger evidence of its efficacy.\\n\\n- From the results in Figure 4, it is not clear whether the proposed method is more stable for the choice of the initial value of weight decay. \\nIn a similar vein, an ablation study on the choice of the threshold of co-clipping is required.'},\n",
       " 'review_771': {'summary': 'This paper delves into the effect of weight decay in the realm of federated optimization. The authors conduct a series of experiments highlighting how specific elements in federated learning, such as the presence of diverse data and the execution of local updates, can amplify the influence of weight decay. The paper further provides a theoretical exploration of weight decay within federated learning and introduces a novel methodology named FedNAR, which is derived from their analysis. The newly proposed FedNAR method showcases enhanced convergence speed and performance on various simulated federated tasks, and notably, it displays a heightened tolerance to complications introduced by weight decay.',\n",
       "  'strengths': '1. The writing and presentation are generally of high quality, making the idea and method of this paper easy to follow.\\n2. The research includes sufficient empirical findings. Six different federated learning algorithms, encompassing various variants of FedAvg, are examined to investigate the impact of weight decay. Weight decay is explored across a wide range, providing clear insights into their findings.\\n3. The proposed algorithm, FedNAR, is well-motivated by empirical findings and appears to be a simple yet effective enhancement. It can be readily adapted to different federated learning backbone algorithms.\\n4. The study offers comprehensive and rigorous theoretical analysis of weight decay in federated learning. The results are novel, crucial, and hold the potential to catalyze further investigations within the federated learning community.\\n5. Moreover, the paper’s experimental design is comprehensive, encompassing a broad spectrum of scenarios that integrate both vision and language datasets along with a variety of hyperparameter configurations.',\n",
       "  'weaknesses': '1. The bound is similar to previous works, without providing any superior bounds. This may not be a significant issue, since incorporating weight decay itself makes theoretical analysis harder and can lead to convergence challenges.\\n2. Though this is not my major concern, it would definitely make the paper stronger to try experiments at larger scales, e.g., GPT fine-tuning on various downstream tasks.'},\n",
       " 'review_772': {'summary': 'This work proposes to generate 3D adversarial examples for attacking 3D object detectors in driving scenarios using NeRF. In particular, it integrates a series of techniques, including primitive-aware sampling and semantic-guided regularization, to ensure the physical realism and realizability of the generated adversarial examples. Extensive experiments have validated the effectiveness of the proposed method in reducing detection performance and serving as data augmentation.',\n",
       "  'strengths': '1. As an early attempt of generating 3D adversarial examples using NeRF, this work could offer a new perspective for the community in understanding and tackling real-world 3D adversarial attacks. \\n\\n2. The extensive experiments validate the superiority of NeRF as a 3D adversarial attack generator. In particular, it is interesting to see that the generated adversarial examples can serve as a data augmentation to improve clean performance, which aligns with the previous observations in classification.',\n",
       "  'weaknesses': '1. My major concern is the assumed attacking setting of this work, i.e., how to leverage the proposed method in real-world driving scenarios. If only a static adversarial example is attached to the scene, generating other static objects on the road may be more practical than generating a vehicle; Otherwise, the authors are expected to show a video under an egocentric view to demonstrate the attack effectiveness, i.e., whether the dynamically moving adversarial vehicles can consistently mislead the 3D detectors from different view directions.\\n\\n2. The claim \"the first exploration of modeling adversarial examples as Neural Radiance Fields (NeRFs)\" in the abstract may not be accurate. ViewFool [1] also models adversarial examples using NeRF although only the view direction is adversarially optimized. It will be more accurate if the authors highlight this work as the first 3D adversarial example generator using NeRF.\\n\\n3. Missing references regarding the early attempts of marrying NeRF and adversarial attacks (which are mostly orthogonal with this work):\\n\\n[1] \"ViewFool: Evaluating the Robustness of Visual Recognition to Adversarial Viewpoints\", Y. Dong et al., NeurIPS\\'22.\\n\\n[2] \"NeRFool: Uncovering the Vulnerability of Generalizable Neural Radiance Fields against Adversarial Perturbations\", Y. Fu et al., ICML\\'23.\\n\\n[3] \"Aug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations\", T. Chen et al., CVPR\\'22.\\n\\n4. Minor issue: There exists some inconsistency in terms of tense and punctuation, which could be improved in the final version.'},\n",
       " 'review_773': {'summary': 'The authors proposed new generative adversarial examples in the form of NeRFs, in the context of driving scenarios. The training objective is minimizing the 3D detection confidence from a variety of views. The parameters to optimize are the latent input to the NeRF, that encodes shape and texture info. Rendering is naturally differentiable due to the usage of NeRF. To improve the physical realizability, they propose three methods: primitive-aware sampling, NeRF disentanglement, and semantic-guided regularization. The authors conducted experiments on the widely used nuScenes dataset to evaluate the performance drop. The results show that their method is able to reduce the detection performance of various detectors, whether they are FOV-based detectors or birdview-based ones. They also evaluated the transferability of their method, and the adversarial training defense method.',\n",
       "  'strengths': 'Using NeRF as 3D adversarial example representation seems novel and interesting. The NeRF representation naturally is differentiable in terms of rendering, so it makes the adversarial attack problem easier. Also, with more uses of NeRF in 3D vision, it is important to explore the vulnerability in NeRF itself. Such adversarial attacks may highlight the potential security issues in NeRF.\\n\\nThe attacking framework (expectation over transformation), the NeRF rendering framework they use (Lift3D) are standard. The method is mostly built upon existing works; it seems not hard to implement their method.\\n\\nThe writing is clear.',\n",
       "  'weaknesses': 'My major concern is that whether the formulation of NeRF is necessarily, from the motivation perspective. In line 175, they fixed the shape and only optimized the texture latent code. The optimization is essentially finding the color, density of the volume. However, I believe most vehicle objectives are not translucent; the optimized 3D object is very hard to realize. This is evident as authors need to improve the physical realizability (line 180).\\n\\nThis leads to the Occam\\'s razor principle: do we really need NeRFs to reach the effectiveness/realizability of the 3D attack? So we are missing a baseline here: optimizing the surface texture as a 3D mesh, using existing differentiable mesh renderers (such as Neural Mesh Renderer). The latter is easier to optimize (2D texture space), and more physically realizable (because it is a texture map rather than a volume). In line 166, the authors said \"enables patch attacks in a 3D-aware manner by lifting the 2D patch to a 3D box\", so we really need a baseline to showcase such lifting is necessary. Also it is not clear how rendering the NeRF into 3D scenes is done. In Fig. 3, the lighting of the NeRF object is not consistent with the environment, and we can see typical blurriness of NeRF.\\n\\nAnother weakness is that the setting is not sophisticated enough to be \"Driving Scenarios\". At first glance, it looks like attacking self-driving algorithms, but the point clouds are not used (correct me if I am wrong). The detection methods (FCOS3D, PGD-Det etc) are based on monocular/multi-view 2D images instead of multi-sensor. In Fig. 3, the inserted adversarial example does not seem to block the LiDAR rays. The experiment is not done through a full driving simulation software, but by rendering 3D objects into existing 3D data. Whether such mixed environment can represent the real-world driving scenario is not clear. It\\'ll be better to claim general 3D detection scenario and do more experiments with other objects, instead of only claiming driving-specific scenarios.\\n\\nIn general, my decision largely depends on the first point: the NeRF representation may not be necessary under the current settings. Optimizing the texture image should just work; such volume formulation will make it harder to physically realize and does not bring much benefit other than differentiable rendering.'},\n",
       " 'review_774': {'summary': 'Deep neural networks (DNNs) have shown susceptibility to adversarial examples, which raises significant safety concerns, particularly in safety-critical applications like DNN-based autonomous driving systems and 3D object detection. While there is a wealth of research on image-level attacks, most of them focus on the 2D pixel space, which may not always translate into physically realistic attacks in our 3D world. In this paper, the authors present Adv3D, the first exploration of modeling adversarial examples as Neural Radiance Fields (NeRFs).\\n\\nThe utilization of NeRFs allows for the generation of adversarial examples that possess photorealistic appearances and accurate 3D generation, thereby enabling more realistic and realizable adversarial attacks in the 3D domain. The authors train their adversarial NeRF by minimizing the confidence of surrounding objects predicted by 3D detectors on the training set. They evaluate Adv3D on an unseen validation set and demonstrate its ability to significantly degrade performance when rendering the NeRF in various sampled poses.\\n\\nTo ensure the practicality of the adversarial examples, the authors propose primitive-aware sampling and semantic-guided regularization techniques, which facilitate 3D patch attacks with camouflage adversarial textures. The experimental results showcase the generalizability of the trained adversarial NeRF across different poses, scenes, and 3D detectors. Additionally, the authors provide a defense mechanism against these attacks through adversarial training via data augmentation.\\n\\nIn summary, the authors introduce Adv3D as a novel approach that models adversarial examples using NeRFs, resulting in more realistic and realizable attacks in the 3D domain. They demonstrate the effectiveness of their method through extensive evaluations and propose a defense strategy to mitigate the impact of these attacks.',\n",
       "  'strengths': '1. The writing and presentation of this paper are good and clear.\\n2. The idea of leveraging NeRF in generating adversarial examples is interesting\\n3. The authors conducted sufficient evaluation of the proposed method',\n",
       "  'weaknesses': '1. The practicality of the proposed attack is questionable\\n2. There is a lack of real-world experiments\\n3. The study seems to lack technical insights as the adversarial attacks are well established. There is no surprise that using some fancy new idea can lead to adversarial examples, but the essence is the same.'},\n",
       " 'review_775': {'summary': 'This work develops adversarial attacks against 3D object detectors by utilizing instance-level NeRFs.  \\nThey start with a representation of a vehicle, parameterized by a NeRF that predicts both geometry and texture and render the vehicle into a image, which they compose into the original image by copy-pasting. They use the composited image to adversarially attack 3D object detectors, which provides a gradient signal used to optimize the NeRF (texture only).  \\nExperiments show their adversarial examples are effective against a variety of different 3D object detectors, and they show that training on these samples improves robustness (and even overall performance).',\n",
       "  'strengths': '* Novel application of NeRFs, utilizing the fully differentiability to optimize for adversarial texture.\\n* Work is well written and overall clear to follow.  \\n* Analysis provides good insights (referring to Sec 5.3 analysis of 3D detector architecture robustness and Sec 5.4 adversarial training actually boosts performance).\\n* Multiple architectures used in experiments.',\n",
       "  'weaknesses': '* Section 4.4 could use more elaboration - this is a key section for the overall work and in the current revision is quite vague.\\n* Some of the attacks (Fig. 3) do not look photorealistic - how can the reader be convinced these adverarial samples would actually work in the real world?'},\n",
       " 'review_776': {'summary': 'This work proposes a new attack on monocular 3D object detectors utilising NERF representation to create multi-view consistent attacks utilising Lift3D [26]. The authors show successful attacks on nuScenes dataset and the effect of their design choices on the attack success. Furthermore, a mitigating strategy is shown how to make monocular 3D object detection robust to these types of attacks.',\n",
       "  'strengths': 'This manuscript includes a comprehensive set of ablation studies and detailed analyses, which effectively highlight the influence of different components in the proposed pipeline. Figure 4 is especially illustrative and insightful. Notably, the successful tackling of numerous molecular 3D detectors, each with varying detection strategies, is commendable.\\n\\nThe authors present an effective strategy to counteract the proposed adversarial attacks on molecular detection systems. \\n\\nThe overall presentation of the paper is lucid and the figures contribute significantly to accurately conveying the intended ideas.',\n",
       "  'weaknesses': '1- A comparison against baselines is missing, most notably the mesh-based baseline [43]. This comparison is very important since the proposed setup in Lift3D [26] is very similar when constraining the Nerf to shape and texture latents , resembling the mesh generation and texturing scheme in [43]. \\n\\n2- A crucial evaluation protocol has been overlooked. In the context of adversarial attacks, the imperceptibility of the attack is a significant factor; how discernible is the attack in contrast to the clean sample? This critical information is absent in this work. It leaves us questioning the perceptibility of image corruption in terms of pixel alteration. If the corruption is so pronounced that even a human observer fails to detect the cars, can it still be considered a successful attack? Previous studies typically provide this information [43]. Moreover, the inclusion of tests on KITTI should be considered vital to the evaluation process.'},\n",
       " 'review_777': {'summary': 'The paper proposes a transformer-based day-ahead forecasting model for solar irradiance at a ground station.\\nThe model ingests previous irradiances and contextual (image-sequence) information with a temporal and vision transformer.\\nA cross-former merges the tokens, and a temporal transformer decoder estimates irradiances in a 24-hour window.\\n\\nAn optional multi-quantile output head also allows the model to estimate uncertainty by forecasting quantiles. \\nThis multi-quantile loss produces predictions with slightly lower accuracy, which may be justifiable at the benefit of uncertainty quantification.\\n\\nFurther considerations involve rotary positional encodings for the context image information, which is motivated by the images centered on the measurement station.\\n\\nOverall, the paper presents a combination of state-of-the-art methods (ViVIT, transformers) with problem-specific ideas (ROPE, Quantile regression) crafted towards a suitable application (irradiance forecasting).',\n",
       "  'strengths': '* important application (irradiance forecast) addressed with state-of-the-art machine learning (temporal + vision) and architecture crafted towards the forecasting application.\\n* uncertainty quantification with a loss function inspired by quantile regression (Koenker & Hallock, 2001)\\n* separate evaluation in easy and hard cases. Comparison to reasonable comparison methods and baselines\\n* evaluations between different stations to test out-of-domain generalization',\n",
       "  'weaknesses': '* some design decisions are not justified or unclear (see questions: learned positional encoding). \\n* fast/sloppy preparation of some parts manuscript:\\n  * errors/typos in domain-specific equations: GHI = DNI + DHI x cos(z) <- I believe the x cos(z) should be with the DNI (direct normal irradiance) and not the DHI to account for the sun angle.\\n  * equation 7: shouldnt it be \\\\hat{y}_\\\\alpha, as there is a prediction \\\\hat{y} for each quantile \\\\alpha?\\n  * style and references are not consistent and some are not retrievable (ArXiv.org vs ArXiv, abs/2010.08895. Or “Rothfuss, H. (2015); Data access at eumetsat.” has no meaning and can not be retrieved); is “348 [BSRN] BSRN. Baseline surface radiation network.” from A Driemel · 2018 <- Cited by 249,  Baseline Surface Radiation Network (BSRN) ?'},\n",
       " 'review_778': {'summary': 'This submission presents a multimodal model for next-day solar irradiance prediction. They use time series of past irradiance and satellite image to predict irradiance 24h in advance. The model consists of one transformer branch for each modality and a shared (cross-modal) transformer. Their method can be used to predict uncertainty as well. They display improvements over the SOTA. Finally, they released  in open access a dataset acquired with 6 stations across 15 years.',\n",
       "  'strengths': '- The problem is interesting, difficult, useful, and not a lot of work has been done with machine learning on the subject\\n\\n- The model architecture is reasonable\\n\\n- the authors compare their method to many baselines and competing methods\\n\\n- The authors provide a large-scale (at least temporally) dataset in open access',\n",
       "  'weaknesses': '- Some details are missing, making it hard to understand how the method works precisely.\\n\\n- The uncertainty prediction with quantile lacks a proper evaluation, related work, and comparison baselines.'},\n",
       " 'review_779': {'summary': 'The work presents a method to integrate information about cloud (using satellite images) with timeseries data related to Solar Irradiance to improve the solar irradiance forecasting.',\n",
       "  'strengths': 'Here some interesting aspects of the paper:\\n- the release of a new dataset containing both timeseries and satellite images for many years for several sites. \\n- an attempt to build a multimodal architecture based on transformer.\\n- usually the subdivision between sunny days and cloudy days is done in the forecasting works related to solar irradiance (e.g. pv production). Authors have proposed to subdivide the days in \"hard\" and \"easy\" based on the similarity between two consecutives days. I think this approach is interesting and help the fair assessment of the model.',\n",
       "  'weaknesses': 'The main weakness I see is that day-ahead use case is not explicitely evaluated.\\nI know that the sliding window is more general but an important real word use case is to have a real day-ahead prediction. \\nAuthors could test their algorithm on day-ahead use case (extracting properly the sliding windows of interest, i.e. from 0:00 to 23:00).\\n\\nMoreover, some details on the real input of the model seem missing.'},\n",
       " 'review_780': {'summary': \"The work presents a multi-modal model, called CrossViViT, to perform day-ahead solar global horizontal irradiance predictions. In that, the model combines spatial information from satellites, i.e. RGB, IR and vapor channels, across Europe with time series information from six point-like stations, i.e. clear sky, pressure, direct normal irradiance, diffuse horizontal irradiance as well as a derived proxy global horizontal irradiance based on the Ineichen model. CrossViViT's performance has been compared again various other statistical and numerical models (Persistence and FFT) as well as other state-of-the-art deep learning approaches based on the transformer building blocks. The performance, measured in RMSE or MAE, \",\n",
       "  'strengths': \"- Application case from natural sciences incl. challenging real-world problems of multi-modality and missing data\\n- Distinction between 'easy' and 'hard' prediction cases; this is commonly overlooked\\n- Open discussion of strength and limitations of CrossViViT in contrast to other method, in particular:\\n    * Showcasing that it does not win across the board\\n    * Improving the interesting 'hard' cases for domain applications\",\n",
       "  'weaknesses': '- The reviewer thinks that the evaluation in the manuscript could generally be improved with findings from other papers as follows:\\n    * Normalize that forecasting values into a stated range (e.g. [0-1]) or state the value ranges otherwise an RMSE/MAE improvement by certain value cannot be put into a frame of reference\\n    * Alternatively, consider reporting MAPE, mean average percentage, improvements instead that already includes that maximum range\\n    * By extension the plots in Fig. 4 can be considered somewhat misleading as they do not show the minimum value 0 or give a magnitude of improvement\\n- The authors dismiss the use of fourier-layers, e.g. AFNO, without clear substantiation\\n- Since cross-attention is such an integral part for mixing tokens from the spatial and temporal domains, it would be meaningful to show the equation in your manuscript beyond the reference\\n- It would be meaningful to extend the discussion of the findings towards the domain and/or real-world. What does it mean that you can achieve\\n- Non-adherence to the conference paper template, fonts in tables are too small, figures are outside of the text margins\\n- Color palette is difficult to read for color-blind people (red-green)\\n- The study is not reproducible as there is no code given; there is no indication that it will be released in case of acceptance\\n- Might be good to show the rough location, possibly with an arrow, for the TAM station on the map in Fig. 2\\n- To the reviewer\\'s personal taste: change the title from a question to a typical title like \"Solar Irradiance Time Series Forecasting with Spatio-Temporal Context\"'},\n",
       " 'review_781': {'summary': 'This work considers finite-sum (distributed) optimization problems in the strongly convex and second-order similar regime. The authors proposed SVRS and its acceleration, AccSVRS, to solve the problem and provided the corresponding communication and computation complexities, which outperform existing works in several perspectives. The authors further characterized the lower bound for solving such problems, which validates the near optimality of the proposed AccSVRS algorithm.',\n",
       "  'strengths': '1. The study is comprehensive in general, covering both upper and lower bounds\\n2. Proposed algorithm achieves near-optimal communication/computation complexity. \\n3. The design of the algorithm, which incorporates PPA, VR, gradient sliding and Katyusha, is interesting.\\n4. The paper is well-written, and the flow is clear.',\n",
       "  'weaknesses': '1. The design of the AccSVRS, as the core algorithm achieving near optimality, can be further elaborated. For now, I do not have a clear understanding on Steps 5 and 6 in AccSVRS. Some discussions similar to Section 3.1 connecting Katyusha X paper will be appreciated.\\n2. Some more questions below.'},\n",
       " 'review_782': {'summary': 'The paper considers distributed strongly convex optimization problems in the setting where the communication between nodes is bottleneck. The authors propose new methods, SVRS and AccSVRS, that guarantee new communication complexities. Also, they proved the lower bound that ensures the optimality of the AccSVRS method.',\n",
       "  'strengths': \"I think that the paper is strong. The authors provide new theoretical guarantees in the considered setting. They improve the previous methods. I haven't checked the proofs in detail and I can miss some essential parts, but the theory sounds to me. \",\n",
       "  'weaknesses': \"It is well known that the (Loopless-)Katyusha method converges after $n + \\\\sqrt{n \\\\frac{L}{\\\\mu}}$ iterations. By applying Katyusha to the authors' problem, we can get the communication complexity $n + \\\\sqrt{n \\\\frac{L}{\\\\mu}},$ since Katyusha requires only one gradient in each iteration. In the regime when $\\\\delta = L$ the Katyusha method has better communication complexity than $n + n^{3/4} \\\\sqrt{\\\\frac{L}{\\\\mu}}.$ Why doesn't it contradict the lower bound (Theorem G.7 and Theorem 4.4)? Does it mean that your method is only better in the regimes when $\\\\delta \\\\ll L$?\\n\\nMinor comments:\\n\\nThe paper's setup can be slightly confusing. Many other papers (e.g., \\\\[1,2\\\\]) assume that the nodes can do calculations and send vectors *in parallel,* meaning that they count each round as *one* communication, *one round = one communication*. In comparison, this paper assumes that *one round = $n$ communications* in the full participation regime. Can the authors write a small text *in the paper* explaining the difference between the setups? It seems that we have at least two different setups that both have the right to life.\\n\\nTypos:\\n\\nEq. (18): $\\\\nabla$ is missed.\\n\\n\\\\[1\\\\]: https://arxiv.org/abs/2202.09357\\n\\\\[2\\\\]: https://arxiv.org/abs/2304.04169\"},\n",
       " 'review_783': {'summary': 'The paper presents a novel algorithm for distributed optimization, named Accelerated Stochastic Variance-Reduced Sliding (ASVRS). The authors focus on the problem of minimizing the average of a large number of smooth and strongly convex functions, a common scenario in machine learning and data analysis. The proposed ASVRS algorithm combines the techniques of gradient-sliding and variance reduction, aiming to improve the convergence rate and reduce the communication cost in distributed settings.',\n",
       "  'strengths': \"The ASVRS algorithm is a novel contribution that combines gradient-sliding and variance reduction techniques in a unique way. This combination appears to be original and innovative. The authors provide detailed proofs for the convergence rate and communication complexity of the ASVRS algorithm, demonstrating its theoretical advantages over existing methods. I didn't check the details but the result seems reasonable. \\n\",\n",
       "  'weaknesses': \"The theoretical analysis relies on several assumptions, such as the strong convexity of the functions. This makes the application of the work rather limited.  It would be helpful to discuss the implications of these assumptions and how the algorithm's performance might be affected if they are not met.\"},\n",
       " 'review_784': {'summary': 'The authors consider distributed minimization problems under data similarity (hessian similarity). The authors consider stochastic methods that reduce communication complexity via device sampling. In particular, from the stochastic point of view, the variance reduction techniques: SVRG and Katyusha, are taken. The sliding (stochastic preconditioning/mirror descent with unusual Bregman divergence) technique is used for dealing with similarity. The authors obtain record results in communication complexity (the previous ones were beaten by the logarithmic factor). To complete the picture, the authors provide lower bounds that give the optimality of their upper bounds. Synthetic experiments are also given. ',\n",
       "  'strengths': '1) Direct acceleration (without envelops) is an interesting and important result. In theory it removes the extra logarithmic factor, and in practice it works better. \\n\\n2) The lower bounds complete the picture. \\n\\n',\n",
       "  'weaknesses': '1) I think the literature review is not complete. In particular I find two papers also about the hessian similarity, which also use the variance reduction technique and obtain such non-accelerated results as the authors have. A detailed comparison in approaches and results is needed. \\n\\nBeznosikov, A., & Gasnikov, A. (2023). Similarity, Compression and Local Steps: Three Pillars of Efficient Communications for Distributed Variational Inequalities. arXiv preprint arXiv:2302.07615.\\n\\nBeznosikov, A., & Gasnikov, A. (2022, September). Compression and data similarity: Combination of two techniques for communication-efficient solving of distributed variational inequalities. In International Conference on Optimization and Applications (pp. 151-162). Cham: Springer Nature Switzerland.\\n\\n2) The lower bounds are a good supplement to the upper bounds, but they are to be expected. The idea of getting them is also known. Unfortunately, here the authors  don not  also give a complete summary of the literature: the problem with a matrix A is classical (the authors note it), but the partition of the problem into columns is also classical - see the papers:\\n\\nZhang, M., Shu, Y., & He, K. (2020). Tight Lower Complexity Bounds for Strongly Convex Finite-Sum Optimization. arXiv preprint arXiv:2010.08766.\\n\\nHan, Y., Xie, G., & Zhang, Z. (2021). Lower complexity bounds of finite-sum optimization problems: The results and construction. arXiv preprint arXiv:2103.08280.\\n\\nKovalev, D., Beznosikov, A., Sadiev, A., Persiianov, M., Richtárik, P., & Gasnikov, A. (2022). Optimal algorithms for decentralized stochastic variational inequalities. Advances in Neural Information Processing Systems, 35, 31073-31088.\\n\\n3) Experiments for me are not the most important thing in this paper, which is primarily theoretical. But I would still like to see real datasets (3 for symmetry with synthetic data). I would also advise authors to change not \\\\mu, but to change \\\\delta in synthetic experiments, this way the effect of similarity will be noticeable. \\n\\nSummary: For me, this is a borderline paper. For now I put a (weak) rejection, but I hope the authors will take part in discussion and make the changes I asked for. \\n\\n'},\n",
       " 'review_785': {'summary': '**Summary** \\n\\nThe paper studies finite-sum minimization ($\\\\min_{x} f(x):= \\\\frac{1}{n} \\\\sum_{i= 1}^n f_i(x)$) in the distributed setting with a central node and $n-1$ non-central (client) nodes. The setup and the paper\\'s assumptions are as follows. \\n\\n1. Each function $f_i$ is held in the $i$-th client node, and the first node is designated the central node. The machines on the non-central nodes can communicate function values and gradients with each other as well as with the central node. \\n\\n2. The different $f_i$\\'s are assumed to be related to each other via the notion of \"second-order similarity\", which essentially means that the Hessians of $f_i$ and $f$ evaluated at the same point do not differ from each other by too much in the operator norm. A benefit of this assumption is that different clients do not need to all send their Hessian information. \\n\\n3. The $f_i$\\'s are all convex, $f$ is $\\\\mu$-strongly convex, and the $f_i$\\'s all satisfy $\\\\delta$-average-second-order-similarity as described in 2. \\n\\nThe paper\\'s results are three-fold: \\n\\n1. A non-accelerated algorithm called SVRS, which attains a communication cost of $\\\\widetilde{O}(n + \\\\sqrt{n} \\\\delta/\\\\mu)$. This result improves upon the previous best result of Khaled and Jin when $\\\\delta \\\\geq \\\\sqrt{n} \\\\mu$. \\n\\n2. An accelerated algorithm called AccSVRS, which attains a communication cost of $O((n+ n^{3/4} \\\\sqrt{\\\\delta/\\\\mu})\\\\log|\\\\epsilon|)$, which improves upon the previous best accelerated rate by Khaled and Jin by a factor of $\\\\log(L/\\\\mu)$. Therefore, this new rate is \"smoothness-free\". \\n\\n3. Lower bounds for 2. \\n\\nThe paper\\'s technique is based, broadly, on the use of Bregman-SVRG: instead of calculating exactly in each iteration, we calculate the approximate entities every time and periodically offset the error by exact calculations; additionally, through the use of a Bregman divergence term, the update rule ensures that the next iterate is not too far from the current one in some chosen distance metric. \\n\\n',\n",
       "  'strengths': '\\n**Strengths** \\nI think the paper scores highly on the story-telling aspect: it reads quite well! I also think the paper studies an important problem (faster communication complexity for distributed optimization). \\n',\n",
       "  'weaknesses': \"\\n\\nIn results: \\n\\n1. Line 64: The paper's result from SVRS beats that of SVRP by Khaled and Jin when $\\\\delta \\\\geq \\\\sqrt{n} \\\\mu$. As of now it's not clear to me what the scope of this assumption is: are there many cases where this inequality holds? It appears to me that Lines 124 and 198 allude to this but it's not entirely clear to me. Can the authors please elaborate?  \\n\\n2. Line 68 - 70: The paper's result with acceleration shaves a log factor from the previous best result as well as removes a component-wise strong convexity assumption from the previous best result. It would be nice to see some intuition for why the removal of log factor here is important and why the component-wise strong convexity is that much stronger than total strong convexity. \\n\\n\\nIn the writing: \\n\\n1. In lines 14 - 17, there are no references for these stated applications. It would be much more convincing to have citations for each of the stated applications. \\n\\n2. The problem parameter $\\\\mu$ should be introduced separately, rather than as part of the related work in lines 40 - 48, since it's an important parameter that comes up repeatedly. \\n\\n3. The inclusion of Lemma $3.1$ in the main body does not serve (in my opinion) much purpose because it's mathematically quite dense to parse Equation $(10)$. Theorem $3.2$ is ok since it clearly gives the claimed rate. Instead of Lemma $3.1$, I'd have preferred to have a proof sketch for Theorem $3.2$. \\n\\n\"},\n",
       " 'review_786': {'summary': 'The authors propose an online constrained meta-learning algorithm that is able to sequentially learn a  sequence of tasks that are subject to hard (and stochastic) constraints. The authors also theoretically quantify the optimality gaps and constraint violations produced by the proposed method, by considering the dynamic regret of online learning and the generalization ability of the task-specific models. They also validate the effectiveness of the proposed method on numerical experiments on meta-imitation learning and few-shot image classification.',\n",
       "  'strengths': 'The authors validate their proposed method, both theoretically and experimentally.\\n\\nThe authors present a new meta-learning method aiming at facing the more challenging situation in which the tasks are stochastically subject to constraints.',\n",
       "  'weaknesses': 'The statements and the notation of the paper could be simplified and made more intuitive, less heavy.\\n\\nWhy can the constrained meta-learning framework be interesting in practical application? The authors do not well motivate the setting they consider. This is a very important aspect in my opinion. Could you please describe some examples of possible applications in which the proposed constrained setting can be useful/necessary?\\n\\n'},\n",
       " 'review_787': {'summary': 'The paper studies the theory of biased-regularization meta-learning under the sequential task setting. Despite there having been previous works in this area, this paper distinguishes itself by introducing the concept of the Online Constrained Meta-Learning problem and presenting a straightforward solution. It applies constrained optimization with biased meta-regularization, utilizing Follow-the-Perturbed-Leader (FTPL) FTPL to handle the non-convex meta-objective function, providing theoretical analysis and proofs of upper bounds, and developing a practical algorithm for large-scale problems. Empirical experiments validate the effectiveness of the proposed algorithm in meta-imitation and meta-reinforcement learning.',\n",
       "  'strengths': '- This paper first studies the online constrained meta-learning, which is rarely concerned. To this end, this paper gave the formal problem formulation of constrained sequential learning. \\n\\n- The author distinguishes the assumptions proposed by this paper and follows others. It makes it easier to examine the assumptions applied in this paper.\\n\\n- A solid work that follows the setting of learning with biased regularization. The author gives a detailed discussion of different cases.',\n",
       "  'weaknesses': '- Of a particular relevant missing work, [1] can also be deemed as the constrained (conditional) meta-learning. The author should further discuss this work since [1] also shows the generalization results. \\n\\n- More implications are needed to explain the results, i.e., Corollary 1. \\n\\n- The bounds of the derived results have not been examined. For instance, the second term in RHS of Prop 3 is the order of $\\\\mathcal{O}(d^2\\\\mathcal{B} L_0^2 \\\\ln |\\\\mathcal{D}^{tr}_0|)$, which can be a dominate term.  Furthermore, the diameter $\\\\mathcal{B}$ and model size $d$ can also be large enough. This result may not be applied to overparameterized settings.\\n\\n- The relationship between $\\\\mathcal{D}_t$ and $\\\\mathcal{D}$ is vague. Suppose $\\\\mathcal{D}$ refers to any $t$ in $\\\\mathcal{D}_t$. The statement of Propositions and Theorems should clarify this point.\\n\\n- From the Proofreading of Appendix 4, I found the bounds in Proposition 3 & 4 depend on many terms. However, in Prop.1 & 2, the author removes the small terms (in Big-O notation) without discussing the orders of these terms in what limits. \\n\\n——Minors——\\n- Confusing statement about “Problem (1), (3)”. Since the author refers to Equations (1) and (3) as “Algorithms” and “Problems” simultaneously, it may be better to define the “Problems” officially.\\n\\n- Adding a notation cheatsheet in the appendix may be more readable.'},\n",
       " 'review_788': {'summary': 'In this paper, a novel online constrained meta-learning framework is presented. The framework is designed to facilitate continuous learning from sequential tasks while ensuring that these tasks adhere to strict constraints. In addition to existing analyses of meta-learning, this study goes further by presenting the upper bounds for optimality gaps and constraint violations that arise from the proposed framework. \\nThis framework takes into account the dynamic regret of online learning and the generalization capability of the task-specific models. Finally, the paper offers a practical algorithm to implement the framework, and its superior effectiveness is validated through experiments conducted in the domains of meta-imitation learning and few-shot image classification.',\n",
       "  'strengths': '- This paper consider that the meta-objective is non-convex.\\n- Study the dynamic regrets.\\n- Two elaborate applications demostrate the superior effectiveness of the algorithm.',\n",
       "  'weaknesses': '- The bound is scaled with $\\\\mathcal{O}(\\\\frac{1}{\\\\sqrt{T}})$. This seems to ignore the size of every training datasets.\\n- The comparion with existing online meta learning bounds is necessary.'},\n",
       " 'review_789': {'summary': 'The paper studies the problem of online meta-learning with constraints. After a formalization of the problem, the paper proposes an algorithm in the case where the loss function is convex, using Follow-the-Perturbed-Leader (FTPL) to update the meta-objective.\\nThen the paper theoretically prove upper bounds on the regret and the violation of the constraints for their constrained learning setting.\\nFinally, the paper presents experimental results on two different applications, meta imitation learning with collision avoidance and robust few-shot image classification.  ',\n",
       "  'strengths': '###\\xa0Originality\\n\\n- The paper presents a detailed theoretical analysis in the constrained setting.\\n- The algorithm is a combination of iMAML [1] using FTPL instead of FTL for the online setting.\\n\\n### Quality\\n\\n- The paper presents and proves theoretical upper bounds in the constrained setting with their proposed algorithm, with a lot of theoretical developments in the appendix. It shows the soundness of their approach.\\n\\n### Clarity\\n\\n- The formalization of the problem is clear.\\n\\n### Significance\\n\\n- Results on the different benchmarks and applications presented show strong performance compared to baselines.\\n\\n[1]: Rajeswaran, A., Finn, C., Kakade, S. M., & Levine, S. (2019). Meta-learning with implicit gradients. Advances in neural information processing systems, 32.',\n",
       "  'weaknesses': '### Clarity\\n\\n- The relation of the proposed algorithm to previous work is quickly dismissed. The authors introduce online meta-learning algorithms in l.23-33, and in the related works section (l.88 - 98), the paper presents only optimization-based meta-learning algorithm. However, there is no discussion to clearly explain the differences with their proposed algorithm.\\n- The way the tasks are set up in the applications are not very well described. Specifically in the robust few-shot classification benchmarks, it is not clear how the benchmark is adapted for this *online* setting, since these datasets are more commonly used for few-shot meta-learning. \\n\\n\\n### Quality\\n\\n- If I understand correctly, the approach presented is a combination of iMAML with FTPL for the online setting and with the constraint penalty. Thus, it would make sense to add other meta-regularization algorithm baselines in the benchmarks, such as iMAML at least.\\n- In the robust few-shot classification application presented, the other baselines are not designed for *online* meta-learning. The comparison seems unfair.\\n- The authors state that their approach speeds up the adaptation to new tasks (l.357), but we can see in Figure 3 (right) that it is the opposite, their algorithm takes more time to adapt.\\n'},\n",
       " 'review_790': {'summary': 'In this paper, the authors explore the influence of locality and globality in graph-based spatiotemporal forecasting architectures. Existing spatiotemporal models are global trained on multiple multivariate timeseires, which can capture the strong dependency among individual nodes in a network. Standard local models such as RNNs learn each timeseries independently which lost the interaction information with other nodes, but are fitted solely on each individual trajectory resulting in good short-term prediction performance. \\n\\nDirectly combine the predictions from global and local models would result in a large number of model parameters (introduced by individual models). The authors instead propose to use a learnable embedding vector to represent the locality for each node and incorporate it in the GNN message passing procedure. The guide the learning process for such node embeddings, the authors further proposed two regularization terms to make the model more generalizable, with the assumption that the underlying dynamics of nodes within the same network topology would not differ too much.\\n\\nExperiment result over several benchmark datasets show the proposed method is able to make better prediction results than compared baselines.\\n\\n',\n",
       "  'strengths': '1. The writing for this paper is very easy to follow\\n2. The idea to inject local information into existing global spatiotemporal models is interesting.\\n3. The experiments are comprehensive, though some baselines are missing.',\n",
       "  'weaknesses': '1. My major concern is the contribution/novelty of this paper. The authors propose to learn a node embedding to mimic the role of local models such as RNN trained on each individual timeseries. First of all, the node embeddings are static, whereas the output of RNN models are dynamic. Those local features for each individual node can changes over time which can be well-captured by any local models. Secondly, the learnable node embeddings seem to me are similar to those exogenous factors specific to each node, how to guarantee the learned embeddings would not serve as the same role as those exogenous factors? Finally, learning these embeddings would make the whole model not able to perform inductive tasks. When a new node/timeseries comes in, one needs to retrain the model instead of directly use the model to do the inference, opposed to existing spatiotemporal GNNs.\\n\\n2. Also there are some missing baselines in terms of spatiotemporal GNNs, such as continuous graphODE approaches [1][2] and other discrete methods [3].\\n\\n[1] Huang, Zijie, Yizhou Sun, and Wei Wang. \"Learning continuous system dynamics from irregularly-sampled partial observations.\" Advances in Neural Information Processing Systems 33 (2020): 16177-16187.\\n\\n[2] Song Wen, Hao Wang, and Dimitris Metaxas. 2022. Social ODE: Multi-agent Trajectory Forecasting with Neural Ordinary Differential Equations. In Computer Vision–ECCV 2022: 17th European Conference.\\n\\n[3]Sanchez-Gonzalez, Alvaro, et al. \"Learning to simulate complex physics with graph networks.\" International conference on machine learning. PMLR, 2020.'},\n",
       " 'review_791': {'summary': 'This paper examines the interaction between global and local effects in graph-based spatiotemporal forecasting. It addresses the limitations of a single global model by introducing a framework that incorporates trainable node embeddings into graph-based architectures. This framework enables the learning of specialized components and combines the benefits of shared message-passing layers with node-specific parameters. Additionally, the framework facilitates model transfer to new node sets. The paper offers empirical evidence and provides guidelines for adapting graph-based models to the dynamics of each time series to improve prediction accuracy.',\n",
       "  'strengths': 'It is nice to see a paper that investigates the attribution of \"local\" and \"global\" learning in modeling spatial-temporal graphs. The evaluation is very comprehensive and the paper is very informative. It may have great impact that can benefit the broad community that researches on spatial-temporal graphs.',\n",
       "  'weaknesses': 'The paper tries to answer a set of very big questions (\"local\" vs \"global\"), which I feel could be too hard to find a concrete answer in a 9 pages conference paper.\\n\\nSimilar questions can be asked for GNNs as well: Is message-passing more important or the node feature encoding more important? Should I go fully inductive like GCN, GraphSAGE? Or I just stick to non-inductive GNNs? Is the isotropic message-passing enough like vanilla GCNs, or do I need anisotropic message-passing like graph attention networks (GAT)? Do I interleave the MP layers with node encoding layers like most GCNs do? Or I should stack multiple node encoding layers before doing message-passing?\\n\\nI feel it is a little too overwhelming to answer all these questions at once. I really appreciate the authors\\' efforts to investigate these questions, but it feel less convincing when it fits into a 9-pages conference paper, that each claim will be supported by less empirical evidences. Sometimes I will question that, how does this claim hold for other applications when the nature of a problem changes, would the conclusions change?\\n\\nWhat\\'s more challenging is that, these questions seem to not having a general answer that hold for all the applications, making it especially hard to draw conclusions by merely relying on empirical studies (or you will need a lot of experiments across much more domains). \\n\\nIn general, it is overall a technical solid paper and an ambitious one as well.'},\n",
       " 'review_792': {'summary': 'This paper presents a methodological framework aimed at rationalizing the inclusion of trainable node embeddings in STGNNs for spatiotemporal forecasting applications. The authors examine the interplay between globality and locality in graph-based spatiotemporal forecasting and provide insights and guidelines for specification design. The paper demonstrates how incorporating trainable node embeddings in STGNNs can effectively combine the advantages of shared message-passing layers with node-specific parameters, while efficiently transferring the learned model to new node sets. The proposed framework is supported by empirical evidence and offers a principled approach for accommodating various node embeddings.',\n",
       "  'strengths': '1. The authors investigate the interplay between globality and locality in graph-based spatiotemporal forecasting, resulting in five major findings.\\n2. The paper illustrates how including trainable node embeddings in STGNNs can effectively combine the benefits of shared message-passing layers with node-specific parameters and efficiently transfer the learned model to new node sets.\\n',\n",
       "  'weaknesses': '1. The paper is not well-organized, making it difficult to understand the main points and arguments presented.\\n2. The proposed framework adopts the TTS model as an STGNN, but some important TTS methods are not discussed in the related work, such as [1] and [2]. \\n[1] Jianfei Gao and Bruno Ribeiro. On the equivalence between temporal and static equivariant graph representations. In International Conference on Machine Learning, pages 7052–7076. PMLR, 2022. \\n[2] Da Xu, etc. Inductive representation learning on temporal graphs. In ICLR 2020.\\n'},\n",
       " 'review_793': {'summary': 'This paper proposes a method to leverage local effects in graph-based spatio-temporal forecasting. The authors claim that existing spatio-temporal graph neural networks are global models, i.e. all nodes share the same set of parameters, and thus may fail to capture some node-specific patterns. On the other hand, local models, in which some layers within the models are node-specifically parameterized, have better performances compared to global ones, but at the cost of many additional parameters. The authors find a method, random node embeddings, to strike a balance between local and global methods. The authors also propose regularizations to improve transferability of the node embeddings and the resulting models. Experiments over real-world data are given where the proposed method achieves consistent improvements over a variety of models and datasets.  ',\n",
       "  'strengths': '1. The studied problem is interesting. It challenges the assumption that a shared global STGNN is used for all nodes, which is standard in previous works. \\n2. The proposed technique, i.e. trainable node embeddings, is simple and sound. The regularization terms designed also make sense. \\n3. The proposed technique with trainable node embeddings are effective over various models (DCRNN, AGCRN, GWNet) and real-world datasets, which shows the generality of the proposed technique. \\n4. The experimental results showing that node embeddings and regularizations are effective in terms of knowledge transfer are a plus. Intuitively, people may think that models with node specific parameters will not perform well in unseen nodes, but the results show the opposite. ',\n",
       "  'weaknesses': '1. The proposed method with node specific embeddings is effective, but not new. Specifically, STID [40] proposes exactly the same technique in terms of trainable node embeddings. I am slightly concerned about whether the technical contribution meets the standard of NeurIPS with this existing work. \\n2. The fine-grained categorization about spatio-temporal graph neural networks do not seem necessary, e.g. T&S, TTS and anistropic VS istropic. I fail to see how introducing these concepts help better understand the paper, and thus I would suggest these parts be removed. '},\n",
       " 'review_794': {'summary': 'This paper presents a new method to aggregate gradients in a distributed training setting. Effectively, the proposed algorithm projects gradients onto a learned lower dimensional subspace and then aggregates the projections using standard techniques like averaging. This leads to a more robust aggregation against Byzantine failures. The projection is similar to a robust PCA, and is learnt using an approximate MLE via a Taylor expansion, leading to a computationally more feasible algorithm. Thorough experiments are conducted that demonstrate the efficacy of the proposed algorithm.',\n",
       "  'strengths': '1. The proposed novel algorithm empirically performs better than existing methods when measured by iteration complexity.\\n2. The authors provide a thorough comparison to existing methods and place their work in context.',\n",
       "  'weaknesses': '1. The exposition in the paper lacks clarity in some places -- for example, the IRLS subroutine in Algorithm 1 is not described or even briefly summarized in the main paper.\\n2. The authors do not present their theoretical convergence results in the main body of the paper. \\n3. As pointed out by the authors, the main proposed algorithm does not seem to perform significantly better than other existing algorithms when comparing wall clock runtimes.'},\n",
       " 'review_795': {'summary': 'The paper proposes a new appraoch for aggregating gradients for distributed ML training under Byzantine failures, noise due to data augmentation, etc. The approach relies on constructing a low-dimensional subspace such that the proportion of variance of the gradient vectors contained in the subspace is maximized. The authors derive the loss function for their setting and formulate the problem as a regularized convex optimization problem which can be solved with standard solvers to obtain the basis for the subspace. The update direction is then obtained by projecting the individual gradients onto the basis and then averaging the result. Experiments on different datasets and number of workers show improved prediction accuracy over baselines when distributed training is performed using the proposed method.',\n",
       "  'strengths': '1. The proposed approach is principled and easy to interpret as it tries to identify the subspace which contains the maximum proportion of the variance of the gradients and is also easy to implement due to its formulation as a regularized convex optimization problem which can be solved by off-the-shelf workers.\\n\\n2. The approach is extensively evaluated on a range of datasets (MNIST, CIFAR10, tiny-Imagenet) and for different noise models (random noise, adversarial data augmentation etc). I also appreciate the authors presenting results on wall-clock time to accuracy and per-iteration time thereby acknowledging the extra time required per iteration in their approach to compute the aggregated gradients. This opens the door to future research on speeding up the proposed aggregation method while retaining the accuracy gains.',\n",
       "  'weaknesses': '1. My main concern with the approach is its novelty. Since the goal appears to be to estimate the subspace containing the maximum proportion of gradient variance, I am not sure why this cannot be done by retaining the top-k Principal Components of the gradients. The authors even acknowledge in line 109 that the idea to use the ratio of variance of projected and true gradients has been explored in the Robust PCA literature. However, they do not explain why simply considering the principal components will not work, nor do they perform experiments with PCA/Robust PCA as baselines. I would like to see at least one of the two (explanation/experiments) to be convinced of the need for the proposed approach and its gains over PCA.\\n\\n2. The extra computational cost and the added time per iteration as seen in Fig 10 (b) is also a weakness. While I do appreciate the authors measuring and presenting this time, it is not clear at this point if the accuracy gain justifies the extra time. One way to demonstrate this would be to allow the other approaches to run for the same amount of time in Fig 10 (c). If it could be shown that even after running for that long these approaches cannot match the accuracy of Flag Aggregation, then the extra time required could be justified.'},\n",
       " 'review_796': {'summary': 'Authors propose a gradient aggregation method for distributed optimization that is robust to Byzantine device failures in large scale distributed setups. In each round, given the set of gradients from each workers, the authors aim to find the optimal low-rank subspace that can explain the variance of a majority of the gradients. The authors formulate the problem as a MLE under a beta distribution setup  and solve an approximate version of the problem though SDP.',\n",
       "  'strengths': 'Byzantine device failures is an important concern for large scale clusters.  The presented method is well motivated theoretically and backed up with experiments comparing their robustness properties to other aggregation methods. Results demonstrate a significant advantage of this aggregation setup. ',\n",
       "  'weaknesses': 'Although it is evident that Byzantine failures can have a significant impact on gradient computation if using simple aggregation rules, its unclear how often such failures happen in the cluster sizes the authors have considered. Augmentation pipelines induce their own noise to gradient information, but its unclear if these will be adversarial in _each_ update step. The amount of noise induced and its effect on adversarial training setups is also not evident.  (See questions). This makes it unclear how the clear advantages of the method translates to real-world workloads especially considering that the method adds a potentially expensive top-k SVD computation step.'},\n",
       " 'review_797': {'summary': 'This paper tackles the problem of Byzantine robustness in distributed learning by proposing a new robust aggregation rule called Flag Aggregator. The latter is based on maximum likelihood estimation with regularization. They empirically show that using distributed gradient descent with Flag Aggregator performs well against simulated Byzantine attacks compared to other existing solutions. ',\n",
       "  'strengths': 'The problem of Byzantine robustness is important in distributed learning. Moreover, the proposed Flag Aggregator seems to follow a creative approach.',\n",
       "  'weaknesses': 'My main concern is the great lack of clarity of the paper, especially in the theoretical part. I also think that the theoretical and experimental parts lack several elements.\\n\\n* Lack of clarity: the paper has several clarity-affecting issues which makes it really hard to assess the technical contributions. \\n\\t* The paper starts (right away) with an unclear optimization problem (Equation 1): what are A, Y and C? \\n\\t* line 99: why is $Y Y^\\\\top G$ a \"reconstruction\" of $G$? and what is meant by reconstruction exactly?\\n\\t* lines 100-103: I could not verify the stated claims/intuitions. \\n\\t* line 116: why does orthogonality imply efficiency? Authors seem to say that it is because we can derive a one-rank matrix factorization, but this does not require orthogonality of the matrix. In fact, $YY^\\\\top G$ is just $G$ if $Y$ is orthogonal.\\n\\t* lines 123-135: this paragraph assumes that the reader knows what the Flag/Grassmanian manifold is, which was not the case for me.\\n\\t* Section 2.2: where does the vector $v$ come from? It is directly sent by the workers? Also, why do you assume that it follows a Beta distribution?\\n\\t* Algorithm 1: I could not find IRLS explained in the text. Also, it is strange that workers locally perform the update step. It always happens at server level in distributed SGD.\\n\\t* line 163: what is Flag Median?\\n\\t* line 188: what is a \"second order optimal local solution\"?\\n\\n* Lack of convergence guarantees: After all, a Byzantine-robust learning solution should have convergence guarantees, since simulated attacks are not guaranteed to be optimal; i.e. instantiate worst-case adversaries. Typically [Karimireddy et al. 2022, Allouah et al. 2023], convergence to a neighborhood of the original solution is ensured in the presence of Byzantine workers for smooth non-convex losses. \\n\\n* Experimental section: I suggest simulating more Byzantine attacks. The tested attacks (uniformly random vectors) are extremely weak compared to FoE [Xie et al. 2020], ALIE [Baruch et al. 2019] and others, which is unfortunate since the paper consider Byzantine adversaries. Also, some advanced defenses like NNM [Allouah et al. 2023] and Bucketing [Karimireddy et al. 2022] are missing although they were intended for non-iid; it is important to check how they perform against your method to assess the significance of the contribution.\\n\\n[Allouah et al. 2023] Fixing by Mixing: A Recipe for Optimal Byzantine ML under Heterogeneity, AISTATS 2023.\\n\\n[Karimireddy et al. 2022] Byzantine-Robust Learning on Heterogeneous Datasets via Bucketing, ICLR 2022.\\n\\n[Xie et al. 2020] Fall of Empires: Breaking Byzantine-tolerant SGD by Inner Product Manipulation, UAI 2020.\\n\\n[Baruch et al. 2019] A Little Is Enough: Circumventing Defenses For Distributed Learning, NeurIPS 2019.'},\n",
       " 'review_798': {'summary': 'This work proposes Flag Aggregator (FA) for a more robust aggregation of gradient in data-parallel training. FA formulates gradient aggregation as a Maximum Likelihood Estimation procedure using Beta densities. Theoretically, FA is analyzed using techniques from convex optimization. Empirically, FA demonstrates decent performance against Byzantine failure for image classification tasks (esp. ResNet-18 on CIFAR10) on a 4-GPU cluster networked with 100GbE.',\n",
       "  'strengths': '+. Proposed a simple Maximum Likelihood Based estimation procedure for aggregation purposes, with novel regularization functions\\n\\n+. Provided code for reproducibility\\n\\n+. Well-written: easy to follow',\n",
       "  'weaknesses': '-. Marginal wall-clock time improvement, maybe due to heavy SVD overhead: e.g., Figure 10\\n\\n-. Missing benchmark: \\n1. only two small models are evaluated (e.g., ResNet18 and 2-layer CNN), how about more models like RNNs and larger models like GPT2?\\n\\n2. only image classification tasks are evaluated (e.g., CIFAR10 and MNIST), not even CIFAR100 nor full ImageNet, how about more tasks like language modeling?\\n\\n-. Missing modern cluster: 4-GPU cluster with one GPU per machine is not a modern setup for evaluating scalability of distributed training\\n\\n'},\n",
       " 'review_799': {'summary': 'This paper considers the problem of estimating (heterogeneous) treatment effects via both interventional and observational data. The authors proposed a new estimation, namely the Fused and Accurate Shrinkage Tree (FAST), which optimally weights the interventional and observational estimator, and combines with a new spilt criteria for tree-based heterogeneous treatment effect estimation. The authors further conducted experiments to compare FAST against existing methods.',\n",
       "  'strengths': '- Apart from a few typos, the paper is well written and ideas are presented in a rigorous but clear also way. \\n- The idea of applying shrinkage method to combine interventional and observational data for better estimator is novel and could be a nice addition to the literature.\\n- Note that I have not gone through all the proofs in the appendix, the mathematical correctness might need further input from other reviewers. ',\n",
       "  'weaknesses': '\\n\\nGenerally I like this paper, but there are still a few weaknesses.\\n\\n- The main issue with shrinkage method is interpretability: we need to understand better how the variance-bias trade-off behaves in different regimes, especially the authors takes a more analytic way to first estimate the required quantities, then solve the optimal weights. More specifically for example, it would be beneficial to at least see different how trial mechanisms affects the estimation. For example, in a more realistic setting, one may consider non-randomized trials rather than RCT, in which treatments are assigned by a *known* true model. By adjusting the parameters of such true assignment model, the estimator variance for the trial population HTE estimator can be controlled (even with fixed N). Then the performance of FAST can be evaluated against different variance regimes of trial HTE estimator, which will help us understand the sweat spot of the method.\\n\\n- Regarding experimental settings. It is indeed quite standard for these type of papers to have 1 or 2 synthetic experiments and 1 real data experiment. However, in the case of this paper I found the simulation setting is a bit weak. It would be great to perform experiments on multiple data generating mechanisms with randomly sampled parameters and coefficients, allowing us to evaluate the marginal performance of the method. Otherwise the authors at most demonstrated the capability of the method on only one single data generation mechanism (which arguably is much easier to hack/cherry-pick).\\n\\n\\n- The other potential room for improvement is the baseline. I understand that the paper mainly only compares to data fusion methods. However, due to the variance-bias trade-off of the shrinkage method, it would be natural to also expect some comparisons to variance reduction methods for trial estimators as well. '},\n",
       " 'review_800': {'summary': 'The paper introduces a Fused and Accurate Shrinkage Tree (FAST) algorithm for heterogenous treatment effect estimation given trial and observational data. The FAST algorithm introduces (i) a shrinkage based approach that combines trial and observational data for MSE reduction in treatment effect estimation, and (ii) a split criteria which down-weights observational data with high confounding bias. Further, the paper provides theoretical analysis demonstrating the benefits of the proposed split criteria. Experimental results on synthetic and real-world data demonstrate that the proposed approach outperforms baselines per metric MSE.',\n",
       "  'strengths': '- The paper is well written and easy to follow. The reviewer enjoyed reading this paper.\\n- The proposed FAST algorithm is well-justified and the theoretical analysis might be of interest to some readers. \\n- The paper tackles an important problem (fusing small RCT with large readily available observational data ) with many applications. \\n- The algorithm seems simple and easy to implement',\n",
       "  'weaknesses': \"-  Eqn. 5:  The paper seems to have glazed over the rationale for dropping $\\\\sigma_b$ in the shrinkage estimator. It's unclear in what scenarios, e.g., how large the observational sample size must be for $\\\\sigma_b$  to become negligible.\"},\n",
       " 'review_801': {'summary': 'The authors propose a novel shrinkage method that fuses an unbiased estimator with a biased estimator. This method effectively reduces the MSE of the unbiased estimator. The approach offers a practical and straightforward implementation specifically tailored for estimating heterogeneous treatment effects. The authors extend the conventional node split criterion to align with the fused estimator and penalizes the use of observational data with substantial confounding bias. The authors also provide a theoretical analysis that explains the advantages of the modified splitting criterion.',\n",
       "  'strengths': \"- The application of the weighting strategy from shrinkage estimation to fusing unbiased and biased estimators in order to reduce the MSE of the unbiased estimator is a great idea.\\n- The modification of the node-splitting criterion that aligns with the fused estimator is an excellent enhancement to the methodology.\\n- The paper is well-organized and thanks to the authors's thoughtful and consistent notation, the methodology is easy to follow.\",\n",
       "  'weaknesses': \"I'm concerned with the omission of $\\\\sigma^2_b$ in practice. If we only look at the weight $w$, it make sense if $\\\\sigma^2_b$ is small comparing to $\\\\sigma^2_u$. However, in the tree building process, we need working estimates of the MSE of fused estimator, $\\\\frac{(\\\\sigma^2_b+b^2)\\\\sigma^2_u}{\\\\sigma^2_b+b^2+\\\\sigma^2_u}$, and I don't think omitting $\\\\sigma^2_b$ is justified by the same reason anymore.\"},\n",
       " 'review_802': {'summary': 'The paper deals with the problem of estimating the heterogeneous treatment effects with multiple data sources. In particular, the paper aims to utilize the information from the observational data to better estimate the causal effects in the trial data. Inspired by the shrinkage estimation, a weighting scheme is developed to balance the unbiased estimator based on trial data and the potentially biased estimator based on observational data. Specifically, a tree-based algorithm with new split criterion is proposed based on above motivations. Some theoretical results about the causal effect estimation is derived. Finally, the author provides simulations and real data analysis to demonstrate the performance of the proposed method.\\n',\n",
       "  'strengths': 'The papers deal with an interesting problem in practice, i.e., data fusion. In particular, we may have multiple data sources. However, some sources has limited observations with unbiased causal effects and other sources have sufficient observations with biased causal effects. The paper utilizes the tree-based algorithm with a new splitting criterion to tackle this issue. In addition, some theoretical analysis are provided to prove the advantages of the method.',\n",
       "  'weaknesses': '1. Although the paper considers an important problem in practice, the reason why the method chooses tree-based algorithm is not convincing. In particular, other ML methods can also achieve data fusion. The advantages of using tree-based algorithm over other methods are confusing and are not clearly discussed. \\n2. In the introduction and simulation studies, the author also mentions many other methods that deal with the data fusion problem. However, the reason why the proposed tree-based method can perform better than other methods are not interpreted. \\n3. Although the paper provides the theoretical analysis for the causal effect estimation, the interpretation for the theorem are not convincing. For example, many other methods also have theoretical guarantee for the causal effect estimation. Which part in the theoretical analysis can illustrate the advantages of data fusion and the tree-based algorithm?\\n4. In the general picture, the idea of data fusion is very similar to that of transfer learning, i.e., we want to transfer the information from the observational studies to help the estimation of causal effects in trial data. However, the paper does not mention any related literature in transfer learning. In particular, what is the advantages and differences of the method compared with transfer learning? A more comprehensive literature review is encouraged. '},\n",
       " 'review_803': {'summary': 'This paper proposes a novel strategy for estimating the heterogeneous treatment effect called the Fused and Accurate Shrinkage Tree (FAST). The authors confirm the consistency of the proposed tree-based estimator and demonstrate the effectiveness of their criterion in reducing prediction error through theoretical analysis. The advantages of the proposed method over existing methods are demonstrated via simulations and real data analysis. As I am not very familiar with this field, it might be better to consider my opinion less.',\n",
       "  'strengths': '1. This paper is technically sound.\\n2. The proposed method has better performance than the existing methods.',\n",
       "  'weaknesses': 'Imcomplete references: The tree-based method seems to not be a new method in this field. There might be some other references as follows.\\n\\nAgarwal, Abhineet, et al. \"Hierarchical Shrinkage: Improving the accuracy and interpretability of tree-based models.\" International Conference on Machine Learning. PMLR, 2022.\\n\\nNasseri, Keyan, et al. \"Group Probability-Weighted Tree Sums for Interpretable Modeling of Heterogeneous Data.\" arXiv preprint arXiv:2205.15135 (2022).'},\n",
       " 'review_804': {'summary': \"This paper presents a generalized backtracking line-search method, which estimates coordinate-wise stepsizes referred to as 'preconditioner' of gradient descent. Stemmed from the observation that any existing methods do not exceed the performance of backtracking line-search method, this paper designs a generalized backtracking line-search technique which is realized as a cutting plane method, whose separating hyperplane comes from the hypergradient, i.e., gradient with respect to hyperparameter of the algorithm, which is a stepsize in this case. Followed by the worst-case convergence analysis for smooth strongly convex function, the writers also provide experimental results illustrating the competitiveness of this method for ill-conditioned problems and robustness among problem classes.\\n\",\n",
       "  'strengths': 'Section 4 contains the key insight of this work: that a failed preconditioner (defined as one that violates a Armijo-type condition) provides a cutting plane on the set of valid preconditioners. This is a very nice idea that is, as far as I know, novel, and I expect this work to lead to a lot of follow-up work. This is a new type of result and I think it is valuable.',\n",
       "  'weaknesses': '.'},\n",
       " 'review_805': {'summary': 'This paper extends backtracking to multi-dimension. The authors propose a cutting plane method to find optimal per-coordinate step-sizes (in other words, to find an optimal preconditioner) for smooth convex optimisation. Experiments on ill-conditioned logistic regression problems show that the proposed algorithm can find good preconditioner and improve over vanilla gradient descent.  ',\n",
       "  'strengths': 'This paper fills a potential gap in the optimization literature by proposing multidimensional backtracking. The proposed method is technically sound and seems to work well in practice.',\n",
       "  'weaknesses': \"I do not see any major issues with the paper, except maybe that it is a bit hard to follow and understand (even though the English is good). Maybe because I don't have enough background on the topic. I'm really sorry for the short review.\"},\n",
       " 'review_806': {'summary': 'This paper provides a backtracking approach for smooth convex optimization on a per-coordinate basis with a theoretical analysis that show the gain with respect to classical backtracking line-search and that compare to the optimal per-coordinate conditioners.',\n",
       "  'strengths': 'This paper is super well written and organized. The contribution is also significant as it is a building block of many problems in machine learning.\\nIn general, further improving the \"adaptivity\" of optimization algorithms is essential to seamlessly apply theoretical results (i.e., optimal per coordinate step sizes) to operational purposes.',\n",
       "  'weaknesses': 'The only drawback might be focusing on smooth and strongly convex problems, but it is still a significant first step.\\n'},\n",
       " 'review_807': {'summary': \"The authors suggest incremental updates of $\\\\mathbf{x}$ for finding the minimum of strongly-convex function $f$ that guarantee decreasing $f(\\\\mathbf{x}_{t})-f(\\\\mathbf{x}_\\\\ast)$ based on only 1st-order gradient information. \\n\\nTheir idea is in each step,\\n- choose a candidate matrix $\\\\mathbf{P}_t$ based on set $\\\\mathcal{S}_t$, and\\n- check the condition (4), that guarantee sufficient decrease of the $f$, and\\n- if the condition is satisfied:\\n    - apply update $\\\\mathbf{x}_{t+1} = \\\\mathbf{x}_t - \\\\mathbf{P}_t\\\\nabla f(\\\\mathbf{x}_t)$\\n    - $\\\\mathcal{S}_{t+1} = \\\\mathcal{S}_t$\\n- else\\n    - $\\\\mathbf{x}_{t+1} = \\\\mathbf{x}_t$\\n    - update $\\\\mathcal{S}_{t+1} = \\\\text{cut}(\\\\mathcal{S}_t, \\\\mathbf{x}_t, \\\\mathbf{P}_t)$\\n\\nThey provide proofs for\\n- approaching the optimal in Proposition 3.2\\n- how to choose candidate and cut algorithm in Theorem 5.3, and its maximum number of calls.\\n\\nThey conduct some simple experiments in Section 6, and show the proposed algorithm's efficiency.\",\n",
       "  'strengths': \"originality\\n- considering backtracking using preconditioned matrix $\\\\mathbf{P}_t$ would be novel idea. But I'm not an expert of this field, and not so sure on the originality.\\n\\nquality\\n- The proposed algorithm is supported by some proofs, and it shows good empirical results.\\n\\nclarity\\n- Basically, the manuscript is readable.\\n\\nsignificance\\n- The proposed algorithm seems be better than other baselines except for Diag. Hessian+LS, which uses information of 2nd order derivatives, i.e. Hessian, even the proposed algorithm uses 1st-order derivatives of $f$. It would be significant.\",\n",
       "  'weaknesses': '- The manuscript contains some typos.\\n- I have a concern on Figure 5. The horizontal axis shows number of f/grad evals, but I guess the number of CUT calls should be also taken into account.\\n'},\n",
       " 'review_808': {'summary': 'RL methods trained on simulators suffered from generalization problems because of the \"simulation-to-reality-gap\". Previous works proposed robust RL methods in a tabular setting, with limited search spaces. The paper aims to develop a computationally tractable robust RL algorithm with large search spaces. To this end, the paper proposed two novel uncertainty sets and the first policy-based approach for robust RL with provable convergence guarantees.',\n",
       "  'strengths': 'The paper studies a critical problem. Several technical contributions are proposed to devise a robust policy-based RL method with a large search space. The theoretical analysis seems solid.',\n",
       "  'weaknesses': 'The paper aims to devise a robust RL method. More real-world experiments are expected to demonstrate the robustness of the proposed methods.\\n\\n---------------------\\nAfter reading the rebuttal, my main concerns were addressed.'},\n",
       " 'review_809': {'summary': 'This paper studies the sim-to-real transfer problem. It extends the learning of a robust policy by using the framework of robust Markov decision processes (RMDPs). It extends this paradigm to large state and action spaces using two uncertainty set formulations: double sampling, and integral probability metric.\\nThese formulations are then used in the proposed algorithm robust natural actor critic (RNAC). RNAC is tested in MuJoCo as well as on a real robot.',\n",
       "  'strengths': '* Proposed uncertainty sets as well as the RNAC algorithm seem like practical steps forward in sim-to-real transfer with robustness approaches.\\n* The theoretical analysis seems interesting',\n",
       "  'weaknesses': '* The experiments compare only to PPO. They should compare to other sim-to-real methods such as dynamics randomization [1] or action noise envelope [2].\\n* The related works being relegated to the appendix seems like a red flag. The authors should better organize the paper to include related works and comparisons to the main paper.\\n\\n### References\\n[1] Peng, X.B., Andrychowicz, M., Zaremba, W. and Abbeel, P., 2018, May. Sim-to-real transfer of robotic control with dynamics randomization. In 2018 IEEE international conference on robotics and automation (ICRA) (pp. 3803-3810). IEEE.\\n\\n[2] Jakobi, N., Husbands, P. and Harvey, I., 1995. Noise and the reality gap: The use of simulation in evolutionary robotics. In Advances in Artificial Life: Third European Conference on Artificial Life Granada, Spain, June 4–6, 1995 Proceedings 3 (pp. 704-720). Springer Berlin Heidelberg.\\n\\n\\n================================\\n\\nThe additional experiments alleviate my concerns about the experimental analysis.'},\n",
       " 'review_810': {'summary': 'This paper tackles robust reinforcement learning in large state spaces, where the transition kernel is accessible only in a nominal setting. The authors demonstrate that the $f$-divergence, R-contamination, and the $l_{p}$ norm are computationally infeasible in the context of robust RL for large state spaces. To overcome this limitation, the authors propose two new tractable uncertainty set formulations suitable for large dimensions: double sampling (DS) and the integral probability metric (IPM).\\nDS involves independently and identically distributed state sampling following a transition kernel $p^o_{s,a}$. The IPM corresponds to the robust Bellman operator, but with a regularization term on the norm of weights. Both approaches are enabling Robust RL in scenarios previously hindered by computational complexity.\\nThe paper introduces a new algorithm, the Robust Natural Actor Critic (RNAC), for training both a critic and an actor for the proposed IPM and double sampling uncertainty sets. The authors provide convergence guarantees for the RNAC algorithm.\\nFinally, the authors demonstrate the efficency of their approach via two applications: one involving the suite of MuJoCo environments and the other, a real-world robotics application. These practical applications lend credence to the theoretical contributions and the robustness of the proposed approach.\\n',\n",
       "  'strengths': \"- The authors provide two straightforward and computationally feasible uncertainty set formulations for large state spaces.\\n- The paper offers substantial theoretical contributions.\\n- The real-world robotics application lends credibility to the paper's robustness claims.\\n\",\n",
       "  'weaknesses': '- The convergence guarantees are valid for $(s,a)$-rectangular uncertainty sets, which is rather limiting. However, it is commendable that the authors have acknowledged this limitation in their work and suggested it as an avenue for future research.\\n- The paper seems incomplete without the appendix. The need to constantly refer to the appendix disrupts the flow of reading.\\n'},\n",
       " 'review_811': {'summary': 'This paper studies the actor-critic approach for robust RL. Especially, a Double-Sampling Uncertainty Set and an Integral Probability Metric Uncertainty Set are developed to overcome the curse of problem scale. A robust natural Actor-Critic algorithm is then proposed with convergence results. A significant number of experiments are designed.',\n",
       "  'strengths': 'The paper is well-written and clear in general. The design of the two uncertainty sets is new and novel, which shows advantages under large-scale problems.',\n",
       "  'weaknesses': \"1. The motivation for designing the two uncertainty sets is somehow unclear to me. I understand there is uncertainty in the sets designed, but don't understand the motivation of this uncertainty set. In lines 640-646, the authors explain the uncertainty set contains transition kernels that are perturbed from the uniform distribution, this explanation seems unclear to me, and I can't understand the motivation for such a definition. \\n2. One of the critical problems in studying robust RL with function approximation is the contraction of the approximated Bellman operator. The approach used in this paper is similar to the previous ones, i.e., use conditions on the radius of the uncertainty set and discount factor. This hence reduces the novelty and contribution of the paper.\"},\n",
       " 'review_812': {'summary': 'The authors study the problem of federated learning over partially class-disjoint data and propose using equiangular tight frame (ETF) techniques that allows achieving better performance in both the global and personal learning tasks. They show that the existing federated learning approaches suffer either from angle collapse for locally missing classes or from waste of space for locally existing classes, and propose their approach FedGELA which solves both the issues.',\n",
       "  'strengths': '+ Extensive experiments comparing the proposed approach, FedGELA, with the existing federated learning approaches.\\n+ Detailed theoretical analysis of the proposed approach.\\n+ Highlighting the issues of angle collapse and waste-of-space in the federated learning with partially class-disjoint data.',\n",
       "  'weaknesses': '- Borrows the existing EFT techniques and hence the novelty seems to be limited.\\n- Overall improvement in average accuracy is marginal (~1.5%) over the existing approaches.'},\n",
       " 'review_813': {'summary': 'This paper introduces a novel Federated Learning Algorithm to address the Partially class-disjoint data (PCDD) problem. The approach is based on the simplex equiangular tight frame (ETF) phenomenon to solve the angle collapse issue and introduces a second projection to personalize an adapted structure to save space. The main contributions can be summarized in three aspects: identifying the angle collapse and space waste challenges in the PCDD problem, introducing the novel FedGELA algorithm, and conducting a range of experiments to evaluate its performance. The paper also includes a theoretical analysis with convergence analysis.',\n",
       "  'strengths': \"1. The paper is well-written with a proper structure and clear explanations. The presentation of the authors' ideas is easy to follow due to the effective use of figures and notations.\\n2. The methodology of the FedGELA algorithm is interesting, and the mathematical deductions are sufficient. The algorithm is clear and provides enough information for reproducibility.\\n3. The algorithm has been wisely experimented, and the plots are suitable and clear.\\n\\n\",\n",
       "  'weaknesses': '1. The authors claim that \"none of the existing methods can intrinsically mitigate PCDD challenges to achieve holistic improvement in the bilateral views of federated learning.\" However, the PCDD problem seems closely related to the general non-iid (non-independent and identically distributed) problem. The main differences between these two problems have not been explained.\\n2. Based on my understanding, if PCDD is different from the non-iid problem, it should perhaps be related to the multi-label problem. However, the presentation of the paper, the experimental data, and the methods of experimental comparison all tend to be more inclined towards non-iid problems. Non-iid is a common problem setting, which contradicts the first author\\'s claim of contributions.\\n3. The performance improvement is limited.\\n4. I disagree with the statement that \"restricting local structure will waste feature space and limit the training of the local model on existing classes.\" I believe the notion of \"waste of space\" is unfounded as it appears to have no impact on computational efficiency or performance improvement.\\n\\nConclusion:\\nThe methodology and algorithm presented in this paper are interesting, and the paper is written in high quality. However, there seems to be an important flaw in the problem setting. PCDD appears not to be a new issue but rather a non-iid problem under some special conditions.\\n'},\n",
       " 'review_814': {'summary': 'This paper mainly focuses on the partially class-disjoint data (PCDD) problem in federated learning (FL) settings, which is a common yet challenging problem in distributed data sources. Inspired by a classifier structure (simplex equiangular tight frame, ETF), the authors of the paper propose FedGELA to tackle the PCDD problem. FedGELA is a variant of FedAvg with local model adaptation (personalization): They first define the classifier $W$, which is the ETF that the classifier should converge to. Here, they also take the client local data distribution ($\\\\phi$) into account. Afterwards, the feature extractor $H$ will be optimized locally at each client and communicated via server-client communication. Finally, the global feature extractor and the $W$ at central server, as well as the local feature extractors and the adapted $W$ at clients will be returned.',\n",
       "  'strengths': 'The proposed method is motivated very well. The schematic illustration is also clear. The theoretical analysis is sound. Experiments and the results are good.',\n",
       "  'weaknesses': 'From my understanding, FedGELA focuses only on the alignment in the feature embedding space, which has been done by many previous works (FedGen [1], FedProto [2], …). Therefore this paper lacks significance to some extent. Also, the definition of $W$ (ETF, the global classifier), as well as the locally adapted ones looks straightforward.'},\n",
       " 'review_815': {'summary': 'This paper addresses a challenge in Federated Learning referred to as partially class-disjoint data (PCDD), where each client contributes a part of classes (instead of all classes) of samples. Without full classes, the local objective will contradict the global objective, yielding the angle collapse problem for locally missing classes and the space waste problem for locally existing classes. This is a real-world challenge since it is not uncommon for example that some classes will be well sampled in certain regions, but not others. Prior art mainly focus on the general heterogeneity without specially considering partially class disjoint challenges. Without full classes, the local objective will contradict the global objective, yielding the angle collapse for locally missing classes and the waste of space for locally existing classes. The goal is to achieve holistic improvement in the bilateral views (both global view and local view) of federated learning. \\n\\nThe authors propose FedGELA where the classifier is globally fixed as a simplex ETF while locally adapted to the personal distributions. Globally, FedGELA provides fair and equal discrimination for all classes and avoids inaccurate updates of the classifier, while locally it utilizes the space of locally missing classes for locally existing classes. \\n\\nThe proposed approach builds upon simplex equiangular tight frame (ETF), which provides each class the same classification angle and generalizes well on imbalanced data. Specifically, in their FedGELA approach, the classifier is globally fixed as a simplex ETF while locally adapted based on the local distribution matrix to utilize the wasted space for the existing classes. In the global view, FedGELA merges class features and their corresponding classifier vectors, which converge to ETF. In the local view. it provides existing major classes with larger feature spaces and encourages to utilize the spaces wasted by locally missing classes. \\n\\nContributions are summarized as :\\n- Study algorithmic implication of a real-world  challenge (partially class-disjoint data (PCDD), namely angle collapse and space waste \\n- Propose FedGELA and theoretically show the local and global convergence analysis for PCDD with the experimental verification \\n- Evaluate on multiple benchmark datasets under the PCDD case and a real-world dataset to demonstrate the bilateral advantages of FedGELA over the state of the art methods.\\n\\n',\n",
       "  'strengths': '1. Related work well covers comparison among a range of FL methods and why PCDD not covered. Examples of why prior art does not address PCDD include: generic federated leaning adopt a uniform treatment of all classes, then attempt mitigate personal differences; personalized federated learning places less emphasis on locally missing classes and selectively shares parameters/prototypes to minimize the impact of personal characteristics. While these methods might directly or indirectly help mitigate the data shifts caused by PCDD, neither achieve holistic improvement for global and local views\\n2. Performance evaluaton on 3 relevant datasets (SVHN, CIFAR10, CIFAR100), against all the top state of the art algorithms as baselines, and showng it outperforms. FedGELA consistently exceeds all baselines.\\n\\n',\n",
       "  'weaknesses': 'Overall, the paper represents is a solid contribution - well defined problem not addressed by prior art and representative of real-world problem for fedrated learing. Solid treatment of prior art, and differentiation from prior methods. \\nWeaknesses:\\n1. Only 1 real PCDD federated application Fed-ISIC2019 was evaluated - however I am not aware of other benchmarks I would recommend.\\n2. Performance improvements against to the best baseline for all tests were all <3% performance improvement.'},\n",
       " 'review_816': {'summary': 'This work examines the impacts of missing values in data on fairness interventions, particularly in contrast to the commonly implemented \"impute-then-classify\" procedure for handling missing values. The authors present the following:\\n- investigation of how missing values impact algorithmic fairness in the context of three main modes of missing data (missing completely at random, missing at random, and missing not at random);\\n- a theorem capturing the performance gap between optimal solutions when employing a generic imputation mechanism vs. not when using equalized odds (information-theoretic result);\\n- methods for adapting fairness-intervention algorithms to missing data, both for linear and non-linear settings;\\n- empirical evaluation of their proposed methods.\\n\\nTheir findings suggest that fairness intervention strategies benefit from the preservation of information encoded in the missingness of data in terms of group fairness and accuracy.',\n",
       "  'strengths': '- Clear motivation of the problem setting, both in the introduction and recapping in the conclusion.\\n\\n- Overall, mathematical notation is quite clean and easy to follow. \\n\\n- The authors provide an interesting information-theoretic performance gap result under a general imputation mechanism in the context of classification accuracy and equalized odds fairness constraint. This result implies that following imputation, then classification will never perform better (in terms of accuracy and group fairness) than using the information encoded in missing features, and moreover will result sub-optimal performance due to information loss. \\n\\n- Multiple methods are presented to address missing values in the context of linear classification and one bagging-based method for nonlinear classification. These missing-value adaptation methods are flexible and can be used in conjunction with preexisting fairness-intervention algorithms (used in a black-box way).\\n\\n- The authors provide meaningful discussion of challenges and limitations in using their methods (determining choice of fairness intervention, which the adaptation methods depend on; sensitive groups/attributes not being known beforehand). They also effectively demonstrate the value of this research direction in the context of algorithmic fairness.\\n\\n- The authors provide implementation and hyperparameter details used in their experiments in the Appendix, supporting reproducibility (though this should be referenced in the main paper).',\n",
       "  'weaknesses': 'It\\'s unclear what the trade-offs are between the three methods presented for linear classification. The figures comparing the performance between the methods against baselines are very hard to visually interpret, and there is insufficient discussion highlighting the performance differences between these and the baselines. It\\'d be helpful to further flesh out this section. It also makes it unclear what the value is in providing three methods for a more constrained and less practically-applicable setting given this presentation.\\n\\nFurthermore, it is unclear how one would determine which of the three linear methods one should use - the authors note \"we believe that the best adaptive algorithm is not universal, and one should select the adaptive algorithm based on the distribution of the data\". What suggestions do you have for the reader in doing this?\\n\\nAdditional suggestions:\\n- In alignment with a question provided in the Questions section, proofs in the Appendix would benefit in some places from more rationale between steps - readers may not necessarily share your same mental model or background, and this can help cognitive overhead on the reader.\\n\\n- Overall, the empirical results presented in the plots (Figures 1-3) are very hard to read and interpret, and are unfortunately quite inaccessible (font size, curve markers and overlap, overall size). The paper would benefit from making these more human-interpretable and by highlighting key takeaways (as stated above) and trade-offs.  \\n\\n- Nit: Please state upfront in Section 4 the settings you provide algorithms for! Based on the organization of the paper, a reader would have to be motivated to get to Section 5 to uncover that you provide methods for linear and nonlinear settings. :]\\n\\n- Nit: please include references in the main paper to additional results/content in the Appendix throughout, i.e. proofs, additional experimental details, etc.\\n\\n- Minor nit: please include the year in citation references.'},\n",
       " 'review_817': {'summary': 'The paper works on the missing value issues in algorithmic fairness. Typical approaches tend to firstly impute the missing the data, then process for the classification task. However, the authors prove that the imputed data harms the group fairness as well as the averaged accuracy. To avoid losing missing pattern of the data to be imputed, the authors propose to modify the dataset to preserve the feature within the missing patterns, then continue with an off-the-shelf fairness-intervention algorithm to the modified dataset. Experiment results show that the proposed adaptive algorithm improves fairness and accuracy over impute-then-classify methods.',\n",
       "  'strengths': '* Theoretical illustration on the conclusion that ``imputed data harms the group fairness as well as the averaged accuracy\".\\n\\n* The authors propose three methods for adapting linear fair classifiers to missing values:\\n\\n     * **Method 1:** Adding missing indicator variables $\\\\to$ this adaptive algorithm improves the accuracy of classifier under the same group fairness constraint than a classifier trained using impute-then-classify;\\n\\n     * **Method 2:** Affinely adaptive classification;\\n\\n     * **Method 3:** Missing pattern clustering;\\n\\n* A general algorithm for  nonlinear classifiers.\\n\\n* Experiments on various datasets demonstrate the effectiveness of the proposed methods.',\n",
       "  'weaknesses': \"* (1) Although the overall presentation is well-done, some parts could be much better if modified accordingly (please refer to **questions**).\\n\\n* (2) Although the motivation of Theorem 1 is good, when I was going through the proof and assumptions made in Theorem 1, I feel like the assumptions are too strong, i.e., in this example, the conclusion should be based on:\\n\\n  * (2a) The feature $X$ is of only one dimension; (it would be much better if it could be assumed as a two dimension, since missing values in one dimension feels like completely missing of a feature; while in real-world scenario, missing features are also like to be the case where part of information is missing in a feature $x=[x_1, x_2]$, i.e., $x_2$ is missing). \\n\\n  * (2b) The construction of the probability distribution $P_{S, X, Y}$: given the attribute is $S=s$, it seems that the authors are requiring $Y=1$ won't appear in non-missing $X$ (as specified: $\\\\text{Pr}(Y=1, X=0|S=s)\\\\text{Pr}(Y=1, X=1|S=s)=0$), and $Y=1$ appears only for missing values (as specified:  $\\\\text{Pr}(Y=1, X=\\\\text{NA}|S=s)=\\\\alpha_s, \\\\text{Pr}(Y=1, X=\\\\text{NA}|S=s)=0$).\\n\\nAlthough the example itself is correct, it is hard to believe whether the conclusion will remain the same in more complex scenario.\"},\n",
       " 'review_818': {'summary': 'This work investigates how different types of missing data affect algorithmic fairness, and provide algorithms that work to address this issue. Three types of missing data are considered: MCAR (missing data is independent of the observed and unobserved values), MAR (missing data depends on the observed values only, and MNAR (dependence of the missing data on the unobserved values). The contributions are (1) Theory showing that a model trained on imputed data (the classic impute-then-classify method) has unavoidable reduced performance; (2) Introduce strategies for adapting mitigation strategies in fair classification to missing data; and (3) provide an empirical analysis that supports the theory and compares against state-of-the-art fair classification algorithms that use impute-then-classify.',\n",
       "  'strengths': '*ORIGINALITY.* I am not familiar with work in the missing data space, but looked through the related work section, skimmed a few of the works mentioned, and looked briefly at the literature on missing data in ML. This work seems to differ from previous contributions, and is adequately cited. The difference between the approach in this work and the approaches of previous work seems adequately explained. \\n\\n*QUALITY.* The main contribution of this paper is to provide alternative methods to the classically used imputation-then-classify strategy for dealing with missing data in fair classification. This is a well-motivated problem, as imputation is used regularly when data is missing, and this work investigates the information lost when performing imputation, and provides an alternative, competitive strategy for dealing with missing data. \\n\\n*CLARITY.* This work is clearly structured and well-written---I enjoyed the read! \\n\\n*SIGNIFICANCE.* This work is a useful contribution to the literature on mitigating unfairness when values are missing from the feature vector (not including the sensitive attribute). The strategies for finding suitable models in this setting can be used for linear and non-linear classifiers, and the empirical analysis shows promising results that are competitive (and often outperform) methods that use imputation.',\n",
       "  'weaknesses': \"The fairness of models returned by the algorithms is not captured in the graphs in the main body of the work. The paper touts that training classifiers from imputed data can significantly worsen values of group fairness (and average accuracy), but their empirical analysis (in the main body) only compares the accuracy over datasets often used in fair classification. \\n\\n*MINOR COMMENTS* \\n- The core contributions of this work seem to be applicable to general cases of missing data, not just fairness.\\n- Lines 114-117, providing a small example of the different types of reason for missing data could strengthen the description in this paragraph. \\n- Eqn 1 define the indicator function and distribution of interest in the expected value \\n- Fano's inequality (line 193) should be cited\"},\n",
       " 'review_819': {'summary': 'This paper investigates the impact of missing values on algorithmic fairness and highlights the limitations of the commonly used \"impute-then-classify\" approach. The authors propose algorithms that preserve the information encoded within missing patterns, leading to improved fairness and accuracy.',\n",
       "  'strengths': '1. The paper theoretically shows that for the fairness measure of equalized odds, impute-then-classify can significantly reduce the performance. Furthermore, it is also shown that the reduction in the performance grows with the mutual information between the missing pattern and the labels.\\n\\n2. The paper proposes 3 methods to handle missing values for linear fair classifiers by encoding the missing value patterns. These methods are interpretable and can be combined with any preexisting fairness intervention method including in-processing and post-processing methods. \\n\\n3. The paper extensively evaluates the proposed method on synthetic data as well as real data. The authors also show the superiorty of the proposed methods for linear setting for the MNAR missing pattern.\\n\\nOverall, the paper is mostly clear and has original ideas. ',\n",
       "  'weaknesses': '1. The proposed method is only applicable to fair classification and when the group attributes are discrete. Furthermore, the approach allows missingness only in the non-group attribute input features, i.e., the method requires the group attribute and the labels to be fully observed. It might be useful to extend the method for fair regression and for missingness in group attribute and labels.\\n\\n2. The results in the paper focus only on a single measure of fairness, i.e., equalized odds. (By the way, the MEO abbreviation in the figures in the main body should be expanded in the caption when first used.) It might be useful to extend the method for other notions of fairness and provide analogous empirical evaluation.'},\n",
       " 'review_820': {'summary': 'This paper presents an information-theoretic finding that reveals the fundamental limitation of impute-then-classify approaches when considering fairness-accuracy tradeoffs. Additionally, it introduces three techniques for addressing missing features within the framework of linear fair classifiers, as well as an ensemble method for non-linear counterparts. One notable aspect of these developments is their ability to capture missing pattern information, which is overlooked by impute-then-classify algorithms. Furthermore, the paper presents experimental results that demonstrate the superior tradeoff performances of the proposed methods, particularly when dealing with datasets that exhibit prominent missing patterns.',\n",
       "  'strengths': 'S1. The paper focuses on a significant issue that arises in numerous applications.\\n\\nS2. By utilizing the concept of mutual information, the paper reveals the fundamental limitation of impute-then-classify methods.\\n\\nS3. The proposed methods effectively harness the information embedded within missing patterns.',\n",
       "  'weaknesses': 'W1. I believe that scenarios where sensitive attributes are missing present more practical relevance, importance, and challenges compared to scenarios where features are missing. Although the authors mention the possibility of extending their findings to such settings in the conclusion section, the specific details of this extension remain unclear as the computation of fairness constraints relies on knowledge of sensitive attributes.\\n\\nW2. The main inspiration for this paper appears to be derived from [3]. While the main contribution of this paper lies in its adaptation to the fairness context, it does not take into account the scenario where sensitive attributes are missing. Exploring this more challenging setting may open up the opportunity for a distinct idea to be explored.\\n\\nW3. The paper introduces several methods for linear and non-linear settings, suggesting that the choice should depend on the data distribution. However, it does not provide concrete guidelines as to how to make the choice.\\n\\nW4. Theorem 1 looks interesting, but the main body of the paper lacks technical discussion, not even including proof sketch.'},\n",
       " 'review_821': {'summary': 'In this paper, the authors propose an iterative training approach to improve image captioning models.\\nThis approach _refreshes_ the training dataset every epoch with _higher quality_ image-text pairs (authors call it \"data curation\").\\nDataset samples with very high training loss are updated -- the real image is replaced with one generated by the Stable Diffusion model.\\nThe authors compare their approach with two baselines: one which removes high-loss samples, and one where the image is replaced by another from the training dataset itself.\\nExperiments are performed with the BLIP model and two captioning datasets -- COCO and Flickr30K.\\nAuthors also perform an accompanying human study to provide directions for future work.',\n",
       "  'strengths': 'This paper has numerous technical strengths:\\n\\n- The proposed method is conceptually simple and easy to implement.\\n- The strategy of updating the training dataset with \"better\" samples is very general: it is agnostic to the model architecture and the multi-modal task at hand.\\n- The writing and presentation quality of the paper is excellent. It contains adequate implementation details to make this work reproducible.\\n- The experimental setup and ablation study is very meticulous. Tables of results contain experiments that begin with a BLIP baseline, and subsequent rows introduce one change at a time.\\n- The authors have conducted a human study with sensibly defined failure categories to understand how failure modes of Stable Diffusion can impact captioning performance.\\n',\n",
       "  'weaknesses': 'Like its technical strengths, this paper also has some shortcomings.\\nBelow I list a few salient concerns with the paper.\\nI look forward to hearing the authors\\' response, and I am happy to update my final assessment.\\n\\n1. **Results do not match with the presented story:**\\nThe main results (`Table 2`) indicate that all considered dataset curation approaches are beneficial over a BLIP baseline that doesn\\'t train on curated data.\\nHowever, the main pitch of this paper is to use generative models like Stable Diffusion to replace images (last row),\\nwhich in fact performs marginally better or even worse than other curation techniques.\\nThe biggest improvements are generally yielded by \"Remove\" strategy.\\nI recommend the authors rethink the positioning of motivation and frame it as an exploratory study --\\nit seems obvious to use generative models for iterative training/distillation and some works already do it for other applications,\\nbut for this task, a practitioner is better off by simply filtering noisy samples altogether.\\n\\n2. **Captioning metrics appear saturated, maybe overkill for COCO/Flickr:**\\nThe captioning metrics on COCO and Flickr are already saturated,\\ne.g. decimal improvements are less meaningful for COCO in the range of 130+ CIDEr and 20+ SPICE score.\\nSince BLIP is already rained with large amounts of data and diverse tasks,\\nthe proposed approach may be an overkill for the tasks considered in this paper.\\nI suggest the authors rethink other applications where the benefits of this strategy are more prominently observed (see Weakness 5 below).\\n\\n3. **What if the caption is noisy and can\\'t generate meaningful images?**\\nAn image-text pair may be unaligned if the caption is uninformative,\\nas frequently encountered in larger web datasets like\\n[Conceptual Captions](https://arxiv.org/abs/2102.08981),\\n[YFCC](https://arxiv.org/abs/1503.01817),\\n[RedCaps](https://arxiv.org/abs/2111.11431), etc.\\nFor instance, captions coming from alt-text may not have any semantic content whatsoever\\n(e.g. see Figure 2 in [ALIGN paper](https://arxiv.org/abs/2102.05918)) to generate meaningful images.\\nThe proposed approach forces the generative model to create an arbitrary image and ends up adding noise to the training data.\\nSome selective mechanisms to replace either image or caption may be needed to scale this approach to general image captioning beyond COCO and Flickr30K.\\n\\n4. **Related work needs more coverage:**\\nThe main focus of this paper is image captioning, hence a broad coverage of prior works on image captioning is necessary.\\nHowever, this section only cites a handful of very recent modeling papers.\\nI suggest the authors begin the discussion with some early image captioning papers like:\\n\\n  - (Vinyals et al, CVPR 2015) Show and tell: A neural image caption generator\\n  - (Karpathy and Li, CVPR 2015) Deep visual-semantic alignments for generating image descriptions\\n  - (Donahue et al, CVPR 2015) Long-term recurrent convolutional networks for visual recognition and description\\n\\n5. **[Related to 1, 2] Have the authors considered applications others than image captioning?**\\nWhat if this curation strategy is used to train general visual representations?\\nI suggest a CLIP-style contrastive model and/or BLIP/VirTex-style generative model.\\nThe contribution can be strengthened by broadening the scope to various downstream tasks.\\n'},\n",
       " 'review_822': {'summary': 'This paper focuses on improving image captioning by improving the quality of the existing dataset.\\xa0To this end, this paper proposes three data curation methods: the removal of an image–caption sample; replacing a caption with another caption; and replacing images using a text-to-image generation model. Experimental results demonstrate that models trained with the proposed methods consistently outperform baselines.',\n",
       "  'strengths': '1.The proposed method is well-motivated, that is to improve the quality of the existing dataset. This paper explores the problem of making better use of existing datasets, which is a very interesting research direction.\\n\\n2.The authors conduct extensive experiments over these two datasets, where the models trained with the proposed methods outperform baseline methods consistently.\\n\\n3.The paper is well-written and easy to follow.',\n",
       "  'weaknesses': '1.From my understanding, it is risky to judge the quality of the sample based on the loss value. A sample with a large loss value may be a hard sample or a mislabeled sample, so it is risky to judge the sample quality only based on the loss value.\\n\\n2.In addition to the performance of the model on the test set, the generalization ability of the model is also important.\\xa0It is not clear whether the proposed method reduces the gap between the training set and the test set or improves the quality of the training set.\\n\\n3.Lack of necessary theoretical analysis.'},\n",
       " 'review_823': {'summary': 'This paper proposes a data curation model for image captioning. If the loss of a particular image caption pair is high, then either remove the image-caption pair from the training set or replace the caption with a more similar caption or they generate a new image for the difficult caption. The authors demonstrate these strategies help to improve the performance of BLIP caption generation model.\\n',\n",
       "  'strengths': 'The idea is interesting.\\n\\nPaper shows some positive gains on COCO and FLickr30K.\\n',\n",
       "  'weaknesses': 'The details of the method are not clear. How to select a replacement caption?\\n\\nWhy one should pick only the high-loss image-caption pairs? Loss may be high due to many other reasons.\\n\\nCompared to other data augmentation methods in the literature that is also discussed in the related work, what is the novelty?\\n\\nWhy this is a significant finding? I am not sure if this is a significant finding. \\n\\nThe method is also evaluated using a single model. \\n\\nObtained results are not state-of-the-art.\\n\\nIt is not clear whether such a mechanism will contribute to any state-of-the-art methods in captioning.'},\n",
       " 'review_824': {'summary': 'This paper studies data curation strategies for training image captioning models. Firstly, it identifies the “difficult samples” based on the captioning loss dynamically at the end of each epoch. Subsequently, it introduces three data curation strategies to modify the difficult samples: (1) removal of an image-text pair, (2) replacement of the caption and (3) replacement of the image using text-to-image generative models. The main technical innovation is the third strategy, which is carefully designed in terms of prompt engineering and fine-tuning on the image captioning datasets.\\n\\nThe empirical studies show that the proposed data curation strategies can enhance the performance of the baseline BLIP captioning model. The authors also conduct analysis on the data curation ratio, dynamic versus static curation strategy and the errors of images generated by the stable diffusion model.\\n',\n",
       "  'strengths': '* The idea of employing text-to-image generative models to curate training data for image captioning is novel and well-motivated.',\n",
       "  'weaknesses': '### Effectiveness of the proposal\\n* According to Table 2, the performance of the third data curation strategy, which is the main technical innovation of this work, is not advantageous compared to the heuristic removal and caption replacement strategies.\\n* According to Figure 5, all three proposed strategies are sensitive to data curation ratio. Consequently, training the captioning model multiple times is necessary to achieve satisfactory performance, which is less efficient compared to the baseline BLIP model.\\n\\n### Design of the method\\n* Identifying the samples to modify based on training loss is questionable. A higher loss does not necessarily imply that the sample is harmful to training. Although Section 5.2 has shown that more errors are identified in images of higher loss, the experimental setup has two issues: (1) The loss is computed over the generated images rather than the real images in the original dataset. (2) The errors are categorized as targeting image generation, rather than image captioning. In other words, an image that possesses imperfect visual quality but aligns well with the caption may not necessarily be considered a noisy training sample for image captioning.\\n\\n### Missing reference\\n* An idea similar to the “round-trip captioning evaluation” is already proposed by [1], which generates a caption from the synthesized image and measures the similarity between input text and predicted caption.\\n\\n### Clarity\\n* In line 243, it is unclear whether the “model loss” refers to captioning loss or image generation loss.\\n\\n[1] Inferring Semantic Layout for Hierarchical Text-to-Image Synthesis.\\n'},\n",
       " 'review_825': {'summary': 'This paper focuses on data curation for image captioning. This paper shows that mismatched image-caption pairs do harm to the captioning model. To address this problem, generative models are used. In detail, the BLIP model is used to generate captions based on images, and the Stable Diffusion model is used to create images based on captions.',\n",
       "  'strengths': '1. The data curation is an important and effective topic, which could benefit many tasks including visual synthesis, image captioning, language and visual representation, etc.\\n2. This paper discovers the weak point of captioning datasets, especially for the Flicker30K.\\n3. It is interesting to use the BLIP model and the Stable Diffusion model to create data for training.',\n",
       "  'weaknesses': \"1. There are many methods to augment text dates, e.g., adding or editing some words, using synonyms, and changing sentence structure. I think these methods are also worth evaluating.\\n2. From Table 2, we can see that the BLIP's performance is not significantly affected by the methods proposed in this paper (i.e., Remove, ReplaceCap, and ReplaceImg). For example, the CIDEr of COCO only slightly raises from 132.0 to 133.1.\\n3. Figure 5 shows that the proposed methods might make the performance worse, especially in the COCO dataset. So I am concerned about the generalization of the proposed methods.\"},\n",
       " 'review_826': {'summary': 'In this paper, the authors propose a new model that can perform subject-driven text-to-image generation. Instead of fine tuning a leerte pretrained model on each subject, the authors use apprentice learning to first construct a virtual dataset from a large number of teacher models, each specific to a kind of subjects, and then have the student model learn from the constructed dataset. The authors have also shown strong qualitative and quantitative results and ablation study.',\n",
       "  'strengths': 'The paper is very well written and easy to follow. The results seem very promising. The paper tackles an interesting problem that is relevant to the applications.',\n",
       "  'weaknesses': '1. This paper could have been impactful if the authors plan to open source or provide a way to reproduce the results. However, from the checklist the authors indicate that they have no plan to open source the model. Given that this model is trained with hundreds of TPUs, unless the authors provide the pretrained model or explicit instructions on how to reproduce the results in a non-cost prohibitive way, I don’t really see a way for the peer researchers to verify the results, nor do I see any real benefits for the practitioners from this paper.\\n2. The authors performed human evaluations. However, details about the instructions given to human evaluators and the compensation are not provided.'},\n",
       " 'review_827': {'summary': 'The paper proposes an in-context learning method for model customization given personalized objects. The method first collects a large-scale dataset of custom concepts ensuring all images in each custom concept cluster are similar to each other and fine-tunes the model for each concept using Dreambooth. These expert models are then used to get the dataset to train the in-context learning method. It takes a few image text pair of the concept and a new text prompt to generate the image corresponding to the new prompt. The method is based on the Re-Imagen framework. To ensure high quality image text pair dataset from dreambooth models, CLIP based feature similarity threshold is applied. ',\n",
       "  'strengths': 'The method is one of the first works on in-context learning for model customization. This prevents the time-consuming step of fine-tuning models given any new subject images. Both qualitative and quantitative results show that the method performs on par or better than existing zero-shot or fine-tuning methods.  \\n\\nThe paper is well-written, easy to understand, and has extensive ablation experiments to validate the importance of different aspects of the method. \\n',\n",
       "  'weaknesses': \"Why is there a need to train the Dreambooth expert models for training the final SuTI model? How does the performance change if the collected dataset itself is used directly to train the final model with N-1 image text pairs for in-context input and 1 sample as the new inference? It would be great to have an analysis regarding that. \\n\\nOther objects included in the image often take the characteristics of the main subject, e.g., kite in Figure 10 2nd column last row or the british shorthair cat in Fig. 9 1st column last row in the appendix. Does adding a specific characterization in the text prompt for the other subject prevent that? Or is it overfitting in such scenarios? Does having more in-context demonstrations prevent that? \\n\\nCan it be combined with other editing-based methods like SD-Edit or similar approaches to edit a specific region of the image or combine multiple specific subjects in the same image? E.g., to generate the canine dog of Figure 5 eating the cherry bowl of Figure 4. The editing example shown in Figure 5 changes the whole image instead of just the birds in the TV show.  \\n\\nAnother point I would like to make is that it would have been great to also show the performance of SuTI with the SD backbone. This is not a weakness per se, and it doesn't affect the final rating. It's excellent work, but it would be helpful to assess the method's performance on such open-source models. Some of the baseline methods shown in the paper are already with the SD backbone. \\n\"},\n",
       " 'review_828': {'summary': 'This paper introduces SuTI for the subject-driven text-to-image (T2I) generation method. Numerous expert models are first trained on millions of image clusters collected from the internet, each focuses on a specific visual subject. A dataset is then created, consisting of concept images, target prompts, and corresponding target images. By training the apprentice model on this dataset, SuTI can generate high-quality and customized subject-specific images without the need for test time fine-tuning. Both the qualitative and quantitative experiments are performed with the baselines.',\n",
       "  'strengths': '- The presented method is well-motivated and easy to understand.\\n- SuTI demonstrates fast generation and has a broad domain of applicability.\\n- The paper includes extensive experimental evaluations with impressive results.',\n",
       "  'weaknesses': 'Some details of the experiments require clarification:\\n\\n- The hyperparameters used for training the baselines, such as the number of training iterations and learning rates, should be provided.\\n- More information is needed regarding the human evaluation, including the number of questions, the number of evaluated images, and the number of users involved.'},\n",
       " 'review_829': {'summary': 'The paper presents a novel subject-driven text-to-image generator named SuTI. This model leverages in-context learning as opposed to subject-specific fine-tuning. SuTI is built upon the principles of apprenticeship learning and is capable of generating high-quality, customized, subject-specific images. Remarkably, it achieves this at a speed that is 20 times faster than optimization-based methods.\\n\\nSuTI has demonstrated superior performance over existing models on benchmark tests such as DreamBench and DreamBench-v2. The paper highlights the recent advancements in text-to-image generation models, which have shown significant progress in generating highly realistic, accurate, and diverse images from given text prompts.',\n",
       "  'strengths': \"The paper exhibits several strengths across the dimensions of originality, quality, clarity, and significance:\\n\\n1. Originality: The paper introduces SuTI, a novel subject-driven text-to-image generator that uses in-context learning instead of subject-specific fine-tuning. This approach is original and innovative, as it deviates from the conventional optimization-based methods, offering a faster and more efficient solution.\\n\\n2. Quality: The quality of the paper is evident in the rigorous testing and validation of the SuTI model. The model has been benchmarked against existing models on DreamBench and DreamBench-v2, where it has shown superior performance. This demonstrates the robustness and reliability of the model.\\n\\n3. Clarity: The paper is well-structured and clear in its presentation of the SuTI model. It provides a comprehensive explanation of the model's workings, its applications, and its performance in various tests. The use of visual aids and examples further enhances the clarity of the paper.\\n\\n4. Significance: The significance of the paper lies in its contribution to the field of text-to-image generation. By introducing a faster and more efficient model, the paper pushes the boundaries of what is currently possible in this field. This could have far-reaching implications for a variety of applications, including content creation, design, and more.\",\n",
       "  'weaknesses': 'One weakness of the paper is the lack of discussion around the cost and complexity of constructing the training dataset. The process of creating a comprehensive and diverse dataset for training a model like SuTI can be a significant undertaking, both in terms of time and resources.\\n\\nThe paper does not delve into the specifics of this process, leaving readers without a clear understanding of the potential challenges and costs associated with data collection and preparation. This lack of transparency may make it difficult for others to replicate the study or apply the model in different contexts.'},\n",
       " 'review_830': {'summary': 'This paper proposes a method for subject-driven text-to-image generation, where a model is tasked to generate novel renditions of a subject given a few images of that subject. Different from previous fine-tuning approaches, this paper trains a model that conditions its generation on the given subject images. To train such a model, this paper first trains a large amount of subject-specific fine-tuned models, and use these fine-tuned models to generate new training data for knowledge distillation. The distilled model achieves good qualitative performance.\\n',\n",
       "  'strengths': '- It is nice that the apprenticeship model does not require finetuning on new subjects. It is an interesting idea to directly use subject images as the conditional input for generation.\\n- The paper is mostly well-written.\\n- The learned model achieves good qualitative results.',\n",
       "  'weaknesses': \"- The training data covers a wide range of subjects. Therefore, it is hard to tell if the apprenticeship model learns to generalize to new subject or not. Have the authors performed de-duplication to ensure that the subjects used for evaluation do not appear in the training set of the expert models?\\n- The proposed method requires training of 2M expert models, where each expert is a 2.1B Imagen model. This is extremely expensive both computational-wise and storage-wise. \\n- The inference speed of the apprenticeship model seems to be slow, as each demonstration sample needs to pass through the Imagen model. Methods such as DreamBooth do not incur additional inference cost after the finetuning.\\n- It would be nice to see some ablation on the importance of the expert model. For each subject cluster, how many synthetic images are used to train the apprenticeship model? What if only the real images are used to train the apprenticeship model?\\n- It would be better if the paper could give a more detailed illustration of the apprenticeship model's architecture, instead of referring to the ReImagen paper. \\n\"},\n",
       " 'review_831': {'summary': 'The paper proposes a factorization model to extract P pairs of latent components from a multivariate time series such that in each pair one of the time series Granger causes the other. The authors apply the approach in analysing EEG and fMRI data to show meaningful conclusion.',\n",
       "  'strengths': 'The paper addresses an interesting problem of finding latent variables with Granger causal structure from a multivariate time series. The paper is generally well written.',\n",
       "  'weaknesses': 'Although the paper proposes an intriguing approach for finding latent causal structure, in general, it might be limiting since it only considers structure with pairwise time series demonstrating causal influence on each other while in practice we would expect multiple time series potentially affecting each other. Can the authors elaborate the effectiveness of the assumed latent structure a bit more?\\n\\nThe simulated data does not provide complete insight of the performance of the method. It might be useful to explore more realistic situation such as more time series, more intricate (conditional) causal influences among multiple time series, and/or situations where the proposed model might fail to capture causality, e.g., one time series driving more than one time series. This might be helpful in better assessing any false positive detections and false negative misses.\\n\\nIt will be useful to compare the proposed method to standard conditional Granger causality on the real dataset to extract the underlying causal structure and assess if it is similar to the one inferred by the proposed approach.'},\n",
       " 'review_832': {'summary': 'This paper proposes a novel (blind) source separation method that extracts pairs of components from multivariate time series between which Granger causality (GC) is maximal. This can be a very useful tool to assess direction information flow between brain areas in an unsupervised way, without having to specify the areas a-priori. The method is very elegant and implemented in a straightforward way by setting up a corresponding optimization problem and solving it via block-coordinate descent alternating between updates of the projection vectors for the sending and receiving source. Analytic gradients are provided but also autograd is reported to work well. An interesting deflation scheme is also provided whereby the sending source is projected out in each step. Thus, the same sending source cannot be found in multiple GC component pairs, but the (residual) of a sending source can play a role as either sender of receiver in a subsequently extracted pair. The method also implements time-reversal, a method to robustify GC estimates with respect to artifacts of volume conduction. A small set of simulations illustrates the convincing properties of the method, and a convincing application to motor-imagery brain-computer interface data is also provided. ',\n",
       "  'strengths': 'The paper proposes an elegant and potentially useful method. The derivation of the method is easy to follow, apart from minor gaps. The technical parts are sound. The simulations and real data results are convincing and provide a good picture of the capabilities of the method. The writing is clear. Overall, a nice and self-contained paper.',\n",
       "  'weaknesses': 'The simulations and real data analyses could be better developed. The simulations could be more quantitative, e.g. studying 100 systems instead of only one, and reporting distribution of reconstruction metrics. The impact of factors such as the SNR could be systematically studied, and different types of noise could be studied. More methods could be included in the empirical comparisons. For example, BSS methods like MVARICA [1] and SCSA [2] do not assume independent components but model the sources exactly by an MVAR model, from which GC between every pair of components can be assessed. In the BCI context, the extraction of class-specific sources using CSP [3] or SMR oscillations using SSD [4] could be compared to the proposed method. Although I understand that not for all methods working code may be found. \\nTheoretically, it would be critical to also discuss the identifiability of the model. Linear mixtures of MVAR processes are again MVAR models and a valid question is why the maximization of GC should provide the “true” unmixing. This is especially critical as research has shown that even a mixing of independent sources can induce spurious GC [5-9]. Moreover, no non-Gaussianity of residuals as in [2] is assumed to guide the reconstruction.\\n\\n[1] https://www.sciencedirect.com/science/article/abs/pii/S1053811908008549\\n[2] https://ieeexplore.ieee.org/abstract/document/5466024\\n[3] https://ieeexplore.ieee.org/abstract/document/4408441\\n[4] https://www.sciencedirect.com/science/article/abs/pii/S1053811914005503\\n[5] https://www.sciencedirect.com/science/article/abs/pii/S1053811912009469\\n[6] https://www.sciencedirect.com/science/article/abs/pii/S105381191401009X\\n[7] https://ieeexplore.ieee.org/abstract/document/7412766\\n[8] https://link.springer.com/article/10.1007/s10548-016-0538-7\\n[9] https://www.frontiersin.org/articles/10.3389/fncom.2016.00121/full\\n'},\n",
       " 'review_833': {'summary': 'The paper formulates the problem of learning a pair of spatial projections that optimize a criterion based on the Granger causality between the resulting components, which is itself based on regressing the first, driving, component to the second, driven, component using a Wiener filter and the converse for the time-reversed signals. A block coordinate descent algorithm is proposed to solve for one spatial projection while the other is fixed and vice versa. Experimental results on EEG and resting state fMRI data illustrate the identification of meaningful spatial filters. \\n\\n ',\n",
       "  'strengths': 'The paper is well motivated, well written, and clear.\\n\\nSynthetic experiments are simple but results are convincing. \\n\\nThe method is applied to two different modalities of neuroimaging data and paradigms (EEG during motor imagery tasks and resting state fMRI) and the results are discussed in depth. ',\n",
       "  'weaknesses': 'Explicit statement of the assumptions about the nature of the relationship (linear or non-linear), time-invariant, etc. is lacking. Standard Granger causality assumes a linear, time-invariant relationship. These assumptions should be stated when introducing the pairs in (2). \\n  \\nThe algorithm could be made more succinct by removing some of the redundancies. \\n\\nMinor: \\nLine 79 should be clarified that $\\\\mathbf{y}_p(t)$ is also lagged form. \\n\\nLine 93 variables should be defined. I assume that there exists scalar $c$ for any choice of $a$ and $b$. \\n\\nOn line 114, the statement \\'the driven signal is not explicitly removed.\\' is a bit misleading. While it is not removed the explainable variance associated this component is removed by the filtering (spatiotemporal regression).\\n\\nIn algorithm 1, the dependency between the cost function $J$ and $\\\\mathbf{X}$ is not explicit. \\n\\n*Nit picks:* I find the capitalization of methods beyond proper nouns a bit jarring. \"Granger Causlity\" -> \"Granger causality\". \"Kernel CCA\" -> \"kernel CCA\". \\n\\nLines 70, 81 closing double quotes are wrong direction.\\n\\nLines 132–133 and 160–161 \"We asked GCA\" seems odd phrasing. '},\n",
       " 'review_834': {'summary': 'This paper presented a novel unsupervised learning approach using Granger Causality by identifying the driving/driven components. This method was demonstrated on EEG and fMRI data, in coincide with the neurophysiological facts.\\n ',\n",
       "  'strengths': 'The paper proposed an algorithm to identify the pairwise causal structure between latent variables from a multivariate observational data set and the results are supprted by simulation data and empirical data.',\n",
       "  'weaknesses': '1)  The number of latent variables is a key parameter for this unsupervised learning, however it is pre-defined without any adaptive mechanism. similarly, no adaptive mechanism for L. \\n2) The literature is outdated and there is no performance comparison against similar algorithms for causal inference. PCA and ICA are not algorithms for causal inference. \\n'},\n",
       " 'review_835': {'summary': \"The paper proposes an implementable and concrete version of Li et al's infinite dimensional fidelity DE, an method of fusing simulations at different levels of fidelity/resolution, to trade off between computational tractability and statistical accuracy.\",\n",
       "  'strengths': 'if i understand correctly the \"infinite-fidelity\" model of Li et al has many attractive data fusion properties for varaible-resolution simulation, but is not implementable.\\nThe claim of this paper is that an this specific parameterisation to the infinite-fidelity approach can be implemented with the GP induced by a linear ODE with a GP prior over functional inputs (to the ODE), which induces a GP posterior. Some fancy work with inducing points is done to make this tractable in practice.',\n",
       "  'weaknesses': 'many small typos, and some odd phrasing that undermine my confidence in the results. See questions.\\n\\nThe paper seems not to be about design of experiments but rather sharing uncertainty between low and high-fidelity simulations that have already been performed, and yet lacks a justification for the informativeness of the low-fidelity simulations.\\n\\nI suspect this paper could be great with some typo- and bugfixes, but in the current form I hesitate recommend with confidence. There are too many confusing things to be sure I have understood the paper correctly.\\n\\nI think a simple diagram or two could have made this much clearer.'},\n",
       " 'review_836': {'summary': 'This paper presents a Gaussian process (GP) based multi-fidelity model that makes use of fidelity indicators. This paper extends the autoregression two-fidelity formulation to a linear fidelity differential equation. By assuming the lowest fidelity function and all the residual functions follow GP, a joint GP model of all the fidelity can be derived. To allow flexible kernel choices, the integral in the kernel function is approximated with Monte Carle samples. In the case of multi-dimensional observations, the proposed model assumes a coregionalization formulation. To further speed up inference, the proposed model relies on the assumption that the inputs of high fidelity are a subset of the inputs of low fidelity. The proposed method compared to state-of-the-art multi-fidelity methods on both synthetic and real data sets and shows significant improvement on mean prediction accuracy. \\n',\n",
       "  'strengths': '- This paper extends the common autoregression multi-fidelity formulation to a linear  linear fidelity differential equation, which results in a joint GP model over the observations of all the fidelity.\\n- The proposed method makes an explicit assumption about the role of fidelity indicator in the model, which allows it to use this information for modeling.\\n- With a sophisticated GP model, the proposed method requires less training time and works better with low data compared to the neural network based multi-fidelity method.\\n- The proposed method significantly outperforms state-of-the-art multi-fidelity methods on both synthetic and real data.\\n',\n",
       "  'weaknesses': '- The modeling assumption in the linear fidelity differential equation formulation is quite restrictive, which may not be applicable for many real world problems. For example, this model is not very effective if low fidelity data is only good at certain area, i.e., the knowledge transferring factor needs to depend on input x.\\n- For simplicity, the proposed method assumes that $\\\\beta(t)$ is a constant. This means that the knowledge transferring factor is full determined by the fidelity indicator, which may be too restrictive for the use case where the fidelity indicator only shows the order of fidelity not the relative quality.\\n- The proposed method jointly models the observed data of all the fidelity under a single GP model, which does not scale well when a lot of data are available.\\n'},\n",
       " 'review_837': {'summary': 'Multi-fidelity models are widely used for combining training data obtained from information sources with different degrees of precision or accuracy. More specifically, this allows for the combination of greater quantities of noisier but more cheaply-obtained examples with more faithful (but limited) data. In this work, the authors describe an extension to infinite-fidelity fusion that incorporates information contained within the fidelity indicator itself, while also mitigating issues relating to training time and complexity, as well as scalability to high-dimensional outputs. The authors also formulate a surrogate model than unifies a large selection of pre-existing multi- and single-fidelity models. Experiments on synthetic and real-world data indicate that the model obtains significant performance improvements over competing techniques, without incurring an unreasonably large speed penalty (compared to IFC).',\n",
       "  'strengths': '- The problems investigated in this work, along with the associated solutions, are non-trivial, and the authors diligently include detailed derivations for all their contributions. \\n- The improvements over IFC are well-motivated in this work, and I appreciated how there was a strong emphasis on computational complexity and training stability. Both of these are highly prized by practitioners, and I would expect the performance improvements reported here to be transferrable to other problem domains as long as the training process is stable.\\n',\n",
       "  'weaknesses': '- The paper is currently quite dense and difficult to follow at times. While I appreciate that the authors present several varied contributions here, I believe the presentation of the main paper could be improved further to highlight the key takeaways while deferring detailed derivations to the supplementary.\\n- The paper bears very strong writing similarities to *GAR: Generalized Autoregression for Multi-Fidelity Fusion* by Wang et al., where some sentences are nearly copied in their entirety with only a single word replaced here and there. This is especially noticeable in the *Introduction* and *Background* sections of the paper, as well as some of the *Related Work*. The contributions themselves are different, although I am surprised that this 2022 paper is only given a cursory reference given the degree of similarity in the problem statement and experimental set-up.\\n- Maybe I missed this while reading the paper, but while is the IFC method listed as IFC-GPT in the figures and tables?\\n- A handful of limitations for this method are listed at the very end of the paper, but these currently come across as an afterthought. I would prefer to see additional ablation studies or synthetic examples showing specific situations where the proposed models may not work as well as expected.\\n'},\n",
       " 'review_838': {'summary': 'The author proposes a general auto-regression model for multi-fidelity fusion. By simplifying the ODEs over the fidelity indicator in a linear form, close-form solutions can be derived. And the computational efficiency can be further improved using a rank-1 approximation. The experiment results also show superior performance of the method. ',\n",
       "  'strengths': '1. A general linear fidelity differential equation is proposed. It serves as an simplified version of IFC and generalized version of IMC.\\n2. Close-form solutions provide a more efficient way to conduct multi-fidelity fusion with infinite fidelities, especially for high-dimensional problems.\\n3. The effectiveness of this approach is demonstrated through the testing of both simulated and real-world data.\\n4. The paper exhibits a clear structure and is straightforward to comprehend.',\n",
       "  'weaknesses': '1. In experiment section, it seems the baseline methods are tested with default settings without fine tuning. The comparisons are not completely fair.\\n2. One big benefit using the ODE formulation is to extrapolate since the ODE formulation can capture the underlying dynamics between different fidelities. In the paper, there is no discussion regarding this matter.\\n3. \\\\eta is set 0.5 and 0.75 in all experiment settings. It might be a bit high.'},\n",
       " 'review_839': {'summary': 'The paper proposes a novel Bayesian causal discovery (BCD) method that infer the posterior distribution $p(G|\\\\mathcal{D})$ by projecting the DAG $G$ into an equivalent search space. Instead of sampling $G$, the method constructs the posterior distribution by sampling a binary matrix $W$ and potential vector $p$ with via MCMC sampling and variational inference. The Bayesian causal discovery method can scale up to 100 variables and achieves better accuracy on large datasets.',\n",
       "  'strengths': '- The idea of employing the projection framework from DAG-Nocurl paper is interesting. Especially, the difficulties of the sampling based posterior distribution estimation for DAG learning methods lie in the order of parents sampling. The potential function p automatically reserves the causal order.\\n\\n- The proposed method is a combination of sampling-based method and variational inference method. Compared to the state-of-art BCD methods that adopt VI, the proposed method achieves better SHD, especially on high-dimensional data.',\n",
       "  'weaknesses': '- (**Major**) The experiments are not comprehensive. There is a trade-off between efficiency and accuracy compared sampling-based approach to VI approach. Compared to the existing VI-based BCD methods, It is possible that the proposed approaches are more accurate but also suffer from low efficiency. Please refer to the question section for details.\\n\\n- (**Minor**) The tuning of hyperparameters such as scale of p and theta. Since the original framework of DAG-Nocurl is derived for continuous parameterization, the algorithm requires the tuning of additional hyperparameters, which increases the training difficulty. But I understand this is a minor concern.'},\n",
       " 'review_840': {'summary': 'The paper proposes a Bayesian causal discovery method based on a novel parametrization of the binary DAG space and SG-MCMC. The proposed method does not rely on DAG regularization nor restricted to linear models, overcoming the limitations of prior approaches. Experimental results demonstrate the competitive performance of the proposed method compared to existing approaches.\\n',\n",
       "  'strengths': 'The paper is well-written and easy to understand. It is easy to follow the core idea of the proposed method.\\n\\nThe proposed method is sound and well-motivated (i.e., there are apparent limitations of previous work but this method overcomes such issues.)\\n\\nSeveral techniques are employed smoothly to propose the method.\\n\\nExperimental results demonstrate the effectiveness and scalability of the proposed method.\\n',\n",
       "  'weaknesses': 'For the empirical evaluation, comparison with MCMC approach [1] is missing. Also, AUROC is not reported, which is widely used for the evaluation of uncertainty quantification in Bayesian causal discovery literature.\\n\\nThe proposed method is claimed to be scalable and computational complexity is analyzed, but the actual computation cost (e.g., wall clock time) is not compared with DiBS. Computation resources they used are also not provided (e.g., CPU, GPU).\\n\\nSimilarly, “per node degree 2” seems very limiting which results in a very sparse graph for large d. Large d will certainly affects the performance of likelihood computation and posterior sampling of W where more edges may demonstrate dependencies.\\n\\n[1] Improving markov chain monte carlo model search for data mining, 2003\\n'},\n",
       " 'review_841': {'summary': 'The authors propose a method for the posterior inference of DAG structure *and* function parameters with potential applicability to arbitrary functional relations between nodes. The authors modify a novel characterization of DAGs, and interpret this characterization in terms of a sorting operation which can be relaxed to allow differentiability. The authors define priors on DAGs (in the alternative space) and function parameters and based on a specific model choice characterize likelihood. They use the resulting joint distribution to iteratively sample some parameters and conduct variational inference re. others. The authors examine the performance of their proposed methodology on various synthetic and real datasets.',\n",
       "  'strengths': '- The paper is very well written. It presents the previous work, motivation for current research, and reasoning behind methodological choices very clearly.\\n- The paper utilizes recent, previous research intelligently and presents concrete innovations to solve well-defined problems.\\n- Posterior inference in the DAG structure and parameter space without some of the limitations of previous work is valuable and is likely to inspire future work.',\n",
       "  'weaknesses': '- DAG model selection results have causal implications given specific model assumptions regarding generative model of the data. ANM is such a model assumption. However, it is unclear whether the identifiability results still apply in this case, given the priors defined on DAG structure and function parameters. I think the authors\\' work still would be valuable as only a DAG inference method; however, since the authors present their proposal as a causal discovery + inference method, this point needs further discussion.\\n- I think the authors\\' presentation should be modified to make sure their inference method is more clearly understood. Given their initial presentation, including \"posterior sampling\" in the title, and frequent reference to Gibbs sampling throughout the text, leads the reader think that the authors will present results with a correct MCMC algorithm and produce a full posterior distribution. However, most promising results presented by authors include their iterative algorithm that samples from the posterior of some parameters and uses variational inference for others. This is fine as a methodological choice, but their presentation leads the reader to have higher expectations, which can become crucial depending on the use case of the reader.\\n- Causal sufficiency assumption prevents using the current method in problems where unobserved confounding is likely. In my opinion this is acceptable given the difficulty of the problem.'},\n",
       " 'review_842': {'summary': 'BayesDAG proposes a hybrid SG-MCMC sampling and variational inference for drawing samples from the posterior distribution of DAGs in the context of Bayesian structure learning. \\nThis work is closely related to a recently published \"Yu et al., Dags with no curl, 2021\" [NoCurl] where the space of DAGs is converted to the space of a skew-symmetric matrix, \"W\", and a potential vector,\"p\".\\nThe main difference is that [NoCurl] focuses on an optimization setting (to return a most probable DAG) while the focus of the current paper is on Bayesian inference (via sampling). \\nThey also mention that (for reasons that are not entirely clear to me) NoCurl approach optimization is challenging (due to uninformative gradients) and that this is due to the fact that the entries of the skew-symmetric matrix, W are continuous. \\nTo address this problem, they replace the continuous matrix W with a binary matrix. \\nFor this purpose, they slightly modify the theory presented in NoCurl (namely, replacing relu with step function). Then they reformulate the problem as a  matrix permutation setting and finally propose an approximate solution for the latter formulation via Sinkhorn approach to learn latent permutations by the Gumble trick.    ',\n",
       "  'strengths': '1. This is a well-written paper addressing an important problem i.e. Bayesian structure learning.\\n2. The proposed approach is an interesting (albeit sophisticated) combination and modification of several algorithms and recent advances in the field.\\n3. Even though I did not follow why the continuous matrix W had to be replaced by a binary matrix in the first place, but I found the way they did it and managed to approximate its gradient, very interesting.  \\n ',\n",
       "  'weaknesses': '1. As I mentioned in the summary section, a key contribution of this paper is the insight that it is better to replace the continuous matrix W (of NoCurl algorithm) with a binary matrix (see lines 101-104). But their justification for this claim does not seem convincing to me and should be explained better. To be more concrete: \\n(a) Why should replacing a continuous matrix with a discrete matrix be helpful when we are relying on gradient information for optimization and sampling? \\n(b) In line 100 they mention a \"reported failure\" of NoCurl. It would be great if the authors would provide a reference to where this failure is reported (Or if it is reported in the original NoCurl paper, the relevant section). \\n\\n2. Given the close link of the present paper with the NoCurl approach, it would be great if the authors would compare their algorithm (with binary W) with an alternative approach where just like NoCurl, a continuous W would be used (and relu instead of step function, etc).    \\n\\n3. I see references to repositories that the authors have used but no link to their own code. Given that implementation of the proposed algorithm from scratch is by no means trivial, I encourage the authors to provide the code. Both for facilitating other researchers to use their algorithm as well as allowing the reviewers to check the reproducibility of the reported results.\\n\\n\\n'},\n",
       " 'review_843': {'summary': 'This paper investigates how to improve the robustness of a model under adversarial attacks while ensuring its Average Precision (AP) on clean data samples. This studied problem can be very important in some application scenarios but has not been extensively explored yet. By integrating the idea of existing adversarial training based methods into AP maximization algorithms, a novel solution is proposed in this paper. Experimental results obtained on multiple datasets with various binary imbalanced settings demonstrate the superiority of the proposed solution in terms of AP and robustness, comparing with baseline methods, which only focusing on optimizing either AP or robustness of models.\\n',\n",
       "  'strengths': '1. The problem explored in this paper, i.e., enhancing model robustness while maintaining AP, is a practical and important problem in some application scenarios but has not been well studied, as related works only focused on improving either model robustness or model AP.\\n2. A novel solution is proposed in this paper by integrating existing adversarial training methods with AP maximization algorithms. Experimental results including performance comparison and ablation studies verify the effectiveness of the proposed solution.',\n",
       "  'weaknesses': \"1. To provide a more comprehensive perspective to evaluate the robustness of trained models, stronger attack methods, such as AutoAttack, should be included in experiments.\\n2. Authors didn't discuss limitations of the proposed solution. Based on the description in the methodology part, the training efficiency of the proposed solution may be a problem.\"},\n",
       " 'review_844': {'summary': 'This paper extends the discussion of adversarial robustness from accuracy to precision, and also extends TRADES solution to this new setting. The paper is fairly standard, with a new problem, a new solution, some minor theoretical studies (obviously also extended from TRADES), and some fairly good empirical results. The paper is highly condensed, so several critical points need further clarification. ',\n",
       "  'strengths': '- The paper interestingly studies a new problem of precision in the adversarial setting. \\n\\n- The paper introduces a new algorithm to achieve the listwise regularizations',\n",
       "  'weaknesses': \"1. the empirical method and theoretical discussions are extended from TRADES, which might raise some concerns about the novel contributions of this work. \\n\\n2. the experiments are only conducted against FGSM attack, this is probably too limited, especially since there are several cases the performances are fairly close. \\n    - please also use PGD and autoAttack. \\n\\n3. the an essential step of the algorithm is the approximation in Section 4.2, it's probably necessary to offer more empirical results on this regard, such as ablation studies with varying batch sizes. \"},\n",
       " 'review_845': {'summary': 'This paper considers the adversarial robustness of the AP metric, which is an important measure of deep learning under some imbalanced applications. To do this, the authors develop a novel formulation that combines an AP surrogate loss with a regularization term toward adversarial ranking robustness, maintaining the consistency between the ranking of clean data and that of perturbed data. Empirical studies demonstrate the effectiveness of the proposed methods.',\n",
       "  'strengths': 'To the best of our knowledge, this is the first work to consider the AP-based adversarial robustness problem, which will bring some new insights to the adversarial robustness community.\\nThe contributions of this paper are novel and the theoretical results are technically sound.\\nThe empirical results are also promising.',\n",
       "  'weaknesses': 'However, some essential issues should be fixed:\\n1. During the evaluation, this paper merely considers the simple FGSM-based attack manner, which is insufficient to support the effectiveness of the proposed method. Some stronger attacks, such as PGD-based and AutoAttack [1], should be considered.\\n2. Another minor question is how AP-based AT impacts the performance of accuracy-based AT. Can the proposed methods improve AdAP without sacrificing overall accuracy? Because merely considering AP while overlooking accuracy may be meaningless.\\n3. Why do we need to develop AdAP? What are the differences between AdAP and AdAUC in the ranking performance? Please give me some intuitive examples like Fig.1\\n4. Finally, some latest advanced AP optimization methods are missed, such as [2].\\n\\n\\nRef:\\n[1] Reliable Evaluation of Adversarial Robustness with an Ensemble of Diverse Parameter-free Attacks.\\n[2] Exploring the algorithm-dependent generalization of AUPRC optimization with list stability. '},\n",
       " 'review_846': {'summary': 'The paper focuses on adversarial training in terms of Average Precision (AP), which is guided by three design principles: trade-off between AP and robustness, robustness in terms of AP instead of accuracy, and consistency of attacks. By utilizing the techniques of stochastic compositional optimization, the paper proposes a series of adversarial training algorithms to handle the inter-dependent perturbations.',\n",
       "  'strengths': '1.\\tNovelty: To the best of our knowledge, it is the first work to consider adversarial training of AP. It is a non-trivial extension due to the non-decomposable formulation of AP.\\n\\n2.\\tSignificance: As a widely-used ranking metric, the robustness of AP is significant to the machine learning community. Besides, the design principles and techniques might be instructive to the robustness of other ranking metrics.\\n\\n3.\\tClarity: The paper is overall well-written with clear notations.\\n\\n4.\\tSoundness: The effectiveness of the proposed method is well-supported by experiments under various settings.\\n',\n",
       "  'weaknesses': '1.\\tThe authors solve a non-zero-sum game to ensure consistency. However, unlike previous work on adversarial training, the equilibrium state of this game is unknown and requires more discussion.\\n\\n2.\\tFig. 2 provides a visualization of the trade-off between robustness and AP, but how the hyperparameter $\\\\lambda$ affects the trade-off is unclear. Ideally, it should present a positive correlation.\\n\\n3.\\tThe related work could be further improved by discussing the latest literature on AP stochastic optimization such as [1,2].\\n\\nRef:\\n\\n[1] Wang et. al. Momentum accelerates the convergence of stochastic auprc maximization. ICML, 2022.\\n\\n[2] Wen et. al. Exploring the algorithm-dependent generalization of auprc optimization with list stability. NeurIPS, 2022.\\n'},\n",
       " 'review_847': {'summary': 'This paper studies the average precision issue in adversarial training. As attacking a single image may not affect the final accuracy, the average precision could be largely decreased. As a result, such a phenomenon is demonstrated to be harmful to applying adversarial training. To encourage AP robustness, a novel method is proposed by combining adversarial training and AP maximization. Additionally, by adding point-wise regularization, different variants are proposed. Through empirical analysis of many well-known datasets, the authors carefully validate the effectiveness of the proposed methods.',\n",
       "  'strengths': '- This paper is well-written and can be easily understood.\\n- The effectiveness is great on many datasets.\\n- Detailed analysis of many variants of AdAP is provided.',\n",
       "  'weaknesses': '- The major concern is the motivation of this paper. Why average precision is important in adversarial training is not sufficiently addressed. It seems like the research problem is ad hoc such that the proposed method could directly combine adversarial training and maximum precision. In the real world, I don’t think attacking a single example is worth investigating, and the described situation exists ubiquitously. Moreover, it is possible that in many realistic scenarios, the difference between the average accuracy and average precision might not be very large. Please justify.\\n\\n- I am not sure why two regularizations AdAP_MM and AdAP_PZ should be proposed together when the first one does not have a significant advantage compared to the last one.\\n\\n- The proposed method is limited to binary and imbalanced classification settings, which are strict on the problem setting. The performance of multi-class or balanced adversarial training is still questionable.\\n\\n- How does the hyper-parameters $\\\\lambda$, $\\\\gamma_1$ and $\\\\gamma_2$ are decided? Are they sensitive to different values?'},\n",
       " 'review_848': {'summary': 'The paper presents VillanDiffusion, a framework for analyzing backdoor attacks on different types of diffusion models (DMs). VillanDiffusion covers various DM configurations such as unconditional and conditional DMs or training-free samplers and provides new insights into caption-based backdoor attacks. ',\n",
       "  'strengths': '+ originality, the paper presents a unified framework for analyzing backdoor attacks on DMs, covering various configurations and training-free samplers. the soundness of this paper is also noteworthy, with detailed proof in Appendix.\\n\\n+ The experiments are comprehensive and demonstrate the effectiveness of the VillanDiffusion framework in detecting backdoor attacks on DMs.\\n\\n + The paper is well-structured, with each section building on the previous one, making it easy to follow.',\n",
       "  'weaknesses': '- the effectiveness of their backdoor attack on Celeba is limited: the increased FID score is huge in this scenario, which does not show the advantage of their method against other baselines.'},\n",
       " 'review_849': {'summary': 'This paper proposes a universal backdoor attack framework on diffusion models facing different kinds of content schedulers, different kinds of samplers, and conditional and unconditional tasks.',\n",
       "  'strengths': '1. This paper proposes a universal backdoor attack framework on diffusion models, which are important.\\n2. The experiments are sufficient.\\n3. This paper is well written and technically sound.',\n",
       "  'weaknesses': '1. From my point of view, backdoor in diffusion models is an end-to-end process, can you explain the main difference from some prior works in diffusion models such as [1]? If the only difference is to test on different diffusion models, the contribution is limited.\\n2. There is no comparison with the former methods, and thus I cannot find out whether there is improvement in backdoor attack.\\n3.There are some flaws such as line 191 learns should.\\n\\n\\n\\n[1] Chou S Y, Chen P Y, Ho T Y. How to backdoor diffusion models?[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023: 4015-4024.'},\n",
       " 'review_850': {'summary': 'This paper proposed a backdoor attack framework called VillanDiffusion, which extends the existing backdoor analysis capabilities for deep models (DMs). By encompassing both unconditional and conditional DMs, including denoising-based and score-based models, as well as incorporating training-free samplers, the proposed framework enables holistic evaluations of backdoor attacks. Experiments demonstrate that VillanDiffusion not only facilitates the analysis of diverse DM configurations but also offers valuable insights into caption-based backdoor attacks on DMs. ',\n",
       "  'strengths': 'The paper is written in a clear and understandable manner, making it accessible to a wide range of readers. The authors effectively convey their ideas and concepts, ensuring that the content is comprehensible. Besides, the authors provide a thorough analysis of backdoor attacks on deep models and propose a unified approach, VillanDiffusion.',\n",
       "  'weaknesses': 'There are concerns regarding the effectiveness of the VillanDiffusion framework The framework proves to be effective when the poison ratio reaches up to 20%, which is significantly higher than what is typically observed in other tasks. This discrepancy raises doubts about the practicality of the framework, emphasizing the need for further investigation and evaluation across various tasks and poison ratios to ensure its broader applicability.'},\n",
       " 'review_851': {'summary': 'This paper presents a unified backdoor attack framework (VillanDiffusion) to expand the current scope of backdoor analysis for DMs. The proposed framework covers mainstream unconditional and conditional DMs (denoising-based and score-based) and various training-free samplers for holistic evaluations.',\n",
       "  'strengths': '1. Their experimental results not only analyzed DDPM but also score-based models. Besides, they also analyzed other acceleration sampling methods.\\n2. Their experiments included caption triggers.',\n",
       "  'weaknesses': '1. To show that no modifications are needed to the sampling process, the article should include details of the sampling process.\\n2. The order of formulas 8-12 in the article is not clear enough. To describe in the order of forward process → backward process → sampling process may be more clear.\\n3. Please check some spelling errors in the article. For example, \"Praobility\" in the title on line 138. \\n4. Please check whether the last term in Eq. 4 is $L_0(x_1,x_0)$.\\n5. The article claims that BadDiffusion will fail when the coefficient is $\\\\frac{1}{2}$ (line 55), but there is no further explanation.\\n6. The article claims that an attacker only needs to obtain the model parameters $\\\\theta_{download}$. However, to execute a backdoor attack, some adjustments need to be made to the initial noise. This is difficult to achieve in reality, and the article needs to emphasize this point.\\n7. Although the article extends the attack to other models, such as score-based models, there is no essential difference from BadDiffusion[2]. On BadDiffusion, just changing the coefficient of the noise term $1-\\\\bar\\\\alpha_t \\\\mathbf{I}$ in the formula $q\\\\left(\\\\mathbf{x}_{t}^{\\\\prime} \\\\mid \\\\mathbf{x}_{0}^{\\\\prime}\\\\right):=\\\\mathcal{N}\\\\left(\\\\mathbf{x}_{t}^{\\\\prime} ; \\\\sqrt{\\\\bar{\\\\alpha}_{t}} \\\\mathbf{x}_{0}^{\\\\prime}+\\\\left(1-\\\\sqrt{\\\\bar{\\\\alpha}_{t}}\\\\right) \\\\mathbf{r},\\\\left(1-\\\\bar{\\\\alpha}_{t}\\\\right) \\\\mathbf{I}\\\\right)$ (Eq. 6 in their article [2]) to $b_k \\\\mathbf{I}$ can easily obtain the results in this article. In addition, Eq. 11 is only a change of sign of Eq. 38 in [1].\\n\\n\\n[1] Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., & Poole, B. (2020). Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456.\\n\\n[2] Chou, S. Y., Chen, P. Y., & Ho, T. Y. (2023). How to backdoor diffusion models?. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 4015-4024).'},\n",
       " 'review_852': {'summary': 'Based on definitions of feature necessity, relevancy, and irrelevancy from previous work,as well as systematic issues with Shapley values for explainability on boolean classifiers (e.g. non-zero Shapley values assigned to irrelevant features, zero Shapley values assigned to relevant features, among others) identified in previous work, the authors offer proof for their existence in functions with an arbitrary number of variables. They conclude that the existence of such systematic issues is cause for concern in using Shapley values for explainability, as misleading information about feature importance can induce errors in human decision making.\\n ',\n",
       "  'strengths': '- Originality: The work offers proof for the existence of issues with Shapley value explanations on boolean functions with an arbitrary number of variables that were previously only studied empirically.\\n- Quality and Clarity: The theoretical framework, preliminaries, and proofs are described in a very concise manner. Despite the theoretical nature of the paper, the authors are able to concisely state to the reader what is described in each formula (e.g. lines 125-127: Thus, given an instance (v, c), a (weak) AXp is a subset of features which, if fixed to the values dictated by v, then the prediction is guaranteed to be c, independently of the values assigned to the other features). Similarly, the main idea for each proof is described in a very intuitive manner, increasing readability of the paper significantly.\\n- Significance: The present work proves systematic issues exhibited by Shapley value explanations on boolean functions. Shapley values are one of the most popular solutions, as they are based on clearly defined axioms, i.e. properties deemed desirable for explanations. For boolean functions, the present work shows that these axioms (which Shapley values do fulfill) may be lacking for treating irrelevant and relevant features as would be expected.',\n",
       "  'weaknesses': 'I am a bit concerned with the novelty, as the present work only provides proof for observations about unexpected behavior of Shapley value explanations for boolean functions that were already observed empirically in previous work (however, the authors also state themselves that these issues have been identified empirically in previous work). To raise concern about e.g. I1, it would be sufficient to simply identify a case where irrelevant values are assigned nonzero Shapley values. \\n\\nI also believe the title promises a bit more than is provided by the paper. The proofs and resulting claims are restricted to boolean functions, however, it would be interesting to see how and if the described issues occur in continuous settings, e.g., when explaining DNNs.'},\n",
       " 'review_853': {'summary': 'The paper demonstrates / constructs functions with features whose Shapley values (i.e., attributive importance in a prediction) is misaligned with their true relevance.',\n",
       "  'strengths': '- Addresses a theoretical gap in our understanding of Shapley values.',\n",
       "  'weaknesses': '- I find the problem being investigated to be mostly a mathematical curiosity that so happened to be open and has now been addressed. '},\n",
       " 'review_854': {'summary': \"This paper reviews previous work on ideas of feature importance and hi-lighted inconsistencies with Shaley values. It defines ideas of importance and irrelevance of features in a Boolean ML model. These definitions are based on the idea of a minimal set of inputs needed to freeze an model output. necessary inputs are in every minimal coalition that can freeze the output, relevant inputs are in at least one minimal coalition, and irrelevant inputs are in no coalitions. They then go on to show that, among other issues, there exist Boolean models and certain inputs where irrelevant inputs are given large Shapley values, while relevant inputs are given a Shapley value of zero. Thus, the logic goes, Shapley values do not track importance.\\n\\nThe paper's original contributions are to prove that model/input pairs with issues exist/can be found for models of any input size. Previously, only small models were exhibited to have these issues, but it was unknown if larger models also had these issues. They also give lower bounds on the number of models that have these issues.\",\n",
       "  'strengths': '- Generally clear and straightforward exposition.\\n- Good background and presentation of previous results.\\n- Results are easy to understand.\\n- idea of necessary, relevant, and irrelevant is intuitive.\\n\\n',\n",
       "  'weaknesses': '- Paper is based on a comparison of apples to oranges, without an in-depth analysis of the issue. It is possible that the whole paper is based on a misunderstanding. Further analysis is needed.\\n- Some grammatical issues.\\n- Contributions are not very significant.'},\n",
       " 'review_855': {'summary': \"In this paper, the authors formally define five anomalies for an\\nexplainability score and prove that for every n >= 4, there exist\\nBoolean classifiers defined over n features that exhibit one or more\\nof these anomalies for the SHAP score. In this way, the authors\\nprovide evidence of the inadequacy of Shapley values for\\nexplainability.\\n\\nThe aforementioned anomalies are defined by considering the concept of\\nabductive explanation. More precisely, given a binary classification\\nmodel M : {0,1}^n -> {0,1} and a tuple v in {0,1}^n, a subset X of {1,\\n..., n} is said to be a weak abductive explanation of (M,v) if for\\nevery y in {0,1}^n such that y[i] = v[i] for every i in X, it holds\\nthat M(y) = M(v). In other words, the values of v for the features in\\nX are enough to obtain the same result as M(v), so they are enough to\\nexplain the output of M for v. Moreover, a subset X of {1, ..., n} is\\nsaid to be an abductive explanation of (M,v) if X is a weak abductive\\nexplanation of (M,v), and there is no weak abductive explanation X' of\\n(M,v) such that X' is a proper subset of X. In other words, X is an\\nabductive explanation for (M,v) if X is a minimal weak abductive\\nexplanation for (M,v). Then a feature i is said to be relevant for\\n(M,v) if there exists an abductive explanation X of (M,v) such that i\\nbelongs to X, and otherwise i is said to be irrelevant for (M,v). With\\nthis notion of irrelevance, the anomaly I5 for the SHAP score is\\ndefined as the existence of a feature i such that i is irrelevant for\\n(M,v), but the absolute value of the SHAP score of i is greater than\\nthe absolute value of the SHAP score of every other feature. Thus,\\nthis can be considered as an anomaly of the SHAP score, as i is an\\nirrelevant feature that is considered more relevant according to the\\nSHAP score that all the other features (some of which are\\nrelevant). The other four anomalies considered in the paper (I1, I2,\\nI3, I4) are defined in a similar fashion.\",\n",
       "  'strengths': '1. The five notions of anomaly studied in the paper clearly represent\\nanomalies for explainability scores. These notions are properly\\nformalized in the paper.\\n\\n2. The paper provides valuable insights into the SHAP score,\\nspecifically providing a formal framework to assess its adequacy as an\\nexplainability score.\\n\\n3. The paper provides one of the first formal results of the\\ninadequacy of Shapley values for explainability.\\n\\n4. The paper is well written.',\n",
       "  'weaknesses': '1. The results of the paper show that a tiny proportion of the Boolean\\nclassifiers defined over n features exhibit some of the anomalies I1,\\nI2, I3, I4 or I5. For example, the paper proves that at least\\n2^{2^{n-1} - n - 3} Boolean classifiers exhibits anomaly I1, which is\\na tiny proportion of the 2^{2^n} possible Boolean classifiers defined\\nover n features. Hence, it could be the case that the vast majority of\\nBoolean classifiers do not exhibit the anomalies studied in the paper.\\n\\n2. In practice Boolean classifiers are given in some specific\\nformalism, such as decision trees or binary decision diagrams. The\\nauthors do not provide any results about the formalisms that are\\nsuitable to express the Boolean functions exhibiting anomalies. For\\nexample, is it possible to express the Boolean functions in the proofs\\nof Propositions 3, 4, 5 and 6 as decision trees of polynomial size in\\nthe number n of features? If this is not possible, can these functions\\nbe expressed as FBDDs (or d-DNNFs) of polynomial size in the number n\\nof features?'},\n",
       " 'review_856': {'summary': 'Naively utilizing CLIP with prevalent class-based prompts for zero-shot VRD has several weaknesses, e.g., it struggles to distinguish between fine-grained relation types and neglects essential spatial information of two objects. To this end, the authors propose a novel method for zero-shot VRD: RECODE, which solves RElation detection via COmposite DEscription prompts. Specifically, RECODE first decomposes each predicate category into subject, object, and spatial components. Then, it leverages large language models (LLMs) to generate description-based prompts (or visual cues) for each component. Different visual cues enhance the discriminability of similar relation categories from different perspectives, boosting performance in VRD. To dynamically fuse different cues, they introduce a chain-of-thought method that prompts LLMs to generate reasonable weights for different visual cues.',\n",
       "  'strengths': '- The framework for decomposing visual cues and using LLM to separately generate prompts for subject, object, and spatial features seems novel.\\n- The proposed method shows noticeable performance improvements, and the authors provided an ablation study to solidly analyze the design choices of the proposed method.',\n",
       "  'weaknesses': '- The baselines in the experiments seem weak. Are the baseline methods recent enough models? To verify the effectiveness of the proposed method, the RECODE should be attached to the recent state-of-the-art model and show consistent performance improvement.'},\n",
       " 'review_857': {'summary': 'This paper presents RECODE, a novel method for zero-shot visual relation detection (VRD), designed to address the shortcomings of models like CLIP in distinguishing subtle relation categories and spatial discriminability. RECODE leverages large language models (LLMs) to generate detailed description-based prompts for each relation class component, thereby enhancing VRD performance. The authors also introduce a chain-of-thought method that breaks down the problem into smaller parts for LLMs, thereby assigning reasonable weights for each component. The effectiveness and interpretability of the method are demonstrated through experiments on four benchmark datasets.',\n",
       "  'strengths': '1. The approach introduces a novel framework, called RECODE, for zero-shot VRD that addresses the limitations of traditional class-based prompts. It decomposes the visual features of a triplet into subject, object, and spatial features and generates detailed descriptions of visual cues for each relation category. The use of chain-of-thought prompting for generating reasonable weights is a unique and creative approach.\\n\\n2. The approach leverages large language models (LLMs), specifically GPT-3.5-turbo and CLIP, for the generation of descriptions and similarity calculations. The use of LLMs provides a strong foundation for generating informative and accurate descriptions of visual cues. The evaluation is conducted on four benchmark datasets, and the results demonstrate significant improvements over baseline methods.\\n\\n3. The paper provides clear descriptions and explanations of the proposed framework, including the visual feature decomposing, semantic feature decomposing, and relation classification steps. The process of generating descriptions of visual cues and weights using LLMs is well-described, and the chain-of-thought method is illustrated with examples. The evaluation metrics and experimental setup are clearly presented.\\n\\n4. The proposed approach addresses the challenge of zero-shot VRD by improving the discriminability of similar relation categories. By incorporating specific visual cues and generating descriptions, the approach enhances the performance of relation classification. The experimental results show significant improvements over baseline methods, demonstrating the effectiveness and interpretability of the proposed approach. The approach has the potential to advance the field of VRD and contribute to applications such as image understanding, scene understanding, and human-computer interaction.',\n",
       "  'weaknesses': 'While the experimental results show improvements over baseline methods, the paper lacks a thorough analysis of failure cases. Understanding when and why the proposed approach fails to accurately predict relations is crucial for identifying its limitations and potential areas of improvement. Analyzing failure cases and providing insights into the challenges faced by the model would strengthen the evaluation and guide future research directions.\\n'},\n",
       " 'review_858': {'summary': 'This paper proposed a novel method for zero-shot visual relation detection by leveraging LLM (e.g. GPT) and VLM (e.g. CLIP). Specifically, the proposed approach decomposes each predicate category into subject, object and spatial component and enrich each section with the help of LLMs, which can generate the description-based visual cues to help distinguish semantically similar concepts. Different visual cues are used to enhance discriminability from different perspectives, and the authors again use LLM to assign weights to different components for effective fusion. Extensive experiments on four different datasets are provided to demonstrate the effectiveness and interpretability.',\n",
       "  'strengths': '1. The proposed approach is theoretically sound and intuitive. Enriching the prompt from class-based to description-based can provide more information to enhance the relation sensitivity, and it also improves the explainability as the relation classification score can reveal the most important factors for the prediction.\\n2. The decomposition of subject-object pair makes it much more efficient for processing visual signals as the previous O(N^2) patches now reduce to O(N). The spatial relationship also makes sense as an abstract from real objects to just the relations.\\n3. The paper is well-written and easy to follow. The extensive experiments and ablation studies/visualization help a lot for understanding the model.',\n",
       "  'weaknesses': '1. The most important issues with this paper is that the evaluation section does not have important baselines. Specifically, in Table 1 and Table 2 the authors only show the performance of the proposed model with simplified version (CLS and CLSDE), which more like an ablation study. Many previous work actually attempted similar tasks and have been experimenting on the same dataset, e.g. [1][2][3]. \\n2. In Table 2 I guess the bolded numbers should be the highest (best)? For HICO-DET, CLS has the same performance on \"Rare\" category  with RECODE thus should be highlighted as well I think?\\n3. A very very minor issue: the zero-shot chain-of-thought prompt used in most literatures are \"let\\'s think step by step\" not \"let\\'s think it step by step\". Formal usage should be \"think\" or \"think about it\" or \"think through it\", rather than \"think it\".\\n\\n[1] https://arxiv.org/abs/1804.10660\\n[2] https://arxiv.org/abs/1707.09423v2\\n[3] https://arxiv.org/pdf/2004.00436.pdf'},\n",
       " 'review_859': {'summary': 'This paper aims to address the VRD problem using LLMs. The paper decomposes the visual features into human, object, and spatial features, and designs prompts to generate visual cues that describe each of these types of visual features. The relation classification is established by calculating the distance between visual and semantic features, and dynamic weights generated by LLMs are also integrated to enhance the training process.',\n",
       "  'strengths': '1. This paper focuses on a critical issue in visual relationship detection tasks, exploring the potential of leveraging LLMs to enhance visual relationship understanding.\\n2. The paper introduces a novel and reasonable approach by decomposing each predicate category into human, object, and spatial descriptions.\\n3. The authors thoroughly investigate various approaches to enhance the quality of prompts, encompassing both the generation of visual cues and the improvement of weights.',\n",
       "  'weaknesses': \"1. It appears that the visual cues employed in the main papers are presented as mere examples, leaving uncertainty regarding the specific visual cues utilized in the experiments. Furthermore, the visual cues depicted in Figures 3 and 4 exhibit notable differences, with Figure 4 generating more complex sentences. As a result, evaluating the quality of the visual cues based on the current evidence becomes challenging.\\n2. The RECODE's performance gain on the HICO-DET and V-COCO datasets is marginal, and the authors did not provide error bars in their reports. Additionally, the ablation studies were solely conducted on the VG dataset, which could have substantial differences compared to the HICO-DET dataset. Consequently, it is difficult to be convinced that the RECODE is as effective as claimed by the authors.\\n3. The main technical contribution of this paper lies in the development of specifically designed prompts. However, the improvements made to the prompts are relatively straightforward, and the utilization of CoT is a standard practice.\\n4. There are many incurious statements/claims. For example, in line 47-55, it is unclear why a person has to stand while holding an object.; in lines 67-69, it is not clarified why the act of holding depends on spatial factors.\"},\n",
       " 'review_860': {'summary': 'In this paper, the authors developed a joint model of CLIP and LLM to solve the task of Visual relation detection. In this model, images are encoded into a triplet,~\\\\ie, object, subject and spatial branches. Then it leverages large language models (LLMs) to generate description-based prompts (or visual cues) for each component. Experiments on four VRD benchmarks shows good results compared to the baseline models.',\n",
       "  'strengths': '+ Interesting and good applications of LLMs including GPT-3.5 and large multi-modality pertaining models~\\\\eg, CLIP.\\n+ Show higher performance than baseline methods.\\n+ Good storytelling to readers understand the key idea.',\n",
       "  'weaknesses': '### Technical Novelty and main ideas\\n1. This paper pays its major attention to designing and using LLM~\\\\ie, GPT-3.5 to facilitate the deduction of multi-modal models. Many contributions lie in the design and feeding prompts into LLMs. This contribution seems insignificant to me and seems not generalizable for future LLM using different architectures with GPT-3.5. Besides, the authors also lack deep investigation into the improvements of the Chain of Thought (CoT).  Although the overall application and using LLMs seem interesting. but the solid contributions of this paper are not clear to me.\\n\\n### Presentation and motivation issues\\nThe descriptions of CoT and experimental results are somehow unclear.  Besides, the novelty of using CoT in this task is not sufficient. Designing prompts \\n\\n2. The reviewers tested the same prompt using GPT-3.5, while in this case, with or without Chain of Thought (CoT) does not show significant differences. (with CoT: avg: 0.51, 0.3, 0.19 for s,o,p; w/o CoT: avg: 0.59, 0.33, 0.14 for s,o,p) The reviewer understands the results may not be stable but is still unclear about this case.\\n\\n3. Why did Figure 5(a) choose 0.4, 0.4, 0.2? The authors should explain how `obviously unreasonable` on lines 188 - 190 is `obviously unreasonable`.\\n\\n### Experimental issues\\n\\n4. For Figure 2 and Figure 7 in the supplementary material.\\na) Where did the cues for the CLS baseline displayed by the sentence come from? Line 214 of the text states to use \"relational CLasS-based hints (e.g., ride)\", which are somehow inconsistent with the statements. Can the authors explain in more detail how the CLS baseline is tested? Where does the performance difference come from if two settings use the same prompts?\\n5. Although the newly proposed setting, the authors do not discuss other similar works.  PEVL[1] and STIP[2]. Differences and relation discussion could help.\\n\\n[1] Yao, Y., Chen, Q., Zhang, A., Ji, W., Liu, Z., Chua, T. S., & Sun, M. (2022). PEVL: Position-enhanced pre-training and prompt tuning for vision-language models.\\xa0_arXiv preprint arXiv:2205.11169_.\\n\\n[2] Zhang, Y., Pan, Y., Yao, T., Huang, R., Mei, T., & Chen, C. W. (2022). Exploring structure-aware transformer over interaction proposals for human-object interaction detection. In\\xa0_Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition_\\xa0(pp. 19548-19557).\\n\\n6. The time efficiency of different compared methods in Tab.4 should also be provided.\\n7. [Experimental Description] For the conjecture in line 247, does deduction give evidence for a confusion matrix? The reviewer did a cursory check of the dataset and there are a total of 117871 annotations, These provided actions seem to be rare.'},\n",
       " 'review_861': {'summary': 'This work proposes a design of a probability density that is more over-dispersed than the target density, so that, somewhat surprisingly, the resulting MCMC samples, after optimally reweighted, can achieve lower KSD than MCMC samples from the true target density. Consistency of the two proposed algorithms, SPiIS-MALA and SPiT-MALA, is proved. These two algorithms are benchmarked on PosteriorDB dataset to demonstrate their superior performance over raw MALA and SIS-MALA (MALA plus optimal reweighting).\\n',\n",
       "  'strengths': '- The paper tackles an interesting yet to my knowledge underexplored problem in sampling, which is how to design a density so that the resulting samples provide a good discrete support for the ensuing optimally reweighting step that finds a weight to minimize KSD.\\n- The angle of the attack is, although not new (e.g. Graf and Luschgy 2007), quite surprising (i.e. the density needs to be over-dispersed). The motivational section on the optimal quantization of Wasserstein distance is well-put.\\n- The consistency of the two proposed methods is proved which is nice.\\n- Many kernels are studied (Langevin-Stein/KGM/Riemann-Langevin-Stein) and are used in producing the empirical results.\\n- The writing of the paper is excellent and lots of intuition and toy examples are given to illustrate the points.\\n',\n",
       "  'weaknesses': '- The consistency proof of Theorem 1 seems like a rather straightforward application of Theorem 2 (Durmus and Moulines 2022) and Theorem 3(Riabiz et al. 2022). In particular, it seems to me the same proof should go through for quite generic $\\\\Pi$, not necessarily the one that takes the form in (8). Hence, it is not clear whether the design (8) is theoretically justified, other than the heuristic argument given in Sec. 3.1.\\n- There is a considerable gap between the heuristic argument in Sec. 3.1 and the proposed algorithm, which is the weights used in Sec. 3.1 is not optimal but in the algorithms they are. The authors claimed the choice $dP/d\\\\Pi$ is \"near-optimal\" (without justification), but then noted that using $dP/d\\\\Pi$ will perform substantially worse than the optimal weight, which seems contradictory to the first claim. \\n- The experimental results comparing SIS-MALA and SPiIS-MALA are somewhat mixed. For an end user, there is no provided criterion on whether they should use the proposed method or the baseline SIS-MALA. Moreover, I cannot find standard derivation of the reported numbers.\\n  *  There seems to be missing experiments that benchmark the performance of SPiT-MALA compared to baseline (e.g. $\\\\Pi=P4). The only experiment I found for SPiT-MALA is in D.6 where the consistency is verified. \\n- In many places it is hinted that $P$ will be close to $\\\\Pi$ as the dimension $d$ increases. This implies that the proposed method is only applicable to small dimensions and thus the application value is limited.  Further analysis on the relation to dimension could be helpful. Moreover, there is only one experiment for $d=66$ (last row in Table 1) that corroborate the point that the extent of improvement decreases when the dimension increases; more experiments could be used to strengthen this point.\\n'},\n",
       " 'review_862': {'summary': \"The paper analyses which target distribution to use for MCMC in the situation where a stein-descrepency will be used to post-process it's output samples.\\nThey propose to use a different target distribution for the MCMC to the distribution being approximated, and show this improves performance on a variety of posterior inference problems.\",\n",
       "  'strengths': '- The paper identifies and clear question: how to choose the invariant distribution \\\\pi for MCMC if using a stein-descrepency to post-process the samples.\\n- They provide a method for selecting $\\\\pi$ via a variational problem framing, where $\\\\pi$ is selected to minimize the variance in the post-processed approximation. This gives a closed form expression for $\\\\pi$ (up to a normalizing constant) such that it can be easily used within MCMC. Their analysis is agnostic to the choice of stein kernel making their results broadly applicable. \\n- Figure 1 nicely illustrates the property of over-dispersion that their choice of $\\\\pi$ has, and shows that on a simple 1D problem that this results in lower error bars compared to using $P$ for the MCMC. \\n- In their experiments their proposed method is shown to consistently improve (better results in 70% of  PosteriorDB tasks) upon the baseline of setting $\\\\pi$ to the target distribution being approximated. \\n- Their presentation is generally very clear, with informative figures provided. ',\n",
       "  'weaknesses': \"I could not see any weaknesses in this paper, however the it's subfield is not within my area of expertise and I did not check the proofs. \"},\n",
       " 'review_863': {'summary': 'This paper proposes a proposal distribution $\\\\Pi$ to generate finite points \\nsuch that a weighted version approximates the target distribution $P$ under \\nStein discrepancy. ',\n",
       "  'strengths': 'The main strength lies in a new proposal for the sampling distribution $\\\\Pi$ that \\nis more efficient for follow-up approximation to the original distribution $P$ in the \\nsense of Stein discrepancy. \\n\\nAsymptotic consistency is established, and extensive simulations on Bayesian computation \\nis also conducted to illustrate the benefit of the proposal.',\n",
       "  'weaknesses': \"The authors might consider expanding the section on the actual contribution (the proposal of $\\\\Pi$), \\nand be more brief on the background. For instance, the section on Wasserstein distance doesn't seem necessary. \\n\\nThe second limitation is in the theoretical guarantees. Can one provide a non-asymptotic convergence guarantee \\nfor the proposed method?\"},\n",
       " 'review_864': {'summary': 'The paper studies the design of the MCMC algorithm which is well suited for post-processing to obtain consistent approximation $P_n^\\\\star$ of the target measure $P$ using Stein kernel discrepancies ($D_P( \\\\cdot)$). The authors suggest the following novel procedure: (1) choose a measure $\\\\Pi$ which differs from the target measure $P$ by the factor $\\\\sqrt{k_p}$, where $k_p$ is the Stein kernel  (solving variational problem) (2); Sample from $\\\\Pi$ using (pre-conditioned) MALA; (3) solve linearly-constrained quadratic problem or construct sparse approximation to obtain $P_n^\\\\star$.  \\nTheorem 1 provides assumptions to ensure convergence of Stein kernel discrepancies $D(P_n^\\\\star)$ to zero.  Step (1) is based on SNIS procedure and the choice of $\\\\Pi$ which gives the smallest variance of the Stein kernel discrepancies between SNIS estimate P_n and target measure $P$. \\nThe results are illustrated by numerical experiments.',\n",
       "  'strengths': '-Novel variational algorithm for explicit construction of measure \\\\Pi. \\n-Theoretical analysis of the algorithm in the case of using MALA as a MCMC sampler\\n',\n",
       "  'weaknesses': \"- Only asymptotic convergence in D_P metric is proved in Theorem 1. \\n- Would be good to sketch ideas of construction of Stein's kernel in the main text. \\n- It could be difficult to calculate Stein's kernel in more practical problems\\n- Works in moderate dimensions\\n\\n\"},\n",
       " 'review_865': {'summary': 'This paper presents a novel approach for constructing an MCMC target that is specifically designed for post-processing using Stein importance sampling and Stein thinning, where the goal is to assign optimal weights to a subset of sample particles in order to construct the best possible approximations of a distribution $P$.\\n\\nThe proposed method introduces a new target distribution, denoted as $\\\\Pi$, which is obtained by tilting the original target density $p(x)$ with the square root of a Stein kernel $k_P(x)$. This construction is derived by solving a variational problem that minimises the trace of the variance of a limiting Gaussian distribution. The use of $\\\\Pi$ as a target for the Metropolis-Adjusted Langevin Algorithm (MALA) instead of the original target distribution $P$ is justified through an almost sure consistency guarantee (Theorem 1) and numerical experiments conducted on a set of benchmark problems.',\n",
       "  'strengths': \"**Originality**: Whilst previous works have extensively studied post-processing using Stein's discrepancy, this paper introduces a novel perspective on improving Stein importance sampling through the design of a target distribution that is distinct from the original target $P$ but more suitable for post-processing techniques. This novel approach of leveraging the target design to improve post-processing methods is both interesting and original.\\n\\n**Quality**: The construction of the proposed target distribution $\\\\Pi$ is clearly explained (Section 3.1). The paper presents both a theoretical guarantee (Theorem 1) and extensive numerical evidence to support the choice of $\\\\Pi$. The assumptions in Theorem 1 appear to be mild, and the authors provide comprehensive discussions comparing them with similar conditions in related literature. Overall, the significance of the proposed method is convincingly demonstrated.\\n\\n**Clarity**: This paper exhibits a high level of clarity throughout, including an extensive review of related literature and methodologies (Section 2).\",\n",
       "  'weaknesses': '**Motivation**: While the authors have effectively justified the use of the proposed target $\\\\Pi$ instead of the original target for constructing MALA samplers, the rationale for employing S$\\\\Pi$IS over running MALA **without** post-processing is slightly weak. Specifically:\\n\\n1. A main advantage of Stein importance sampling (SIS) lies in its ability to provide unbiased estimation when the MCMC sampler used to generate the sample is biased. Consequently, allocating computational resources to post-processing is crucial in such cases, as it is uncertain whether running the chain for a longer time would improve the quality due to the bias. However, for $\\\\Pi$ sampling, one must set up an unbiased sampler (e.g., MALA) that targets $\\\\Pi$, raising the question of whether conducting S$\\\\Pi$IS is more beneficial than simply allocating the same computational budget to running the chain for an extended period. The reported experimental results do not seem to address this question, as they solely compare S$\\\\Pi$IS with standard SIS. Including experiments comparing S$\\\\Pi$IS with MALA without post-processing would be valuable in addressing this concern.\\n2. S$\\\\Pi$IS requires the setup of an MCMC sampler targeting a distribution different from $P$. Thus, the generated sample must be used in conjunction with the post-processing step to perform inference on $P$. This contrasts with standard SIS, where samples can be drawn from a sampler targeting $P$, which is typically what practitioners would do regardless of their intention to use post-processing methods. This raises the question of whether setting up a sampler that targets such a specialised distribution and relies on post-processing is more practically attractive than directly targeting $P$. Including discussions addressing these concerns would be beneficial.'},\n",
       " 'review_866': {'summary': 'This paper introduces a novel approach to make Wasserstein distributionally robust optimization problems robust to adversarial outliers including geometric perturbations and non-geometric contamination of the data. This goal is achieved by considering relevant Wasserstein ball which includes both type of adversarial attacks. Later, the authors provides strong duality results which allows them to improve the computation complexity of the proposed outlier-robust WDRO problem.',\n",
       "  'strengths': 'This is a well written paper with novel contributions. The robustness of WDRO to the outliers is a very natural problem and the authors proposed a Wasserstein distance based constraints to provide robustness. This is particularly hard if we do not make any presumptions on the distribution of data; therefore, I find the contributions of this paper to be significant to the literature. There might be some concerns that I have mentioned in the weaknesses part, but, overall I am impressed by the work done here. \\n',\n",
       "  'weaknesses': 'As I have mentioned at the strengths part, I believe this paper has a novel contribution to the robust optimization literature. Some few weaknesses that I observed was that authors assumed the readers have prior knowledge on relation between adverserial attacks and Wasserstein and TV perturbations. These are not so obvious for me and might be useful to include some discussion/motivation about how these attacks can be associated with claimed perturbations in metric space. \\n\\nI believe it would strengthen the paper if authors can obtain some results on larger datasets. Considering the time constraint of the conference, I believe it would be sufficient to add one large dataset to experiments. \\n'},\n",
       " 'review_867': {'summary': 'This paper introduces an outlier-robust Wasserstein Distributionally Robust Optimization (DRO) framework that aims to capture both geometric uncertainties and non-geometric perturbations, such as adversarial outliers. By utilizing the outlier-robust Wasserstein distance, the proposed framework allows for the arbitrary corruption of a fraction of the data. The authors design an uncertainty set using a robust Wasserstein ball and derive minimax optimal excess risk bounds. They also establish a strong duality for efficient computation. The resulting problem involves tuning three parameters:\\n\\n- the bounded covariance parameter $\\\\sigma$,\\n  \\n- the radius of the ambiguity set $\\\\rho$,\\n  \\n- and the contamination parameter $\\\\varepsilon$.\\n  \\n\\nMoreover, the authors address dimension dependencies in risk bounds for low-dimensional features by introducing the projection robust optimal transport. The paper concludes with experimental validation of the theory on regression and classification tasks.',\n",
       "  'strengths': '- The paper replaces the Wasserstein distance with the outlier-robust Wasserstein distance to tackle the case that the observed distribution is contaminated with outliers.\\n- The authors establish the excess risk bounds of decisions for the cases $p=1,2$.\\n- The authors derive tractable reformulation by replacing $\\\\mathcal{G}_{\\\\text{cov}}$ and leveraging dual of the problem.\\n- The low-dimensional features are considered to address the problem of dimension dependency.',\n",
       "  'weaknesses': '- In Remark 3 and Appendix E, the paper briefly touches on the selection of the parameter $\\\\varepsilon$. However, the overall discussion on parameter selection is limited. The model introduced in the paper involves several parameters, such as $\\\\rho$, $\\\\varepsilon$, and $\\\\sigma$, which may not be fully independent. Therefore, a more comprehensive discussion about the tuning of these parameters is warranted.\\n  \\n- In the experiments, the paper exclusively uses the standard Wasserstein DRO (WDRO) as the baseline for comparison. However, considering that both models aim to address the outlier challenge, it would be valuable to include DFO [A], which is another model specifically designed for handling outliers, as a reasonable baseline for comparison.\\n  \\n- The presence of a few missing references should be addressed in order to enhance the completeness and accuracy of the paper. In Section 4, it would be beneficial to include references [B, C, D], which introduce the concepts of Wasserstein projection pursuit and projection robust Wasserstein, respectively.\\n\\n[A] Jiang, Nan, and Weijun Xie. \"DFO: A Framework for Data-driven Decision-making with Endogenous Outliers.\" (2022).\\n\\n[B] Huang, Minhui, Shiqian Ma, and Lifeng Lai. \"A riemannian block coordinate descent method for computing the projection robust wasserstein distance.\"\\xa0*International Conference on Machine Learning*. PMLR, 2021.\\n\\n[C] Paty, François-Pierre, and Marco Cuturi. \"Subspace robust Wasserstein distances.\"\\xa0*International conference on machine learning*. PMLR, 2019.\\n\\n[D] Niles-Weed, Jonathan, and Philippe Rigollet. \"Estimation of wasserstein distances in the spiked transport model.\"\\xa0*Bernoulli*\\xa028.4 (2022): 2663-2688.'},\n",
       " 'review_868': {'summary': 'It is well known that Wasserstein distances do not commute well with total variation distance - a slight perturbation in TV can change the Wasserstein distance by a lot. This means that models that are robust to corruptions in the data distribution in Wasserstein distance can still be vulnerable to outliers or corruptions in TV sense. This paper addresses this problem by considering robustness with respect to both TV and Wasserstein. The paper studies worst-case excess risk w.r.t. corruptions in a new distance termed the \\'outlier robust Wasserstein distance\\'. The authors derive upper and lower bounds on the worst-case excess risk for families of distributions that are either sub-Gaussian or have bounded covariance. The upper bounds depend on a recently introduced term called the \"resilience\" of a probability measure. Intuitively, resilience of a measure quantifies the deviation in expectation of a function (in this case the loss function) when taken w.r.t. a measure in a probability ball around the original measure. The authors also propose a tractable reformulation of the min-max problem via strong duality. Finally, the authors tighten their results for the case when the true distribution lies on a low dimensional linear subspace, by extending their results to corruptions in outlier robust max-sliced Wasserstein distance. The authors also verify their excess risk bounds on a toy dataset for linear regression problem with mean absolute deviation loss. \\n\\n',\n",
       "  'strengths': \"- significance: the problem of incorporating outlier robustness into the framework of wasserstein distributionally robust optimization (WDRO) is of significance to both ML and optimization communities, and has already received some recent interest. This paper makes progress on this significant problem. \\n- novelty: I think the upper and lower bounds on the min-max excess risk are novel. The strong duality result appears to be a generalization of Gao and Kleywegt's result on strong duality for WDRO, but I think it is is non-trivial. \",\n",
       "  'weaknesses': \"- **Contextualizing the work within related literature**: Although the paper is overall well written, I wish it did a better job at contextualizing their results properly by comparing it with the two special cases of WDRO without TV corruption and of TV robustness without WDRO. For WDRO without TV corruption for example, a natural point of comparison is [this](https://optimization-online.org/wp-content/uploads/2016/04/5396.pdf) paper by Gao and Kleywegt. One point of comparison could be the existence and the form of the worst-case distribution in the min-max risk. This question is answered for the WDRO without TV corruption in Gao and Kleywegt's paper but this paper does not address it at all, which seems odd to me. For TV corruption without WDRO (aka Huber contamination), there are several works from the robust statistics community.\\n- **Usefulness on top of stricter WDRO**: I think Remark 1 deserves much more discussion. From proposition 1 it is clear that the new compound model of outlier robust WDRO can be subsumed under plain vanilla DRO by increasing the budget of the Wasserstein contamination in proportion to the resilience of the true distribution. Then, how much additional utility do we gain by analyzing the min-max excess risk under the compound model in detail? I must admit I don't understand what the authors mean by the expensive pre-processing step for WDRO. Please explain this to me satisfactorily, and I am willing to change my opinion on this particular weakness. \\n\"},\n",
       " 'review_869': {'summary': 'This paper empowers WDRO with the ability to resist outliers, building upon the outlier-robust Wasserstein distance $W_p^\\\\epsilon$. The excess risk of the solution to both the outlier-robust WDRO and its empirical version is given. An improved bound of the excess risk is derived for the setting of low-dimensional features. The optimization algorithm for the outlier-robust WDRO is developed with the dual form of the minimax problem. Empirical study validates the effectiveness of the proposed method with a simple regression setting involving both Wasserstein and Total Variance contaminiation.',\n",
       "  'strengths': '1. DRO is known to be over-pessimistic in the existence of outliers. Empowering Distributionally Robust Optimziation with robustness against noisy labels is important. The outlier-robust Wasserstein distance is a well-developed revision of the original Wasserstein distance to account for certain degree of contamination. Thus, constructing the uncertainty set of DRO with $W_p^\\\\epsilon$ is both significant and reasonable.\\n2. The theoretical analysis of the excess risk of the proposed method is sound and comprehensive. The results quantify how the solution adapts to given geometric and TV contamination. The effectiveness of the empircial algorithm is also guaranteed by the empirical bound of excess risk.',\n",
       "  'weaknesses': \"1. The effectiveness of outlier-robust WDRO is theoretically guaranteed by the excess risk bound. My main concern is over the **advantage** of outlier-robust WDRO v.s. WDRO. As is stated by the authors, the excess risk of outlier-robust WDRO is upper bounded by the $W_p$ regularizer with a larger Wasserstein radius. The authors also recognize that the same upper bound could be achieved by a radius-expanded WDRO. Two advantages of WDRO given in Remark 1 are not convincing. \\n\\n- The authors claim that a heavy preprocessing step is required by WDRO to estimate the exact radius. However, in practical settings beyond simulated experiments, the exact parameters of contamination levels $\\\\rho, \\\\epsilon$  are also latent. Either an estimate or tuning of the radius is necessary for both WDRO and the outlier-robust version. \\n- The authors prove an improved bound of the excess risk for outlier-robust WDRO in the setting of low-dimensional features and claim that the bound of WDRO could not be improved, which is unsupported. A tight bound of the excess risk of WDRO with low-dimensional features might be given to consolidate the author's claim. Otherwise, an inequality between the excess risk of WDRO and its outlier-robust version might be given similarly to Eq.4. Furthermore, the proposed low-dimensional feature setting is somewhat impractical because the exact dimension $k$ is typically unknown in real datasets. \\n\\nIn the experiment section, I suppose the radius for WDRO is selected to be the true contaminaton radius. The curve of performances of WDRO and outlier-robust version with increasing radius might demonstrate their gap more convincingly.\\n\\n2. I am concerned if the formulation of outlier-robust WDRO (eq.3) is well defined. Consider a simple case where all the samples of $\\\\tilde \\\\mu$ are discretely distributed on $2/\\\\epsilon$ points, one of which is denoted by $(x_0,y_0)$. By arbitarily modifying $y_0$ to $y'$ we get a new distribution $\\\\nu(y')$. According to Line 131 we have $W_p^\\\\epsilon(\\\\tilde \\\\mu, \\\\nu) =0$. Thus, all the $\\\\nu(y')$ is included in the uncertainty set of the correspondong $W_p^\\\\epsilon$ DRO. However, the risk of a given predictor on the group of $\\\\nu(y')$ could be unbounded since $y'$ is unconstrained. As a consequence, there might be no solution to eq.3. Intuitively, though eq.3 incorporates the clean distribution into the uncertainty set, it might also include more dirty distributions since the outlier-robust Wasserstein distance tolerates a small fraction of outliers, but the risk on these outliers could be unbounded. Therefore, I'm concerned if the porposed outlier-robust DRO would be biased towards more dirty distributions instead of recovering the clean one.\\n\\n3. I am also concerned with the selection of the radius $\\\\rho$ of outlier-robust WDRO. As is indicated by Theorem 1, larger $\\\\rho$ leads to higher excess risk while Line 203 states that the excess risk bound only stands for $\\\\rho \\\\geq \\\\rho_0 + W_p(\\\\mu, \\\\hat \\\\mu_n)$, implying that $\\\\rho$ shall not be too small. Since both $\\\\rho_0$ and $W_p(\\\\mu, \\\\hat \\\\mu_n)$ are unavailable in practical settings, the selection of the parameter seems tricky. \"},\n",
       " 'review_870': {'summary': 'This paper examines multi-objective reinforcement learning---the setting in which multiple distinct objectives are desired, and often combined, to form a composite objective. Concretely, the paper explores the limits of aggregating different objectives by appealing to three main pools of ideas. First, to the von Neumann-Morgenstern expected utility, axioms; Second, to Pareto indifference; and Third, to dynamic consistency. The main result is an impossibility result, illustrating that objectives with different time-based objectives (that is, different discount factors), cannot be aggregated in a way that yields a Markovian reward function even if the individual objectives themselves are Markovian. The paper then explores what lies beyond this impossibility result, exploring a mechanism for expanding the state-space to collapse the non-Markovian aggregated objective down to a Markovian one. This results in a \"historical\" discount factor, a hindsight view of the discount factor. ',\n",
       "  'strengths': '**STRENGTHS**\\n\\nThe paper possesses many strengths:\\n1) The aspirations of the work are ambitious and important. Clearly establishing when certain kinds of objectives can and cannot be captured is important.\\n2) The work is rigorous, and well-connected to classical results in decision theory.\\n3) The examples are clear and help to communicate the main ideas.\\n4) The impossibility result on its own is interesting. Once I understood the details, it is not ultimately surprising, but I do not believe the result needs to be surprising to be useful.\\n5) Historical discounting is a new and interesting idea.\\n',\n",
       "  'weaknesses': '\\n**WEAKNESSES**\\n\\nAt the same time, the paper has several weaknesses:\\n1) Language. First, and my biggest critique, the work commonly makes use of unusual and vague language surrounding some of the main concepts. For instance, the title, and central idea of the work---multi-objective agency---is not well-defined, and by my reading is not an appropriate choice of description for the content of the work. I would recommend moving away from \"agency\" as a term, and certainly \"multi-objective agency\", as neither are well defined in this paper. Instead, I would suggest using \"multi-critieria objectives\", or \"multi-objective RL\", as is used in prior literature. It is much more clear and precise, and more well connected with the work.\\n2) Clarity, and detail of exposition. Ideas are often introduced abruptly and not explained in much detail. For instance, the axioms in section 3.1 are simply stated without any added context or explanation. While vNM is quite common, dynamic consistency is less so, and likely deserves a more thorough, careful, and simple explanation, given its central role in the work. Similarly, after some theorems are introduced, they are sometimes not discussed. Other details are often left unexplained, such as \"...none of which is a mixture of the other two\" in Theorem 4 (the main result). From a quick reading it is possible to understand this, but it would be worthwhile to spell this out carefully.\\n3) Notation is sometimes defined quite precisely, but it is often overly complex or not defined. For instance, in Theorem 5, it is unclear what {$\\\\succ_\\\\Sigma^{sas\\'}$} is intended to mean. Conventions tend to deviate quite a lot from typical work in reinforcement learning as well (getting rid of the Q function in favor of two uses of V, using $\\\\Pi$ instead of $\\\\pi$). \\n4) Unsurprising results. Lastly, I do believe most of the results are unsurprising. When discount factors vary across objectives, it is perhaps expected that their aggregation will not be representable in the same form (and that we can augment the state space to remedy this). Still, it  is useful to make these arguments carefully and rigorously.'},\n",
       " 'review_871': {'summary': 'The authors analyze the implications of preference aggregation within a Markov Decision Process Framework. They show that it is not possible to ensure dynamic consistency in an aggregated MDP if one also wants to be able to accommodate arbitrary preference criteria, even if the criteria are individually dynamically consistent. They further show that by relaxing the Markov condition incrementally, dynamic consistency can be recovered.\\n',\n",
       "  'strengths': 'Addresses a fundamental representational issue in MDPs. The authors clearly have a deep understanding of the temporal consistency literature in economics and decision theory, and bring it to bear here. The technical exposition is clear, and the reasoning is sound. The example of procrastination is instructive. The construction of a patch to deal with different discount rates is perhaps the most directly useful contribution. There is also some interesting extended discussion about intemporal preferences that could be quite relevant in an AI context.\\n',\n",
       "  'weaknesses': 'The authors attempt to motivate the contribution in the context of the current \"Reward is Enough\" debate in RL. This is tantalizing, but seems to me a bit forced. Really we have a basic technical question in representation of intertemporal preferences, and the paper underlines a common lesson that aggregating across separate preferences is never as straightforward as one might think. The technical points are perhaps connected to some arguments debate participants have brought up (and they should indeed be better versed in intertemporal choice), but ultimately we face the same questions we always do about how much and what kind of state should we incorporate to keep things approximately enough Markovian.\\n'},\n",
       " 'review_872': {'summary': 'The paper considers a general multi-objective sequential decision-making setting where each objective may use a different discount factor. Using an axiomatic approach, the authors prove that under some axioms (vNM axioms + dynamic consistency for the relation on each objective), an aggregated preference relation cannot simultaneously satisfy the vNM axioms, dynamic consistency, Pareto indifference, and some technical conditions. In addition, the authors discuss some ways out to this impossibility result, notably via state augmentation or relaxing dynamic consistency.',\n",
       "  'strengths': 'Impossibility result, although the result is actually not very surprising when different discount factors are allowed\\n\\nProposition and discussion about different solutions to this impossibility result',\n",
       "  'weaknesses': \"The presentation and organization of the paper could be improved. Notably:\\n\\nThe results could be presented in a more accessible way to a more general audience. The authors seems to know well the related literature in decision theory and economics, which may not necessarily be the case for the NeurIPS audience. For instance, the second and third paragraphs of Section 5.1 are quite hard to follow for a non-expert.\\n\\nSection 4.2 should be checked. Some notations (e.g., h_{:-1}, y_i, or y) are not explained properly or are not used in a rigorous way.\\n\\nIt is not clear to me why Section 5 combines a presentation of other solutions to the impossibility theorem and a discussion of related work.\\n\\nAs far as I know, most work in multiobjective reinforcement learning applies an identical discount factor on all the objectives. Since the impossibiity theorem doesn't apply in this case, the results of this paper don't apply to most such work. Therefore, I believe researchers may be mislead by the title of this paper. I suggest the authors to use a more precise one.\"},\n",
       " 'review_873': {'summary': 'This paper considers the problem of proving best of both worlds guarantees for algorithms based on the FTRL framework for the multi-armed bandits problem. While it has been demonstrated in (Zimmert and Seldin (2019,2021)) that Tsallis-INF (FTRL with the $1/2$-Tsallis entropy regularizer) achieves optimal regret in both the adversarial and stochastic settings simultaneously, their analysis for the stochastic case relied on the assumption that the optimal arm is unique. The more recent work of Ito (2021) showed that Tsallis-INF still enjoys $\\\\\\\\log T$ regret in the stochastic case even if the optimal arm is not unique. In this paper, the authors generalize the analysis of Ito (2021) to other regularizers. Namely, they prove, without the uniqueness assumption, best-of-both-worlds guarantees for FTRL with any $\\\\\\\\beta$-Tsallis regularizer (including the log barrier and the Shannon entropy regularizers) using a new arm-dependent learning rate, albeit all regularizers are mixed with the log barrier for technical reasons.',\n",
       "  'strengths': '- This work provides best of both worlds guarantees without the unique optimal arm assumption for FTRL with a broad family of regularizers. While the use of the $1/2$-Tsallis regularizer is the optimal choice (and already analyzed by Ito (2021)) for the standard bandits problem, other choices are still useful in closely related problems as illustrated in the decoupled exploration and exploitation problem.\\n- Moreover, this work seems to be the first to provide BOBW guarantees (without requiring prior knowledge of the suboptimality gaps) for the $\\\\\\\\beta$-Tsallis regularizer when $\\\\\\\\beta$ is not $1/2$.\\n- Overall, the paper is well written and the presentation is clear. A concise sketch of the analysis technique is provided in the last section, and the proofs seem mostly well written and easy to follow.',\n",
       "  'weaknesses': '- Unlike Ito(2021), the provided bounds include an added term of order $|U| \\\\\\\\log(T) / \\\\\\\\Delta_\\\\\\\\min$ where $U$ is the set of optimal arms and $\\\\\\\\Delta_\\\\\\\\min$ is the smallest sub-optimality gap. Thus, the bounds are negatively affected when there are many optimal arms. While this is still an improvement in cases where prior works only achieved a $K \\\\\\\\log(T) / \\\\\\\\Delta_\\\\\\\\min$ dependence (as in the Shannon entropy case), in other cases (most notably for the $1/2$-Tsallis regularizer analyzed by Ito (2021) without the uniqueness assumption) the provided results are inferior to prior works.\\n- The fact that all regularizers are summed with a log barrier term is a little unsatisfactory. For instance, in the Shannon entropy case, we potentially lose the appealing property of having closed form expressions for the predictions of FTRL.\\n- Though probably curable with a doubling trick, the fact that the proposed approach sometimes requires prior knowledge of the time horizon is a minor weakness.'},\n",
       " 'review_874': {'summary': 'This paper studies the problem of designing adaptive multi-armed bandit algorithms that perform optimally in both the stochastic setting and the adversarial setting simultaneously (often known as a best-of-both-world guarantee). The authors show that the uniqueness assumption is unnecessary for FTRL with a broad family of regularizers and a new learning rate schedule. For some regularizers, their regret bounds also improve upon prior results even when uniqueness holds. ',\n",
       "  'strengths': '1.\\tThe considered problem, i.e., best-of-both-world for multi-armed bandit, is important in the bandit literature.\\n2.\\tThe theoretical analysis looks sound, and the improvement is significant.\\n3.\\tThis paper is well-written and clearly organized.\\n',\n",
       "  'weaknesses': '1.\\tThis paper does not provide any experimental result. It would improve the paper if the authors could conduct empirical evaluation for their algorithms and compare to existing BOBW algorithms, to validate their theoretical results.'},\n",
       " 'review_875': {'summary': 'The authors focus on best-of-both-worlds (BOBW) algorithms based on follow-the-regularized-leader (FTRL) in multi-armed bandits.\\nThe theoretical guarantees for most existing FTRL-based BOBW algorithms were based on the assumption that the best arm is unique in order to take advantage of self-bounding techniques.\\nIt is known that this assumption can be removed by the paper in [13], but its analysis was only applicable to the case of Tsallis-INF (FTRL with 1/2-Tsallis entropy), one of the most representative BOBW algorithms.\\nExtending the analysis of [13], the authors show that a BOBW guarantee can be obtained with FTRL with more general regularizers, i.e., negative Shannon entropy, log-barrier, and FTRL with $\\\\beta$-Tsallis entropy, without the assumption of an unique optimal arm.\\nFurthermore, by using the new theory, the authors improve the regret upper bound in the stochastic regime in the decoupled setting.',\n",
       "  'strengths': '- The paper is very well organized and well written.\\n- The paper greatly advances the theory of [13], excluding the unique optimal arm assumption for a wide range of typical regularizers. The assumption have been employed for constructing BOBW algorithms with FTRL, and this is an interesting and important technical contribution to the community.\\n- In addition, the authors affirmatively answer the question of whether it is possible to achieve BOBW without knowing $\\\\Delta_{\\\\min}$ when $\\\\beta$-Tsallis entropy with $\\\\beta \\\\neq 1/2$ (which was unresolved in Zimmert and Seldin [31]), and the question of whether it is possible to achieve BOBW with Shannon entropy using ${\\\\Delta_{\\\\min}}$ to $\\\\Delta_i$-wise in the stochastic setting (unresolved in Ito et al. [14]). The both of contributions are interesting and important. The related points are listed in weakness.',\n",
       "  'weaknesses': '- There do not appear to be any major weaknesses in this paper.\\n- One weakness would be a discussion of whether removing the assumption of unique optimal arm actually improves or worsens the performance of algorithms (The reviewer expects the algorithm becomes more conservative, and the performance becomes worse.)\\n- Since the discussion excluding the assumption of unique optimal arm is cumbersome on its own, it would be desirable to have a discussion of which techniques in the paper contributed to resolving the problems. More specifically, which components of the algorithm play an important role in resolving the problems of [31] and [14], which are mentioned in the above Strengths part? In addition, if we accept the assumption of unique optimal arm, can we achieve improvements in [31] and [14] with a much more similar argument?\\n\\nMinor issues and typos:\\n- line 87: Sepcifically -> Specifically'},\n",
       " 'review_876': {'summary': 'The paper introduces a new algorithm for multi-armed bandit problems, leveraging the FTRL framework and the flexible $\\\\beta$-Tsallis entropy family of regularizers, where $\\\\beta \\\\in [0,1]$. This algorithm firstly uses a new learning rate schedule to offer best-of-both-worlds guarantees for a wide range of regularization parameters. Secondly, it eliminates the requirement of the uniqueness assumption of the optimal arm. Thirdly, it improves the stochastic bounds for Shannon entropy and Log-barrier regularization.',\n",
       "  'strengths': '- The paper introduces new elegant learning rates for $\\\\beta$-Tsallis entropy, providing a best-of-both-worlds guarantee.\\n- It generalizes the regret analysis approach by Ito (2021) by removing the uniqueness assumption of the optimal arm.\\n- As $\\\\beta$-Tsallis entropy is an important regularization in bandit algorithm, the results could be useful in other settings too.\\n',\n",
       "  'weaknesses': '- The results presented in the paper for the plain multi-armed bandit, in my view, lack interest and significance compared to the algorithmic and analysis novelties. Specifically, there is no improvement in terms of regret bounds in the plain multi-armed bandit problem, as FTRL with $1/2$-Tsallis regularizer (1/2-Tsallis-INF algorithm) already achieves the optimal bound in both adversarial and stochastic regimes, and the uniqueness assumption has already been addressed by Ito (2021). The only potential value lies in applying the same ideas to other settings, such as the decoupled exploration and exploitation problem explored, as discussed in the paper.\\n\\n- The bounds in intermediate regimes between stochastic and adversarial, where $C \\\\neq 0$ seem to be suboptimal as they do not interpolate well between the optimal bounds of the two regime. Read question 2 and 3 for further clarification of this issue.\\n\\n- There are few undefined notations used in the analysis. For instance, Equation (6) introduces the notation $D_U$ without providing a clear definition, and the same issue applies to $\\\\phi_U(x)$ and $\\\\phi_V(x)$ in Equation (7). If the used notation for this part were consistent with Ito (2021), $\\\\phi_U(x)$ must accept $x$ from $\\\\mathbb{R}^{|U|}$ but in Equation (7) it takes $x \\\\in \\\\mathbb{R}^{K}$. This inconsistency requires revision for clarity and accuracy.\\n'},\n",
       " 'review_877': {'summary': 'The authors set out to characterize the non-linear behavior of denoising auto-encoders (DAEs), for Gaussian mixtures, in the high dimensional limit with the number of hidden units being fixed. The authors particularly tease out the role of the skip-connection, compared to the reconstruction auto-encoder (RAE) which is known to essentially perform principal component analysis (PCA).\\n\\nUsing the replica method, the authors obtain closed-form expressions for the mean-squared error (MSE), as well as the cosine-similarity (w.r.t cluster means). The obtained formulae are supported by experiments on both synthetic and real data sets, clearly highlighting the role of the sample complexity and the noise level.',\n",
       "  'strengths': '- Presents an effective characterization of (non-linear) DAE behavior on Gaussian mixtures, clearly explaining the role of the reconstruction and scaling components supported by compelling empirical evidence (also on real data).\\n- Draws a number of important conclusions, pointing to fruitful directions of future work, e.g., L200, L218, L278.',\n",
       "  'weaknesses': 'One would wish the long sequence of mathematical expressions could be made less opaque.\\n  - This is remedied by a seemingly complete and well-composed supplementary.'},\n",
       " 'review_878': {'summary': 'This paper presents theoretical results of the test error of 2-layer denoising auto-encoder. In a high-dimensional limit regime where data distribution follows from Mixture of Gaussian, closed-form expressions of the error are obtained. The results are further analyzed and supported by numerical experiments on real data sets.',\n",
       "  'strengths': '- The main result (result 3.3) is highly non-trivial and provides a tight formula for the test error of the 2-layer denoising auto-encoder (DAE). \\n- It shows that DAE can perform much better than PCA in terms of MSE error. \\n- The role and importance of the skip connection is also highlighted in both theory and in practice, as well as the non-linearity in DAE.',\n",
       "  'weaknesses': '- The optimal MSE error mse_o grows with the data dimension d (eq. 9), however the gap between mse_f and mse_o (eq 8) remains a constant, this suggests that the difference between DAE and PCA is not so significant in terms of the relative error of MSE, i.e. | mse_f - mse_o | / mse_o vs. | mse_PCA - mse_o | / mse_o. Thus it is still not very clear whether DAE brings something essentially different to PCA or not (I agree that at least they are different). \\n- In the main result 3.3, it is not clear how the regularization term g is used, i.e. under Assumption 3.2, the parameter lambda does not appear in eq. (8), this is a bit strange to me .'},\n",
       " 'review_879': {'summary': 'The authors consider a two layer weight-tied denoising autoencoder with a skip connection in the regime of vanishing rate and samples proportional to the dimension. They heuristically derive an exact characterization of the optimal network parameters and the corresponding network performance in the the high-dimensional limit using the replica method. Their experiments show that their results match on synthetic data and are very close to the performance on more practical data.',\n",
       "  'strengths': '- Exact characterization of all quantities of interest in the high-dimensional limit. \\n- Strong experimental validation of theoretical claims',\n",
       "  'weaknesses': '- From a theoretical perspective there is a lack of rigor to this method\\n'},\n",
       " 'review_880': {'summary': 'This paper studies the performance of denoising autoencoders (DAEs) in high-dimensional settings. The DAEs are trained on data sampled from a Gaussian mixture with $K$ components perturbed by isotropic Gaussian noise. The DAEs are one-layer networks with arbitrary activation functions, tied weights, and a skip connection. They are trained with an $L_2$-regularized loss function, and the high-dimensional limit is considered, where the ratio of the number of training points to the input dimension converges to a constant α.\\n\\nThe main results of the paper are formulas for the denoising test mean squared error (MSE) for the full DAE, as well as two simpler architectures: a \"bottleneck network\" in which the skip connection is removed, and a \"scalar linear network\" that simply rescales the input by a scalar. The final formulas involve complicated integrals and optimization problems, but they only depend on low-dimensional quantities, such as the number of neurons in the hidden layer and the number of components in the Gaussian mixture.\\n\\nThe authors use the derived asymptotic test error to analyze the role and importance of each component in the performance of DAEs. They find that the skip connection is essential for good performance and that DAEs can outperform other denoising methods, such as principal component analysis (PCA). \\n\\nTaking the noiseless limit, where the variance of the noise converges to zero, they can also derive the test error of reconstruction autoencoders, which are trained with noiseless inputs. ',\n",
       "  'strengths': 'The authors managed to derive fairly complicated asymptotic formulas via the replica method from statistical physics. The empirical experiments seem to confirm the accuracy of their predictions. This provides yet another example of the successful application of the replica method and its surprisingly powerful nature.\\nThis paper fills a gap in the literature and complements previous results that mainly focused on RAEs and the infinite data regime (optimization of the population loss).\\n\\nThe exact formulas derived in this paper are utilized to derive interesting non-trivial results, which can serve as stimuli for future research. Specifically:\\n\\na) The MSE obtained by training a DAE with gradient descent matches the asymptotic predictions, suggesting that while non-convex, the optimization problem has a favorable landscape.\\n\\nb) The exact formulas obtained for the Gaussian mixture predictions align with those obtained for a DAE trained on MNIST datasets, indicating the presence of universality phenomena.\\n\\nc) As α increases, the denoising MSE of the DAE approaches the asymptotic performance of the oracle denoiser (derived in the appendix).',\n",
       "  'weaknesses': 'The paper exhibits weaknesses similar to other papers in this field. The exact analytical formulas derived are somewhat obscure, and it seems that several of the observations made in the paper can be deduced directly from the results of the empirical experiments, without relying on the analytical formulas (e.g. the improved performance of the network with skip connections compared to the one without can be easily inferred). The authors should emphasize the results that their analytical formulas allow to obtain.\\n'},\n",
       " 'review_881': {'summary': 'The paper attempts to elucidate the theoretical reasoning for the benefits seen in score matching. The author proposes a family of exponential distributions that can efficiently compute the score matching loss while having a comparable statistical efficiency to that of maximum likelihood. ',\n",
       "  'strengths': '- The paper is well written/organized and easy to follow. The author does a good job introducing related theoretical information.\\n- Equations are extensively described with a thorough description.',\n",
       "  'weaknesses': '- There are no experimental results. It would be nice if there were some machine learning models that were optimized with score matching and ML and compared with each other. '},\n",
       " 'review_882': {'summary': 'In this paper, the authors present a mathematical setting where Score Matching (SM) method has more statistical benefits than Maximum Likelihood (ML) technique, when estimating a parameterized probability distribution $p_\\\\theta \\\\in P(\\\\mathbb{R}^n)$ known up to a normalizing constant $Z_\\\\theta$. In particular, they describe an explicit exponential family of distributions $F$ for which SM loss $L_{SM}$ is efficient to compute, with same statistical efficiency as ML loss $L_{ML}$ (Theorem 2 and 3), while $L_{ML}$ is shown to be intractable in polynomial time depending on the parameters of this family (Theorem 1). Given an odd integer $d$ and $B>0$, any distribution $p_\\\\theta \\\\in F$ is notably defined by (i) its vector of sufficient statistics, which consists of all monomials in $x^1,..., x_n$ of at least degree $1$ and at most degree $d$, and (ii) its parameter $\\\\theta$, which lies in the $\\\\ell_\\\\infty$-ball with radius $B$. This work is the first one to put in perspective the statistical efficiency of SM and ML for a large family of continuous probability distributions. \\n\\n\\nThree main theoretical results are stated here. In Theorem 1, the authors prove that, for any $p_\\\\theta \\\\in F$ (with $d=7$) and any set of $N$ independent samples from $p_\\\\theta$, it is NP-hard (in $n$ and $N$) to provide an accurate approximation of $L_{ML}(\\\\theta)$ and $\\\\nabla L_{ML}(\\\\theta)$. This result comes from the difficulty to approximate $Z_\\\\theta$, which is necessary to compute $L_{ML}(\\\\theta)$, while it does not appear in $L_{SM}(\\\\theta)$. In Theorem 2, they derive an upper bound of the $\\\\ell_2$-error between $\\\\theta$ and its ML estimator obtained via $N$ samples, in the limit where $N\\\\to \\\\infty$, for any $p_\\\\theta \\\\in F$. Their proof relies on the asymptotic result given by [1] and consists of lower bounding the smallest eigenvalue of the Fisher information matrix of $p_\\\\theta$. In Theorem 3, they derive the same upper bound in the case of the SM estimator for any $p_\\\\theta \\\\in F$, by invoking the asymptotic result from [2] and bounding the Poincaré constant of $p_\\\\theta$. Combined together, Theorems 2 and 3 show that ML and SM techniques roundly have the same statistical efficiency.\\n\\n[1] Asymptotic statistics, Van der Vaart, 2000.\\n\\n[2] Statistical Efficiency of Score Matching: The View from Isoperimetry, Koehler et al., 2022.',\n",
       "  'strengths': '- This work provides a fair comparison between statistical efficiency for SM and ML technique, which is of primary interest for the community of machine learning.\\n- Although Theorems 2 and 3 rely on important theoretical results, their results are not straightforward to obtain, and their proofs are original and clear to understand.',\n",
       "  'weaknesses': 'Although the theoretical results presented here are interesting in their own, they should be combined with numerical experiments, which should illustrate the trade-off between these two methods in practice, depending on the parameters of the exponential family.'},\n",
       " 'review_883': {'summary': 'This paper provides an example of fitting exponential family models for which score matching \\nand MLE are both statistically efficient, but MLE is computationally hard to optimize. ',\n",
       "  'strengths': 'The strength is in the construction of an example to showcase the benefit of score matching \\nover MLE. ',\n",
       "  'weaknesses': \"Several aspects  could be improved. \\n\\n1. First, for the computational lower bound, the points to evaluation loss and gradient is worst case. \\nWhen one has samples from such distribution, is solving MLE still computationally hard? \\n\\n2. Although the aim of this paper is to provide examples to advocate for score matching, but for the \\ndistribution family proposed in the paper, are there simple (or simpler) estimators that are both computationally and \\nstatistically efficient? \\n\\n3. In the paper, the analysis of the statistical performance is quite crude, which makes it hard to see what's \\nthe statistical cost one needs to pay when computation is the restriction. Is there proper computation-statistic \\ntradeoff for the model considered in the paper? \"},\n",
       " 'review_884': {'summary': 'The authors describe an exponential family where the sufficient statistic $T(x)$ contains all non-constant monomials of degree $\\\\leq d$, the background density is $h(x) = \\\\exp(-\\\\sum_{i=1}^n x_i^{d+1})$, and the parameter $\\\\theta$ is constrained to have infinity norm bounded by $B$. Using a reduction from $3\\\\mathsf{SAT}$, they show that under this exponential family, finding the MLE is NP hard, and thus unless $\\\\mathsf{NP} = \\\\mathsf{RP}$, that it would take time exponential in the random vector dimension $n$ to compute the MLE. \\n\\nThey also show that the MLE has asymptotic sample efficiency $(nB)^{O(d^3)}$. They show that score matching also has asymptotic sample efficiency $(nB)^{O(d^3)}$. Unlike the MLE, score matching can be solved in time polynomial in the dimension of $\\\\theta$, which if $d$ is considered constant, is polynomial in $n$. This is because the objective corresponding to score matching is convex in $\\\\theta$.\\n\\nThis is a concrete example of a situation where score matching has a provable advantage over the MLE (same asymptotic sample efficiency, but one needs exponential time unless $\\\\mathsf{NP} = \\\\mathsf{RP}$ and the other is polynomial time).',\n",
       "  'strengths': '- clear contribution\\n- relevant related work is discussed\\n- this is a significant result (rigorous justification for potential benefit of score matching over MLE)',\n",
       "  'weaknesses': \"No glaring weaknesses, but the paper was a bit difficult to follow; I found it hard to connect the math-heavy theorem/lemma statements together. For example, I did not understand how Lemmas 4.2 and 4.3 built toward Lemma 4.4 on my initial read. \\n\\nTypos spotted:\\n- Equation under line 172, $\\\\|\\\\theta\\\\|_2^2$ should be $\\\\|\\\\theta^*\\\\|_2^2$?\\n- Line 482, $f''(x) = 56\\\\gamma x^6 - 2\\\\beta + 6\\\\beta x^2$ should be $f''(x) = 56\\\\gamma x^6 - 4\\\\beta + 12\\\\beta x^2$ I think, but this doesn't affect anything\\n- Lemma A.6, the $(2/e)^n$ should be replaced with $(e/2)^n$\\n- Math at the bottom of page 16, second line, you want to minimize the exponent so instead of $-BM(BM)^{-d}$ it should be $-BM(BM)^{-1}$ right? I don't think this affects anything though since you bound it by $-1$ regardless\\n- Math under line 519, I'm not sure that $(n+\\\\ell)\\\\log(2L) + 2 + n\\\\log(BM) \\\\leq \\\\frac14 L^{d+1}$, unless some lower bound on $d$ is assumed? Like I'm not sure if that holds for $d=1$?\\n- Lemma B.3, bound on Laplacian in the Lemma statement doesn't seem to match the derivation (exponent of 2d vs 4d)\\n- Line 564 - this appears to be claiming that $\\\\sum_{j=0}^k \\\\binom{k}{j}^2 = 2^k$, which is false? I think you could bound it by $2^{2k}$ though by Cauchy-Schwarz, so it probably doesn't matter, just changes some constants down the line.\\n- Line 573 - $B_\\\\iota \\\\to W_\\\\iota$\\n- Line 583 - $\\\\alpha_i \\\\to d_i$\"},\n",
       " 'review_885': {'summary': 'This paper studied the problem of collaboratively learning least squares estimates with multiple agents, each of which only observes a different subset of the features. The authors proposed a distributed, semi-supervised algorithm called Collab consisting of three steps: 1) local training, 2) aggregation, and 3) distribution. The authors showed that the proposed Collab algorithm is nearly asymptotically local minimax optimal. The authors conducted experiments to verify their algorithm on real and synthetic data.',\n",
       "  'strengths': '1. This paper provides deep theoretical insights into their proposed Collab algorithms. The results in Theorems 4.1 and 4.2 that the performance of Collab is no worse than local imputation with collaboration and global imputation are novel and surprising.\\n\\n2. The asymptotic local minimax lower bound is interesting and could be of independent interest.',\n",
       "  'weaknesses': 'Although the results in this paper are interesting, as the authors themselves admitted, they are only limited to the linear model and Gaussian features. But the authors did provide some interesting discussions in Section 7 on future directions. '},\n",
       " 'review_886': {'summary': 'Summary\\n-------\\n\\nThe paper studies collaborative linear regression when m agents attempt to collaboratively\\nestimate a linear model, under communication constraints. Each agent i only observes di\\nof the d features. A central server designs a protocol to elicit sufficient information\\nfrom each agent and compute the parameter theta of the linear model so as to minimize\\ncommunication costs and the estimation error.\\nThe authors present, what appears to be a near-complete solution, for the case where the\\ncovariates are distributed as a Gaussian and when the covariance matrix is known. This\\nincludes asymptotic normality results for the proposed estimator and lower bounds which\\nmatch as n goes to infinity. The authors also compare their method against other baselines\\nbased on imputing data and show that their estimation errors are no worse but at\\nsignificantly lower communication cost.\\n\\nDecision: While the paper is well-presented and pleasant to read, I am not an expert in\\nthis topic and did not have the time to go through the proofs in detail. As such,\\nI am unable to evalute the technical merit of the paper (challenges of the problem,\\nnovelty of proof techniques). I have given a positive score with low confidence to reflect\\nthis but will heed to more expert reviewers during the discussion.\\n\\n\\nDetailed comments\\n-----------------\\n\\nThe authors have used local and global imputation\\nbaselines in Table 1 to show the communication benefits, and have gone on to show that\\ntheir method does no worse theoretically than these methods.\\nHowever, I am not sure if these are particularly strong baselines to compete with; for\\ninstance, I would not have expected communicating all data points to be necessary.\\nIn fact, at the outset, my intuition suggested a solution which computes local\\ncoefficients by each agent which are then aggregated by the server in an appropriate\\nfashion.  It would have been helpful if the authors had better illustrated the challenges\\nin doing so. For instance, is the method in 3.1 the most natural way to solve this\\nproblem, or are there other naive ways to aggregate the coefficients that yield\\nsub-optimal solutions?\\n\\nThe same applies to the non-Gaussian case and the setting when the co-variance matrices\\nare unknown. The authors could have done a better job of illustrating the challenges.\\nIn general, I did not get a sense for how challenging this problem setting was to\\nappreciate the contributions by the authors.\\n\\nDo the results in Theorems 3.1-3.2 implicitly capture the difficulty of the problem in\\nterms of the number of covariates each agent has access to?\\n- For instance, in the worst case there could be only n samples (when there is a perfect\\n    partition of the covariates among the agents, and they have the same points),\\n    but in the best case there could be mn\\n    samples (when all agents have all the covariates and have distinct points)\\nIf so, is it possible to make this more explicit in the results.\\n\\nThe paper is largely well-written. The problem is well-motivated, the setting is described\\nclearly, and the method/results are organized well. I would have however liked to see a\\nsketch of the main proof ideas and how they differ from similar results in the linear\\nregression literature. A breakdown of the key proof challenges that the authors had to\\novercome would have also been useful.\\n\\nWhat was the reason for the discussion around o(n) communication complexity? It appears\\nthat local imputation methods and the method of the authors are able to achieve consistent\\nestimation with communication cost that does not depend on n.\\n\\nIn the experiments, the imputation-based methods outperform the method of the authors when\\nthere are more samples. Intuitively, I would have expected this since they are more\\ncommunication-heavy. However, this is not the case in the low-sample regime. Can you\\nexplain why this is the case?\\n',\n",
       "  'strengths': 'See above.',\n",
       "  'weaknesses': 'See above.'},\n",
       " 'review_887': {'summary': 'The paper studies statistical inference in learning a linear regression model in the cross-silo or vertical federated learning setting. The paper formulates the problem as a missing data problem and chooses single imputation methods to deal with the associated inference of the common parameter. The paper shows the theoretical properties of the proposed estimator under some assumptions. Finally the paper compares their results with other existing methods.',\n",
       "  'strengths': 'The paper studies a very important problem and relatively easy to follow.',\n",
       "  'weaknesses': '1. The paper is not carefully written with confusing notations and problem formulation:\\n\\n1(a). In Section 2, it says that “the $i^{th}$ agent has data $(x_{i+}, y)$” and then later uses $y_i$ to denote the $i^{th}$ agent labeled data. It is unclear whether these labels are the same or not. If they are the same, this is an unrealistic assumption in practice and obviously contrary to the common assumption in the literature that only one active party has access to the label data. \\n\\n1(b). Equation (1) defines a weighted MSE, with expectation assessed with respect to the feature $x$, which is problematic. Why not consider the typical unweighted MSE with expectation evaluated with respect to $y$ in regression setting? \\n\\n2. It seems that the contribution of the paper is to apply existing single imputation based missing data method to vertical federated learning setting, with the exception that here they assume each agent has access to its own label data (which again is problematic).\\n\\n3. The paper does compare their methods with several other methods in the experiment. However, there are not enough discussions of these methods.'},\n",
       " 'review_888': {'summary': 'The authors investigate collaborative learning of least squares estimates for multiple agents with varying feature subsets. The goal is to coordinate the agents efficiently to achieve optimal estimators without exchanging labeled data. To address this, the authors propose the distributed algorithm Collab, consisting of local training, aggregation, and distribution steps. Despite not sharing labeled data, Collab approaches near-asymptotic local minimax optimality, outperforming methods that do utilize labeled data. They validate our approach through experiments on real and synthetic datasets.',\n",
       "  'strengths': 'Distributed learning with heterogeneous data sources is a problem of broad interest. In this study, the authors tackle this problem in a simplified setting and provide robust theoretical guarantees. Their theoretical results are strong, demonstrating the solid foundation of their approach. In addition, the point of minimizing communication resources is an interesting angle. Furthermore, the experimental results are compelling, further supporting the effectiveness of their method. ',\n",
       "  'weaknesses': '- Settings need more justification: the authors discuss a setting where a linear regression problem is running on satellites with completely different features. This seems restrictive and can the authors elaborate more on the motivation of their study?\\n- Random X with zero mean. If X is not zero-mean, then the regression with partial information is not consistent anymore (different features may have correlations). I can imagine this is a very common scenario and can the authors provide some discussions on this? \\n'},\n",
       " 'review_889': {'summary': 'The paper discusses the idea of estimating least squares collaboratively when each agent has access to a different set of features of the same data. The aim is to design an effective and efficient algorithm in terms of communication cost (various agents transferring/communicating information/data). The paper introduces a new algorithm *COLLAB* that is efficient and also applicable in security fields where features can not be transferred between agents/sensors/machines/systems. The authors theoretically prove that the proposed algorithm *COLLAB* is minimax optimal and perform a set of experiments to showcase the capability of the proposed algorithm *COLLAB*.',\n",
       "  'strengths': 'The paper discusses the setup typical in many fields (especially security applications) where data can not be transferred between agents due to security reasons or input-output constraints (network bottleneck). In the setup discussed, when the agent has a linear model, ordinary least squares (OLS) is a logical way to solve and get the parameter value. The idea behind *COLLAB* is logical and intuitive however needs more clarity in the presentation. The comparison against the imputation methods is also logical, as these are go-to models for such setups. The authors derive local minimax lower bounds to showcase that the proposed algorithm *COLLAB* is very close to the optimal, which is interesting. For the correctness of this section, I would rely on other reviewers as I was not able to follow the derivations clearly. The experiments are also a good mixture of real-world and synthetic data sets where the capability of the proposed algorithm is shown. ',\n",
       "  'weaknesses': '* A nice idea, but some assumptions are very hard/limited, and the evaluations are limited.\\n* Some details (especially Sections 3.1 and 3.2) are presented convolutedly and are hard to grab. Some minor clarifications:\\n  - L110, is the `x` written same as L99? It probably should be `X`?\\n  - L132, L133: I am still not sure what `(i)` refers to here.\\n  - In general, I believe it is convenient to stick to the notation where bold **`X`** is a matrix, bold **`x`** is a vector and `x` is a scalar. It makes it easy to follow the equations.\\n* Evaluations are limited. More empirical evaluations are to be performed to showcase the results of the proposed algorithm against other methods. A limitation here is the linear model in the agents, which limits the modelling capability of the model.\\n* Considering non-linear cases as well would make the paper more solid. Then the agents are more flexible, and the authors can experiment with more complex data sets.\\n* Computation benefits should be shown empirically as well. Currently, it is only shown theoretically.   \\n'},\n",
       " 'review_890': {'summary': 'The authors proposes to solve graph-based semi-supervised learning (GSSL) problems by first finding the \"optimal graph\" for SSL. The optimal graph has edges only from labeled to unlabeled nodes, or between unlabeled nodes. These edge weights are computed through FISTA algorithm in the dual space, and theoretical guarantees are provided for sub-linear convergence rates. Experiments are conducted using both synthetic and real-world datasets.',\n",
       "  'strengths': 'This paper is very well written and nicely presented. The clear writing made it easy to follow.\\n\\nI did not carefully read through the proofs in the appendix, but the motivation for the framework and derivation of the algorithm seem correct. I appreciate that this paper did solid work on all aspects - problem formulation, clever optimization algorithm, theoretical convergence analysis, and numerical experiments. ',\n",
       "  'weaknesses': 'Please see the questions below.'},\n",
       " 'review_891': {'summary': 'This paper proposes a novel methodology for graph-based semi-supervised learning by leveraging a asymetric graph construction technique. The main contribution of the paper is the design of a block-wise graph learning framework to estimate the weights of a graph.',\n",
       "  'strengths': 'The main strengths of the paper are:\\n- The derivation of the structure of the optimal affinity graph\\n- The derivation of an optimization algorithm for the implementation of the block-wise graph learning algorithm\\n- The thorough experimental evaluation to assess the performance of the proposed algorithm in different scenarios\\n',\n",
       "  'weaknesses': '- While the derivation of the optimal affinity graph is novel, the optimization algorithm for learning the graph weights are heavily influenced by prior works, and therefore not much novel.\\n\\n- The plots (c) and (d) in Figure 3 are not as helpful as the x-axis represent number of iterations where instead the authors should use computational time. Therefore, from Figures 3c and 3d we cannot conclude much about the computational efficiency of the proposed algorithm.'},\n",
       " 'review_892': {'summary': 'This paper proposes an efficient and effective method for constructing affinity graphs in Graph-based Semi-supervised Learning (GSSL), with a focus on the distinct roles of labeled and unlabeled nodes. The authors present a formulation for the GSSL problem, comprising two steps: graph construction and label inference. They investigate the optimal construction of the affinity graph in the first phase to facilitate enhanced performance in the second label inference phase. The paper offers four main contributions: a succinct definition of the optimality of the affinity graph in GSSL, a block-wise graph learning framework to infer the weights in the optimal graph structure, proof of a global sub-linear convergence rate for the proposed method, and extensive experiments on synthetic and real-world datasets to demonstrate the effectiveness and efficiency of the proposed method.',\n",
       "  'strengths': 'Originality:\\nThe paper presents a novel approach to constructing affinity graphs in GSSL, with a focus on the distinct roles of labeled and unlabeled nodes. The proposed method is based on an asymmetric structure and a block-wise graph learning framework, which are different from existing methods. The paper also offers a succinct definition of the optimality of the affinity graph in GSSL, which is a unique contribution to the field. Overall, the paper is highly original in its approach to graph construction in GSSL.\\n\\nQuality:\\nThe paper is well-written and presents a rigorous derivation of the proposed method. The authors provide a clear explanation of the problem formulation and the proposed solution, as well as a detailed analysis of the benefits of the proposed method. The experiments are extensive and well-designed, with results that demonstrate the effectiveness and efficiency of the proposed method. The paper also includes a thorough review of related work, which adds to the quality of the paper. Overall, the paper is of high quality.\\n\\nClarity:\\nThe paper is well-organized and easy to follow. The authors provide clear explanations of the concepts and methods used in the paper, and the figures and tables are well-designed and easy to understand. The paper also includes a summary of the contributions and a conclusion that summarizes the main findings. Overall, the paper is highly clear and well-presented.\\n\\nSignificance:\\nThe paper makes a significant contribution to the field of GSSL by proposing an efficient and effective method for constructing affinity graphs. The proposed method is based on an asymmetric structure and a block-wise graph learning framework, which are different from existing methods. The paper also offers a succinct definition of the optimality of the affinity graph in GSSL, which is a unique contribution to the field. The experiments demonstrate the effectiveness and efficiency of the proposed method, which has the potential to improve the performance of GSSL algorithms in a wide range of applications. Overall, the paper is highly significant in its contribution to the field of GSSL.',\n",
       "  'weaknesses': \"1. Lack of comparison with more recent state-of-the-art methods: While the paper compares the proposed method with several existing methods, some of these methods are relatively old and may not represent the current state-of-the-art in GSSL. It would be useful to compare the proposed method with more recent methods to provide a more comprehensive evaluation.\\n\\n2. Limited discussion of the limitations of the proposed method: While the paper discusses the benefits of the proposed method, there is limited discussion of its limitations. It would be useful to discuss the situations in which the proposed method may not be effective and to provide guidance on when to use the proposed method versus other methods.\\n\\n3. Lack of real-world applications: While the paper includes experiments on synthetic and real-world datasets, there is limited discussion of real-world applications of the proposed method. It would be useful to provide examples of how the proposed method could be applied in real-world scenarios and to discuss the potential impact of the proposed method on these applications.\\n\\nOverall, while the paper presents a novel approach to constructing affinity graphs in GSSL, there are some weaknesses that could be addressed to improve the paper's impact and relevance.\"},\n",
       " 'review_893': {'summary': 'The paper proposes a method for graph construction stage of graph based semi-supervised learning. They further evaluate their method with experimental results. ',\n",
       "  'strengths': 'The authors present strong theoretical results. ',\n",
       "  'weaknesses': 'The experimental results for the proposed method in Table 2 are only marginally better than the baselines. '},\n",
       " 'review_894': {'summary': 'The paper presents an optimal asymmetric graph structure for the label inference phase in graph-based semi-supervised learning (GSSL). The key motivation or intuition proposed by the authors is that we need to differentiate the roles of labeled and unlabeled nodes. Therefore, the authors design an efficient block-wise graph learning algorithm with a global convergence guarantee. The proposed method is shown to be superior to SOTA graph construction methods in GSSL through extensive experiments on synthetic and real-world datasets. The paper addresses the challenge of constructing a high-quality graph, which significantly influences label prediction performance, and proposes a solution with theoretical motivations and benefits, such as enhanced robustness to noisy node features. ',\n",
       "  'strengths': '1.\\tQuality: The work is of high quality, with rigorous theoretical motivations and comprehensive experiments. First, the motivation is strongly supported by some theoretical analysis. The proposed asymmetric optimal graph structure is deduced from Definition 1 rigorously. The authors provide a comprehensive explanation of the optimization problem and the structure of the optimal affinity graph. Second, they also present a detailed implementation of the block-wise graph learning algorithm BAGL. The paper is well-referenced, indicating a thorough understanding of the existing literature. Third, the provided convergence analysis on BAGL is also rigorous. The global sublinear convergence rate in Theorem 3 makes sense to the reviewer. Forth, the experiments are comprehensive, including several comparisons from the aspects of prediction accuracy, efficiency, and convergence rate. \\n2.\\tClarity: The paper is well-structured and clear, with each section logically leading to the next. The authors provide clear definitions and explanations of complex concepts, making the paper accessible to readers with varying levels of expertise in the field. However, some parts of the appendix are suggested to move to the main body to give more background context on graph-based semi-supervised learning. The use of mathematical notation and diagrams further enhances the clarity of the paper.\\n3.\\tSignificance: The reviewer thinks the work makes some significant contributions to the GSSL field. First, the investigated problem is significant since most GSSL literature only focuses on the label inference step. This paper focuses on the neglected graph construction step instead, as the quality of the graph affects the subsequent step a lot. Second, the proposed method achieves the SOTA global convergence rate, contributing to the GSSL field significantly.\\n',\n",
       "  'weaknesses': 'There are several potential improvements in this paper.\\n1.\\tThe background knowledge of the unified label inference framework can be elaborated. The details behind Eq.(1) should be provided to give readers without GSSL backgrounds more context. For example, Appendix B.2 should be added to the main body. Table 5 is very informative.\\n\\n2.\\tThe recent graph structure learning method should be discussed or compared since the goal of GSL is also similar to the task investigated in this paper.\\n\\n3.\\tThe conclusion part is short. More future work can be added.\\n\\n4.\\tOther comments in questions section.\\n'},\n",
       " 'review_895': {'summary': 'In this paper, the authors propose a new task named language-driven scene synthesis. This new task takes text prompts, human motion, and existing objects to generate the next object in the scene. To handle the multiple conditions, they design a guiding points strategy to unify them. It first explicitly predicts a \"pseudo\" target point cloud from the conditions and then uses these predicted points as a guide for the diffusion model to predict the \"truly\" target point cloud. They demonstrate their approach is theoretically supportive. In the experiment, they show that their method outperforms the state-of-the-art baselines. Furthermore, they introduce three scene editing tasks that are useful for application.',\n",
       "  'strengths': '- The proposed language-driven scene synthesis task integrates text prompts, human motion, and existing objects as conditions. It is an interesting direction that injects user preference for scene synthesis and thus enables real-world scene editing applications with text prompts. \\n- To handle the multiple conditions, the authors revisit point cloud representation and propose a guiding point concept to use the conditions explicitly. They first predict a \"pseudo\" target point cloud from the conditions and then use these predicted points to guide the diffusion model to predict the \"truly\" target point cloud. This explicit strategy injects a strong inductive bias to utilize all the conditions for placing the next object.\\n- The experiment part is intensive and demonstrates the proposed method with text prompts, human motion, and existing objects as conditions achieve the best results compared with baselines.',\n",
       "  'weaknesses': '- I have a question regarding the application of the proposed new tasks. When we take only human motion as a condition for scene synthesis, MIME (Yi et al., 2023) treat this as \"turning human movement in a \"scanner\" of the 3D world.\" In your proposed task that uses human motion and text prompts, I understand it is useful when we want to place a table in the VR setting. However, what is the use case if the human motion is setting down and using \"put a chair under the human\" as a prompt? We can not use this in VR since we can not sit without a real chair.\\n- I don\\'t like the presentation of this paper. The reasons are as below. \\n  1) Section 3.2 seems to break the flow of the whole paper. After reading this subsection, I need to back to Section 3.1 multiple times to remind myself of the notation for Section 3.3. It is suggested to make the theoretical support in the main paper shorter and at a high level and move the others to the supplement. \\n  2) Since Section 3.2 uses too much space in the main paper, the authors make Section 3.3 short and unclear. However, this is the main contribution of this paper. It is messy for the audience to read the operations with only unclear text descriptions (also without any shape information for the variables). It is suggested to add equations or pseudocode to describe the operations. \\n  3) Figure 2 is also unclear. For example, for the text, it is stated that \"the input key is the text embedding e′, the input queries are the given scene entities.\" However, in Figure 2, the text embedding e′ and the scene entities are concatenated and then fed to the attention modular. \\n  4) I read the supplement. The motivation part deserves to be moved to the main paper. The implementation details also need to be clarified. Especially, Table 2 is unreadable. Why not list the equations of the operations?\\n- For the baselines, can you add text prompt conditions to MIME for your proposed task for a fair comparison? Considering their method is transformer-based, it should be easy to add text conditions.\\n- For the editing tasks, is the target object necessary to be the M+1 object? In the text prompt, the target object is already indicated. In this case, it seems that we can change any object in the scene instead of only the last one. \\n- In Line 171, you claim that \"we extract spatial information from the text prompt by utilizing the off-the-shelf multi-head attention layer.\" What is the meaning of \"off-the-shelf\" here? \\n- In Table 2 of the supplement, the output of the text encoder is 1D. I remember that the output of the CLIP text encoder is a list of tokens. Do you apply pooling here?'},\n",
       " 'review_896': {'summary': 'This paper deals with scene synthesis with human pose, room layout, and text prompts.\\nThe main architecture is a multi-conditional diffusion model, which performs progressive generation, where a new object is synthesized and conditioned on the existing scene point cloud and the language description.\\nThe key contribution is a guiding point network, which first generates a reference point cloud as a weighted sum of existing objects and human pose, then the reference point cloud is used as a condition to guide the denoising processing for a new object.\\nThe trained network allows scene generation guided by language and can produce semantically meaningful scene edits.\\n',\n",
       "  'strengths': \"The progressive generation of scenes guided by language makes it much easier to interact with the synthesis process and alleviates the control burden from the designer's side.\\nThe experiments show the effectiveness of the proposed pipeline and the learning objective.\\nThe ablation study is interesting.\",\n",
       "  'weaknesses': 'The architecture is quite intuitive, but the derivation is not quite clear and seems disconnected from what the author wants to do.\\nEquations (2) and (3) are standard, but starting from equation (4), when the guiding point is introduced, some unsureness kicks in.\\nFor example, why do you assume that x_0 is a uniform distribution over a domain S, how do you define S in the first hand, and why x_0 be uniform is a good assumption? Also, why q(y|x_0) is non-zero uniform over S?\\nWhat is the difference between S and S_hat, and what do you mean by sampling set of x_0?\\nWhy then q(x_0) becomes uniform?\\nHow do you infer q(x_0|y) is also uniform over S? how?\\nIf q(x_0) is uniform, then \\\\mu_0 is the center of the region S? why this is a meaningful quantity in your consideration?\\nWhy is S_tilt a sampling set of S_hat?\\nEq. (10) is very intuitive, why do we need all the previous derivations?\\n'},\n",
       " 'review_897': {'summary': 'This paper targets to generate 3d scene  by conditioning on text prompts and other inputs, e.g., room layouts. For this purpose, they operate on 3d point cloud representation and propose a multi-conditional diffusion model to generate guiding points to achieve 3d scene synthesis purpose. The experiments are evaluated on synthetic indoor dataset.  ',\n",
       "  'strengths': '- Adopting human pose into 3d scene generation process is a novel condition to consider during generation.',\n",
       "  'weaknesses': '- The authors did not motivate well on why a diffusion model is necessary or better for this task. Given the large amount of prior work in scene layout, is there any advantage of diffusion model, such that it can do something prior method cannot?\\n- Their dataset is too simple. On one hand, the authors deal with 3D point cloud representation, which usually noisy and sparse in real-world scanning data. On the other hand, they only test the solution on synthetic dataset, which seems to be in a different distribution with real-world scan. An evaluation on real-world dataset can make the world more solid. \\n- Their video supplementary is confusing in terms of what kind of application that are aiming at. Is the audio cut off accidentally in the mp4? As for the application, is that the authors hope to leverage human pose to generate 3d objects in the indoor scene? '},\n",
       " 'review_898': {'summary': 'This paper focuses on language-driven scene synthesis, a new task integrating text prompts, human motions, and existing objects as multiple conditions. The proposed task is challenging as it requires a strategy for encoding the multi-modal conditions into a unified space. To solve the problem, the authors introduce a novel guiding points concept to combine multiple conditions, which can explicitly contribute to the denoising process. They also introduce three scene-editing applications based on the text prompt input. They demonstrate the approach empirically and theoretically; the intensive experiments show that the proposed approach achieves significant improvements over the state-of-the-art methods.',\n",
       "  'strengths': \"1. Extending the scene synthesis to a language-driven setting, incorporating text prompts and human motions as input, holds great promise and significance in bridging the gap between research and real-world applications. It also enables downstream real-world scene editing applications.\\n\\n2. This paper proposes a somewhat novel method to handle such a multi-conditional setting. The authors introduce guiding points that explicitly guide the reverse process of the diffusion model, offering a departure from the implicit unification approach used in previous multi-conditional diffusion models.\\n\\n3. This paper's theoretical demonstration and experimental analysis are comprehensive, especially the ablative experiment, which demonstrates the impact of different modalities and how the proposed modules contribute to the overall performance.\\n\",\n",
       "  'weaknesses': '1. In comparing MIME to your approach, I notice that MIME focuses on generating 3D scenes based on 3D human motion, whereas your method takes a human pose as input. Considering this distinction, is it fair to make a direct comparison between MIME and your approach?\\n\\n2. It has come to my attention that Proposition 2 and Corollary 2.1 are included in section 3.2. However, it may be more suitable to relocate them to the supplementary materials. I am uncertain about the significance of these components within the section, and it seems that the author included them primarily to showcase their expertise.'},\n",
       " 'review_899': {'summary': 'This paper approaches the task of predicting a location and orientation of furniture, conditioned upon a person’s motion sequence, existing furniture, and text. By conditioning on text, which prior work does not do, the proposed method enables users to actively specify furniture location. In addition, experiments show it enables object replacement, shape alteration and displacement. This work introduces captions to prior human motion-furniture dataset PROXD, and shows SOTA performance given captions.',\n",
       "  'strengths': 'This paper adds a useful contribution to the task of human-guided scene layout\\n- Prior work generates furniture from motion. This work enables users to specify location using text, making it much more applicable to real-world scenarios\\n- Gathering captions to a standard dataset PROXD enables the proposed method to significantly outperform prior work across metrics. The paper contains good analysis of text prompts in Supplemental.\\n- The method also can leverage text from HUMANISE, again enabling significant improvement\\n- The approach also enables object editing, which is experimentally evaluated\\n\\nThe method proposes the intuitive approach of “guiding points” to this conditional 3D diffusion task, which it shows is highly effective in experiments.\\n- The idea of conditioning on a weighted combination of predicted locations from each conditioning component is intuitively more powerful than conditioning on latent encodings \\n- The paper provides theoretical guarantees guiding points explicitly contribute to denoising\\n- Experiments show conditioning upon guiding points is more effective than translation vectors alone, or unconditional\\n- Experiments also show correlation between accuracy of guiding points and final performance, empirically confirming theoretical findings.\\n',\n",
       "  'weaknesses': 'Edit: after rebuttal, my concerns are well-addressed.\\n\\nThere are several missing details and comparisons that make full assessment of the paper challenging. This includes missing limitations.\\n- I do not understand how the training works for scene synthesis, which makes it hard to fully assess the importance of guiding points. My understanding is the LSDM denoises a point cloud given the output of the guiding points network. I assume then, the guiding points network is trained jointly, end to end with the LSDM, at each denoising step? And that no networks are pretrained, including text encoder (I’d assume this is pretrained)? This would mean S is not actually trained to predict final position, but rather consists more of geometric features? Based on Figure 6, it is hard to determine if S is directly supervised.\\n- It feels like another reasonable design choice would be to initialize diffusion with guiding points, and denoise these, as opposed to (or in addition to) conditioning upon them. Testing this choice could perhaps more directly validate the theoretical findings that using S specifically for conditioning is helpful. \\n- In qualitative results, a single human location is used. However, the proposed task is to consider a vector of human locations (“motion”). How does text work given the input is not a single location, but a set of locations? Text is sensitive to location e.g. “Place a desk in front of me”. Is time assumed to be the last timestep? In this case, does the dataset generate text descriptions based only on the last location of the human? In reality, I would imagine users would like to specify text based on any number of timesteps throughout the trajectory e.g. “place the desk in front of me [at frame i<N of N]”\\n- The comparison to multi-conditional modeling is not fully satisfying. The method compares to itself without F, but otherwise keeps the same geometric-based architecture. Namely, it combines weights linearly using w. A more standard conditional diffusion approach would be to concatenate features or combine them through nonlinear (e.g. transformer) layers. This comparison would make the argument for the proposed method stronger.\\n- Is there a breakdown into in-contact vs. not in-contact objects? Prior work specifically uses this; as this paper claims to outperform in not-in-contact objects, it would be a helpful metric to report.\\n\\nContributions feel slightly niche (minor weakness)\\n- The central contribution of conditioning upon a geometrically transformed linear combination of feature distances of objects and humans is a cool contribution. However, it feels specific to the task of furniture placement conditional on human motion and text. Is there a wider reason this method is important?\\n- Saying scene synthesis has gained significant attention in the past few years and citing one paper from last year with 3 citations (L16) is not convincing the task is very important\\n- Text-conditioned diffusion models predicting position and orientation already exist in the near subfield of human motion generation (Tevet et al. Human Motion Diffusion Model, ICLR 2023). The application in the near subfield of furniture position and orientation on its own feels like a relatively modest step.\\n'},\n",
       " 'review_900': {'summary': 'This paper first studies the expressive power of a random-feature attention layer and then provides the generalization gap of the attention layer. A sample complexity bound is shown, which indicates a larger number of attention heads help the generalization. This paper also compares the results between attention and MLP layers given several target functions. Numerical experiments support the theory. I am willing to update my score after the rebuttal if my concerns are addressed with revisions in the manuscript.\\n\\n-------------------------------------------------------------------\\nAfter rebuttal, I increased my score to 5. Please see comments below.',\n",
       "  'strengths': '1. The paper is clear and well-written. The proof seems to be solid.\\n2. The random feature analysis of attention layers is new to this community. The analysis combines the expressive power and the generalization gap, which is better than some existing works.\\n3. The comparison between attention layers and MLP covers a lot of target functions, which is impressive.',\n",
       "  'weaknesses': '1. Equation 3 is important for further derivation. From my understanding, Equation 3 indicates that the attention map is fixed for all data. I think attention layers usually have different attention maps for different data. I believe this is a big limitation of this work. Some clarification about \"fixed attention\" is needed to avoid misunderstanding.\\n\\n2. An attention map fixed at random initialization makes the attention layer useless and meaningless. I think at least the attention layer should be trainable.\\n\\n3. About the related works of generalization analysis of Transformers, the references discussed are too old. Here are some recent references. I would like to see a discussion of these works (Some of these works are concurrent works). \\n[1] Jelassi et al., 2022, \"Vision Transformers provably learn spatial structure. \"\\n[2] Li et al., 2023, \"A Theoretical Understanding of Shallow Vision Transformers: Learning, Generalization, and Sample Complexity. \"\\n[3] Oymak et al., 2023, \"On the Role of Attention in Prompt-tuning. \"\\n[4] Tarzanagh et al., 2023, \"Max-Margin Token Selection in Attention Mechanism. \"'},\n",
       " 'review_901': {'summary': 'The paper examines the capabilities of a single-layer multi-head attention layer in a scenario where the Key and Query matrices are predetermined and randomly selected from a Gaussian distribution. The only modifiable component is the Value matrices, and when provided with a convex loss, the minimization problem becomes convex.   The authors establish expressivity results showing that, whether there is or not there is bias in the Key and Query matrices, the model can effectively learn a class of functions that exhibit permutation invariance to the Key vectors. Furthermore, they demonstrate that the sample complexity of their model is superior to that of two-layer random feature networks for the specific function class. The attention model investigated uses ReLu rather than the more common softmax attention',\n",
       "  'strengths': '- Results are new and although not surprising require certain efforts to prove and could be a useful addition to the literature of random-feature -type models (more to that literature I think rather than to the attention/transformer literature)\\n\\n- Paper is well written (but please correct the many typos) and the authors provide comprehensive explanations of limitations ',\n",
       "  'weaknesses': '- A major weakness is that instead of the common softmax function, the authors opt to use the ReLU function. \\nThe use of ReLu is nonstandard in transformers and should be mentioned explicitly in the abstract and contributions. Relu and softmax actually have rather different properties and this should be clarified\\n\\n- The fixed Key and Query matrices restrict the learning setting to a linear problem.\\n\\n- The (as the authors admit) seemingly unnatural constraint set in (12) is rather \"artificial\". Why is such a constraint needed? Besides, knowledge of this K1,K2 requires bounds on B(f_*) making it rather impractical\\n\\n- Thm 2 only applies for bounded loss. Is it possible to extend to say square-loss?\\n\\n- Comparing RFA to RFMLP is based on comparing upper bounds to each other. Is it known if the latter bounds are tight?\\n\\n- As the authors acknowledge, it is rather expected that RFA would beat RFMLP for the specific function class that involves correlations between key and query tokens. While the analysis is non-trivial it is questionable what is that we really learn from those bounds regarding attention?\\n\\n- Even though the results are new and the proofs require efforts, the techniques are rather standard and is not clear if they are revealing of any special properties of attention? If so, this would be interesting to emphasize.\\n\\n- There are a lot of typos\\n\\n- My overall concern with the paper is not about the motivation of the setting (use of ReLu and random features) and also it is a bit unclear what the take home message is (other than a technically solid analysis in a mathematically interesting setting)\\n'},\n",
       " 'review_902': {'summary': 'The paper considers the representational and generalization properties single-layer scalar-valued transformer models with random key and query matrices and value vectors that can depend on those random matrices. They draw a comparison to the well-studied random-feature models for two-layer neural networks. Concretely:\\n* Theorem 1 proves that functions of the form $f_*(x_{0:N}) = \\\\frac1N \\\\sum_i F(x_0, x_i)$ can be efficiently represented under the random feature, with quadratic dependence on the input dimension $d$ and no dependence on the sequence length $N$. \\n* Theorem 2 extends this approximation-theoretic result to generalization by proving a generalization bound on the empirical risk-minimizing random feature transformer (among transformers with bounded value vectors) that fits a noiseless dataset. The proof follows from bounds on the Rademacher complexity of the family of functions that approximately represent the dataset.\\n* The paper gives several examples in Section 3.3 of functions of the above form and show that they admit much stronger learning rates for random feature attention models than for standard random feature models. Generally, standard random feature models have a substantial dependence on $N$, while random feature attention has no such dependence. \\n* Theorem 3 proves a generalization bound similar to Theorem 2, but in the regime where the random feature matrices (e.g. the product of the key and query matrices) is biased in favor of larger elements on the diagonal. (This is empirically motivated in the appendix by a finding that BERT weight matrices frequently concentrate mass on the diagonals.) They prove generalization bounds for a restricted family of target functions, where high-degree polynomials of $\\\\langle x_0, x_i\\\\rangle$ and low-degree polynomials of $x_0 \\\\otimes x_i$ may be averaged together. They provide several examples showing how this model can reduce the error rates over the standard random feature attention model.\\n* Numerical experiments in Section 5 validate their theoretical results by comparing the error rates as a function of sample complexity of random feature MLPs, random feature attention, and biased random feature attention.',\n",
       "  'strengths': 'The work is novel, interesting, and relevant to the growing study of the theoretical properties of transformers. The work formalizes some intuitive advantages that attention models hold over standard MLPs in their ability to compute and aggregate pairwise functions of sequential inputs. Theoretical results are presented cleanly and the proofs that I read appeared correct. The work is creative, and draws inspiration for Theorem 3 from empirical observations. There is interesting follow-up work to be done on understanding the strengths and limitations of this model, especially on the optimization front.',\n",
       "  'weaknesses': 'While the bounds are interesting in their own right, the comparisons between random feature attention and MLP models focus on a few particular examples, whose generality is unclear. Moreover, the comparisons are between upper bounds for both models; ideally, the results would contrast with _lower_ bounds for random feature MLPs.\\n\\n### Minor pointers\\nl244: \"scaler\" -> \"scalar\"\\n\\nl657: $W$ in equation block should be $W_m$'},\n",
       " 'review_903': {'summary': 'This paper explores the learning capabilities of a single attention layer, assuming keys and queries to be random and frozen (as in the random features model).',\n",
       "  'strengths': 'The paper is very well written, and the technical claims look formally supported.\\n\\nThe paper deals with an important problem, which is to theoretically better characterize the representation power of single attention layers.\\n\\n',\n",
       "  'weaknesses': 'Typo in line 95 \"theorey\"\\n\\nThe family of target functions considered in the discussion doesn\\'t contain terms that consider the interaction between token $i$ and token $j$, with $i, j \\\\neq 0$. Attention model success also hinges on capturing the relation between different tokens in the context. It looks like this work leverages on something orthogonal, and I wonder if the results are really representative of the attention layer power.\\n\\nTypo in line 176 \"$i$\"\\n\\nIt is not clear to me how the permutation invariance of the input tokens represents a valuable propertyy over which attention should perform better than MLPRF. It could be that the toy-model analyzed has this power as a natural difference with respect the standard MLPRF, without really capturing the properties of attention.'},\n",
       " 'review_904': {'summary': 'The paper presents a novel perspective on interpretable representation learning, introducing Transitivity Recovering Decompositions (TRD) as a method for identifying graphs that can learn local-to-global representations. The proposed approach achieves state-of-the-art (SOTA) performance on Fine-Grained Visual Classification (FGVC) datasets while maintaining interpretability. The TRD is well-defined, supported by theoretical and empirical analysis, and conducts thorough interpretability and robustness experiments.',\n",
       "  'strengths': '1.\\tThe authors provide a well-defined and theoretically supported Transitivity Recovering Decompositions (TRD) method, which is further validated through empirical analysis.\\n2.\\tThe experiments conducted on FGVC benchmarks demonstrate consistent SOTA performance across multiple datasets, although the improvements are marginal.\\n3.\\tThe paper includes comprehensive interpretability and robustness experiments, effectively showcasing the effectiveness of TRD to a certain extent.\\n',\n",
       "  'weaknesses': \"1.\\tThe introduction section requires improvement in terms of providing a high-level overview of the proposed TRD. A simple end-to-end pipeline overview in the introduction would greatly benefit readers' understanding.\\n2.\\tThe inference pipeline of the proposed system is not clearly described. Including the training and testing pseudo code would substantially enhance the clarity of the paper.\\n3.\\tThe robustness analysis is limited. To comprehensively evaluate the interpretability of TRD, it is crucial to observe the results under the influence of causal interventions. For instance, replacing a percentage of local views from another class and observing the results would provide valuable insights.\\n\"},\n",
       " 'review_905': {'summary': 'The authors propose TRD, an algorithm that decomposes both input images and output classes into graphs over views by recovering transitive cross-view relationships for fine-grained visual categorization.',\n",
       "  'strengths': '1. The paper is well written and easy to follow.\\n2. The proposed TRD is demonstrated both theoretically and empirically. ',\n",
       "  'weaknesses': '1. It seems that most of the experimental results in Table 1 are copied from the Relational Proxies paper. But the experimental setup seems different. For example, the number of local views is different. \\n2. As we know, deep GNNs usually suffer from over-smoothing issue, i.e., as the number of layers increases, the learned representations become nearly indistinguishable and the performance degrades significantly. The authors use an 8-layer GAT with 4 attention heads in each hidden layer. The reviewer wonders how the number of layers affects the performance of your models. Does the over-smoothing phenomenon exist?  \\n3. The proposed method seems strongly related to Relational Proxies. Can you explain more about the relationship and difference between these two methods? Moreover, compared with Relational Proxies, the performance gains of TRD are very marginal, as can be seen from Table 1 and Figure 5. \\n\\n'},\n",
       " 'review_906': {'summary': 'This paper aims at fine-grained representation learning. The authors state that local-to-global relationships leveraged in recent fine-grained visual categorization (FGVC) works are abstract. To make such abstract relational representations more human-understandable, the authors first theoretically show the existence of semantically equivalent graphs for abstract relationships and derive their key information theoretic and topological properties. Then, the authors present Transitivity Recovering Decompositions (TRD), which is a graph-space search algorithm that identifies interpretable equivalents of abstract emergent relationships at both instance and class levels and with no post-hoc computations. The authors run experiments to demonstrate the effectiveness of their methods.',\n",
       "  'strengths': '+ This paper is well-written and easy to follow.\\n+ The motivation is strong, and the technique in this paper is solid.\\n+ The proposed method reaches SOTA performance on standard small, medium, and large scale FGVC benchmarks. The authors conduct ablation studies and present visualization results to show the effectiveness of their method.',\n",
       "  'weaknesses': '- The authors state that the local-to-global (emergent) relationships leveraged in existing methods are abstract fashion. However, no detailed and deep explanation for the term \"abstract\" is provided in this paper.\\n- The authors propose a graph-based model for fine-grained visual categorization (FGVC) recognition. However, the authors do not provide a comprehensive review of the relevant literature in the field, such as [1-3], and do not compare their approach with other relevant methods in their experiments.\\n- The author\\'s comparison seems unfair. In the field of FGVC, a common practice is to resize images to 448$\\\\times$448, but the authors do not follow this approach. Furthermore, there is a lack of experimental details, which raises concerns about the validity of the experiments. I am unsure whether the pre-trained models used in the study are sourced from ImageNet-1K or ImageNet-21K. Additionally, I find the results of TransFG and FFVT on the Aircraft dataset in Table 1 confusing. While I understand that ViT-based models may have limitations on the current dataset, the reported results seem unexpected.\\n\\n[1] Where to Focus: Investigating Hierarchical Attention Relationship for Fine-Grained Visual Classification, ECCV22\\\\\\n[2] Weakly Supervised Posture Mining for Fine-Grained Classification, CVPR23\\\\\\n[3] SR-GNN: Spatial Relation Aware Graph Neural Network for Fine-Grained Image Categorization, TIP'},\n",
       " 'review_907': {'summary': 'In this work, a probabilistic view of adversarial examples based on the [projected stochastic gradient Langevin algorithm](https://proceedings.mlr.press/v134/lamperski21a.html) is introduced and used as an optimization algorithm instead of the SGD or Adam optimizer for adversarial examples. In addition, the geometric constraint (Lp norms) is replaced by a semantic distance criterion based on an instance-wise energy-based model (i.e., an EBM is trained for each instance, using transformed versions as the training dataset) to ensure semantic/visual proximity to the original input. They improved the adversarial examples using the [CW objective](https://www.computer.org/csdl/proceedings-article/sp/2017/07958570/12OmNviHK8t) and thin-plate splines transformation to create a more diverse training dataset for EBM training. Moreover, they generated a set of successful adversarial attacks (i.e., fooled the classifier) via rejection sampling and proposed a simple selection procedure to select the final adversarial examples based on the softmax probabilities of an auxiliary classifier and the energy of the examples. The experiments show that the proposed method is able to generate adversarial examples that fool the classifier while being visually/semantically indistinguishable to humans.',\n",
       "  'strengths': '- The proposed method is very detailed and intricate.\\n- The Langevin Monte Carlo-based optimization procedure seems to improve the quality of adversarial examples overall.\\n- The paper is well-written and clearly structured.\\n- Code is provided.',\n",
       "  'weaknesses': '- Previous work, e.g., by [Sharma & Chen](https://openreview.net/forum?id=Sy8WeUJPf), has also generated visually similar adversarial examples for the MadryNet while still using a geometric distance ([elastic-net regularization](https://arxiv.org/abs/1709.04114)). This raises questions about the generality of the work’s central claim that it “transcends the restriction imposed by geometric distance, instead opting for semantic constraints” (L4-5) beyond the limitations of the adversarial attack methods shown in the present work.\\n- The present work only shows experiments on digit-based datasets (MNIST & SVHN). Applications to datasets with natural images (e.g., CIFAR or ImageNet) are missing. Consequently, the necessity and applicability of the proposed adversarial attack are very unclear, since for natural images the adversarial examples typically remain visually very close to the original inputs; also after adversarial fine-tuning.\\n- The work is missing interesting experiments, e.g., what would happen if we use the proposed adversarial attack approach for adversarial training? Does it improve adversarial robustness? Does the adversarial attack also bypass certified defenses? Overall, the experimental section is very short (3 lines of results) and would greatly benefit from, e.g., the aforementioned experiments.\\n- The approach requires an instance-wise energy-based model for its semantic distance loss, which must be trained for every sample (on different augmented versions); cf. L122. This may limit its applicability.\\n- The proposed attack and problem setup are not quite original, i.e., it combines well-known techniques, or previous work (see first point above) has also already targeted the visual similarity challenge of adversarial examples for adversarially fine-tuned models.'},\n",
       " 'review_908': {'summary': 'This paper proposes to generate semantics-preserving adversarial examples by framing the construction of adversarial examples as a box-constrained non-convex optimization problem. More specifically, the authors propose a Langevin Monte Carlo (LMC) technique to craft adversarial examples that preserve the meaning of the original inputs they are derived from. With this framing, they cast the generation of adversarial examples as a semantic-based probabilistic distribution. The authors showed that their semantic-aware adversarial attack is capable of fooling robust classifiers while preserving most of the semantics of their source images.  ',\n",
       "  'strengths': 'This paper is quite interesting paper and well-written. The problem is well-defined, and the solution quite intuitive. The math is also quite sound. Although the problem of generating semantics-preserving adversarial examples has been studied extensively in the past, it still remains relevant. This paper proposes another interesting perspective on how to approach this problem.     ',\n",
       "  'weaknesses': 'Although the paper is interesting, the evaluation is quite limited. For instance, the approach is only evaluated on MNIST and SVHN. Evaluating the approach against \"more challenging\" datasets like ImageNet, CIFAR-10, CIFAR-100 would make their contributions more compelling. Also, studying the transferability property of their attacks would strengthen their paper, and give more confidence to the readers about the strength of their attacks. Moreover, I would have liked to see how the magnitude of the noise used in Thin-plate-spine affects the overall performance of their attacks. Finally, the related work section is rather limited. There is a plethora of interesting studies in crafting adversarial examples that are semantics-preserving. For instance, [1] and [2] are quite related to the approach the authors propose, and should be evaluated or discussed further in the related work section. \\n\\n[1]: Semantics Preserving Adversarial Examples. https://aisecure-workshop.github.io/amlcvpr2021/cr/27.pdf\\n[2]: Localized Uncertainty Attacks. https://ui.adsabs.harvard.edu/abs/2021arXiv210609222A/abstract\\n'},\n",
       " 'review_909': {'summary': 'The adversarial examples generated by classical methods such as PGD have different semantic meaning to the original label, which means that the adversarial examples are easy to be distinguished by human. In this paper, the authors focus on the generalization of adversarial example which preserves the original semantic information. They propose a semantically-aware distance measure to replace the geometrical distance measure. And they use Langevin Monte Carlo method to find the minimal point (adversarial sample) of their proposed loss function. Several techniques that further enhance the performance of the proposed method are presented. From the experimental results, it seems that their generated examples preserve the original semantical imformation.',\n",
       "  'strengths': '* As far as I know, the proposed adversarial attack method is novel.\\n* They proposed a semantical distance measure to generate the semantic-aware examples. Although the idea of semantical measure already exists in many previous work, I think the usage here in adversarial example generalization scenario is interesting and reasonable.\\n* Their method is theoretically and experimentally reliable.',\n",
       "  'weaknesses': '* One of the limitation of this paper is that, the loss of semantics of adversarial examples only exists in some simple tasks, such as MNIST and SVHN. As the experimental results in previous work shows, the adversarial examples of CIFAR and ImageNet have very little disturbations that cannot be distinguished by human and preserve the semantical information. Hence, I think the significance of this paper is somewhat limited.\\n* The motivation of using EBMs and LMC is not very clear to me. In my opinion, we can directly optimize the semantic-aware loss to generate the adversarial examples. The necessity of using the EBMs and LMC should be stated more clearly.\\n* In the experiment part, the success rate involves subjective factors. They use human annotators to determine whether the adversarial examples have the same meaning as the original label. Is there a more subjective metric? Otherwise, the experimental results may suffer a credibility crisis.\\n* More experiments on CIFAR-10 and CIFAR-100 are necessary.\\n* Can you give a more detailed explaination of the training of the energy-based model? I noticed that Section 2.5 includes some brief introduction, but what is the data distribution $p_d$ here? What is the specific training algorithm?\\n\\nIf the authors can address my concerns well, I will consider raise the score.'},\n",
       " 'review_910': {'summary': '\\nThis paper introduces a novel approach to adversarial attacks that goes beyond traditional norm bounded attacks. Instead, the proposed method focuses on unrestricted attacks that are both effective and capable of preserving the semantic meaning of the input data.\\n\\nThe method utilizes Langevin Monte Carlo techniques to sample from a distribution of potential attacks. To ensure semantic preservation, a learned energy function is employed, which guides the generation of adversarial samples. Rejection sampling and refinement techniques are then applied to select and further improve the quality of the generated samples.\\n\\nThe evaluation of the proposed method demonstrates a significant success rate when attacking defended models. By allowing for unrestricted attacks while maintaining semantic integrity, this approach presents a promising advancement in the field of adversarial attacks, showcasing its effectiveness and potential for practical application.',\n",
       "  'strengths': '1. Interesting work on unrestricted adversarial attack, which is important given that most attacks now are bounded attack.\\n\\n2. The method is effective in breaking already defended models. Fig 1,2 clearly shows the advantage over norm bounded attacks.',\n",
       "  'weaknesses': '1. What is the computation cost of the attack? The paper only evaluates on two toy datasets, MNIST and SVHN, the reviewer is wondering if the method can generalize to larger dataset.\\n\\n2. Ablation study on the component is missing. Like TPS as data augmentaion, the effect of the choice of the sampling method. Also the method requires specify several hyper parameters, like M. Ablation study is useful.'},\n",
       " 'review_911': {'summary': 'This paper is proposing context-aware Diffusion Models. They make the models learn the context information by setting up auxiliary networks to estimate the neighbor distributions from the estimated denoised sample from Diffusion Models. The benefit of this approach is that additional cost from the auxiliary networks are not applied during the sampling. Both quantitative and qualitative experiments are reported.',\n",
       "  'strengths': '- Motivation is agreeable.\\n- Good writing.\\n- Reasonable method for motivation.\\n- Experiments are done well.',\n",
       "  'weaknesses': 'Specifics of the weaknesses of this paper are written below as questions and limitations, but I believe most of them can be resolved during the rebuttal. I will increase my rating if my concerns can be resolved.'},\n",
       " 'review_912': {'summary': 'This paper proposes an idea of context prediction to boost difussion-based image generation.\\nThe core idea is that in each step of diffusion, after the denoised point is generated, neighborhood context prediction is performed.\\nIn particular, to maintain the spatial orders of the neighborhood, a permutation invariant loss is used for optimization by replacing the context prediction with neighborhood distribution prediction. Performance improvement against standard diffusion models were presented. in experiments.\\n',\n",
       "  'strengths': \"1. The idea is very interesting and sound.\\nFrom an image denoising point of view, neighborhood info is commonly used, so it's a natural extension of diffusion-denoising models.\\n2. Performance improvement showed in experiments are promising. \",\n",
       "  'weaknesses': 'The proposed approach probably takes longer to train. Can you discuss from that perspective?'},\n",
       " 'review_913': {'summary': \"This paper presents ConPreDiff, a method introduced to improve the performance of diffusion models by preserving the neighborhood context of predicted pixels/features. They achieve this by predicting the neighborhood context during the diffusion generation process. To simplify the modeling complexity, they propose predicting distributions instead of directly reconstructing the neighborhood. The method's effectiveness is demonstrated through extensive experiments on unconditional image generation, text-to-image generation, and image inpainting.\",\n",
       "  'strengths': '* The idea is intuitive and easy to understand. \\n* The proposed method is general and can be easily applied to recent diffusion models.\\n* The performance of the proposed method is very impressive.',\n",
       "  'weaknesses': \"* Recent diffusion models use UNet backbone, which stacks many convolutional and self-attention layers. Thus, it has a large receptive field. Additionally, LDM also has a decoder, which also has a decent receptive field. Therefore, I am confused about the paper's main claim that the point-wise reconstruction neglects to fully preserve the local context.\\n* There are no visual comparisons of the proposed method and baselines. I am not sure if ConPreDiff can really be more local-context consistent compared to other methods.\\n* The authors need to discuss the additional training cost. Besides, they also need to provide the additional parameters they use for the context prediction.\"},\n",
       " 'review_914': {'summary': 'This paper proposes to improve diffusion based image generative training objectives by adding context prediction loss. The motivation of predicting context comes from other non-diffusion based models like semantic segmentation and representation learning. To mitigate the complexity of predicting large per pixel neighbourhood context, the author further models the context as a probability distribution using Wasserstein distance. Experiments show the proposed model achieves new SoTA generation on MSCOCO for both discrete and continuous diffusion models.\\n',\n",
       "  'strengths': 'The introduction is well-written and the motivation of predicting context in the diffusion based model is easy to follow.\\n\\nThe presentation of the method including the loss derivation and the training pipeline is easy to understand.\\n\\nThe authors conduct intensive experiments showing the proposed context prediction loss can be used on various DM models, achieving SoTA performance on MSCOCO FID and inpainting tasks.\\n',\n",
       "  'weaknesses': 'The paper lacks training and implementation details. For example, the text-to-image experiment uses T5 encoder as the text encoder, but did not mention architecture details and training details.\\n\\nOne big motivation to model context as a probability distribution is to improve the training efficiency. As shown in Figure 6, feature matching has lower throughput compared to distribution matching, but it has better FID. I think an important baseline is missing – sampling based feature matching, i.e. use the same number of random samples as proposed in the distribution matching, 9 instead of the full neighbourhoods features for context prediction.\\n'},\n",
       " 'review_915': {'summary': 'This paper proposes to improve diffusion-based image synthesis by explicitly reinforcing each point to predict its neighborhood context during training, without extra cost at inference. To reduce computation/time complexity of context decoding the authors propose efficient large context decoding adopting Wasserstein distance to characterize the distribution reconstruction loss. The method is applicable to both discrete and continuous diffusion backbones and achieves new SOTA text-to-image generation on MS-COCO with FID 6.21',\n",
       "  'strengths': '1. The paper is well-written and easy to follow. \\n2. The method of explicitly reinforcing each point to predict its neighborhood context for diffusion models is well-motivated with effective designs to reduce substantial computation complexity for large-context neighborhood reconstruction.\\n3. The method is proven effective in boosting FID scores on MS-COCO text-to-image synthesis for both continuous (eDiff-I) and discrete diffusion (VQ-Diffusion) backbones.',\n",
       "  'weaknesses': '1. The main results are on text-to-image synthesis and image inpainting. It would be good to add unconditional generation results. \\n2. The method emphasizes on diffusion with better neighbouring context, leading to generations \"semantically better consistent with the text prompts\"(L233), \"prommising cross-modal semantic understanding\" (L234), \"can synthesize more complex objects and scenes\" (L236-237). I don\\'t think the claims are well-justified: e.g. Fig. 2 and Fig. 3 only presents results of the proposed method without any comparison to warrant the aforementioned conclusions. More analysis and evidence of \"better semantics\" are required other than the overall FID score.\\n3. Some notations are misleading, e.g. L 114-116, for h_i (h_{t-1}), the subscript is used to indicate both spatial and time; x_t is not defined in the main text. '},\n",
       " 'review_916': {'summary': \"The paper presents a theoretical framework for understanding the trainability of deep neural networks with LayerNorm and residual connections. The authors derive analytical expressions for the neural network Gaussian process (NNGP) kernel and the partial Jacobian norm (PJN) for a wide range of activation functions. They show that the combination of LayerNorm and residual connections leads to an everywhere-critical regime, where the network can be trained effectively irrespective of the initialization. The authors also provide insights into the role of the hyperparameters and the activation function in determining the trainability of the network. The paper's contributions include a theoretical understanding of the trainability of deep neural networks with LayerNorm and residual connections and insights into the design of effective architectures.\",\n",
       "  'strengths': 'The main strengths of the paper are:\\n1. Introduces partial Jacobians and their averaged norms as tools to analyze the propagation of gradients through deep neural networks at initialization.\\n2. Presents a very cheap and simple empirical test for criticality using APJN evaluated close to the output.\\n3. Shows that criticality formulated in terms of partial Jacobians is equivalent to criticality studied previously in the literature.\\n4. Investigates homogeneous architectures that include fully-connected layers, normalization layers, and residual connections, and shows that the combination of LayerNorm and residual connections can drastically increase correlation length leading to improved trainability.\\n5. Considers examples of modern architectures, ResNet and MLP-Mixer, and shows that they are critical everywhere at µ = 1 (i.e., with residual connections) due to the interaction between LayerNorm and residual connections.\\n6. Empirically demonstrates that deep MLP-Mixer with µ = 1 trains well for various initializations.',\n",
       "  'weaknesses': 'Some potential limitations of the paper could include:\\n1. The analysis is limited to homogeneous architectures with fully-connected layers, normalization layers, and residual connections. The results may not generalize to other types of architectures or layers (e.g., attention layers).\\n2. The paper focuses on the infinite width limit, which may not be directly applicable to finite-width networks commonly used in practice.\\n3. The empirical test for criticality based on the averaged partial Jacobian norm may not be sufficient to fully capture the behavior of deep neural networks (in terms of accuracy for instance).\\n4. The paper does not provide a comprehensive comparison with other methods for improving the trainability of deep neural networks, such as weight initialization schemes or adaptive optimization algorithms.'},\n",
       " 'review_917': {'summary': 'The paper studies the effect of the expected value of the Jacobian norm of a particular layer with respect to a previous layer as the depth of a neural network (NNs) increases. The study is done under the assumption of infinite width NNs, and with the goal of assessing sensitivity to initialisation hyperparameters (the standard deviation of the normal initialiser of the weight and biases of the network) depending on architecture and as depth increases. The importance of understanding this setting comes from the connection with exploding and vanishing gradients that the network is likely to exhibit in training, unless the initialisation (in expectation) is in the critical region. The conditions for criticality across architectures are studied in this work.\\n\\nThe settings studied include feed-forward networks, residual networks with and without layer-norm applied to the pre-activation, as well as group norm and briefly Batch Norm in conjunction with residual networks.\\n\\nReasons for rating: While the contribution of the paper is worthwhile, the clarity could be greatly improved. At the moment, the paper resembles more a series of facts rather than a clear logical deduction. I worry that this will limit the value it can bring to the ML community.\\n',\n",
       "  'strengths': 'Strengths:\\n * The paper provides a theoretical assessment of why, in the infinite width limit, certain neural networks can achieve better trainability. In particular, the authors study the effect of residual connections and layer norm, both which have become a staple of deep learning. This type of study can help explain why certain architectures are less sensitive to initialisation compared to others.\\n * Code reproducing the figures is provided in the supplementary material as notebooks (and a clear readme.txt detailing the results).\\n * Proofs in the attached SM are generally readable and can be followed.\\n',\n",
       "  'weaknesses': 'Weaknesses:\\n* The clarity of the paper can be drastically improved. \\n  * In the paper, the same recipe of proof is applied repeatedly in multiple settings. I think the paper would benefit from clarifying that recipe in the main text, and working through the logical steps one by one in one example. At the moment, there is no clear explanation of the logical flow of what is occurring. My understanding of that recipe is:  In the setting studied (for that specific architecture), in the infinite width limit find a recurrence relationship between the NNGP kernels at layer l+1 and l when evaluated at the same datapoint. Use that recurrence relationship, together with the recurrence relationship for APJN to find the conditions of criticality for initialisations. I urge the authors to clarify this recipe (in more detail) in the main manuscript. as well as work through an example.\\n * There are many sentences for which it is unclear where they come from, either from a proof in the Appendix or from a previous work or the authors consider it trivial. Such an example is Eq 4, which potentially follows from Thm 1.3, but the order of the two is unclear. Similarly, the proof of Thm 1.3 in the Appendix is not well delimited or clarified (given that it is the main result). \\n'},\n",
       " 'review_918': {'summary': 'The paper addresses the theoretical treatment of deep neural networks and introduces a novel practical approach to identify criticality within these networks. The authors work in the setting where the number of parameters per layer approaches infinity, enabling the formulation of quantitatively predictive descriptions ( establish criteria for hyperparameter selection). These criteria are based on the notion of criticality.¨\\n\\nTo identify criticality, the paper introduces partial Jacobians, which represent derivatives of preactivations in layer l with respect to preactivations in layer l0 (where l0 ≤ l). Recurrence relations for the norms of these partial Jacobians are derived and utilized to analyze criticality in deep fully connected neural networks featuring LayerNorm and/or residual connections.\\n\\nThe authors devise a straightforward and cost-effective numerical test to determine the optimal initialization for various types of deep neural networks, including fully connected, convolutional, and normalization layers. They present quantitative evidence demonstrating that arranging LayerNorm (applied to preactivations) and residual connections appropriately leads to an architecture that exhibits criticality regardless of the initialization.\\n\\nFinally, the paper applies these methods to investigate the ResNet and MLP-Mixer architectures, revealing the presence of an everywhere-critical regime within these modern models.',\n",
       "  'strengths': 'This research represents a significant advancement in the field. A notable contribution of the paper is the introduction of partial Jacobians and their averaged norms as powerful tools for analyzing gradient propagation in deep neural networks at initialization. The paper particularly investigates the implications of LayerNorm and residual connections, shedding light on their impact on trainability.\\n It is encouraging that the theoretical prediction derived from this Framework match previously empirically observed or theoretically proven findings. Additionally, the paper strengthens its contributions by testing the findings on more realistic datasets, thereby enhancing the robustness and applicability of the research.\\n\\nThe paper is highly comprehensive and lucid, greatly facilitating understanding. It effectively summarizes the contributions, allowing readers to grasp the main points without constant reference to the appendix. Furthermore, the authors have shared the relevant code with their submission, ensuring transparency and enabling the replication of results. The inclusion of detailed step-by-step derivations significantly aids comprehension and is highly appreciated by readers.\\n',\n",
       "  'weaknesses': 'These suggestions are intended to improve the overall clarity and accessibility of the research.\\n\\nTo enhance the organization of the paper, it would be beneficial to include dedicated sections for limitations, future work and contributions. Additionally, the current title of the section labeled \"results\" may be misleading and should be reconsidered. Furthermore, FashonMNIST is not mentioned in the main text.\\n\\nThe limitations outlined below highlight some of the weaknesses of the paper, despite the fact that they represent the current best efforts in the field.\\n\\nAlthough it may seem like a minor detail, I believe it holds significant importance. For the sake of accessibility, completeness, and readability, I would suggest including relevant lemmas or theorems used from other sources in the appendix to provide a more comprehensive understanding of the research.  Furthermore, It would be helpful if you could extend slightly the captions in the figures for the camera-ready version for the same reason.\\n\\n'},\n",
       " 'review_919': {'summary': 'This paper studies criticality of deep neural networks at initialization. The authors propose a new practical way to diagnose criticality by introducing the partial Jacobian of the network and analyzing the averaged partial Jacobian norm (APJN) and its recurrence relation at large depth. The authors then apply their method to analyze criticality in fully connected networks with LayerNorm and/or residual connections, providing theoretical analysis for infinitely wide networks and a numerical test to select optimal initialization and identifying conditions on network architecture that allow for criticality for any initialization. ',\n",
       "  'strengths': '1. The paper presents theoretical analysis of the APJN in the infinite width limit for various network architectures, and thorough validation by numerics. \\t\\n2. The paper extensively explored application of the theoretical analysis and numerical test on modern architectures (ResNet and MLPmixer), providing practical insights for initializing neural networks for improved trainability.  \\n',\n",
       "  'weaknesses': '1. As most other works studying critical initialization, the work focuses on networks at Initialization with Gaussian random weights, and there is no learning in the network. While the authors briefly mentioned NTK (line 150), I would like to see a discussion on how their approach may be extended for analysis beyond networks at initialization and perhaps shed light on the learning dynamics of the network. \\n2. In section 1.2, the authors discussed several related works and how part of their results were previously obtained in a different form in these works. I would recommend that the authors further stress the novelty of their approach/analysis in this section. \\n'},\n",
       " 'review_920': {'summary': 'The authors study how batch size affects RL performance, and argue that a reduced batch size might (quite surprisingly) bring better performance improvement in a number of settings, in particular for QR-DQN, a smaller batch can lead to much better performance (almost doubling the performance). Different batch sizes are tested in Atari environments together with other hyperparameter changes. The authors also point out a benefit of using a smaller batch size is the reduction in wall clock time. The paper focus on empirical study and analysis, and provide a list of interesting findings.',\n",
       "  'strengths': '**originality**\\n- the paper dedicates to bring a better understanding of effect of smaller batch sizes with extensive empirical studies, although there are already past works that study the effect of batch sizes, the results in this paper bring some new findings and observations and can be considered novel contribution. \\n\\n**quality**\\n- overall presentation is good, but some arguments can be improved. \\n- extensive experiments and ablations are great\\n\\n**clarity**\\n- Overall paper is clear to read. And the structure is easy to follow. \\n\\n**significance**\\n- the observations presented in the paper can be interesting to the research community and help us better understand the effect of different batch size settings \\n- the authors argue that a smaller batch size can bring wall-clock time reduction and given the results they also have potential to bring better performance, which is a result that can be helpful towards better algorithms',\n",
       "  'weaknesses': 'Major concerns: \\n\\n**related work**\\n- the authors claim \"Surprisingly, to the best of our knowledge there have been no studies exploring the impact of the choice of batch size in deep RL.\" well, there are indeed some works that touch on this issue, for example to list a few: \\n  - Accelerated Methods for Deep Reinforcement Learning by Adam Stooke and Pieter Abbeel. \\n  - Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control by Islam et al. \\n  - Shallow updates for deep reinforcement learning by Levine et al. \\n  - An Empirical Model of Large-Batch Training by McCandlish et al. \\n- these are older papers, please do some search on google scholar and have a better discussion of related works. Some of these works found larger batch size to be more beneficial. The authors need to spend a bit more effort in looking at related work and try to explain the discrepancy. \\n\\n\\n**Arguments and conclusions made in the paper**\\n- Some of the arguments can be improved, for example line 95: \"In Figure 3 we can observe that, in general, reduced batch size results in improved performance.\" I don\\'t think this is true, in Figure 3 there are 8 curves in 4 figures that have lower batch sizes than default, and 4 out of these 8 curves have weaker performance than the default, while the other 4 one can argue they are stronger or slightly stronger than default. One can argue in QR-DQN batch size of 8 is really good, but from this figure alone I don\\'t see how it\\'s a general trend. \\n- Line 226 Figure 11 (third column), I am not convinced there is a clear correlation between batch size and gradient norm. The variance is high, and for Asteroids and SpaceInvaders it seems in late stage of training they start to get higher gradient norms. \\n- Line 242 authors argue that \" it is possible that the network is better able to adapt to an earlier rank collapse than to a later one.\" I am not sure how this argument is made, figure 11 col 5 shows that Srank does not positively correlate with performance at all. It seems this collapse has no negative effect on the training or even indicates stronger performance, which is again kind of going against what has been argued in previous literature. And the argument that \"Smaller batch sizes seem to result in networks that are both more expressive and with greater plasticity.\" seems to be entirely wrong to me, as figure 11 shows on SpaceInvaders, small batch size of 8 has lowest srank and highest percentage of dormant neurons. \\n- Overall, I found a number of the points made in paper to be only supported by very weak evidence and they are not convincing. The authors might want to either modify the arguments into more accurate ones, or try to find better evidence to support the arguments. If the evidence is weak, the conclusion might not hold at all and it could be really coming from randomness or because of excessive fine-tuning on a particular algorithm on some particular environments. \\n\\nThe paper is currently lacking in these 2 aspects, but can be a good paper if these concerns are properly addressed. \\n\\nMinor concerns:\\n- **originality** the novelty of the work is reduced by the fact that it is focused on studying existing methods, but mitigated by the novel empirical results, ablations and analysis.'},\n",
       " 'review_921': {'summary': 'The work investigates the influence of replay batch size in experience replay for online reinforcement learning. The key finding is that reducing the batch size can be more beneficial, which contradicts common knowledge about regular deep learning.',\n",
       "  'strengths': 'The paper expands the analysis of an underinvestigated observation that can potentially change the default settings for experience replay and reduce the computational cost of further experiments. The authors provide new insights into the computational impact of batch size in experience replay and analyze network optimization dynamics. One of the strengths of the paper is its extensive experiments conducted with different settings and architectures.',\n",
       "  'weaknesses': 'Experience replay is also used in continual learning. It is surprising that the authors missed the paper that already drew the same conclusion [1], but kept it underinvestigated. Nonetheless, it should be mentioned in the related work section.\\n\\n[1] Wołczyk, M., & Krutsylo, A. (2021). Remember More by Recalling Less: Investigating the Role of Batch Size in Continual Learning with Experience Replay (Student Abstract). AAAI Conference on Artificial Intelligence.'},\n",
       " 'review_922': {'summary': 'This work studies the effect of reducing the batch size in value-based deep RL algorithms. Surprisingly, the authors find that smaller batch sizes generally improve learning performance and speed up training in terms of wall-clock time. Towards understand this \"small batch effect\", they empirically investigate how batch size relates to e.g. multistep learning, variance of gradient updates, network capacity, network plasticity, etc. ',\n",
       "  'strengths': '1. Overall, the writing is extremely clear and well-organized. While reading, I found myself asking questions that the authors then answered in later section of the paper (e.g. Lines 125-129 prompted questions on how batch size relates to plasticity and network capacity)\\n2. The empirical evaluation is thorough; the authors consider a wide range of Atari tasks and investigate how batch size relates to a variety of learning factors.\\n3. The relationships uncovered in this work relate to many RL research areas (e.g. exploration, continual learning), and I believe they will spur interesting future research.',\n",
       "  'weaknesses': '1. The study only considers visual tasks with discrete actions. Does a small batch size improve data efficiency if you use the non-visual RAM observations in a few representative tasks? Do the same trends observed in Fig. 11 still hold? Since the paper is scoped to focused on value-based algorithms, I believe it is sufficient to state the discrete action limitation in the conclusion.\\n2. Since a smaller batch size seems to come with a variety of benefits (e.g. smaller gradient norms), it isn\\'t clear to me if the observed benefits in Fig. 6 are due to improved exploration via higher variance gradient updates. Since it is likely not feasible to isolate exploration, can the authors instead clarify how these figures show improved exploration?  \\n\\n**Minor comments:**\\n2. Lines 59-60: \"r\" -> \"r_t\"\\n3. I believe line 265 should say \"**decreasing** the batch size should increase variance\"\\n3. Lines 266-268: \"That it\\'s effect...\" This sentence is difficult to read and would benefit from rephrasing.'},\n",
       " 'review_923': {'summary': 'The paper demonstrates the advantages of employing smaller batch sizes in value-based RL algorithms. It reveals that utilizing a smaller batch size can moderately or significantly enhance performance across several value-based RL algorithms, with the exception of DQN, where there are no improvements. Nonetheless, the paper reveals that incorporating a deeper network or employing n-step returns can restore the benefits of smaller batch sizes in the case of DQN.\\n\\nTo examine the underlying reasons behind the benefits of smaller batch sizes, the paper conducts a comprehensive set of experiments. These experiments investigate various factors, such as increased update variance, reduced representation norm, and improved network expressivity, shedding light on how smaller batch sizes can help performance.',\n",
       "  'strengths': '- The paper presents a comprehensive and robust series of experiments, providing evidence for the effectiveness of smaller batch sizes in various value-based RL algorithms.\\n- The analysis conducted in the paper offers clear insights into the reasons why smaller batch sizes yield improvements in performance.\\n- The paper also delves into an in-depth investigation to understand why smaller batch sizes do not yield benefits in the case of DQN, providing valuable insights and explanations for this observed phenomenon.',\n",
       "  'weaknesses': 'While the result may not be technically novel, I agree that a comprehensive study on the topic of the benefits of smaller batch sizes is still highly valuable to the research community. Although some researchers are aware that smaller batch sizes can be beneficial, as seen in certain implementations of existing algorithms, such as IMPALA (e.g., https://github.com/facebookresearch/torchbeast uses a default batch size of 8), there is a lack of thorough analysis on this matter. Thus, the paper fills this gap and provides valuable insights and understanding of the issue. I appreciate the significance and value that the paper brings to the field.'},\n",
       " 'review_924': {'summary': 'The main focus of this paper is to address a problem in progressive knowledge distillation, which involves approximating a single large teacher model by utilizing an ensemble of multiple smaller student models. The authors propose an algorithm called B-DISTILL to tackle this specific problem. One notable advantage of this methodology is its capability to effectively balance the trade-off between cost and performance by adjusting the ensemble size of the student models.',\n",
       "  'strengths': '1. The problem formulation of \"progressive knowledge distillation\" is intriguing and well-motivated. In conventional knowledge distillation approaches for model compression, small student models of fixed sizes are typically employed, resulting in a fixed inference cost. A notable advantage of the proposed methodology is its ability to dynamically adjust the inference costs based on the available resources, which is a clear strength of the approach.\\n2. While the concept of approximating a function using a combination of multiple functions is not novel (as evident from classical boosting methods mentioned by the authors), this paper provides a distinct contribution by connecting these ideas to the field of knowledge distillation.',\n",
       "  'weaknesses': '1. The scalability of the proposed methodology appears to be somewhat limited. It was anticipated that B-DISTILL would achieve a similar level of performance as the teacher model while utilizing the same inference cost. However, when applied to TinyImageNet and ImageNet datasets, B-DISTILL falls short of meeting this expectation.\\n2. One important baseline is missing - deep ensembles using the model structure considered in B-DISTILL. Including this baseline would provide a clear motivation for the progressive formulation adopted in B-DISTILL.'},\n",
       " 'review_925': {'summary': 'The authors describe a new method for knowledge distillation with an ensemble of lower capacity student models, and draw connections between their method and classical boosting approaches. They provide a theoretical analysis of the risk of this method, and demonstrate the benefits of their approach in learning tasks with a limited inference budget, either in terms of computing cost or speed of inference. ',\n",
       "  'strengths': ' A compelling idea. Approaching the task of ensemble distillation through a boosting perspective is to my knowledge a novel idea, and the connections that can be made to the boosting literature as a result are quite interesting. At face value, the B-DISTIL algorithm does not seem limited to the distillation setting, and it would be interesting to understand how it compares more generally to other boosting algorithms. ',\n",
       "  'weaknesses': '\\nAs an overall weakness, I found the presentation of the paper to be very confusing. In particular: \\n- The relationship between two-player games and boosting needs to be better described in the related work and problem formulation. Schapire and Freund do not simply \"show that weak learners can be aggregated to produce strong learners\" (lines 90,91) but rather establish key correspondences between the formulation of two player games and boosting algorithms. Language from this correspondence are used throughout section 3.1 (\"players,\", \"minimax value of the game\", \"ensemble of predictors\",\"weak learners\") without a clear description of how two player games and boosting relate to one another, and make the exposition difficult to follow. \\n- Notation needs to be more carefully defined throughout the text. For example, the constants $L,M,N,R$ are all used without explicit reference to what they represent in the main text (see questions below for more notation issues). \\n- It is unclear to me how student models are constructed. Do the configurations in Tables 2-7 provide specifications for the student models used? Or rather for $\\\\mathcal{F}_0$? Are the different rows of the table different base models, or do they somehow relate to the use of intermediate layer connections? How are intermediate connections implemented in each of the specific model architectures described? \\n\\nOverall, I believe that the quality of the paper suffers significantly from issues with presentation, and I am willing to reconsider my score if these issues are addressed. \\n\\nAnother weakness of this work is comparison to previous work with respect to experimental findings. It would be useful to know how the results in Figure 4 compare to anytime inference as described in Huang et al. 2018 or Ruiz and Verbeek, 2020 for image classification results. '},\n",
       " 'review_926': {'summary': 'This paper proposes B-DISTILL, a progressive distillation algorithm that allows for easy trade-off between accuracy and inference-time/latency at runtime. By modeling knowledge distillation as a zero-sum game problem, B-DISTILL utilizes the intermediary connection modules to train and aggregate the sub-student models progressively, resembling the traditional boosting methods. The paper provides mathematical proofs that guarantee the convergence and generalization of B-DISTILL. The experimental results demonstrate the efficiency of B-DISTILL in both anytime inference and early prediction tasks.',\n",
       "  'strengths': '1. The paper presents a novel perspective by redefining the knowledge distillation problem and effectively applying it to the tasks of anytime inference and early prediction.\\n2. The paper provides complete mathematical proof and experimental validation to support its claims.',\n",
       "  'weaknesses': '1. While the method proposed in this paper introduces a novel perspective, its application scope and advantages appear to be quite limited. \\n2. It seems that some dynamic network structures could potentially be used to address the anytime reference problem. However, it appears that the paper lacks a comparative analysis with relevant methods in terms of results.\\n3. It might be worth considering modifying the title. B-DISTILL is more like a training method specifically designed for efficient inference rather than a knowledge distillation-related approach.'},\n",
       " 'review_927': {'summary': 'This paper studies the problem of \"progressive distillation\": Given a large teacher model, the task is to decompose into smaller student model so that progressively evaluating additional models in this ensemble results into more accurate predictions. \\n\\nΤhe main contributions of this paper are:\\n\\n(i) A principled approach called B-DISTIL for approaching the progressive distillation problem: The authors formulate a two player zero-sum game, from which they derive a weak learning condition. B-DISTIL approximately solves this game.\\n(ii) Theoretical guarantees for the proposed approach under certain assumptions.',\n",
       "  'strengths': 'Principled approach with theoretical guarantees that seems to perform well in real-world settings.',\n",
       "  'weaknesses': 'The proposed approach seems somewhat sophisticated —\\xa0perhaps not very easy to implement even. By reading the paper, it was not clear to me whether there exists a simpler (but non-idealized) baseline that could be used for comparison —\\xa0mostly to reassure the reader that the introduced sophistication is actually necessary. '},\n",
       " 'review_928': {'summary': 'The paper addresses the problem of obtaining an ensemble of small models suitable for flexible inference requirements and anytime inference, somewhat similar to cascading classifiers. A key contribution is the derivation of a weak learning condition for the distillation of a pre-trained to an ensemble of smaller students as well as an algorithm to obtain such an ensemble. The students are allowed to reuse intermediate activations of other students to efficiently expand the student model hypothesis set. The method is supported by theoretical results on the generalization error, and empirical results on classification tasks for both synthetic, vision, and sensor data.',\n",
       "  'strengths': '- The paper is well-written, clear, and well-organized. It is mostly easy to follow and understand the argumentation.\\n- The proposed technique is supported both theoretically and empirically, which is a strong feature.',\n",
       "  'weaknesses': '- The computational requirements during training are unclear. Since Algorithm 2 requires the fitting of potentially multiple models to obtain each student it appears to potentially be quite expensive (especially with large $R$ and/or large `max-search`), but this is not addressed explicitly in the paper\\n- The dimensions of $K_t^-$ and $K_t^+$ are $N \\\\times L$ and especially for large $N$, this could be a bottleneck during training (granted, for a mini-batch this is less severe). Furthermore, while reusing stored activations of previous students in subsequent students might keep the parameter count stable, it also requires additional memory and carefulness in which activations to store. Thus there is some overhead on storing and loading activations and $K$-matrices throughout training.\\n- The empirical results are weak at comparing to other baseline methods, and the method is struggling at the TinyImageNet and ImageNet-1k tasks, where additional inference time is required compared to the teacher.\\n\\nMinor:\\n- L14/15: Claiming distillation is a rigid procedure seems too bold, as a multitude of distillation techniques exists providing options to obtain lots of different students. Granted, most are aimed at obtaining a single student, but distillation in general is very flexible.\\n- L121: \"proabability\" -> \"probability\"\\n- Algorithm 1: $R$ is not specified in the algorithm, but needs deduction from Section 3.3\\n- Inconsistent use of RESCHED and RESHED\\n- Formatting of B-Distill and E-RNN are inconsistent in different places in the paper (e.g. L300-309).\\n\\n'},\n",
       " 'review_929': {'summary': 'In this submission, the authors propose a novel approach to speed up the noise estimation network by leveraging the robustness of early-stage diffusion models. Specifically, they present an algorithm to modify the quantization bit width according to the diffusion step. The proposed method shows positive results in reducing activation bits below 8 bits.',\n",
       "  'strengths': '•\\tThe writing of this manuscript is easy to follow, and the illustrations are clear.\\n\\n•\\tThis work is well-motivated. Based on the analysis, the authors provide insights on the different roles that different diffusion steps play and show the room to improve the PTQ process by treating early and later steps differently.\\n\\n•\\tThe experiments show positive results of the proposed method.\\n',\n",
       "  'weaknesses': '•\\tThe real-world benefits of reducing activation bits. With advanced samplers, the sampling steps of diffusion models are significantly reduced, e.g., to 50 steps or lower. Thus, the gain achieved through low bit width calculation in the early steps may be marginal in real-world evaluation. On the other hand, bit width is usually a power of two. To my knowledge, some execution cores are designed to process 8-bit-only or 4-bit-only data. Irregular bit widths like 6 bits are treated as standard bit widths by padding zeros. Thus, the benefits of reducing to irregular bit widths (e.g., 6 bits) instead of standard bit widths (e.g., 4 bits) are questionable from the perspective of hardware. The authors are encouraged to provide real-world evidence of the benefits of RTQ or a discussion of the above concerns.\\n\\n•\\tThe choice of FID threshold. In the RTQ algorithm, the choice of FID threshold is critical since it determines the final bit width dictionary and thus the quantization gain. How do you set this hyperparameter for a new dataset?\\n'},\n",
       " 'review_930': {'summary': 'The author initially notes that errors in the early stages of the reverse diffusion process result in minimal disturbance to the final generated image. As a solution, they suggest employing low-bit activations for the initial reverse diffusion process while preserving high-bit activations for the subsequent stages, in conjunction with PTQ.',\n",
       "  'strengths': '- The idea is clear and easy to understand\\n\\n- The proposed RAQ method outperforms the other methods such as Q-diffusion\\n',\n",
       "  'weaknesses': '- Could you the authors explain how is the entropy calculated and why higher randomness in the pixel values will cause the images blurrier?\\n\\n\\n- Cpmparison to other methods. The authors mentioned two PTQ methods PTQ4DM and Q-diffusion, but only provide quantitative and qualitative comparison to baseline and Q-diffusion.\\n\\n\\n- In section 3.2, it seems obvious that add the same amound of noise to a noisier image will have less influence than to a less noiser image? \\xa0\\n\\n- And the authors did not explain why in figure 3, the performance on two different dataset are so different.'},\n",
       " 'review_931': {'summary': 'This paper presents robustness-aware quantization (RAQ), a novel strategy to use mixed precisions for activations when quantizing diffusion models. The authors found that inaccurate computation during the early stages of the reverse diffusion process has minimal impact on the quality of generated images, and propose to use low-bit activations for the early reverse diffusion process while maintaining high-bit activations for the later stages. Experiments have been conducted for both unconditional and conditional generation using latent diffusion and stable diffusion on various datasets.',\n",
       "  'strengths': '- The paper is well-structured and presents a clear motivation for leveraging the robustness of early-stage diffusion models to use lower-bit activations at those time steps to further improve the computation efficiency.\\n- Experimental results show that the proposed method can use lower precisions for early-stage computation without sacrificing the quality of the generated images. \\n- The experiments with stable diffusion indicate the effectiveness of the proposed methods on text-to-image applications.',\n",
       "  'weaknesses': 'My biggest concern with the proposed RAQ approach is its practicality. The method suggests using low-bit activations for the early denoising process and high-bit activations for the later stages. However, the paper does not provide sufficient arguments on how this varying precision can be efficiently implemented and how much additional benefits it can bring compared to the simple W4A8 cases. In real-world applications, changing activation precisions could introduce complexities in designing and implementing corresponding kernels for different stages of the process, as the weight precisions need to be always upcasted to the activation precisions when performing the compute on conventional GPUs (e.g. the compute will always be WyAy for WxAy precisions, where x=4 and y>=4 for the settings discussed in the paper). Consequently, this could limit the practical utility and impact of the RAQ approach. An analysis of the theoretical speed up or memory saving should be done to show that changing activation precisions for early stages can indeed bring substantial improvements in compute efficiency (so the extra efforts for kernels implementation can be justified), and providing some additional simple experimental results will be preferred.'},\n",
       " 'review_932': {'summary': 'This paper proposes to quantize diffusion models to a different extent along the iterative process for image generation. The main motivation of the proposed approach is that diffusion model is robust to input distortion at early stages (i.e. noisy stages) of the iterative process. Therefore, the proposed approach starts with a 4-bit quantization, and gradually increase activation bits along the iterations. Experiments show that the proposed approach achieves improved performance with the same effective bitwidth.  ',\n",
       "  'strengths': '1. This paper has a good motivation. The empirical experiments show that it is legitimate to apply different rates of quantization at different stages of different diffusion process.\\n\\n2. The proposed method effectively improves the performance with a reduced bitwidth, as shown in Table 1.\\n\\n3. The idea is simple and is easy to follow.  ',\n",
       "  'weaknesses': '1. From Table 1, the bitwidth for each timestep is model-specific. That means optimization has to be done for each model. It would be good to have analysis on the robustness of the bitwidth selection.\\n\\n2.  As one of the main objectives is to improve the sampling efficiency, the comparison of runtime should be included. This is important for readers to understand the improvement brought by the proposed method.'},\n",
       " 'review_933': {'summary': 'The authors design robustness-aware quantization (RAQ) to speed up the noise estimation network by leveraging the robustness of early-stage diffusion models. Specifically, the authors found that the quality of generated images is less affected by the early-stage. Therefore, they reduce the bitwidth of activations for the early-stage, and maintain high-bit activations for the later-stage. Experiments show that the proposed method can speed up early computations while maintaining generation quality.',\n",
       "  'strengths': '1. The idea of the paper is simple yet effective, promoting the application of Post-Training Quantization (PTQ) in the diffusion model.\\n2. The analyses in the paper are extensive. The authors demonstrate the early-stage robustness through entropy transition across steps (Fig. 2) and noise injection. \\n3. The paper is well-organized and easy to read. \\n4. The authors also provide the code for results reproduction, showing the solidness of the work.',\n",
       "  'weaknesses': '1. In Tab. 1, RAQ only sets different bitwidths in five intervals, which is inconsistent with Algorithm 1, which sets different bitwidths in each step. Some explanation is needed.\\n2. The paper only reduces the activation bitwidth on the base of Q-diffusion. However, compared with LDM-4, the FID of Q-diffusion increased by 1.21 about LSUN-Bedrooms (256x256) in Tab. 1. Therefore, the activation bitwidth should not be reduced only. It is better to further apply RAQ to weight bidwidth to obtain a better trade-off between performance and efficiency.\\n3. The authors propose RAQ to accelerate the early-stage computation. However, the running time, FLOPs, and model size are not provided to demonstrate the effectiveness of the proposed method.'},\n",
       " 'review_934': {'summary': 'This paper aims to provide a comprehensive evaluation of robustness for pretrained vision-language models. Specifically, the authors benchmark around 100 pretrained models/classifiers. Based on these empirical results, this paper also provides corresponding discussions and analysis.',\n",
       "  'strengths': '1. The robustness problem of CLIP like model is a valuable topic to study.\\n2. This paper provides a very comprehensive benchmark for CLIP robustness problem. It may contribute to several benefit for the following research.\\n3. Corresponding discussion and analysis are solid to further inspire study in this area.',\n",
       "  'weaknesses': 'Even if I am still concerning the technical contribution of this paper for the NeurIPS conference, I recognize the workload and benchmarking work of this paper. Thus, only a little comments for the weaknesses:\\n1) What about further adding image-text retrieval evaluation and analysis? since CLIP can be used for both classification and retrieval. It may make this paper more solid.\\n2) I would like to discuss with other reviewers about the contribution significance of this benchmarking work to adjust my final score.'},\n",
       " 'review_935': {'summary': \"This paper analyzes the CLIP model's robustness through a large number of experiments, including three main points: resilience to visual factor variations, calibrated uncertainty estimations, and the ability to detect anomalous inputs.\",\n",
       "  'strengths': '1.  The experiments in this paper are very sufficient, the research content is solid, and some new views are proposed from the experimental results. There is a rich analysis of the robustness of CLIP.\\n2. This paper makes a significant contribution to the field by providing a comprehensive evaluation of CLIP models.  Furthermore, the experimental findings presented in this paper offer valuable insights for future endeavors aiming to enhance the out-of-distribution (OOD) detection performance and robustness of CLIP models.',\n",
       "  'weaknesses': 'There is no deeper analysis of the reasons behind these experimental results in this paper.'},\n",
       " 'review_936': {'summary': 'Authors closely study the robustness of vision-language models. They try to investigate their robustness in terms of common visual attributes, detecting OOD inputs, and their power in providing calibrated predictions. They consider many different CLIP models and other vision encoders with different architectures and training procedures to have a comprehensive study and fairly compare CLIP models with other ones.\\n\\nThey provide some more detailed findings about these models w.r.t to the aforementioned criteria.',\n",
       "  'strengths': '+ This paper runs an extensive set of experiments using various models, various datasets, and under different settings.\\n+ Therefore, these results will be insightful for practical use cases where people want to decide which model to use or diagnose possible errors/failures of their models on different conditions.\\n',\n",
       "  'weaknesses': \"+ I didn't see enough new ideas in this paper.\\n+ I mean, running extensive studies is definitely valuable, practical, and insightful, but is there other similar work published in NeuriPS where scaling up and running more experiments is the main contribution? I would appreciate it if the authors correct me in understanding their main contribution and change the rating correspondingly.\\n\"},\n",
       " 'review_937': {'summary': 'This paper studies and compares CLIP and CLIP-FT to standard models on a range of different tasks including OOD robustness, OOD detection, and model calibration. The paper constitutes a meta-analysis across different model architectures / training datasets / training algorithms or loss functions.\\n\\nThe authors claim:\\n\\n####  Robustness\\nCLIP sometimes outperforms other models on certain visual factor variations, but sometimes underperforms them.\\nCLIP models are more shape biased (authors claim due to VLM training), resolution increase decreases shape bias.\\nFine-tuning makes CLIP behavior more similar to other image models.\\n\\n####  OOD Detection\\nCLIP generally performs better than other models in OOD detection; the relationship between IID accuracy and OOD detection performance largely follows accuracy on the line.\\nFine-tuning negatively affects performance.\\n\\n####  Model Calibration\\nCLIP isn’t significantly more calibrated than other models, data distribution affects calibration.\\nTemperature scaling makes CLIP more calibrated than other models, and removes dependence on data distribution.\\nTemperature scaling is apparently more important for CLIP.\\nWhen temperature scaled CLIP is better OOD calibrated than other models.\\n\\n####  Test Time Prompts\\nUsing more prompts generally helps across tasks, except in the case of some visual factor variations where it doesn’t really make a difference',\n",
       "  'strengths': '- The introduction is well written, motivates the paper and gives a clear overview of the claims.\\n- Well written, easy to follow\\n- Objective tone/analysis and solid experimental design\\n- Some nice points/findings dispersed throughout the paper',\n",
       "  'weaknesses': \"- No clear central argument or claim, paper seems more like a pastiche of different experiments rather than a focused analysis. There is little interpretation of the experimental findings. I have written very detailed questions considering the OOD detection results, but similar questions apply to all sections.\\n- It looks to me that the paper tries to do too much in one paper and ends up being imprecise / too shallow on interpreting the results. For example, [2] focuses solely on how the data distribution affects robustness. Here, the authors observe this finding and only note that “The above observations highlight the importance of the choice of training source in determining not only the overall accuracy but also the factor-level behaviors of CLIP models. This suggests that visual factor-level robustness should be considered when designing the training source for CLIP models.” This is a “political” answer which does not provide concrete action items for future researchers.\\nSome claims/analyses are probably wrong:\\n\\n    *  “Temperature scaling reveals a consistent trend of CLIP models, and they still lie on a distinct trend from other models.” This doesn’t seem to be the case ALL of the time. SSL models look pretty similar to CLIP on the “NLL (Temp-scaled)” and “ECE (Temp-scaled)” Imagenet-A plots. Amount of difference seems to be dataset specific. In fact, I only see a significant effect in ImageNet-A, ECE vs ECE-temp scaled, where the temperature scaling seems to affect all models.\\n    *   ““This observation indicates that unlike robustness and out-of-distribution detection, the calibration of CLIP models is influenced by both training data distribution and quantity.” I don’t see how this follows from your data - aren’t robustness and OOD detection also influenced by data distribution?\\n    *  The CLIP training dataset likely overlaps with the datasets used for OOD detection which makes it unclear how meaningful the claims are in regards to CLIP’s good OOD detection performance. This issue should at least be discussed.\\n    *   OOD detection evaluations are missing important baselines (see details below).\\n\\n- The paper lacks novelty: The influence of training data / fine-tuning affecting CLIP performance have been studied in detail before [1,2,3]. This paper evaluates many different models and is thus a meta-study of the previous findings. In that case, the literature review should be expanded, and the paper must be better positioned, e.g. in “in [3], the authors investigate the influence of fine-tuning on OOD robustness. We here investigate whether their claims hold across a broader range of models'' or something like this. Though [3] already provides a thorough and careful empirical investigation across many different models, and I am not sure whether this paper offers much beyond the results presented in [3]. \\n- The graphs were sometimes a bit hard to read/interpret - there were a lot of them and usually the conclusion was different/unique depending on the plot.\\n- Some kind of unifying principle might be nice.\\n\\n### Minor:\\n- Please be more specific about results/claims in the abstract.\\n- 3.1 - Would be nice to explain/list model choices at some point, i.e. refer to Supplement A.2. here\\n- 3.2 (Robustness) - more explanation of why you chose 10 of the 16 would be nice (robustness)\\n- Line 40, style / grammar: “our study further study .. “\\n- Line 42: “training distributions”, it should be distribution\\n- Line 50, remove the extra space before the full stop\\n- Line 280: “highlighting their potential for the robust and reliable applications” → “highlighting their potential for robust and reliable applications.\"},\n",
       " 'review_938': {'summary': 'This paper performs a comprehensive study of various CLIP models on robustness to different visual factors, out-of-distribution detection, and calibrated uncertainty estimations. A total number of 53 CLIP models trained on different training sources and sizes, and different architectures, with additionally 32 CLIP models fine-tuned on ImageNet are studied.',\n",
       "  'strengths': '[Originality]\\n\\nTo the best of my knowledge, no previous studies have done such experiments on the 3 aspects to study CLIP models, especially considering various CLIP models trained on different datasets. Some of the observations made in this paper are new and complementary to the previous studies. For example, CLIP models are not robust in all aspects - they are less robust than models trained on ImageNet in a supervised way when poses are changed. Therefore, the findings are novel. \\n\\n[Significance]\\n\\nAlthough most conclusions that can be drawn from the experiments are already known, e.g., CLIP models are more robust than supervised models, some of them are less well-known and may be valuable to the community. For example, CLIP models trained on WIT perform better than those trained on LAION on OOD detection.\\n\\n[Quality & Clarity]\\n\\nThe quality and presentation of this paper are good. It is easy to understand and follow.\\n\\n',\n",
       "  'weaknesses': 'Some of the discussion on the experiment observations might need more support. \\n\\n1. Line 177: \"The shape bias of CLIP may be attributed to its objective, which involves training the model to associate text and image pairs\": in Figure 2, it seems that fine-tuning CLIP models on ImageNet (with supervised objective?) decreases the shape bias. However, it is also possible that the data source (ImageNet) could be the reason. Is it possible to decouple this? Say fine-tune CLIP with the contrastive objective on ImageNet and see if the shape bias stays the same.\\n\\n2. Line 246: \"We notice that CLIP models trained on LAION-80M dataset exhibit lower calibration performance when compared to standard models.\" Is this fair to compare as CLIP models trained on LAION-80M generally have lower accuracy?\\n\\nAnother minor concern I have is that some results from previous studies are not clearly discussed. For example, in ImageNet-X, it is already observed that \"color-jitter augmentation improves robustness to color and brightness, but hurts robustness to pose.\" Since color-jittering is widely used in the CLIP training, this should be discussed in the paper.\\n\\n[1] Badr Youbi Idrissi, Diane Bouchacourt, Randall Balestriero, Ivan Evtimov, Caner Hazirbas, Nicolas Ballas, Pascal Vincent, Michal Drozdzal, David Lopez-Paz, and Mark Ibrahim. Imagenet-x: Understanding model mistakes with factor of variation annotations. In International Conference on Learning Representations, 2022.\\n\\n[Minor]\\nLine 94: ImageNet 32 fine-tuned CLIP models -> 32 ImageNet fine-tuned CLIP models\\nLine 141: Small -> Smaller\\n\\n'},\n",
       " 'review_939': {'summary': 'The paper introduces a training algorithm for posterior distribution learning in the likelihood free setting that combats overconfident models.  The authors focus on the expected coverage probability (ECP) from Hermans et al., 2022 to measure if a model posterior is conservative.    Specifically, when its value is equal to the credibility level used in its calculation, then the posterior is calibrated.  An equivalent condition is that the distribution of credibility levels constructed from samples (lemma 1) is uniformly distributed.  With this in mind, the authors propose a regularizer that penalizes how far the distribution of these credibility levels are from a uniform distribution.   The main contribution of the paper is the algorithm used to train with this regularizer.  The authors use a variety of techniques in their algorithm including a one-sample Kolmogorov-Smirnov test to work with finite samples, differentiable sorting to implement the test, and importance sampling to choose useful samples to use.  The experimental results demonstrate that the learned models are more conservative than their unregularized counterparts while not sacrificing performance in terms of likelihood.  Furthermore, the authors showed the effect of the hyperparameters on performance and also showed the that the training algorithm can be expensive if not run on GPUs.',\n",
       "  'strengths': '- Directly addresses the \"trust crisis in simulation-based inference\" described in Hermans et al., 2022.\\n- Strong empirical results to demonstrate that the training algorithm works.\\n- The paper progressed smoothly from the background to the proposed algorithm.\\n- The layout of the text and plots are visually easy to digest.\\n',\n",
       "  'weaknesses': \"- It wasn't too clear to me after reading the main text why having uniformly distributed credibility levels was the right thing to want.\\n- Similarly, it took a bit of drawing to see how all of the values in section 2 were related to each other.  Adding something like figure 9 to the main text could greatly help introduce the background material.\\n\"},\n",
       " 'review_940': {'summary': 'The authors suggest a new objective function for simulation-based inference that adds a penalty term to the “expected score” objective that is used by many other works. This penalty term encourages the resulting posterior approximations to be well-calibrated in the sense that the $1-\\\\alpha$ highest probability density regions contain the ground-truth parameter $100(1-\\\\alpha)$% of the time. The penalty term is an extension of the Kolmogorov-Smirnov test statistic for goodness of fit between a $U(0,1)$ distribution and the rank statistics of eq. 7, which are asymptotically uniformly distributed when $p(\\\\theta \\\\mid x)$ is calibrated. Minimizing this penalty term alongside the usual objective function should yield posteriors that are calibrated while substantially different from the degenerate case of the prior (which is trivially calibrated). \\n',\n",
       "  'strengths': '* The proposed penalty/regularization term is relatively lightweight computationally, and can be tacked on to many existing simulation-based inference algorithms. \\n* The intuition is simple; the construction of the statistics $\\\\hat{\\\\alpha}$ is clever, and the Kolmogorov-Smirnov test statistic is well-understood.\\n* The method is assessed on a variety of problems from the test suite of benchmarks provided by Lueckmann et al. (2021), and performs favorably in that the resulting posteriors are either calibrated or tend to be conservative.\\n',\n",
       "  'weaknesses': '* Although synthetic likelihood and ABC approaches are mentioned in the introduction, the proposed method seems prohibitively costly in these scenarios, and seems geared toward amortized methods only, where eq. 7 can be computed rapidly.\\n* For ratio estimation in particular, the non-regularized NRE is better calibrated than the corrected version in some cases (e.g., spatial SIR), suggesting that it is at least possible the penalty term can worsen calibration.\\n* In practice, it appears that attempts at calibration often result in conservative rather than calibrated posteriors; while this is likely still preferable to many users to the alternative of *not* adding this correction, it suggests a bit of a misnomer. \\n'},\n",
       " 'review_941': {'summary': 'The paper proposes a calibration term to be used directly in the training objective of NREs and NPEs. The paper shows that the introduction of this term achieves competitive or better results in terms of coverage and expected posterior density. ',\n",
       "  'strengths': '* The quality of the writing and presentation is high, with the structure easy to follow. In particular the related work is clearly included in the introduction.\\n* The topic is of importance as it is increasingly more common to use neural estimators in SBI applications.\\n* The experimentation is sufficient to show the effect of incorporating the new regulariser. It seems to show that the new regulariser leads to slightly conservative estimators that are on average better calibrated than the baselines. \\n',\n",
       "  'weaknesses': '* The paper does not appear to have any major weakness. A few minor weaknesses that seem to exist have been appropriately described in the paper. These are the computational cost of the approach and the fact that the paper’s main metric of performance is also the same one that has been used in the regulariser. If the authors could think of a different metric to use to evaluate performance then the paper would be further strengthened. However, it is appreciated that finding a new metric would potentially be a new paper in its own right. Perhaps including C2ST as a metric in the appendix might provide additional comparison. While the focus of the paper is on calibration, it is possible to get a perfectly calibrated, but badly performing estimator.\\n* There is no mention of hyperparameter optimisation (although a sensitivity analysis is given).\\n'},\n",
       " 'review_942': {'summary': 'The paper presents a method to perform calibrated simulation-based inference. To do so, the paper employs the well-known coverage and proposes a way to differentiate through this term and to use it as a regularizer during training. The authors evaluate their method on benchmark tasks and conclude that it has good coverage and (sometimes) even outperforms existing methods in terms of log-likelihood.',\n",
       "  'strengths': '**Originality**: \\nThe method is novel and the use of a differentiable sorting algorithm for differentiating through coverage is novel and useful.\\n\\n**Quality**: \\nThe theoretical part of the paper is done rigorously and the paper provides additional empirical results for the impact of hyperparameters and computational cost.\\n\\n**Clarity**: \\nThe figures are clear and support the messages of the paper.',\n",
       "  'weaknesses': '**Quality**: \\nI expect that the method is very expensive if the batch size is large because in this case, GPU will not help either. This should be clarified in the paper.\\n\\nI found it very interesting that CA1NPE outperforms NPE in terms of log-likelihood. What exactly are the methods that the authors use to prevent overfitting? Always training for 500 epochs is clearly not something anybody would do in practice (L497). Please use a proper implementation of NRE or NPE to draw comparisons.\\n\\nThe poor results of Appendix Fig 6 should be mentioned in the main paper and it should be highlighted that the method can be used to produce conservative posteriors, but that it is not suitable to produce calibrated posteriors.\\n\\nAll tasks in the paper are very low dimensional. I would expect the NPE version of this algorithm to scale to high-dimensional asks, but this would need emprical evidence. For NRE, I could imagine that Importance sampling requires exceedingly many samples in high-d parameter spaces. Please clarify and ideally add tasks with a more high-dimensional parameter space.\\n\\n\\n**Clarity**: \\n\\nTwice (L159 and L183), the authors propose alternative formulations of their method. They never empirically investigate these formulations and also do not describe why they are less good. I would appreciate if the authors either add additional details on these methods or remove them entirely to avoid confusion.\\n\\nThe paper introduces **many** symbols which makes the paper very tedious to read. I would appreciate if the authors would redefine symbols in new sections to make the paper easier to follow. Also, some abbreviations do not really have to be defined (rarely used, e.g. KS, SAE, STE).\\n\\nMany papers are listed as `arxiv` although they got published. Please fix.\\n'},\n",
       " 'review_943': {'summary': 'Attribute filtering (AF) is an important part of many scenarios using nearest neighbor search. Here, each data points has a feature vector in a geometric space and also a set of attributes (e.g., data, author) and queries must be matched to nearest vectors satisfying some attribute constraints.\\n\\nWhile many algorithms have been studied for the classic ANNS problem, ANNS + AF is hard and needs new algorithms. Recently, there has been a flurry of attempts at this. Some of the basic approaches include filtering results of classic ANNS (which tends be yield poor results) or building separate indices for each attribute (Which leads to duplication).\\n\\nThis paper proposed that a better way to address this might be to create a fusion distance that incorporates geometric distance between feature vectors and suitably normalized similary score between attribute vectors. They then argue that a proximity graph data structure can be built using this distance. And that this performs better than other baselines selected in the paper. ',\n",
       "  'strengths': 'The authors identify and articulate an important problem.\\nEmpirical comparisons are made with many baselines.',\n",
       "  'weaknesses': \"There is no description of the dataset design in the main section. In appendix O, the datasets are described as usual vector datasets with 3 attributes (e.g., date, location, size) It looks like each vector can only have one possible combination of the attributes. So one can model it is one attribute dimension (cross-product) In such a case, why it not be easier and faster to build separate indices for each possible choice of attributes? Isnt complex index design only needed when datasets have multiple labels with an attribute dimension? In any case, it is impossible to evaluate the algorithm without well motivated datasets.\\n\\nMissing baseline: filter-diskann [www'23], methods therein and equivalent code (in-memory and on-disk) are not compared. Instead weaker baselines are compared.\\n\\nThere is far too much greek notation. The notation can be greatly simplified for better readability. Simple pseudocode would also make for much better reading.\"},\n",
       " 'review_944': {'summary': 'The paper discusses how hybrid query finds objects that are both similar to a feature vector and match some structured attributes. However, existing methods handle ANNS and attribute filtering separately, leading to inefficiency and inaccuracy. The paper proposes a new efficient and robust framework called native hybrid query (NHQ) and two new navigable PGs (NPGs) with optimized edge selection and routing, which improve the overall ANNS performance.',\n",
       "  'strengths': '1. Optimized edge selection and routing are proposed which is efficient for ANNS problems.\\n\\n2. The authors perform a sufficient complexity analysis of the proposed method. This helps readers understand the superiority and limitations of the proposed method.\\n\\n3. Many experiments have been conducted. The authors have conducted experiments on multiple datasets to show their superiority in terms of accuracy, efficiency, and memory usage.',\n",
       "  'weaknesses': '1. Compared to PQ-based methods, the PGs need more storage in runtime. Thus, a discussion on storage cost theoretically and experimentally of NHQ with PQ-based methods is necessary. There is still an improvement space on trade-off strategy on storage and efficiency.\\n\\n2. More related works (HQ-based methods and edge selection strategies) are needed.\\n\\n3. Lack of results of NHQ without edge selection strategy in ablution study.'},\n",
       " 'review_945': {'summary': 'In this paper, authors tackle the problem of retrieving nearest neighbor items under constraints on attributes of the retrieved items. Each item is described by a feature vector and a set of discrete attributes. \\n\\nAuthors propose to use a distance function that uses weighted combination of feature vector based distance and discrete attribute based distance. \\n\\nTo support efficient retrieval for a given query and attribute constraints, authors use graph-based nearest neighbor search indices. The proposed hybrid distance function is used to build the graph in an offline step and to navigate the graph during test-time search.\\n\\nAuthors also propose two heuristics to improve graph construction and test-time graph navigation, and overall the proposed approach yields improvement over baselines.\\n\\nUpdate: I am leaning towards accepting the paper and have updated my rating from  `5: borderline accept` to `7: accept` after reading clarifications from the authors.',\n",
       "  'strengths': '- The proposed idea of using a hybrid distance function (which combines feature vector and attribute based distances) provides significant improvement over two-stage inference pipelines that either retrieve based on feature vectors and then filter based on attributes or first filter based on attribute and then search over filtered items using feature vector.\\n- The proposed approach outperforms popular baselines on a variety of datasets.',\n",
       "  'weaknesses': '- Some missing baselines/ablations\\n    - The three main contribution of the paper are\\n        - a) New distance function for hybrid queries.\\n        - b) New algorithm for constructing graph over items.\\n        - b) New heuristic for efficiently navigating the graph at test-time.\\n    - The experiments clearly show the advantage of using the hybrid distance function over two-stage search (which separately performs nearest neighbor retrieval based on feature vector and then filters based on attributes).\\n    - But individual contribution of the proposed graph construction strategy and the proposed graph navigation strategy is not clear.\\n    - The proposed graph construction algorithm should be compared with NGT, HNSW, Munoz et al. (2019) while keeping every other design variable the same i.e. with the same test-time inference as well as with the same distance function.\\n    - Similarly, the proposed graph search method should be compared with existing methods for speeding up search such as TOGG (mentioned in the paper), Chen et al., (2023), Munoz et al., (2019).\\n- The presentation of the paper can be further improved.\\n    - Most algorithms are described in text but it would help to present them in Algorithm boxes.\\n    - While it is okay to use appendix for extra results, theorem proofs etc, I think some important details such as experiment setup, datasets and baseline description has also been moved to appendix. Reading the paper involved too many jumps between the main paper and the appendix. Authors could make the hybrid distance section more concise to make some space or move some extra results to appendix while keeping only main results in the paper.\\n    - Proof for theorem 4 is missing\\n\\n*Patrick Chen, Wei-Cheng Chang, Jyun-Yu Jiang, Hsiang-Fu Yu, Inderjit Dhillon, and Cho-Jui Hsieh. 2023. FINGER: Fast Inference for Graph-based Approximate Nearest Neighbor Search. In Proceedings of the ACM Web Conference 2023 (WWW \\'23)*\\n\\nMunoz, Javier Vargas, et al. \"Hierarchical clustering-based graphs for large scale approximate nearest neighbor search.\"\\xa0*Pattern Recognition*\\n\\xa096 (2019): 106970.'},\n",
       " 'review_946': {'summary': 'The paper introduces a novel approximate nearest neighbor search framework which baked in attribute constraints via a single composite index compared to many existing two stage solutions. The framework is mainly relying on a newly proposed distance function that fuses both feature vector distances and attribute vector distances. Based on the new distance function, several proximity graph based ANNS methods have been developed. The paper presents an ablation study showing the merits of the methods. The experimental results shown on multiple popular landmark datasets outperform baseline methods.  \\n',\n",
       "  'strengths': 'The proposed fusion distance is an excellent idea that enables the opportunities of the single composite index construction as well as the advantages over the legacy two-stage models. \\n\\nEach step of the method has been well-explained. In addition, most of the components have provided theoretical proof or support analysis.\\n\\nANN problems are often complicated in comparisons considering the nature of trade-offs among different factors including memory, accuracy, speed, etc. The paper has conducted sufficient experiments, ablation studies, and explanations of results. These strengthen the hypnosis and make the work overall to be solid. \\n',\n",
       "  'weaknesses': 'Details about config or setups for some baselines are missing. For example, the parameters or usages of FAISS are not discussed. It makes it harder to understand why FAISS gets saturated at recall 80% as shown in Section 5.2. Is it possible that the number of probes in IVF has not increased sufficiently?'},\n",
       " 'review_947': {'summary': '1. This paper shows how MLE can perform distribution learning in the setting of linear regression and in multi-layer ReLU networks.\\n2. This does not take a distribution on labels to be any specific form but rather unknows and tries to derive the sample complexity for a small total variational distance between the model’s conditional distribution and actual conditional distribution.\\n3. Improves the sample complexity of the previous work which suffers an exponential dependence on the ||W|| term.\\n4. Generalized how one layer Relu layer sample complexity can be extended to multilayer Relu networks.',\n",
       "  'strengths': '1. This work is a nice extension of the previous work mentioned in the reference[27]. It relaxes the assumption of previous work which assumed a fixed distribution of the labels.\\n2. The quality and clarity of the paper is good. Gives good proof techniques using the ideas from the learning theory.\\n3. Nice result for the linear regression in Theorem-4.1 where the sample complexity is linear in k: dimensionality of the labels which is some finite value in most of the cases.\\n4. This paper can be significant where the label distribution is unknown but the data distribution is known. ',\n",
       "  'weaknesses': '1. The proof techniques assumed the distribution of the data is Gaussian which is rarely the case because the actual data distribution for generative models thought of some complex unknown distribution.\\n2. Even though theorem 4.2 proved the result nicely there is a dependence of the square of the dimensionality of data. So the curse of dimensionality remains and these bounds can be very loose. '},\n",
       " 'review_948': {'summary': 'The article provides complexity bounds for learning the conditional distribution y|x. One of the main novelties claimed by the authors is that the control of the TD distance between the estimated distribution and the ground truth is more meaningful. Thus, they are able to provide bounds independently of the distribution of label x. The article is well written and the flow is quite pleasant. \\nSee my comments below for more critical details',\n",
       "  'strengths': 'The document is clearly written and the main arguments are transparent and easy to follow (even if they remain fairly technical). The authors did a great job explaining the intuition before getting into formal details. \\n\\nThe distribution free result (wrt to label x) is quite remarkable.',\n",
       "  'weaknesses': 'My main concern is that the results presented might be difficult to compare to classical results on the subject. Below I describe some of my missunderstanding.'},\n",
       " 'review_949': {'summary': 'In this paper, the authors consider the problem of linear regression and ReLU applied to linear regression. The goal is to recover the weight vector such that the resulting distributions are close as opposed to recovering the weight vector under certain norms such as $\\\\ell_2$ which has been thoroughly studied. For the linear regression, the authors show that the MLE estimator learns the distribution in total variation distance. For the ReLU regression, the authors show again the MLE estimator works when the covariance matrix of the noise is well-conditioned. The resulting algorithm is sample-efficient but not time-efficient.',\n",
       "  'strengths': 'The problem considered is fundamental and it has important connections to learning practically important problems.',\n",
       "  'weaknesses': 'I think the scientific novelty and contribution of this paper is very limited. The proposed results were well-known in the literature in my opinion. As an example, the distributional learning guarantee of linear regression in TV distance was analyzed in [arXiv:2107.10450]. Similarly, one-layer ReLU networks have been analyzed in the works of [Diakonikolas et al, Klivans et al, and Arora et al]. Moreover, the condition number assumption and the high running time of the proposed algorithms are quite restrictive in my opinion.'},\n",
       " 'review_950': {'summary': 'This paper studies conditional distribution learning: given iid samples (x,y) where x ~ D and y ~ p(y|w*,x), the goal is to find some estimate w such that the distributions p(y|w*,x) and p(y|w,x) are close in expectation over x ~ D, or equivalently the learned distribution of (x,y) (where x ~ D) is close to the true distribution.\\n\\nSpecifically, this work studies the 1-layer conditional generative model y = max(W* x + eta, 0) where W* is a matrix and eta is a multivariate mean-zero Gaussian with some unknown covariance Sigma*. The main result shows that for an arbitrary covariate distribution D, and arbitrary W*, so long as Sigma* has covariance at most kappa, the sample complexity of MLE (needed to learn up to total variation distance epsilon) is polynomial in the dimension parameters, log(kappa), and 1/epsilon.\\n\\nAn straightforward extension to multi-layer networks is also given (under the assumption that intermediate activations are known).',\n",
       "  'strengths': '- This work introduces a (to my knowledge) novel perspective to the problem of learning generative models: distribution learning rather than parameter estimation. This more accurately addresses the problem that actually matters in practice for generative models, and avoids needing to worry about identifiability issues.\\n- Due to the new goal, no distributional assumptions are needed (aside from the tame bound on condition number of the noise).\\n- The paper is well-written, with a toy example of linear regression given for intuition. I did not have time to check the proofs, but the approach and proof sketch seem reasonable.',\n",
       "  'weaknesses': \"- As the authors acknowledge, the paper only addresses the statistical question. It's claimed that the MLE is concave; however, I could not find a proof of this fact in the paper. Moreover, looking at the log-likelihood function (8) I do not see why it should be concave.\"},\n",
       " 'review_951': {'summary': 'The paper investigates the sample complexity of learning conditional generative models without assumptions on the input distribution. It applies the Maximum Likelihood Estimator (MLE) to linear regression and 1-layer networks with ReLU activation. The results show that the MLE achieves small total variation error with sample complexities of $O(k/\\\\epsilon^2 log(1/\\\\epsilon))$ for linear regression and O((kd + d^2) / \\\\epsilon^2 log(kd\\\\kappa/\\\\epsilon)) for 1-layer networks. The paper also discusses the extension to multilayer networks,  given access to the internal activations. The results suggest that MLE is a promising approach for learning feed-forward generative models from limited samples, though the authors did mention that the computational aspects of the optimization problem are not thoroughly analyzed in the paper.  \\n',\n",
       "  'strengths': 'This paper provides a solid theoretical foundation for understanding the sample complexity of learning multi-layer ReLU networks using MLE method. The derived bounds do not make assumptions on the distribution of X or the condition number of W, and achieve a sample complexity polynomial in the system parameters. The developed algorithm and theories show considerable improvement over those in the existing literature. Though there are limitations that are also noted by the authors, I think the paper is innovative and provides interesting insights into efficient learning of conditional generative models. \\nMoreover, the paper is well-written and presents its concepts and results in a clear and concise manner.',\n",
       "  'weaknesses': 'The weakness and limitations of the paper are well noted and discussed by the authors. \\n\\n1. To extend the theory to multilayer neural networks, it requires access to intermediate activations, which is impractical\\n2. It assumes that the learner has an understanding of the model architecture, which might not be the case in practice\\n3. It might be challenging to perform MLE on some of the models being considered, such as neural networks, and the computational aspects of the optimization problem are not thoroughly examined in this paper. \\n\\n'},\n",
       " 'review_952': {'summary': 'This paper discusses a new extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave minimax problems. The algorithm introduces a \"quasi-cocoercivity property\" and momentum acceleration to significantly improve the convergence rate in the constrained NC-NC setting. The algorithm attains a complexity of $O(\\\\epsilon^{-2})$ for finding an $\\\\epsilon$-stationary point of the function $f$, which outperforms the best-known complexity bounds. The paper also provides theoretical analysis and comparisons with existing algorithms.',\n",
       "  'strengths': 'As a person who works in minimax optimization, I can make a fair judgment of this work. This paper presents a novel extra-gradient difference acceleration algorithm for solving constrained nonconvex-nonconcave minimax problems, which improves the existing convergence rate and outperforms the best-known complexity bounds to $O(\\\\epsilon^{-2})$. The paper also provides a comprehensive comparison with existing algorithms and a theoretical analysis of the algorithm\\'s performance. I understand the \"extra-gradient difference prediction\" step as the key to the success of convergence rate improvements. In addition, I went through the proofs of Theorems 1 and 2 in detail. Overall, this paper provides valuable contributions to the field of minimax optimization and presents a promising algorithm for solving constrained NC-NC problems.',\n",
       "  'weaknesses': 'The paper assumes that the objective function satisfies certain structural assumptions, which may limit its practical applications. Also the writing style might not be as friendly for readers unfamiliar with the topic (I found it sufficiently clear though).'},\n",
       " 'review_953': {'summary': 'This work proposes a single-loop extra-gradient difference acceleration algorithm to find an \\\\epsilon-stationary point for constrained minimax optimization, which pushes forward the best complexity bounds of NC-NC, C-NC, NC-C problems to \\\\mathcal{O}(\\\\epsilon^{-2}). The proposed approach can deal with more general problems as it does not require monotone or structural assumption. Moreover, for the NC-C problem, the authors prove that the proposed method has better complexity bound under the stationarity of \\\\phi. Experiments are conducted to validate the method empirically. The results show that it can achieve better convergence rate when comparing with the related methods.',\n",
       "  'strengths': '1.\\tThe theoretical contributions are significant. The method employs a novel prediction point scheme to obtain the quasi-cocoercivity property, which relaxes the assumption requirements. Additionally, the paper provides a thorough analysis of the convergence complexity bound, demonstrating its superiority over the current state-of-the-art approaches.\\n\\n2.\\tThe paper is well organized and easy to follow. The logical flow of ideas is well-structured, enhancing the overall readability and comprehension of the presented contents.\\n\\n3.\\tEmpirical studies are conducted to validate the method in both synthetic and real tasks.\\n',\n",
       "  'weaknesses': \"There are some possible limitations where the paper could be further improved.\\n\\n1.\\tI suggest the authors to undertake additional analysis of the algorithm's time complexities, both theoretically and empirically. This deeper exploration would provide valuable insights, particularly for potential industrial applications.\\n\\n2.\\tThe absence of experiments conducted on the C-NC problem should be explained within the paper.\\n\\n3.\\tThere are some empirical evidences that seem to be inconsistent with the theoretical result, for example, FEG has a fast theoretical rate but is less effective in practice; GDA may not converge to stationary points. The authors may explain more about these in the paper.\\n\"},\n",
       " 'review_954': {'summary': \"The authors have designed a single-loop accelerated algorithm for constrained min-max optimization problems of the form $\\\\min_{x\\\\in X}\\\\max_{y\\\\in Y} f(x,y)$. The algorithm provably converges in an approximate local stationary point in three particular setting: \\n1. Non-convex non-concave min-max optimization, where the stationarity is measured for the function $f(x,y)$.\\n2. Convex non-concave min-max optimization, and non-convex concave min-max optimization, where the stationarity is measured for function $\\\\phi(x)=\\\\max_{y'\\\\in Y} f(x,y')$. \\n\\nThe authors showed that their algorithm computes an $\\\\epsilon$-stationary point, in $O(1/\\\\epsilon^2)$ iterations. Finally, they experimentally verify their proposed algorithm.\\n\\n\\n\\nThe authors' rebuttal addressed my concerns, and their additional empirical evidence complemented their already compelling results. For these reasons, I decided to increase my score.\",\n",
       "  'strengths': 'The design and analysis of algorithms for non-convex non-concave minimax optimization is a fundamental problem, and the convergent results are indeed compelling. Moreover, the authors get the state-of-the-art for convex non-concave, and concave non-convex for the merit function they consider. Furthermore the main paper is well-written and easy to follow, and the algorithm seems to combine several interesting ideas.\\n\\nI verified the proofs of proposition 1 and 2, and the rest of the statement seems reasonable. I found the proofs of proposition 1 and 2 to be a bit dense, which made verifying them somewhat taxing.',\n",
       "  'weaknesses': 'Overall, I did not find some important weakness in the paper. As a suggestion, improving the readability and verifiability of the proofs could greatly benefit readers. Lastly, I came across a couple of typos:\\n- In line 242, I think \"conference\" was meant to be \"convergence\".\\n- When considering the proof of proposition 2 in the appendix, is $\\\\widehat{u}_{t+1/2}$ identical to the one referred to in line 706? If so, clarifying this might prevent confusion.\\n- In line 3 in Algorithm 1, do you also need to initialize $y_{-1}$ for the first iteration of the algorithm?'},\n",
       " 'review_955': {'summary': 'Authors propose method of solving nonconvex-nonconcave saddle point problems with convergence rate O(eps^-2) by using gradient difference prediction and momentum acceleration to improve extragradient descent-ascent method. Proposed method is state-of-the-art in theory and leading in practice, including neural network learning with adversarial attacks task.',\n",
       "  'strengths': 'Quite elegant construction of the algorithm, which also allows one to obtain best-known convergence rate guarantees. Algorithms allows practitioners to address the most practically important setting of nonconvex-nonconcave problems efficiently using easy to implement algorithm which will surely replace analogous methods, judging from empirical study.',\n",
       "  'weaknesses': 'No significant weaknesses'},\n",
       " 'review_956': {'summary': 'This research paper introduces an innovative method for learning and utilizing unknown user relations from disrupted behaviors to enhance the learning process and identify corrupted users in an online setting. To achieve this, a new bandit algorithm (RCLUB-WCU) is proposed, along with an online detection algorithm that leverages user relations inferred by RCLUB-WCU. The paper also presents a regret upper bound for RCLUB-WCU, which closely matches the lower bound with respect to T (the number of rounds) up to logarithmic factors and performs well even in degenerate cases. The experiments conducted on synthetic and real-world datasets demonstrate significant improvements in performance compared to previous bandit algorithms',\n",
       "  'strengths': '1. The paper presents a novel application to learn unknown user relations in their preferences from potentially corrupted feedback. At the same time, the paper shows how to leverage the learned relations to speed up learning as well as adaptively detect the corrupted users online from bandit feedback. Overall I think this paper makes a significant contribution to the literature on online learning from corrupted feedback as well as detection of adversarial users in multi-user online learning setting. \\n\\n2. Experiments on synthetic and real-world datasets clearly indicate  lower reward regret of proposed approach in comparison to five other baselines from the past literature on online clustering of bandits. At the same time, the algorithm is able to identify corrupted users with higher accuracy than a simple baseline that directly compares the robust-estimators of preference vectors of a user and its corresponding cluster.\\n\\n3. The authors back up their results with theoretical analysis and guarantees on the performance of the proposed algorithm.',\n",
       "  'weaknesses': \"1. It seems to me that the performance of proposed approach could potentially be sensitive to the nature of underlying user relations in their preferences and the tightness of the detected clusters. For example, to my understanding, this algorithm might not work well if there are too many tight clusters. However, if one chooses too big clusters, then the solution might compromise on personalization as users in a loose cluster might not be represented accurately by a common preference vector defined for the cluster. The paper does not provide any discussion on the impact of cluster sizes on the algorithm. \\n\\n2. The approach requires multiple parameters to be specified. (e.g. regularization parameter, confidence radius parameter, threshold parameter, edge detection parameter). There is no discussion provided on the sensitivity of the results to the choices of these parameters (in the main draft at least).\\n\\n3. The results in Table 1 on detection of corrupted users are not very clear. To begin with, it's not clear what do numbers in the table indicate? I assume they indicate recall of true corrupted users. If so, where are the precision numbers? Where are F1 scores given that thre is class imbalance? Authors need to clearly indicate what they are measuring and also provide an explanation in case they aren't measuring both precision and recall. Also it would be nice to have comparison with multiple baselines. Further, authors could potentially enrich the results with other variants of the baseline, e.g. another baseline variant could simply compare the non-robust estimators of cluster and user. (I believe the current baseline compares the robust estimators of a user and its cluster).\\n\"},\n",
       " 'review_957': {'summary': \"The authors introduce an online learning problem called LOCUD (Learning and Online Corrupted Users Detection from bandit feedback) in which the aim is to detect a small fraction of the overall users with corrupt behaviors; corrupt users occasionally perform undesirable actions, but otherwise mimic normal user behavior, making them challenging to detect.\\n\\nThe paper then proposes a framework that leverages the relations between users to form semantic clusters, and uses the clusters to identify corrupt users. Specifically, the authors propose RCLUB-WCU (Robust CLUstering of Bandits With Corrupted Users) to progressively prune a fully connected graph of users to clusters of connected components based on user interactions and preferences. Then, OCCUD (Online Cluster-based Corrupted User Detection) estimates a robust and non-robust estimation of each user's preferences, and identifies a user as corrupt if the gap between the two estimates exceeds a carefully designed threshold. OCCUD is repeatedly invoked within RCLUB-WCU to continually prune and refine the relational structure amongst the users.\\n\\nExperiments one on synthetic dataset and three real-world datasets show the proposed approach is able to detect more corrupted users while achieving the least amount of regret over time than competing methods.\",\n",
       "  'strengths': '* The paper introduces a challenging but relevant problem of trying to identify corrupt users despite sporadic behavior in an online dynamic environment. This problem is especially relevant for sites like Amazon and Yelp which often contain users that exhibit corrupt behavior.\\n\\n* The proposed approach of leveraging relational information between users to more effectively detect corrupt users is intuitive, and the experimental results suggest its effectiveness.\\n\\n* Analyses and bounds related to regret are given for the RCLUB-WCU/OCCUD algorithm, with proofs provided in the Appendix.\\n\\n* The paper is generally well-written and follows a logical progression.',\n",
       "  'weaknesses': '* Experiments are performed on a small number of small datasets, potentially limiting the generalizability of the proposed approach. Performing experiments with a wider range of larger datasets would significantly benefit the claims made in the paper.\\n\\n* No empirical runtime analysis is provided for the proposed approach or any of the competing methods. Runtime analysis can help practitioners decide what method is likely to work best for their particular problem.\\n\\n* Only one baseline method is compared to the proposed approach for the AUC results (Table 1). Where are the results for the other methods?\\n\\n* Additional experimental results including different corruption levels and number of clusters are provided in the Appendix, but those results (Figures 4 and 5) only shows regret, and only compares the proposed approach with two baseline methods. Can the authors provide results for the other baseline methods, as well as AUC results for these additional and potentially insightful experiments?\\n\\n* Minor clarity improvements:\\n    * Use authors\\' names to cite previous work. \"The work [5] proposes...\" -> \"Ding et al. (2022) propose...\".\\n    * The legends in Figure 5 make the subplots hard to read. Figure 5 is also not color-blind friendly, consider adding markers or using different line styles for different methods.'},\n",
       " 'review_958': {'summary': \"The paper considers the following bandit setup.\\n\\nThere are $u$ users organised into $m\\\\ll u$ clusters. Each cluster has vector $\\\\theta$ attached to it. On step $t$ the learner deals with a user uniformly selected from the pool and picks an arm $a$. If this is a bona fide user, the learner gets average reward $x'_a\\\\theta$, where $x_a$ is the feature vector for the arm and $\\\\theta$ is the vector for the cluster the user belongs to. There is a number of corrupted users though, who give reward $x'_a\\\\theta + \\\\eta + c$, where $\\\\eta$ is noise and $c$ (a bounded quantity) is corruption.\\n\\nWe have a twofold problem of minimising the regret and identifying the corrupted users. The paper presents an algorithm based on a graph of connections between users built by observations of their behaviour. The regret upper bound is matched by a lower bound. It is shown that with high probability we identify the corrupted users correctly and after a while end up with correct clusters.\",\n",
       "  'strengths': 'I think this is an interesting result and a strong guarantee. The explicit modelling of corrupted user behaviour may seem restrictive at first, but it covers many possibilities. The authors were very careful to relax all the requirements as much as possible (e.g., consider sub-Gaussian noise etc). The algorithm is intuitive.',\n",
       "  'weaknesses': 'No obvious weaknesses. The appeal of the result may be limited for some NeurIPS participants.\\n\\nSome minor suggestions (not reflected in my evaluation of the paper):\\n\\n1. I do not think quantifiers should be used as in \\n\\nAt $\\\\forall t$, for any fixed unit vector $z$ ...\\n\\n(Assumption 3.) \\n\\nUsing \"every\" here will not blow the volume of the paper out of proportions, but will improve readability.\\n\\n2. Use $\\\\verb!\\\\left(...\\\\right)!$ in formulas like (7) to get larger brackets.\\n\\n3. I do not find the abbreviations used in the paper convenient and phrases such as\\n\\nCW-OFUL-Ind outperforms LinUCB-Ind because it considers the corruption, but worse than RCLUB-WCU\\n\\neasy to parse.'},\n",
       " 'review_959': {'summary': 'This paper presents an important online learning problem named LOCUD to learn and utilize unknown user relations from disrupted behaviors to speed up learning and identify the corrupted users in an online setting. Also, the authors propose a novel bandit algorithm RCLUB-WCU, and devise a novel online detection algorithm OCCUD based on RCLUB-WCU’s inferred user relations. Extensive experiments demonstrate that the proposed methods can achieve superior performance over previous bandit algorithms and high corrupted user detection accuracy. ',\n",
       "  'strengths': '1. The paper is scientifically sound.\\n2. The clarity of the presentation is easy to follow.\\n3. Extensive experiments of the proposed methods have superior performance than other baselines.',\n",
       "  'weaknesses': '1. The introduction section of the paper lacks sufficient emphasis on the motivation behind the proposed methods. The authors should provide a more comprehensive analysis of the current issues and challenges in the relevant fields, clearly indicating how their research work addresses and improves upon these challenges. This will help readers better understand the significance and contributions of the proposed methodology.\\n2. The abstract section should be more concise. It should effectively highlight the key innovations and improvements introduced by the proposed methodology.\\n3. The paper provides limited discussion and summary of the relevant literature. To strengthen the research methodology, the authors should include a more extensive review of existing research methods, along with an analysis of their strengths and weaknesses. \\n4. The experimental content is not enough to effectively prove the superiority of the method. It is suggested that the authors add more dimensional experiments and give a comprehensive analysis and explanation of the experimental results, thus making the conclusions in the paper more convincing.\\n5. The dataset used in the experiments is relatively small, which may limit the generalizability of the findings. It is recommended to supplement a large-scale real dataset for performance validation.\\n'},\n",
       " 'review_960': {'summary': 'The paper proposed a sampler that balances sampling speed and quality by adding noises and restarting the process. They provide theoretical analysis to show a better upper bound of this method compared to original ODE and SDE samplers. Experiments are done to verify their claims. ',\n",
       "  'strengths': '1. Authors identify the main cause of different performances of SDE and ODE in different regimes. And by taking advantage of the contraction by adding noises, they balance the speed and quality of the sampler.\\n\\n2. The theoretical analysis is clear and well-written. \\n\\n3. The experiments are thorough with a good explanation of the choices of hyperparameters. \\n\\n4. The experiments show good results for the proposed method.',\n",
       "  'weaknesses': 'See questions.'},\n",
       " 'review_961': {'summary': 'By analyzing of the trade-off between good sample quality and sampling time of both ODE and SDE-based generative models, a restart sampling strategy is proposed by this paper to combine the advantages of ODE and SDE sampling methods. The author proves two theorems that estimate the upper bound on the total error measured by the Wasserstein distance between generated and data distributions of ODE, SDE, and restart sampling methods respectively. It is illustrated that the total error can be decomposed into two parts: additional sampling error generated by discretization error and contracted error generated by the accumulated total error from previous sampling steps. Moreover, it is proved that ODE-based samplers have smaller additional sampling errors and SDE-based samplers have smaller contracted errors. So Comparing the three upper bounds on the total error, it can be proved theoretically that restart sampling yields a smaller total error because its additional sampling error and contracted error are both small. Finally, a range of experiments are done by authors which shows empirically that: 1. The total error of the restart sampler is indeed smaller than that of others. 2. Restart sampler surpasses previous SDE and ODE samplers in both speed and accuracy. 3. Restart sampler better balances text-image alignment/visual quality versus diversity than previous samplers.',\n",
       "  'strengths': '1. This paper is written with meaningful motivation and a clear structure. The restart sampling method proposed by this paper is innovative, simple, and effective.\\n2. The reasonableness and effectiveness of the resampling method are proved both theoretically and experimentally.\\n3. The upper bounds on the total error of the three sampling methods give us an intuitive understanding of the advantages and disadvantages of the three sampling methods.',\n",
       "  'weaknesses': '1. The effectiveness of restart sampling method on high-resolution image synthesis is not confirmed. For example, a comparison of sampling speed and accuracy on ImageNet 128*128, 512*512 should be added.\\n2. The paper experiments on the sensitivity analysis of the number of restart iterations K, but there is no experiment on the sensitivity of another hyperparameter: the position and length of the restart interval.\\n3. As pointed out in the paper, the contracted error further diminishes exponentially with the number of repetitions K though the additional error increases linearly with K. Figure 4 illustrates this trade-off phenomenon, too. So it may be hard to find a suitable K to make the restart algorithm work for different datasets or tasks globally, making it difficult to apply. '},\n",
       " 'review_962': {'summary': 'The papers propose a new sampling method for diffusion models, termed Restart Sampling. The authors first theoretically analyze the error propagation in diffusion models for stochastic and deterministic samplers under Wasserstein-1 distance and show that ODE samplers have a lower-discretization error but SDE samplers contract the initial distribution error as we run more steps. This agrees with the intuition and the experimental findings that support that ODE samplers are better for low NFEs but their performance flattens for more NFEs. Based on this analysis, the authors propose a method that tries to achieve the best of both worlds: it contracts the initial error with more steps and achieves the same discretization error as the ODE samplers. The implementation of the new method is very straightforward: one runs the ODE sampler and every K steps reverts back to some prior diffusion time using the forward model.',\n",
       "  'strengths': 'The authors study a relevant problem in diffusion models. The proposed solution is simple, effective and novel. The theoretical results motivate the method and show clearly the differences between the SDE and the ODE samplers. The presentation of the paper is excellent. The authors show many experimental results, starting from toy models and going all the way to state-of-the-art text-to-image diffusion models. I think the paper and the method is of interest to the community and the audience of NeurIPS.',\n",
       "  'weaknesses': 'The error propagation of diffusion models has been studied before. The results that I am aware of are from the papers \"Sampling is as easy as learning the score\", \"Restoration-degradation beyond linear diffusions: A non-asymptotic analysis for DDIM-type samplers\" and \"The probability flow ODE is provably fast\". The first studies the error propagation of the SDE sampling method and the latter two the propagation of errors for deterministic samplers. It would be beneficial to compare with these works, highlight potential differences in the approach and the final results, etc.\\n\\nAlso, apart from the Stochastic and the ODE samplers, there is a whole family of samplers that satisfy the same Fokker-Planck equations and hence give the same marginals, e.g. see the work \"Fast Sampling of Diffusion Models with Exponential Integrator\" and also some of the samplers used in the \"Elucidating the Design Space of Diffusion-Based Generative Models\" (EDM) paper. It would be interesting to compare theoretically and experimentally to these samplers.\\n\\nAnother concern I have is that the evaluation is only as thorough as it should have been and it is only done for relative high NFEs. Since evaluating the performance of a trained model is relatively easy, I would expect a more thorough benchmarking. If the performance of Restart sampler breaks for low NFEs, it is useful to know it and acknowledge it in the paper.\\n\\n'},\n",
       " 'review_963': {'summary': 'ODE-based samplers plateau in performance while SDE-based samplers deliver higher sample quality. The paper attributes this difference to discretization errors and accumulated errors. Based on these, the authors propose a sampling algorithm called Restart which alternates between the forward diffusion process and backward ODE.',\n",
       "  'strengths': '1. The authors provide a theoretical explanation of the phenomenon that ODE samplers outperform SDE samplers in the small NFE regime but fall short in the large NFE regime.\\n\\n2. The experimental results on image generation tasks validate the effectiveness of the method.',\n",
       "  'weaknesses': 'The proposed method relies on several hyperparameters (e.g. $S_{noise}, N_{restart}, i, K_i, t_{min, i}, t_{max, i}$), and the hyperparameters differ in different tasks. It would be hard to effectively tune these parameters in real application.\\n'},\n",
       " 'review_964': {'summary': 'This paper proposes analyzes SDE and ODE-based samplers for diffusion models. Based on the analysis, this paper introduces a new solver, Restart, for sampling from diffusion models. The effectiveness of Restart is demonstrated on various unconditional and conditional generation tasks.',\n",
       "  'strengths': '- The paper is well-written.\\n- The proposed method shows better performance than EDM at moderate NFE regions.',\n",
       "  'weaknesses': 'I am willing to raise the score by 1 or 2 points if the authors address my concerns satisfactorily.\\n\\n**Weakness 1 : Ambiguity regarding Theorems 1 and 2.**\\n- For Theorem 1, if we set $[t_{\\\\min},t_{\\\\max}] = [0,T]$, the terms for contracted errors $TV(p_T^{ODE_\\\\theta},p_T)$ and $TV(p_T^{SDE_\\\\theta},p_T)$ vanish because $p_T^{ODE_\\\\theta}$, $p_T^{SDE_\\\\theta}$, and $p_T$ are all identically Gaussian distributions. Then, we end up with terms depending on $\\\\delta$, $\\\\epsilon_{approx}$, and $t_{\\\\max} - t_{\\\\min}$ only, so Theorem 1 does not provide any insight into how ODE and SDE have distinct \"winning regions\", as illustrated in Figure 1 (b). The proof and claim for Theorem 1 should be reformulated such that even with $[t_{\\\\min},t_{\\\\max}] = [0,T]$, Theorem 1 explains how ODE and SDE have winning regions.\\n- Likewise, I think Theorem 2 also should be proven for the entire interval $[0,T]$, so we can directly compare the errors for SDEs, ODEs, and Restart.\\n\\n**Weakness 2 : (Possibly) weak performance on the small NFE regime.**\\n- How does Restart perform in the small NFE regime (NFE $\\\\leq 30$)? In Figure 3, the figure cuts off just before Restart and ODE intersect in the small NFE regime. This seems to contradict the claim that Restart combines the best of both ODE and SDE. Moreover, given the large size of SOTA diffusion models, it is crucial that diffusion samplers work well in the small NFE regime as well.\\n-  How does Restart compare to recent fast samplers such as [1], [2], [3] in the small NFE regime?\\n\\n[1] DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps, NeurIPS, 2022.\\n\\n[2] Fast Sampling of Diffusion Models with Exponential Integrator, ICLR, 2023.\\n\\n[3] Denoising MCMC for Accelerating Diffusion-Based Generative Models, ICML, 2023.'},\n",
       " 'review_965': {'summary': 'The paper tackles calibration of Gaussian processes in regressions. The authors argue that while maximizing the evidence is a good way to choose hyperparameters to obtain an accurate posterior mean, it generally does not produces an accurate posterior variance. For this purpose, they propose a different way to obtain hyperparameters for the posterior variance which minimizes the length of centered confidence intervals, while constraining the parameters to provide accurate empirical quantiles. By replacing the constraint with a more treatable piece-wise expressions, they transform the problem into an unconstrained one. The further a practical algorithm and a theoretical result to obtain calibrated confidence intervals simultaneously over different confidence thresholds. Experimentation on toy and UCI datasets show the benefits of the method.',\n",
       "  'strengths': 'I think the paper is well written and clear. The solution proposed is reasonable and it tackles an important problem. The algorithms derived seem to be practical, and they are motivated by theoretical arguments that appear valid.',\n",
       "  'weaknesses': 'The authors bring up themselves that the core methodology they propose shares the same scalability issues as standard GPs, as it involves they inversion of a very large matrix. Hence, approximation methods are needed.'},\n",
       " 'review_966': {'summary': 'This paper addresses the issue that the posterior variance of Gaussian processes are often poorly calibrated, typically underestimating quantile estimation. They propose a new method to calibrated uncertainty bounds, by training a quantity related to the posterior variance with new hyper parameters. This method further leverages optimization of the distance between the quantiles and the predictive mean, enabling sharp calibration. The method is tested on synthetic toy examples and standard UCI benchmark datasets, and appears to perform well against existing methods.',\n",
       "  'strengths': 'The paper is well written and presented and addresses a relevant problem, offering a principled solution.',\n",
       "  'weaknesses': 'The definition of a Gaussian process should specify that any **finite** collection of points are jointly Gaussian.\\n\\nThe most concerning issue is that the paper appears to be dismissive of two recent competing methods (Song et al.; Kuleshov & Deshpande) in the introduction, and does not mention them again. Indeed, the current work has advantages over each of these methods in terms of its construction and theoretical guarantees, however comparisons to these methods in terms of performance, as well as some further discussion, should help demonstrate the benefits of the proposed method. For example, the current method still relies upon a reasonably large dataset size, so dismissing a competing method because it only has asymptotic guarantees is maybe premature.\\n\\nI would also question the presentation of the numerical results, in particular the use of both highlighting and boldface to denote best performing model in the tables. Since confidence intervals are provided, it may be advisable to bold the best performing ones, and using green to denote statistical significance that a single model is the best performing (i.e. multiple models can be bolded but none or one should be green).'},\n",
       " 'review_967': {'summary': 'The authors propose a novel method for calibrating Gaussian process posterior variances using held-out data. In particular, they train a new, separate, GP using the held out data for the variance, using the GP trained on the original dataset for the mean. They do this in a way which approximately maximises the sharpness (roughly speaking, minimises the variance). The calibration properties of the method are supported by theory. This is supported by an empirical evaluation of the calibration error on synthetic data and of the sharpness on real-world data.\\n\\nPost-discussion: The authors have provided considerable improvement in their presentation of the results, and have added some extra results which further improve the clarity.',\n",
       "  'strengths': '1. (major) the idea is novel,  and appears to be theoretically well supported, although I did not review the proofs in the supplementary material.\\n2. (major) The main claimed advantage of the proposed method is that is produces sharper predictives than comparable methods, which is well supported by the real-world experimental results, not withstanding the points raise in questions.\\n3. (major) Code is provided, which should improve reproducibility. It is based on a widely used framework, which increases potential for impact.',\n",
       "  'weaknesses': '1. (major) The paper is not sufficiently clear. The method is fairly well explained, but the evaluation is extremely hard to follow, details of which are in the questions section. One particular area for straightforward correction is with Table 2: the values with the lowest mean are highlighted but there are several rows where the estimates are overlapping, so this should be clarified by highlighting.'},\n",
       " 'review_968': {'summary': 'Motivated by the observation that the posterior variance of a Gaussian process is often poorly calibrated, the authors propose an alternative approach of attaching predictive quantiles to the posterior mean. In essence, their approach minimises the width of the predictive quantiles under an empirical calibration constraint computed on held-out validation data. By satisfying the empirical calibration constraint, the authors prove that the predictive quantiles are indeed approximately the right quantiles (Theorem 5.3). The approach is tested and compared against other calibration approaches in a toy example and on seven data sets from the UCI data set repository. The results show that it outperforms other techniques in terms of sharpness.',\n",
       "  'strengths': 'To begin with, I would like to thank the authors for their submission. \\n\\n## Strengths\\n\\n* The paper is easy to follow and generally well written. I found only a few typos.\\n\\n* The problem that the posterior variance of a GP may be poorly calibrated is highly relevant, so methods that attempt to attack this problem, like the proposed approach by the authors, are certainly important.\\n\\n* Accompanying the method with a theoretical result that guarantees correctness (Theorem 5.3) reassures the practitioner.\\n\\n* I really like Section 5.2, where the authors spend some effort on reducing the computational cost in practice. They could have just left it at (7) and state that the optimisation problem would have to be computed for every confidence level $\\\\delta$ of interest, but of course the approach in Section 5.2 is much more elegant.\\n\\n* The experiments appear to show that the proposed approach is sharper than alternatives. I, however, have some doubts about the experimental section. Please see below.\\n\\n## General Comments and Suggestions\\n\\n* Should the title of the paper be \"Sharply Calibrated GPs\" instead of \"Sharp Calibrated GPs\"? I think \"Sharp(ly)\" should be an adverb, since it modifies \"calibrated\".\\n\\n* On line 75, you use $\\\\mathcal{D}\\\\_{\\\\text{tr}}$ without introducing the symbol first. This is confusing, because you have just introduced $\\\\mathcal{D}$, not $\\\\mathcal{D}\\\\_{\\\\text{tr}}$, as the training data.\\n\\n* On line 75, you introduce the cut-point term as $\\\\beta_\\\\delta \\\\sigma_{\\\\mathcal{D}}(\\\\delta, x)$. At this point, you should really better explain this term by answering the following questions: Should $\\\\sigma_{\\\\mathcal{D}}(\\\\delta, x)$ be interpreted as a standard deviation? If so, how do you make sense of that it depends on $\\\\delta$? If not, then what is $\\\\sigma$? If you\\'re learning $\\\\sigma$, why do you also need $\\\\beta_\\\\delta$? Can you not absorb $\\\\beta_\\\\delta$ into $\\\\sigma$? You should also mention that $\\\\beta_\\\\delta$ may be negative. Without that information, (1) doesn\\'t make much sense for small $\\\\delta$.\\n\\n* On line 81: Do you mean \"are small\" or \"are as small as possible\"? This nuance is very important and changes the meaning substantially.\\n\\n* On line 119, you say that the log-marginal likelihood does not account for calibration. Depending on what precisely you mean by calibration, I think that this is false: the log-marginal likelihood is an empirical estimate of the KL divergence, and the KL divergence certainly accounts for the \"whole distribution\" and therefore the calibration.\\n\\n* In Section 5.1, is $\\\\sigma\\\\_{\\\\mathcal{D}\\\\_{\\\\text{tr}}}(\\\\theta, x)$ the posterior variance of the GP where the kernel parameters are now the parameters that we optimise over? From line 146 onwards, you don\\'t actually explain this! Since this is a crucial part of your construction, I think the exposition would be better if you were to clearly explain this somewhere around line 158.\\n\\n* On line 175, you state that (5) can be replaced by (6) with further explanation. Since this is an important step in the derivation of your algorithm, I think that it deserves a careful explanation. Moreover, it is not true that (5) and (6) are equivalent, since $q\\\\_{\\\\text{lin}}$ is linearly interpolated. I think the exposition would benefit from a little more care here.\\n\\n* Line 268: \"calibration\" -> \"calibrated\"\\n\\n* Could you add to the legend of Figure 2 what the squares and crosses are? Why does it look like there are two \"lines of squares/crossed\"?',\n",
       "  'weaknesses': \"## Weaknesses\\n\\n### Assumption 4.1 Not Obviously Satisfied\\n\\nI agree that Assumption 4.1 is obviously satisfied for the variance of a kernel. However, for the inverse length scale, I can believe that Assumption 4.1 might be satisfied, but this is not obvious at all. Would the authors be able to produce a proof that the posterior variance of a GP is monotonic in the inverse length scale?\\n\\n### Theorem 5.3 Might Not Be Valid\\n\\nThe proof of Theorem 5.3 crucially relies on Theorem 1 by Marx et al. (2022). This Theorem 1, however, operates in the setting where all pairs $(x_i, y_i)$ are sampled i.i.d. (see Section 2 of Marx et al., 2022). But in the setting of GPs, which is the setting of the submission, the pairs aren't independent, because they are correlated by the sample from the underlying GP! This means that Theorem 1 might not apply, which means that Theorem 5.3 might not be valid. Could the authors comment on this?\\n\\n### Result of Section 7.1 Looks Questionable\\n\\nIn Figure 2, you state that your approach produces a 99% confidence interval. However, if you look at the right side of Figure 2.(a), then the confidence interval completely misses the data! It hence looks like the shaded region is not actually a 99% confidence interval, which makes me wonder whether the predictions are actually well calibrated.\\n\\n### Bolded Results Are Not Significantly Best Results\\n\\nThroughout the main paper and the supplement, you bold the score with the best average. However, if $x_1 \\\\pm e_1$ and and $x_2 \\\\pm e_2$ are such that $x_1 < x_2$, but $x_1 + e_1 \\\\ge x_2 - e_2$, then you cannot actually conclude with confidence that $x_1 \\\\pm e_1$ is really lower than $x_2 \\\\pm e_2$, because the difference might be explained by random fluctuations. In other words, you should really only bold results that are the best results at reasonable statistical significance. Currently, because of this issue, I think that the results throughout are misrepresented.\\n\\n### What Are STD and NLL in Table 2.1?\\n\\nThe premise of the paper is that you discard the predictive variance and instead produce calibrated predictive quantiles at one or multiple given confidence levels. This means that the predictions now consist of a mean and associated intervals. Therefore, the predictions are no longer probabilistic, so I really don't understand what the STD and NLL in Table 2 are! (For given a mean and an interval, how can you compute a probability?)\"},\n",
       " 'review_969': {'summary': 'This paper explores self supervised learning in the context of molecular representation, specifically based on persistent homology. The paper proposes an autoencoder to demonstrate the general representational power of PH and a contrastive-learning-based loss that can be applied to existing SSL approaches. The proposed approach is evaluated for molecular property predictions, showing improved representations and predictive power compared to baselines across different tasks. The claim is that the new loss function enhances baseline performance particularly with small datasets.',\n",
       "  'strengths': 'The paper is well written and the idea is novel and interesting. ',\n",
       "  'weaknesses': '- Given the technical nature of PH, and its origin in the domain of topological data analysis, a more mathematical foundation of the methods in the paper would be desired. '},\n",
       " 'review_970': {'summary': 'The paper proposes two approaches to leverage topological information (obtained from persistent homology) for molecular representation learning in a self-supervised setting. The first (TAE) uses an encoder-decoder architecture whose decoder aims to recover topological fingerprints. The second approach (TDL) consists of a contrastive loss based on the similarity between topological fingerprints. The latter is combined with existing contrastive learning methods. Experiments on linear probing and downstream prediction tasks show the efficacy of the proposals.\\n',\n",
       "  'strengths': '- Ablation studies: There is a substantial number of experiments and ablation studies.\\n- I like the simplicity of the proposed approach. \\n- Flexibility: TDL can be combined with most SSL approaches.',\n",
       "  'weaknesses': '- Overall, I believe the paper provides limited insight to support the proposals. Also, it does not discuss which structural information the proposed approach captures but not existing methods. From a conceptual level, we know that 1-WL GNNs cannot capture information even from simple homology (e.g., number of independent cycles of a graph). Thus, TAE has inherent limits/failures. In other words, the topological information we loose after pushing a graph through a GNN (which would be captured by TDA) cannot be recovered from GNN embeddings.\\n- Results on downstream tasks: Based on Table 4, the gains from TDL look marginal. The gain is less than one standard deviation from the base model for many datasets.\\n- Incorporation of domain knowledge: The claim that the proposal allows for incorporating domain knowledge seems overstated. The basis for such a claim comes from the choice of the filtration function. However, it is unclear how different filtration functions affect the topological embeddings --- thus, domain experts cannot leverage their knowledge to choose the filtration functions.\\n- TAE vs. TDL...which one should we use? The paper says that \"TAE, which we developed for comparison purposes only...\" (line 283). I am unsure whether TAE should be introduced as a main contribution or as a baseline (in the experiments) for assessing the feasibility of learning the topological fingerprints with a simple architecture. \\n'},\n",
       " 'review_971': {'summary': 'This paper proposes two molecular self-supervised learning methods, which consists of fingerprint autoencoder and topological distance contrastive learning. The insight behind this paper is to utilize topological fingerprint as a supervision in self-supervised learning. Thus, the authors reconstruct the topological fingerprint of a given molecule with autoencoder and filter out similar molecules in negative views in contrastive learning based on the similarity in topological distance space. The experimental results show that their method improves previous baselines in various downstream tasks.',\n",
       "  'strengths': '- The paper is well written and easy to understand.\\n\\n- The experimental results are comprehensive; the authors considers several setups such as linear probing and fine-tuning.',\n",
       "  'weaknesses': \"- Lack of Novelty: Excluding similar molecules from negative sample set is already considered in [1]. Conceptually, the difference of TDL and [1] is that TDL utilizes PH and [1] utilizes ECFP fingerprint (I know that the loss of [1] is based on augmented molecules, but I think this does not make big difference). This limits the novelty of this paper.\\n\\n- Table 1 does not support the effectiveness of proposed method: Correlating the distance in embedding space with the distance in corresponding PIs are not the main purpose of molecular representation learning. If PIs are indeed very important, then why should we use learned representation of proposed method? Can't we just utilize PIs as the molecular representation? In other words, Table 1 and Table 17 seem to contradict.\\n\\n- Insufficient rationalization of the usage of PIs: In molecular domain, ECFP fingerprint is a widely applied molecular representation since it reflect the substructure-wise molecular information. Why should we use PIs in molecular representation learning?\\n\\n- Flexibility of TDL: The authors insisted that TDL can be flexibly and efficient applied with any graph contrastive learning framework. However, any other two existing methods can be composed with each other to improve the performance. For example, ContextPred + GraphCL is possible and the flexibility is not the unique feature of TDL. \\n\\n- Table 4 seems weak: TDL (or TAE) combined with existing method does improve the overall performance. However, Mole-BERT and SEGA shows better performance than the proposed method.\\n\\n----Sorry for confusion. I added the reference.\\n\\n[1] Improving Molecular Contrastive Learning via Faulty Negative Mitigation and Decomposed Fragment Contrast, Wang et al., JCIM 2022\"},\n",
       " 'review_972': {'summary': 'Paper uses self-supervised learning tools for graph representation learning by facilitating topological data analysis (TDA) methods. In particular, for molecular representation learning, the authors use persistent homology outputs to improve the embeddings obtained by GNNs. They evaluated their model in molecular property prediction problem, and consistently got performance improvements.',\n",
       "  'strengths': \"GNNs and TDA are both very successful and completely different methods in graph representation learning. In the past years, there are several approaches to integrate these two methods effectively. With this aim, the paper proposes a new way to use TDA output to improve node embeddings in GNNs by using contrastive learning ideas. The idea is novel and has a lot of room for improvement.\\n\\nMolecular Representation Learning is a significant application area for graph representation learning. The authors applied their model in this domain, in particular, molecular property prediction. They obtain strong results on this important question.\\n\\nThe paper's experimental part and ML details are strong. The authors made an in-depth analysis of the model from various angles.\",\n",
       "  'weaknesses': 'The experimental results (Table 4) do not show significant improvements in several cases. \\n\\nThe results only report the performance of internal models. It would be nice to see the comparison with the SOTA results on these datasets. \\n\\nPH construction seems weak as it does not use clique complexes, and only uses nodes and edges in the filtration, i.e., the top dimension is set to be 1. This filtration are not commonly used in graphs as it reduces PH to only node and edge counting by using a simple Euler Characteristics argument. However, fortunately, this does not affect their performance in this setting since molecular graphs are planar and do not have loops of length 3, as all loops have length $\\\\geq 5$. The authors should add a note for nonexperts that for molecular graphs, this trivial filtration setting is equivalent to the traditional clique complex setting for sublevel filtration because of the special structures of molecular graphs (no cycle of length 3). For TDL, PI is a good choice, but for TAE, it looks weird. To be used in such a loss function, there are better stable PH vectorizations, e.g., Silhouette, landscape.'},\n",
       " 'review_973': {'summary': 'In this manuscript, the authors have developed an interesting self-supervised learning model, by the incorporation of persistent homology into contrastive learning module. More specifically, a special topological distance based contrastive loss is proposed. The model is novel, and the results are very promising. However, I have some concerns about the persistent homology analysis part.\\n',\n",
       "  'strengths': 'The authors have developed an interesting self-supervised learning model, by the incorporation of persistent homology into contrastive learning module. More specifically, a special topological distance based contrastive loss is proposed. The model is novel, and the results are very promising.',\n",
       "  'weaknesses': 'The PH model is not explained clearly. '},\n",
       " 'review_974': {'summary': 'The paper focuses on learning clean distributions from corrupted data. In the training diffusion model, the training dataset contains only highly-corrupted examples. They propose a training algorithm of restoration model by introducing additional measurement distortion.They also provide sampling methods and theoretical analysis. Experimental results show that their superior performance.',\n",
       "  'strengths': '* The problem of handling corrupted datasets is significant even in generative model learning. This paper could be seen as one that explores this directions.\\n* The paper is well-structured and easy to follow.\\n* The fact that a model which is trained by corrupted data does not memorize the training dataset, as supported by Figure 1 and Figure 4, is very important. This might be gives significant implications for various applications.',\n",
       "  'weaknesses': '* Sampling Process\\n  * It would be helpful to provide an algorithm or a detailed explanation of the sampling process from scratch.\\n  * Equations 3.3 and 3.4 describe how the sample at time $t$ is generated from sample at $t-\\\\Delta t$. It is necessary to explain how the evaluation of single networks allows the generation of images in the experiments.\\n\\n* Related work\\n  * It would be beneficial to include a discussion of previous research on dealing with incomplete datasets in generative models, such as [1, 2, 3, 4].\\n\\n[1] Li, S. C. X., Jiang, B., & Marlin, B. (2018, September). MisGAN: Learning from Incomplete Data with Generative Adversarial Networks. In International Conference on Learning Representations.\\n\\n[2] Mattei, P. A., & Frellsen, J. (2019, May). MIWAE: Deep generative modelling and imputation of incomplete data sets. In International Conference on Machine Learning (pp. 4413-4423). PMLR.\\n\\n[3] Ipsen, N. B., Mattei, P. A., & Frellsen, J. (2020, September). not-MIWAE: Deep Generative Modelling with Missing not at Random Data. In International Conference on Learning Representations.\\n\\n[4] Richardson, T. W., Wu, W., Lin, L., Xu, B., & Bernal, E. A. (2020). Mcflow: Monte carlo flow models for data imputation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 14205-14214).\\n\\n* Experiments\\n  * It would be beneficial to provide the FID results for Figure 5 to demonstrate the differences.\\n  * In addition to Figure 5, it would be valuable to compare the proposed model with existing generative models such as AmbientGAN in various experiments.\\n\\n* Presentation\\n  * It would be helpful to have better spacing between subfigures in Figure 2 to improve the clarity of the captions.\\n  * Proper citations are needed in the background section.\\n  * Figure 3 would be better placed within a paragraph rather than between paragraphs.'},\n",
       " 'review_975': {'summary': 'This paper describes a method to learn a denoising diffusion model only with corrupted data. This is an important problem in many areas of  applied science where there is no access to ground truth. Another important potential benefit of this method is to overcome memorization of the training images. The main idea in this method is described as introducing additional corruption and training on this doubly corrupt data. The authors describe a derivation to estimate conditional expectation of the uncorrupted image only using the corrupted data. They show (Table 1) that their method outperforms other methods in solving random inpainting problem. Also, the method is used to fine tune Deepfloyd IF on smaller samples. This result is used to show that the method overcomes memorization.',\n",
       "  'strengths': 'This work is motivated in two ways: learning the score of distribution of clean data with access to corrupted data, and avoiding memorization. These are both very important practical and theoretical topics which this work tries to address. The trick which is used to train the models (adding more corruption) is clever and the network achieves to learn to inpaint and denoise images (figure 7). As mentioned under weaknesses, I think the first goal is not fully achieved and the theoretical results seem incorrect and practical results seem to be constrained to specific types of corruption. However, the memorization results seem very impressive, although the memorization analysis is carries only for the fine tuned model.',\n",
       "  'weaknesses': \"There are a number of fundamental technical and conceptual flaws which need to be considered and fixed: \\n\\n1) The training setup was not clear in the text, but this is what I gathered: the target image during training is a corrupted image $Ax_0$, and the input is a noisy and more corrupted image $BAx_0 + \\\\sigma \\\\eta $. All throughout the corruptions are assumed to be random or block missing pixels. The network learns to remove the noise and inpaint pixels that are removed by B. At the test time, the network removes noise and also inpaint *all* pixels since it doesn't know which pixels are dropped due to A and which pixels are dropped due to B.\\nIf this is the training setup, please clarify in the text. If not, please describe what was the training setup. \\n\\n2) Equation (3), the objective after additional corruption, is the distance between the doubly corrupted image and the $\\\\textbf{clean}, x_0,$ image. The entire premise of the work is that clean image is not available so why is it assumed to be available during training? The objective should be the distance from $Ax_0$ instead. It needs to be clarified whether this is a typo or the authors actually used clean data, $x_0$, during training. \\n\\n2) If that is a typo and the target image during training is $Ax_0$ then after training is completed the network works as a denoiser plus inpainter. As a result, the Tweedie equation is not a good description of the output of this network anymore. That is, the output is not $E[x_0|x_t]$, where $x_t = x_0 + \\\\sigma_t \\\\eta$. So, this output cannot be used directly as an estimate of score in the diffusion model .\\n\\n3) To remedy the above mentioned problem, the authors propose eq 3.3 in which they claim to approximate the score, $E[x_0|x_t],$ with $E[x_0|\\\\tilde{A}x_t, \\\\tilde{A}]$. It is not at all clear what is the justification behind this approximation. Again, this expectation is a very different entity from the actual score, and it is not clear why direct use of it makes sense to estimate the score. This expectation is the solution for inverse problem given the forward measurement $A$, as apposed to the solution for mere denoising problem (i.e. the score). \\n\\n4) Additionally, two more terms are added to the update line in eq 3.4. The justification for this is described from line 166 to 175. It starts with $\\\\gamma_t$ going to zero when $t$ approaches zero. It is not clear as to why $\\\\gamma_t$ goes to zero when $t$ goes to zero. Please clarify this assumption. The reasoning that follows this assumption is also not clear and sounds ad hoc. Did you add these terms because the update line of eq 3.3 did not work in practice? What is the intuition or theory behind this choice? Please clarify both eq 3.3. (why did you estimate one expectation with another?) and eq 3.4 (why did you add two terms and why do they make sense?). \\n\\n5) The theory section needs at least a re-write because it is not clear what is the goal of this section. The section starts with the goal of proving that the optimal estimate of clean image given the corrupted image is equal to $E[x_0| Ax_t = y, A]$. It is not clear why the authors need to prove this, since this is a basic fact from Bayesian machine learning: the optimal estimation of corrupted data is the conditional mean of the predictive distribution (refer to textbooks like Bishop). The problem is that this expectation is not equal to the score, so theoretically it can't be used to estimate the score. Of course what is learned by this network is approximately the optimal reconstruction of $A(x+\\\\sigma \\\\eta)$, but as long as it is not the score, it is not theoretically valid to use it iteratively in a diffusion model. In a nutshell, the learned network is a denoiser/inpainter not a score estimator (i.e. pure denoiser). \\n\\n6) On top of the above mentioned issues, this network learns to reconstruct + denoise images only if $E_{A|\\\\tilde{A}}[A^TA]$ is full rank. This strong assumption requires a high level of randomness in the corruption which is not very common in many real-world applications. For example, if the ground truth images miss some information systematically (let's say they are all blurred) the network will not be able to reconstruct.\"},\n",
       " 'review_976': {'summary': 'In summary, the authors propose a diffusion-based framework that can learn unknown distributions from highly-corrupted samples, allowing the training of generative models without relying on clean training data. Their approach introduces additional measurement distortion and successfully predicts original corrupted images. The method is applicable to various corruption processes and achieves promising results on benchmark datasets.',\n",
       "  'strengths': '- The problem formulation by itself is interesting, and the proposed method is novel.\\n- The paper proposes a new and interesting domain of learning the image data distribution w/o access to the ground truth data samples.\\n- The paper is well written and easy to follow.\\n- The proposed training and sampling procedure is scalable and easy to incorporate into the current diffusion model framework.\\n- The authors attach the theory for the effectiveness of the proposed method.\\n- The proposed method only needs 1 NFE to produce comparable results.\\n- The method paves a way to alleviate the memorize issue of diffusion model.',\n",
       "  'weaknesses': '- From my perspective, I do not see significant weaknesses in this paper. \\n- One potential issue is the significant drop of FID when the model is trained with images corrupted with a large ratio of pixels. However, I think this should not be criticized.'},\n",
       " 'review_977': {'summary': \"This paper proposes to train diffusion models that can recover corrupted data without training on clean data. The key idea is, given a corruption matrix $A$ one can further sample a corruption matrix $\\\\tilde{A}$ given $A$ and the model learns to predict all the existing pixels. It is empirically shown that this trick ensures robustness against higher corruption levels and can restore data with better performance than those that's trained on clean data.\",\n",
       "  'strengths': '- The authors propose the first diffusion-based method that can restore data from corruption without training from clean data. \\n\\n- The method can reuse regular diffusion sampler without much modification. \\n\\n- It is guaranteed theoretically for the model to recover clean data with some rank assumptions.\\n\\n- The method alleviates the memorization issues of diffusion models by considering corruption schemes.',\n",
       "  'weaknesses': '- More exposition is needed on some details. What kind of $\\\\tilde{A}$ is used during inference? Is it necessary to sample using the same $\\\\delta$ during training? Do we fix a $\\\\tilde{A}$ for all sampling steps or resample each step? Does taking the expectation over multiple samples of such $\\\\tilde{A}$ work better?\\n\\n- The paper lacks implementation details. E.g. $h_\\\\theta(\\\\tilde{A}, \\\\tilde{A}x_t, t)$ explicitly depends on $\\\\tilde{A}$. How is this dependency implemented in practice? \\n\\n- Line 248 the authors forgot line break.\\n\\n- The authors only considered random masking corruption. However, there are many other types of linear corruption schemes. Does the method stay robust against other corruption such as Gaussian blur, etc.?\\n\\n- It would be great to analyze the effect of different sampling scheme for $\\\\tilde{A}$. How does FID change w.r.t $\\\\tilde{A}$ with increasing levels of further corruption? Is there a sweet spot for further corruption?\\n\\n- Why is there no comparison with AmbientGAN for Table 1, as it is an important baseline?'},\n",
       " 'review_978': {'summary': 'The work proposes a new algorithm for phase retrieval of sparse signals. \\nSpecifically, it focuses on a faster algorithm targeting quadratic convergence with the same number of measurements that are also needed in other algorithms. A proof of a quadratic convergence rate is established and experments illustrate the benefit also in experiments.',\n",
       "  'strengths': 'The paper focuses on aspects in phase retrieval that are often ignored. In particular, a proofable faster convergence rate has not been the focus of other works so far.\\nIt is well-written and easy to follow. \\nIt may well become a new standard for phase retrieval (or a starting point for other similar algorithms) if other researchers can reproduce the excellent performance.',\n",
       "  'weaknesses': 'The novelty is limited in the sense that second order algorithms are well known. However, adaptation and convergence proof for the phase retrieval setting are indeed novel and interesting.\\nIt is not clear why this subset of existing algorithms has been used for the experiments.'},\n",
       " 'review_979': {'summary': 'This paper focuses on the sparse phase retrieval problem and introduces an efficient second-order algorithm based on Newton‘s method. The algorithm aims to recover sparse signals and offers a quadratic convergence rate while maintaining the same per-iteration computational complexity as first-order methods. Experimental results demonstrate that the proposed algorithm outperforms popular first-order methods in terms of convergence rate and success rate in recovering the true sparse signal.',\n",
       "  'strengths': \"1. The authors' algorithm exhibits a lower complexity per iteration and a higher convergence rate compared to popular first-order methods. It is noteworthy that this is the first algorithm to establish a quadratic convergence rate.\\n2. The experimental results clearly illustrate the superiority of the proposed algorithm.\\n3. The paper effectively communicates the motivation behind the development of the second-order algorithm and highlights the complexity reduction achieved by restricting Newton's step to a subset of variables.\",\n",
       "  'weaknesses': \"1. The authors mention two prevalent loss functions but do not provide an explanation regarding the difference between these functions in the numerical experiments. It would be beneficial if the authors clearly explain the distinction between the two functions, particularly why the first function is used for initialization and the second one is used in Newton's update.\\n2. Equation 12 introduces J_{k+1}, which seems to be highly dependent on the choice of S_0, the initial support. This raises concerns about the algorithm's sensitivity to the initial point. It would be valuable for the authors to address this issue and discuss the potential impact of the initial point on the algorithm's performance. \\n3. Regarding the overall contribution, this paper focuses on approximating the objective function using a quadratic function, which can be limited. Also, this paper may be interested to only a few people attending this conference. \\n\\n\"},\n",
       " 'review_980': {'summary': 'The authors propose a second-order algorithm based in Newton projection for the sparse phase retrieval algorithm. The proposed algorithm is similar to Hard Thresholding Pursuit, where the free variables (i.e. the support) is first identified by a hard thresholding step, followed by an update on the free variables via a Newton projection step.\\nAs is standard for approaches to phase retrieval, the proposed method first performs an initialisation stage to ensure that the initial guess is sufficiently close to the true signal, then applies the proposed second-order method to obtain global convergence. There is are theoretical results proving quadratic convergence for the proposed method.',\n",
       "  'strengths': 'The performance show substantial gains compared to previous methods, moreover, it establishes a quadratic convergence rate.\\n',\n",
       "  'weaknesses': 'This work is incremental compared to HTP of [28]. HTP can already to be interpreted as a second order method. In terms of per-iteration complexity, the proposed method is the same as HTP. The comparison in ‘iteration complexity’ is somewhat unclear because the complexity given in HTP is for exact recovery, whereas the rate given in Table 1 for the proposed method is to obtain accuracy \\\\epsilon — is it just that [28] does not prove a quadratic rate, or do we expect [28] to have worse convergence behaviour in general? Moreover, [28] proves finite convergence for their method, does the proposed method also achieve finite convergence?\\n\\nIn terms of practical performance, the convergence plots show that the proposed method has faster convergence compared to HTP, but the performance for HTP here is worse than the performance reported in [28]. Perhaps it would be useful to replicate the exact experiments in [28] so that a clear comparison can be given? In general, it would be useful to have a discussion on the differences with HTP and an explanation as to why the performance is superior to HTP, given that both are second-order methods. I also had a look at the proof and it is again similar to the proof given in [28], so it would be useful again to have a discussion on the differences and novelty over [28].\\n'},\n",
       " 'review_981': {'summary': 'The authors introduce a novel second-order method for sparse phase retrieval. Compared to previous algorithms, it exhibits faster convergence and better recovery. The method leverages sparsity to reduce the size of the linear system that needs to be solved at each iteration in order to determine the approximate Newton direction (reduced from n^3 to s^3), and a second-order approximation of the intensity-based objective.',\n",
       "  'strengths': 'This paper presents strong results and a theoretical analysis of the algorithm in both the noisy and noise-free case.',\n",
       "  'weaknesses': 'The sample complexity required for initialization and refinement is sub-optimal. The experiments are only on toy data.'},\n",
       " 'review_982': {'summary': 'The paper addresses a major challenge in reinforcement learning: identifying which state-action pairs contribute to delayed future rewards. They propose a solution called \"Return Decomposition\" that redistributes rewards from observed sequences while maintaining policy invariance. Unlike other methods, their approach explicitly models state and action contributions from a causal perspective, making it interpretable.\\n\\nThe authors introduce a framework called \"Generative Return Decomposition (GRD)\" for optimizing policies in scenarios with delayed rewards. GRD identifies unobservable Markovian rewards and causal relationships in the generative process. Using this causal generative model, GRD creates a compact representation to train policies efficiently.\\n\\nThe paper proves the identifiability of the unobservable Markovian reward function and the underlying causal structure and causal models. Experimental results show that their method outperforms existing techniques, and visualizations demonstrate its interpretability. The source code for their approach is publicly available.',\n",
       "  'strengths': '  - The authors provide theoretical proof for the identifiability of the unobservable Markovian reward function and the underlying causal structure. This solidifies the theoretical foundation and robustness of the model.\\n  - The GRD method outperforms state-of-the-art methods in experimental results across a range of tasks. This demonstrates its practical effectiveness and application potential.\\n  - Visualization of the learned causal structure and decomposed rewards contributes to the interpretability aspect, a valued characteristic in contemporary machine learning.',\n",
       "  'weaknesses': \"I have no knowledge about reinforcement learning, and I don't understand why the system assigned me to review papers on this topic. Please disregard my review comments.\"},\n",
       " 'review_983': {'summary': \"The paper introduces a new algorithm called Generative Return Decomposition (GRD) for return decomposition with causal treatment. GRD addresses the problem by modeling causal relationships among variables, providing advantages over flat representations. It specifies each state and action as a combination of constituent variables and considers causal relationships within the system. The algorithm utilizes a factored representation similar to Factored MDP, enabling the formation and identification of the Markovian reward function based on causality. Unlike previous approaches, GRD uses a graphical representation to determine the contribution of each dimension of state and action to the Markovian reward. It also explains and models the observed delayed return as a causal effect of the unobserved Markovian reward sequence. The framework of GRD visualizes the causal relationships among environmental variables. The paper proves the identifiability of the underlying generative process and introduces a component-wise learning approach for recovering the causal generative process and redistributing rewards. The learned parameters provide a minimal sufficient representation for policy training, aiding in the effectiveness and stability of policy learning. The main contributions of the paper include the reformulation of return decomposition with a graphical representation, the introduction of GRD for learning the causal generative process, and empirical experiments demonstrating the method's superiority over state-of-the-art approaches in robot tasks with sparse rewards.\",\n",
       "  'strengths': '1 - Interpretability: Having interpretable reward redistribution is an advantage over non-interpretable methods. This can be used to diagnose the reason for failures policy optimization. \\n\\n2 - Reduces the state dimensionality: A very nice side effect of learning causal masks using a dynamics models is that a policy can be learned using very few features of the state. This leads to simpler policies, which could be more robust. \\n',\n",
       "  'weaknesses': '1 - Writing: The paper needs a lot of work in explaining the method. Especially section 4 and section 5.1. A figure showing how the causal masks are applied would be a good idea. I am willing to improve my score, if the method explanation is improved. \\n\\n2 - Experiments: The experiments include only Mujoco tasks. It would be interesting to see how the method behaves on delayed reward Atari environments like Bowling. \\n\\nMissing Related work: \\n[1] Modern hopfield networks for return decomposition for delayed rewards'},\n",
       " 'review_984': {'summary': 'Delayed reward in reinforcement learning is the major challenge in reinforcement learning. The return distribution technique is the direct way to resolve this issue while preserving policy. The existing works redistribute the returns in an uninterpretable manner. In this regard, this paper proposes a GRD which generates the Markovian rewards in delayed reward scenarios. GRD first checks the casual relations of state and actions and from a compact representation using causal generative model. The experiment results show that GRD outperforms the baselines and helps visualization. ',\n",
       "  'strengths': '* Experiment results seem promising.\\n',\n",
       "  'weaknesses': '* Explanation on line 345-352 is not sufficient and hard to understand. This experiment section is very important since authors insist that GRD give the interpretable structure of reward. \\n* The methods have to construct casual inference which is only possible when all the states are exactly defined. If the number of states explodes, the parameters to learn casual structure would explode. If states and actions are given, we can construct the casual structure without learning with parameters.\\n\\nMinor\\n* Equations are too messy and hard to understand. Use under bracket in equation 6. \\n* Notations are not familiar. It is hard to understand C^{\\\\cdot -> \\\\cdot}, d^a , d^s (?). The authors have to redefine all the variables step-by-step to improve the presentation of this paper.\\n* The arrow size is not consistent in Figure 2. The arrow to \\\\hat{r}_3 is narrower. Also, arrow directions which come from R are weird. '},\n",
       " 'review_985': {'summary': \"This study introduces a novel approach, termed Generative Return Decomposition (GRD), to address a key challenge in reinforcement learning: identifying the state-action pairs that contribute to future, delayed rewards. While many methods redistribute rewards in a non-transparent manner, GRD offers a clear return decomposition by explicitly modeling the contributions of states and actions from a causal perspective.\\n\\nGRD works by first recognizing unobservable Markovian rewards and causal relations in the data generation process. Then, it leverages these to create a compact representation for policy training over the agent's most favorable state-space subset. The researchers provide theoretical proof of the identifiability of the Markovian reward function and underlying causal structure and models. Experimental data also reveal GRD's superior performance and interpretability compared to other methods. However, some limitations exist due to the assumptions made, such as the stationary nature of the reward function, which may not be applicable in dynamic or online RL scenarios.\",\n",
       "  'strengths': 'The paper excels in presenting Generative Return Decomposition (GRD), an innovative method that improves interpretability in reinforcement learning. GRD successfully addresses the identification of impactful state-action pairs for future rewards. Its effectiveness is supported by both theoretical evidence and practical experiments, demonstrating its superior performance over other existing methods. Moreover, the paper demonstrates a high degree of clarity and coherence, enabling smooth comprehension. Additionally, the explicit description of assumptions contributes to a more profound comprehension of the inherent strengths and weaknesses of the study.',\n",
       "  'weaknesses': '- The quality of the text in Figure 1 could be improved by removing the shadow around the text. The same applies to Figure 2.\\n- Minor typos and errors that need to be edited for the next version of the paper. E.g. in line 172: \"provide\" -> \"provides\"\\n- In Section 5, only one policy is considered, which is SAC. How about having the experiments run based on another policy optimization algorithm? What would be the differences in performance and results?\\n- Regarding the last paragraph of Section 5, there are two possible scenarios to train the agent.\\n    - First, the generative model is learned while the policy is being updated, in an end-to-end paradigm.\\n    - Second, the generative model is first trained (and stays fixed thereafter), then the policy begins to be optimized.\\n\\n    In either case, how would that affect the policy training and performance? And how the insights from the GRD interpretations would be changed?\\n\\n- In the experiment section, the visualizations for the learned causal structure are only provided for Ant. Please provide the same type of analysis for other environments.\\n\\n- Considering Figure 4, having GRD, how the agent\\'s robustness and generalizability would be affected? For example, consider the case where there are some anomalies injected into the agent and environment interaction, more specifically changing some values from the state-space. If such anomalies target the features that are less important to the agent, then its performance should not be affected that much, right? If so, could you provide some results in this regard?'},\n",
       " 'review_986': {'summary': 'This paper proposes a novel algorithm for return decomposition with causal treatment. To do reward redistribution, GRD uses factored representations to model the Markovian reward function and dynamics function. ',\n",
       "  'strengths': 'The writing is clear and easy to follow. It is interesting to see the visualization in section 6.4, especially Fig. 4.',\n",
       "  'weaknesses': 'The technical contribution is somehow limited and the stronger experiments are expected.'},\n",
       " 'review_987': {'summary': 'The paper proposes a contrastive Chamfer distance to tackle the point cloud completion problem. The proposed CD loss maximizes the lower bound of the mutual information between two point cloud-based geometric surfaces, which leads to a more robust measurement of the similarities between two point clouds. On the other hand, the proposed CD loss is equivalent to adding a regularizer to the scaled CD, enabling a relaxed point alignment. Experiments of replacing CD with the proposed InfoCD in many state-of-the-art point completion models on MVP and some ShapeNet-based datasets show the good performance of the method. ',\n",
       "  'strengths': '- The introduction of the paper is concise and convincing. The authors have identified existing problems in the current research, and propose a solution based on these findings.\\n\\n- The authors have conducted extensive experiments for the point cloud completion task on various datasets and have used the proposed loss function in different state-of-the-art methods.\\n\\n- Although the analysis of the proposed CD loss is limited to point cloud completion tasks, the potential usage of the proposed loss function might be broader in various point cloud tasks.\\n',\n",
       "  'weaknesses': '- The authors claimed that the CD tends to have a hard constraint that points in the source point cloud should exactly lie on the points in the target point cloud. In contrast, InfoCD does not have this hard constraint. However, since usually the number of points in complete and partial point clouds is imbalanced, CD may not have this hard constraint. I wondered if a simple truncated CD would already solve this problem.\\n\\n- In Line 179, “with another assumption that the matched point pairs keep unchanged over iterations”, which may not always be true. Any intuitions or experimental validations?\\n\\n- Ablation study on $\\\\tau$, lr is incomplete and confusing. The limitation is discussed but lacks some quantitative results for the efficiency analysis. The authors are encouraged to discuss the efficiency of the proposed method compared to the original CD loss.\\n\\n- Table 1, 2, 3, 4 have inconsistent method comparisons. Could the authors provide more explanations?\\n\\n- The application of the proposed CD loss is limited to point cloud completion. However, a broader discussion of other point cloud tasks could be discussed.\\n'},\n",
       " 'review_988': {'summary': 'The paper introduces a novel loss function called InfoCD for point cloud completion tasks. InfoCD maximizes a lower bound of the mutual information, aiming to improve the quality of the completed point clouds. The experimental results presented in the paper demonstrate promising outcomes, indicating the effectiveness of the proposed approach.',\n",
       "  'strengths': '- Exploring the improved CD loss as a research direction for point cloud reconstruction shows promise and holds significant potential.\\n- The paper is well-written and effectively communicates its ideas, making it easy to comprehend and follow.\\n- The experimental setup and execution in the paper are adequate, resulting in promising outcomes and supporting the proposed approach.\\n- The visual results presented in the paper demonstrate good quality, further reinforcing the effectiveness of the proposed method.',\n",
       "  'weaknesses': '1.\\n\\nI observed a discrepancy between the equation presented in the paper and the implementation found in the provided demo code. This discrepancy, potentially caused by missing brackets and misrepresentation of the intended InfoCD, leads to a mismatch between the experimental results and the proposed idea. Consequently, concerns arise regarding the accuracy of the reported findings and the overall effectiveness of the proposed approach.\\n\\nI have reviewed the provided code in \\'loss_utils.py\\' and compared it to the equation mentioned in Section 3.2. I have identified a discrepancy in lines 197 and 198.\\n\\nIn the code, the calculation for l_infoCD(x_i, y_i) is implemented as \"- torch.log(torch.exp(-0.2 * d1) + 1e-7 / torch.sum(torch.exp(-0.2 * d1) + 1e-7,dim=-1).unsqueeze(-1))\". However, it appears that there are missing brackets in the expression. The correct calculation in Python should be \"- torch.log((torch.exp(-0.2 * d1) + 1e-7) / torch.sum(torch.exp(-0.2 * d1) + 1e-7,dim=-1).unsqueeze(-1))\" when the value of \\\\tau is equal to 5.\\n\\nTherefore, the issue lies in the missing brackets in the code implementation, which deviates from the equation provided in Section 3.2.\\n\\n2.\\n\\nBased on last question, I have concerns regarding the fairness of the comparison. Specifically, I would like to inquire whether both the baseline and the baseline + InfoCD models were trained and tested using identical settings, including training hyperparameters and the number of training epochs. My worry stems from the possibility that the observed improvement may be attributed to factors such as updates to the codebase, variations in training hyperparameters, or even longer training durations. This concern is amplified by the existence of a bug affecting the loss function in the provided code.'},\n",
       " 'review_989': {'summary': 'This paper proposed a novel metric to measure the similarity between two point sets, which is based on the basic formula of InfoNCE loss and the Chamfer distances. The key idea is to implicitly estimate the MI between the two point sets, and the way to achieve such target is to treat the distance of between points as a measurement of positive and negative samples.',\n",
       "  'strengths': '1. The reviewer is highly in favor of this paper, as this draft addresses a very fundamental problem in the deep learning of point cloud data, which is the similarity measurement between two point sets.  \\n2. The geometric based CD/EMD metric have been used for years in point cloud completion/reconstruction area, and the proposed InfoCD loss takes one step further to incorporate the idea of mutual information. The formulation of InfoCD, which is the combination of InfoNCE and Chamfer distance, technically makes sense and is very easy to follow.\\n3. The experiments are great, which covers most of the recent work and almost all popular benchmark in point cloud completion. The improvement achieved by InfoCD is non-trivial, and the generalization ability and the performance gain is also impressive.\\n4. Potential performance gain on a lot of related tasks such as 2D-3D reconstruction, unsupervised learning, shape generation can benefit from this work. The potential application of InfoCD may not be limited in point cloud completion task.\\n',\n",
       "  'weaknesses': '1. The convergence analysis is relatively weak, as only the experimental proves is provided instead of a more mathematical proof. This does not trouble the reviewer a lot, because the experimental result compared with CD loss looks very good and convincing.\\n2. It is a little bit pity that only the point cloud completion task is discussed. Maybe one or two applications on other tasks could provide more evidence on the generalization ability and the effectiveness of the InfoCD loss. For example, 2D-3D reconstruction.\\n\\nIn all, the reviewer does not see much weakness in this draft. It is a high-quality paper in terms of the point cloud completion research.\\n'},\n",
       " 'review_990': {'summary': 'This paper proposes a contrastive Chamfer distance loss, which introduces contrastive learning into the CD loss. Experiments are conducted on PCN, MVP, ShapeNet-55/34 and ShapeNet-Part datasets, and state-of-the-art results are achieved on these datasets.',\n",
       "  'strengths': '1. The idea seems reasonable and the overall performance is good.\\n2. The paper is overall well written and easy to follow.\\n',\n",
       "  'weaknesses': '1. Since the proposed loss is a supervised learning loss, I am a bit worried about the generalization ability of the proposed method in different datasets.'},\n",
       " 'review_991': {'summary': 'The paper proposes a contrastive chamfer distance (InfoCD) for point cloud completion. More specifically, the paper shows that minimizing InfoCD is equivalent to maximizing a lower bound of the mutual information between the underlying geometric surfaces, which plays a crucial role in generating and reconstructing detailed object shapes . To verify the effectiveness of the method, extensive experiments are conducted and promising results are obtained.',\n",
       "  'strengths': '1. The idea is interesting and the paper is well-organized.\\n2. Extensive experiments are conducted and performances are promising.',\n",
       "  'weaknesses': '1. Since the real-world scenario is a critical application in point cloud completion, how about the results on the real-world dataset such as KITTI shown in existing works? \\n2. The evaluation metric in Tab.1 should be L2-CD as well according to the PCN paper, since a square root is calculated in the evaluation code.\\n3. It is worth comparing the time and memory efficiency among different methods, especially when they are applied to real-world applications or mobile devices.\\n4. Inconsistency citation names for [25].'},\n",
       " 'review_992': {'summary': 'This paper introduces a method to combine sequential generative models, in this case GFlowNets, so as to create new distributions from base models. This is done by training classifiers that are then used to guide sampling. The method is tested on a simple grid and a molecular domain (emulating the problem of the paper that introduced GFlowNet), as well as on MNIST with diffusion.',\n",
       "  'strengths': 'The paper is moderately easy to read, although some of its results were not immediately clear to me so I spent quite some time doodling on paper to convince myself that the propositions were reasonable.\\n\\nWhat the paper proposes and seems to be able to achieve empirically is very interesting. Combining generative models in the ways shown here could be an amazing multiplier of large pretrained models.',\n",
       "  'weaknesses': 'Generally the paper is not making a good job of convincing the readers that the proposed method should work at the theory level, and that the effort of combining distributions by training a classifier is worth it (compared to retraining a generative model).'},\n",
       " 'review_993': {'summary': \"The current paper focuses on the challenge of composition generation from pretrained generative models, with a specific focus on GFlowNets and Diffusion models. In comparison to prior literature, two novel compositionality operations are introduced for generating samples that are simultaneously likely according to two generative models or likely per a subset and unlikely per the remaining models. This is a strict generalization of operations introduced in prior work on composition of energy-based models. Practically, the operations are instantiated via a framework motivated by classifier guidance in diffusion models. Experiments are conducted on a molecule generation application and a colored MNIST problem.\\n\\nRebuttals acknowledgment: I had a good view of the paper before rebuttals and the authors' response to my questions was fair. I continue to keep my score accordingly.\",\n",
       "  'strengths': 'I really like this work! The contributions are simple and straightforward, but very interesting. The formalization, generalized operations, and relation to classifier guidance were exciting to read through. The authors also appropriately acknowledge the limitations of their work, specifically the need for sufficiently strong component models.',\n",
       "  'weaknesses': '- My biggest apprehension is limited experimental investigation, which would raise the quality of this paper quite strongly in my opinion. I do not hold this to be a strong weakness though.'},\n",
       " 'review_994': {'summary': 'The paper proposes a method to compose multiple iterative generative models, i.e., either multiple GFlowNets or multiple diffusion models. The idea starts out with a mixture model over the generative models. Then, one can construct a categorical distribution over the generative models that tells us which model a sample originated from. By adapting classifier guidance to GFlowNets, the proposed method can compose multiple models in a way that allows both emphasizing or de-emphasizing specific models by treating the different generative models as different classes. On a diverse set of (toyish) experiments the method is shown to be effective for both GFlowNets and diffusion models.',\n",
       "  'strengths': 'The method is very interesting. In particular, the part where the question \"which model was this sampled from\" is treated as a classification task for the purpose of compositional generation.\\n\\nThe paper addresses a very important problem with high impact. \\n\\nThe presentation is easy to follow and the text is well-written.\\n\\n ',\n",
       "  'weaknesses': 'The experiments clearly demonstrate the effectiveness and versatility of the proposed method. Though, the experiments are limited to toyish settings and I believe more complicated settings would greatly enhance the impact of this work.'},\n",
       " 'review_995': {'summary': 'The paper studies the problem of composing independently trained generative processes of diffusion-based generative models and GFlowNets. The paper considers a setting where one has access to $m$ pre-trained samplers for $\\\\{p_i(x)\\\\}_{i=1}^m$, and the goal is to obtain a sampler which corresponds to a composition of these processes. Specifically, the authors consider two ways of composing the processes, namely harmonic mean: where the likelihood of the composition is high only where the component processes have high likelihood and contrast The authors frame this as sampling from a conditional distribution $p(x|y)$, where y is an observation which denotes the index of the process a sample is generated from. This results in a procedure analogous to classifier guidance which is popular in the diffusion literature. The authors show how the classifier guidance results in sampling from the desired composition. A critical component of this procedure is learning the classifier $p(y|s)$, for which the authors propose a MLE based procedure using trajectories from the base model. The authors first validate their approach on some synthetic tasks on a 2D grid, followed by experiments on small molecule generation with GFlowNets and colored MNIST with diffusion. ',\n",
       "  'strengths': '* The paper studies an interesting question - which is relevant to the community. In particular, methods to leverage pre-trained models for various downstream tasks are becoming increasingly important with the growing adoption of pre-trained models for various domains. \\n* Since similar classifier guidance approaches have been studied extensively in the literature on diffusion models, the novelty is relatively limited. Nonetheless, there are several technical aspects of the approach such as the classifier training scheme that are novel (to the best of my knowledge). \\n* The proposed method is relatively simple conceptually, and in terms of implementation. \\n* The experiments are well designed, and the results are quite promising, albeit with some caveats I mention below. \\n* The paper overall is quite well written and easy to follow. I also appreciate the authors including the code with the submission. ',\n",
       "  'weaknesses': '* As the authors discuss in Section 3, their theoretical analysis is analogous to classifier guidance in diffusion models. On the other hand, [1] establishes equivalence between GFlowNets and diffusion models. As a results, it seems to me that the insights provided by the theoretical analysis aren’t particularly novel even though the path to achieving them was different (which could be seen as useful on it’s own)\\n* The experiments on diffusion are limited to a simple coloured MNIST task, with no baselines from the classifier-guided diffusion literature. \\n* The central aspect of the approach is learning the classifiers, however there is no analysis on the classifiers - e.g. how accurate are the classifiers? what is the effect of the classifier performance on the results of the composition? How does the training of the classifier compare to simply training a GFlowNet from scratch in terms of runtime? \\n* (Minor) A simple baseline that is missing in the experiments is training a GFlowNet with the appropriate composition from scratch. \\n\\n[1] Unifying Generative Models with GFlowNets and Beyond. Zhang et al. 2022. arXiv:2209.02606'},\n",
       " 'review_996': {'summary': 'The paper describes a way in which, given sequential samplers from multiple probability distributions, a combination of the samplers can be used to sample from a composition of the distributions. To be precise, the sequential samplers are either GFlowNets or diffusion models, the combination of samplers is a weighted combination of action distributions at each intermediate sampling step, and the composition of distributions can be defined by simple soft conjunction and set difference operators. This is demonstrated in toy illustratory experiments and multiobjective molecule synthesis (GFlowNet) and MNIST with digit class and colour attributes (diffusion).',\n",
       "  'strengths': 'From the perspective of someone who works on both GFlowNets and diffusion models, this is a very well-written paper. \\n- The text reads naturally and the right amount of detail is given in the main text. There is a good choice of illustrations to help the reader.\\n- The composition of multiple GFlowNets has not been considered before and could be useful, especially in multiobjective problems. The unifying perspective on classifier guidance is also an advantage (but see below).\\n- Code is provided, a nice addition to the paper.\\n- I checked the GFlowNet-related math and believe it to be sound.',\n",
       "  'weaknesses': '- Line 234, 255, 634, 643, maybe others: typo \"GFLowNet\"\\n- It would be good to explain why / state as a subclaim that (8) is a policy (i.e., sums to 1 over $s\\'$), which is not actually obvious from the definition. \\n  - It relies on the fact that $p(y|s) = \\\\sum_{s\\'}p(y|s\\')p(s\\'|s)$, which follows from conditional independence of $y$ (a function of the final state) and $s$ given $s\\'$. That is a consequence of the Markov property in GFlowNets. A note should be made about this.\\n  - The equality may not actually hold in practice, when $p(y|-)$ is a trained classifier, so (8) may not exactly sum to 1. What do you do in this case (in the experiments)?\\n- The results on molecule generation raise a few questions:\\n  - The reward exponent was set to $\\\\beta=32$ or $\\\\beta=96$, which is far larger than in past work, where it was at most 16. Why was such a choice made? This is suspicious, since convergence and mode collapse issues worsen at low temperatures.\\n  - Related, with such high exponents, one wonders about mode coverage in the learned distributions. Have you considered the in-sample diversity of the generated molecules (e.g., as measured by average Tanimoto similarity or  diverse top-k metrics)?\\n- On related work:\\n  - There is no substantial discussion of related work in the main text, even though there is a large body of work on compositional generation and classifier guidance with diffusion models (e.g., the many papers cited in the second paragraph of the introduction).\\n  - In the Appendix, the connection with [23] is discussed. The proposed method can easily turn a collection of classifiers for different objectives into a classifier for any convex combination of the objectives. It would be interesting to empirically compare this with conditioning of the model on the linear scalarization weights used in [23].\\n  - The paper would be stronger if more explicit unifying connections were made between guidance in diffusion models and in GFlowNets. Note that diffusion models in a fixed time discretization are actually GFlowNets of a certain structure (cf. \"A theory of continuous generative flow networks\" [arXiv:2301.12594, ICML 2023] and \"Unifying generative models with GFlowNets and beyond\" [arXiv:2209.02606]). Classifier guidance using the gradient of $p_t(y|x_t)$ should be the continuous-time limit of equation (8).'},\n",
       " 'review_997': {'summary': 'This paper proposes an approach of Compositional Sculpting for iterative generative models, including GFlowNets and defusion models.\\nThe model uses classifier guidance to sample from the target posterior distribution composed of pre-trained base models.\\nThe paper also proposes a training algorithm for the classifier.\\nThe approach is validated by empirical analyses of an image dataset and molecular generation.',\n",
       "  'strengths': '- The method is general enough for different GFlowNets and defusion models.\\n\\n- The empirical results validate the method.',\n",
       "  'weaknesses': '(1) It would be convincing to have more complicated experiments, especially for image data.\\nColored MNIST might be too small and simple.\\n\\n(2) More clarity might be helpful for the following points.\\n\\n(2A) What is the model in line 193? \"Under the model we have introduced the variables y_1, ... y_n are dependent given a state s in S, but, are independent given a terminal state x in X.\"\\n\\n(2B) I am confused while reading line 209. The sampling scheme is 1) sample y from its prior 2) sample tau given y. But the following sentence says sampling y given tau.'},\n",
       " 'review_998': {'summary': 'In natural tasks that share input stimuli across participants, the cognitive states or neural responses of different participants might undergo approximately synchronous but slightly jittered dynamics. At the same time, the distribution of neural signals are not exactly consistent across participants at voxels with the same spatial coordinates. These two problems were addressed by two approaches separately by event segmentation and functional alignment. This paper proposes a new approach H-HMM that combines the advantage of both methods. It performed simulation to evaluate its performance and tested it on an fMRI datasets of college students watching the same series of lectures in computer science. The performance appears impressive and achieves what the model is designed for. Further, the paper also demonstrated alignment between fMRI data and semantic features of contents in the lecture.\\n\\n',\n",
       "  'strengths': '* Simultaneous achieving temporal and spatial alignment was not done before. \\n* Comprehensive evaluation of the method is performed on both simulated and real data and showing good performance.\\n* The illustration is generally clear and easy to understand.\\n* The approach holds promise for a wide range of application and should be a significant contribution to the field',\n",
       "  'weaknesses': \"* I think there is a mismatch between the data size of simulated data and that of fMRI data or semantic features, making it a bit difficult to evaluate the expected performance of this method in general. The simulated data have only 5 voxels/features, which is rarely observed in the domain where this algorithm should be applied. The described numbers also do not match up: 4 events with 9-12 time points per event give rise to fewer than 48 time points, yet it is said that the simulated data have 60 time points. It is also strange that the event is represented by binary patterns. Maybe this is just for the purpose of easy visualization but I worry that the performance might depend on these unrealistic properties in the simulation. Doing it with similar property as would be expected for the fMRI data should be more convincing. If you encounter issue that the actual fMRI data have lower effective dimensionality due to smoothness, it may be simulated by spatial Gaussian process or other ways but I don't think it is justifiable to start with low-dimensional data, as you did not perform PCA on fMRI data to get similar dimensionality before application of the algorithm.\\n* The description for the update of group-level G, starting from line 122, is a bit confusing. After the stacking, what is the dimensionality of the matrix? I assume the stacked data have a total number of elements as the number of events * (total number of voxels+ semantic features) * D (since E is in the D-dimensional space). If your stacked data have two dimensions (which I assume is the case since you can do PCA on it), which of the two dimensions (after explaining their size) do you treat as data features and which do you treat as samples in the definition of PCA? After projecting the stacked data for each event into D-dimensional PC space, do you need to do anything you do to get G (which is of the shape of number of events * D)? \"},\n",
       " 'review_999': {'summary': 'UPDATE:\\n\\nI have raised my score and now support acceptance of this paper. I believe it will be a good contribution to the conference.\\n\\n-----------------------------\\nThe authors propose an extension for an HMM model proposed by Baldassano and colleagues to align interindividually different brain responses in both space and time to analyze naturalistic stimulation settings. They test their approach through simulations and on an empirical dataset of 19 participants, who watched a series of 5 computer science lectures. They show that their model is robust to a number of noise levels in the simulation analysis. In the empirical analysis, the model appears to learn a meaningful latent space (concrete vs abstract and future-oriented vs present tense descriptions) and outperforms a null model.',\n",
       "  'strengths': '- The research problem addressed is an interesting and timely problem, namely how to compare spatially and temporally heterogeneous responses across participants\\n- The paper is largely well-written\\n',\n",
       "  'weaknesses': '- The sample size is small\\n- The approach is not compared to other state-of-the-art models, rather the authors compare it to a null model, which is poorly explained\\n- The authors do not provide analysis code or sufficient detail to reproduce their results'},\n",
       " 'review_1000': {'summary': 'The authors develop a method to identify and align events in the brain and external stimulus. They iteratively fit a Hidden Markov Model to find the times of events, and spatial characteristics of those events.',\n",
       "  'strengths': 'Originality: This work is a minor update to past work, by accounting for time shifting as well.\\nQuality: The authors use careful validation with simulated data, and careful cross-validation in real data.\\nClarity: The paper is largely well written.\\nSignificance: The main problem of comparing neural activity across subjects and referencing those patterns to interpretable stimulus-driven semantics is an important one, especially as the amount of data in the field continues to grow.',\n",
       "  'weaknesses': 'The events in this paper refer to extended time periods. Events are often described as instants in time, rather than extended periods. It would be helpful to carefully articulate the definition of events to prevent misunderstandings.\\n\\nThe authors make quite strong assumptions, despite protestations that their method is very general. In particular, I am skeptical about the \"constant events\" in the time course, and about the linear embedding of the semantic content.\\n\\nThe authors only test out a narrow range of timing differences (25%), which leads me toward greater skepticism about the generalizality of the author\\'s results.\\n\\nSuggestion: It would be useful to test this method in a simulation with a deliberately time-warped movie, to check whether the method can recover simulated data can recover the true timercourse.\\nMinor: Figure 2 caption has a typo: should read \"simulated data\", not \"stimulated data\".\\n'},\n",
       " ...}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reviews(\"Conditional Matrix Flows for Gaussian Graphical Models\", \"NeurIPS\", 2023, reply_type=\"Official_Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fbfaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:26<00:00, 39.13it/s]\n"
     ]
    }
   ],
   "source": [
    "def norm(s):\n",
    "    return str(s).strip().lower()\n",
    "\n",
    "def get_title(sub):\n",
    "    t = sub.content.get(\"title\")\n",
    "    return t.get(\"value\") if isinstance(t, dict) else t\n",
    "\n",
    "def unwrap(v):\n",
    "    return v.get(\"value\") if isinstance(v, dict) else v\n",
    "\n",
    "def get_reviews_fast(title, conference, year, reply_type=\"Official_Review\"):\n",
    "    venue_id = f\"{conference}.cc/{year}/Conference\"\n",
    "    target_title = norm(title)\n",
    "    reviews = {}\n",
    "\n",
    "    # --- Try server-side filter by title (fastest) ---\n",
    "    try:\n",
    "        submissions = client.get_all_notes(\n",
    "            invitation=f\"{venue_id}/-/{submission_name}\",\n",
    "            content={\"title\": title},     # server-side filter\n",
    "            details=\"replies\",\n",
    "            limit=1\n",
    "        )\n",
    "    except Exception:\n",
    "        submissions = []\n",
    "\n",
    "    # --- Fallback: scan but break at first match ---\n",
    "    if not submissions:\n",
    "        submissions = client_v2.get_all_notes(\n",
    "            invitation=f\"{venue_id}/-/{submission_name}\",\n",
    "            details=\"replies\"\n",
    "        )\n",
    "\n",
    "    for submission in submissions:\n",
    "        sub_title = get_title(submission)\n",
    "        if norm(sub_title) != target_title:\n",
    "            # only needed in fallback mode\n",
    "            continue\n",
    "\n",
    "        for i, reply in enumerate(submission.details.get(\"replies\", []), start=1):\n",
    "            if any(inv.endswith(reply_type) for inv in reply.get(\"invitations\", [])):\n",
    "                content = reply.get(\"content\", {})\n",
    "                reviews[f\"review_{i}\"] = {\n",
    "                    \"summary\": unwrap(content.get(\"summary\")),\n",
    "                    \"strengths\": unwrap(content.get(\"strengths\")),\n",
    "                    \"weaknesses\": unwrap(content.get(\"weaknesses\")),\n",
    "                }\n",
    "\n",
    "        break  # stop after the matching paper\n",
    "\n",
    "    return reviews\n",
    "gg = get_reviews_fast(\"Conditional Matrix Flows for Gaussian Graphical Models\", \"NeurIPS\", 2023, reply_type=\"Official_Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bf39c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review_8': {'summary': 'This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets.',\n",
       "  'strengths': 'Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \\n\\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated.',\n",
       "  'weaknesses': 'Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost.'},\n",
       " 'review_9': {'summary': 'This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \\nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\\\geq1}$ is used).',\n",
       "  'strengths': '1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \\n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\\n3. Using sub-l1 norm is suitable for structure learning. \\n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \\n5. The paper is well-written, and the relevant work is sufficiently discussed.    \\n6. Due to its flexibility, the proposed method has the potential of having a large impact.',\n",
       "  'weaknesses': 'Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \\n\\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \\n\\nMinor suggestion: \\n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \\n2. Fix minor typos e.g. the end sentence period in line 214.'},\n",
       " 'review_10': {'summary': 'This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution.',\n",
       "  'strengths': '- Well written paper.\\n\\n        - Illustrative toy experiments.',\n",
       "  'weaknesses': '- The proposed method is a combination of already known techniques.\\n\\n        - The experimental section is weak as only a single real problem is considered.\\n\\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\\n\\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\\n\\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros.'},\n",
       " 'review_11': {'summary': 'This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way.',\n",
       "  'strengths': \"The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea.\",\n",
       "  'weaknesses': \"The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso.\"}}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecf6429e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Biologically-inspired adaptive learning in the Hopfield-network based self-optimization model',\n",
       " 'Flexible Attention-Based Multi-Policy Fusion for Efficient Deep Reinforcement Learning',\n",
       " 'Conditional Matrix Flows for Gaussian Graphical Models',\n",
       " 'Matrix Compression via Randomized Low Rank and Low Precision Factorization',\n",
       " 'Color Equivariant Convolutional Networks',\n",
       " 'VideoComposer: Compositional Video Synthesis with Motion Controllability',\n",
       " 'SiT Dataset: Socially Interactive Pedestrian Trajectory Dataset for Social Navigation Robots',\n",
       " 'Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger',\n",
       " 'A Theoretical Analysis of the Test Error of Finite-Rank Kernel Ridge Regression',\n",
       " 'Comparing Optimization Targets for Contrast-Consistent Search',\n",
       " 'Fine-Tuning Language Models with Just Forward Passes',\n",
       " 'PIXIU: A Comprehensive Benchmark, Instruction Dataset and Large Language Model for Finance',\n",
       " 'FLAb: Benchmarking deep learning methods for antibody fitness prediction',\n",
       " 'Sparse Parameterization for Epitomic Dataset Distillation',\n",
       " 'Truly Scale-Equivariant Deep Nets with Fourier Layers']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nips_2023_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "69ce49b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:54<00:00, 29.57it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:15<00:00, 44.97it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:36<00:00, 35.26it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [03:03<00:00, 18.46it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:21<00:00, 41.85it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:14<00:00, 45.78it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:07<00:00, 50.07it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:22<00:00, 40.94it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:06<00:00, 51.01it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:28<00:00, 38.41it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:08<00:00, 49.31it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:05<00:00, 52.01it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:27<00:00, 38.81it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:22<00:00, 41.33it/s]\n",
      "Getting V2 Notes: 100%|█████████▉| 3391/3395 [01:10<00:00, 48.11it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Biologically-inspired adaptive learning in the Hopfield-network based self-optimization model': {},\n",
       " 'Flexible Attention-Based Multi-Policy Fusion for Efficient Deep Reinforcement Learning': {'review_20': {'summary': 'This paper defines the Knowledge-Grounded RL setting, a general RL setting for integrating knowledge (in the form of policies) into a policy to learn new tasks efficiently. Essentially this setting is similar to the MDP setting except that the agent is also given a set of knowledge policies to utilize. The paper also introduces a system/architecture within this KGRL setting, called Knowledge-Inclusive Attention Network (KIAN). The aim is to improve RL that is grounded on external knowledge policies. The paper outlines five desirable human-like properties they desire in their agents: knowledge-acquirable, sample-efficient, generalizable, compositional, and incremental. Moreover, they formally define these so that they are measurable within the KGRL setting (e.g., for evaluating algorithms on these dimensions).\\n\\nWhile previous methods typically intertwine knowledge representation and knowledge-fusion, thereby restricting their ability to adapt to numbers of policies, losing flexibility. KIAN is developed more flexibility, separating the knowledge representation and knowledge fusion.\\n\\nKIAN consists of three components: a policy that learns a strategy (similar to a normal policy) called the internal, embeddings that represent the given knowledge (or external) policies, a query that performs attentive action prediction to fuse the internal and external policies.\\n\\nKIAN also solves other issues that can occur in entropy-regularized KGRL. Entropy-regularized RL is common, but the authors show that in the KGRL setting issues can arise through entropy regularization where only a select few policies are selected, counterproductively reducing diversity in policy usage. The authors show that in the KGRL setting the agent will pay more attention to the policy with large entropy and in continuous control, will rely on the internal policy extensively. The paper introduces modifications so that this does not occur in KIAN.\\n\\nThe authors show results on both MiniGrid and robotics tasks and demonstrate sample efficiency, generalizability, as well as compositional and incremental learning.\\n',\n",
       "   'strengths': 'The paper is mostly well-written and well-explained.\\n\\nThe method makes sense, and is a well-thought out architecture. \\n\\nI like how the authors address the entropy imbalance problem.\\n\\nI like that the authors define and quantify the behaviors they would like in the agent.\\n\\nThe results do seem to demonstrate their method is effective.\\n',\n",
       "   'weaknesses': 'While I think the experiments are good, with appropriate baselines and good environments to test the agent’s capabilities. I am concerned about statistical significance. In particular, only 5 seeds are run, and the performance benefit in many cases is minimal, which may quite possibly be attributed to randomness. While I do believe the method outperforms the baselines, I cannot say so with a lot of confidence to merit inclusion at NeurIPS. If the authors can run more seeds, especially given the large variance, it would dramatically improve their results.\\n\\n\\nQualms:\\nKGRL is consistently referred to as an RL framework, which it is, but the connotation can be misconstrued as being a framework “for” RL, implying it is a solution method for RL problems. I would recommend calling it a “setting” rather than a framework. Indeed, I was confused temporarily as a reader, especially when KGRL is stated as being “introduced” by this paper (as opposed to “described” or “outlined”). \\n\\n\\nNits\\nTypo Line 345: “border” should be: “broader”\\n'},\n",
       "  'review_21': {'summary': 'Humans can learn by aggregating external knowledge from others’ policies of attempting a task. While prior studies in RL have incorporated external knowledge policies for sample efficiency,  there still remains the generalization problem to be solved that agents have difficulties to perform arbitrary combinations and replacements of external policies.\\nThe authors propose a new actor architecture for Knowledge-Grounded RL (KGRL),  Knowledge-Inclusive Attention Network (KIAN), which allows free knowledge rearrangement due to embedding-based attentive action prediction.  KIAN addresses entropy imbalance as well. The authors demonstrate in experiments that KIAN outperforms other methods incorporating external knowledge policies under different environmental setups.',\n",
       "   'strengths': 'The authors clearly define the problem as how RL can be grounded on any given set of external knowledge policies to achieve knowledge-acquirable, sample-efficient, generalizable, compositional, and incremental properties.\\nThe proposed method of KIAN is clearly described. They use knowledge keys and the query performs an attention operation to determine how an agent integrates all policies. \\nThe solution of the entropy imbalance issues when integrating external policies are proposed as well.',\n",
       "   'weaknesses': 'Generally this work has many related works but is tackling the unique challenge problem of fusing knowledge policies with different state and action spaces.\\nLimitations of the proposed method is not clear based on the experimental results.'},\n",
       "  'review_22': {'summary': 'The authors of this work introduce Knowledge-Grounded RL (KGRL), an RL framework that combines multiple knowledge policies to achieve human-like efficiency and flexibility in learning. They propose a new actor architecture called Knowledge-Inclusive Attention Network (KIAN) that enables arbitrary combinations and replacements of external policies through embedding-based attentive action prediction. KIAN also addresses entropy imbalance, a challenge in KGRL, addressing exploration in the environment.',\n",
       "   'strengths': 'Firstly, the paper addresses a relevant and interesting problem in the field of reinforcement learning (RL) by improving sample efficiency from arbitrary external policies and enabling knowledge transfer skills. \\nFurthermore, the paper is a well-written work that effectively conveys the ideas and findings in a clear and concise manner. The authors demonstrate excellent writing skills, employing appropriate terminology and organizing the content in a manner that enhances readability and comprehensibility.\\nIn addition, the paper effectively establishes the motivation and position of the study in the existing literature. The authors articulate the significance and relevance of the research problem, demonstrating a strong understanding of the field. They situate their work within the broader scholarly context, highlighting how their study fills a gap in knowledge or builds upon prior research.\\nThe methodology employed in the research is clearly described, allowing readers to understand and replicate the study. The authors provide a detailed and comprehensive explanation of the experimental and theoretical approach used, supported by well-designed figures and diagrams. These visual aids enhance the understanding of the methods employed and facilitate better comprehension of the research. Lastly, the authors provide solid mathematical understanding for their proposed method. \\n\\nCollectively, these strengths highlight the quality of the paper. ts focus on addressing a relevant and interesting problem, combined with its well-written content, clear methodology, positioning in the literature, and mathematical rigor, make it an intersting contribution.',\n",
       "   'weaknesses': \"The paper has one notable weakness that should be addressed to enhance the overall quality. The evaluation presented in the paper is quite limited. The results obtained for the OpenAI robotics task only offer a slight support for the proposed method. The authors should consider expanding the evaluation to provide a more comprehensive assessment of the proposed method's performance.\\nAdditionally, the use of only 3 or 5 seeds in the experiments may be insufficient, especially when considering the large error bars observed in some models. The authors should consider increasing the number of seeds to improve the statistical robustness of the results.\\nMoreover, the paper lacks clarity regarding the error bars shown in the plots. It is not explicitly stated what these error bars represent, which hinders the interpretation and understanding of the presented data.\\nLastly, the paper would greatly benefit from conducting ablation studies to investigate the effects of various factors on the proposed method's performance. Specifically, the authors could consider performing ablation studies on \\n- the influence and distribution of attention/weights of actors, \\n- the impact of random/irrelevant policies in $\\\\mathcal{G}$,\\n- the impact of the (near) optimal policy in $\\\\mathcal{G}$, \\n- the impact of a larger set of knowledge policies $\\\\mathcal{G}$, \\n- the effects of different types of knowledge policies, \\n- and an investigation of the mentioned entropy balance issue, that the authors specifically address in their method.\\nThese ablation studies would provide valuable insights into the individual contributions and impacts of these factors on the overall approach.\\n\\nOverall, addressing these weaknesses would significantly improve the research paper, clarifying important aspects such as error bars, conducting relevant ablation studies, ensuring consistency in reporting variances, and strengthening the empirical evidence for the proposed method.\\n\\n### Minor\\n- I assume ori-KIAN is KIAN with the original $\\\\mathcal{G}$, this should be mentioned in the text. \\n- l.314 mentions less variance, but tables do not show variances for individual experiments\"},\n",
       "  'review_23': {'summary': 'This paper introduces KIAN, a method for leveraging multiple sub-optimal policies to solve reinforcement learning tasks. The paper starts out by introducing a new Knowledge-Grounded MDP, which adds a set of external knowledge policies to the traditional MDP framework. \\n\\nTo leverage these external knowledge policies, KIAN learns an embedding for each knowledge policy (including an inner knowledge policy for the current agent). Then at each step, the current state is mapped to a query embedding that can be used to find the policy that is best equipped to take an action at that timestep.',\n",
       "   'strengths': '* The paper is structured well and is easy to read.\\n* The authors demonstrated great attention to detail by motivating the theorems and equations with intuition before defining them concretely.\\n*  The paper is very technically sound.',\n",
       "   'weaknesses': '* > In such a case, whenever the knowledge set is updated by adding or replacing policies, prior methods require relearning the entire multi-policy fusion process, even if the current task is similar to the previous one. This is because their designs of knowledge representations are intertwined with the knowledge-fusing mechanism, which restricts the number of policies in the knowledge set from being changed.\\n\\n    * It would be good to point to specific prior works that suffer from this problem so the reader can build intuition.\\n\\n* There are no visualizations of the tasks used for evaluation. Adding pictures of the environments would help readers understand what the agent needs to do.'}},\n",
       " 'Conditional Matrix Flows for Gaussian Graphical Models': {'review_8': {'summary': 'This paper concerns the estimation of precision matrix under $l_p$ norm sparcity penal. The solution is a variational inference through normalizing flow, which is a function of shrinkage parameter $\\\\lambda$ and non-negative norm parameter $p$. It allows for straightforward computation of solution paths for the intervals of $\\\\lambda$ and $p$, and was empirically evaluated on two relatively small data sets.',\n",
       "   'strengths': 'Framework for GGM estimation based on conditional normalizing flows, indeed appears novel. Supporting math seems solid. \\n\\nUsing simulated annealing algorithm to recover a path of solutions for varying $\\\\lambda$ and $p$ is useful, in particular for the case of $p$, as in case of $\\\\lambda$ it was fairly straightforward to perform it with other methods too. I am just wondering how costly and scalable it is under the new framework, an empirical/theoretical analysis would be appreciated.',\n",
       "   'weaknesses': 'Empirical evaluation appears limited. It does not contain comparison with other (e.g. frequentist) approaches to derive the solution paths. Both in terms of estimation accuracy and in terms of computational cost.'},\n",
       "  'review_9': {'summary': 'This paper targets the structure learning problem in Gaussian Graphical Models via (Normalising) Flow-based Variational approximation of the elements of weight metrics that correspond to the Gaussian Bayesian network. \\nThey use sub-l1 pseudo norms to penalize dense precision metrics (which correspond to graphs with numerous links) without imposing an extra high penalty for large non-zero values (which typically occurs if $l_{\\\\geq1}$ is used).',\n",
       "   'strengths': '1. Up to my knowledge, this is the first time flows are applied to the space of positive definite matrices. \\n2. The proposed approach is flexible meaning the class of applicable prior and likelihood functions is quite large.\\n3. Using sub-l1 norm is suitable for structure learning. \\n4. The proposed algorithm is mathematically sound (as far as I can follow) and is quite interesting. \\n5. The paper is well-written, and the relevant work is sufficiently discussed.    \\n6. Due to its flexibility, the proposed method has the potential of having a large impact.',\n",
       "   'weaknesses': 'Due to the factors mentioned in the previous section, I find this work impressive and beautiful. However, unfortunately, the carried out experiments are minimal. Most notably, the algorithm is compared to no alternative work (neither in the main paper nor in the supplementary material). With no quantitative comparisons, it is impossible to evaluate the performance of the proposed algorithm compared to the existing methods. \\n\\nNOTE: In the Rebuttal, some experiments are carried out (though the code is still not accessible).    \\n\\nMinor suggestion: \\n1. Though it is clear in the context, I suggest that the authors do not use the same letter \"p\" (with the same font) for both probability density and norm parameter.  \\n2. Fix minor typos e.g. the end sentence period in line 214.'},\n",
       "  'review_10': {'summary': 'This paper proposes a method that can be used to infer conditional independencies in a Gaussian model. These conditional independencies are related to zeros in the precision matrix. Typically, sparse enforcing norms are used to estimate the precision matrix while enforcing zeros in the elements outside of the diagonal. In this paper a Bayesian approach is considered. For this a pseudo-distribution for the data is considered by taking the exponential to the p-norm. The method is trained via variational inference combined with normalizing flows to increase the accuracy of the posterior approximation. The variational distribution is tuned via simulated annealing and a temperature parameter allows to interpolate between the Bayesian and the Map solution.',\n",
       "   'strengths': '- Well written paper.\\n\\n        - Illustrative toy experiments.',\n",
       "   'weaknesses': '- The proposed method is a combination of already known techniques.\\n\\n        - The experimental section is weak as only a single real problem is considered.\\n\\n        - Although the proposed method is a generalization of several known techniques, I have found in the experimental section a lack of comparisons with other related methods.\\n\\n        My main point of criticism is the weak experimental section which only considers a single real problem and no comparisons with other related methods are carried out in real problems.\\n\\n        Another point of criticism is that, for some particular values of the p parameter one does not actually observe sparsity in the Bayesian solution. For example, when sampling from the Laplace distribution one never observes zeros in practice. Spike and slab priors (a mix between a Gaussian and a point of mass center at zero) are the ones that actually lead to zeros.'},\n",
       "  'review_11': {'summary': 'This work proposed a framework for performing inference on Gaussian Graphical Models by approximating the posterior with a normalizing flow over PSD matrices. In this way, the authors can investigate $l_p$-norm regularized GGMs for any value of $p$ in an efficient way.',\n",
       "   'strengths': \"The idea of using normalizing flows for GGM inference definitely brings in advantages of both Bayesian and frequentist worlds; to me, that's an innovative idea.\",\n",
       "   'weaknesses': \"The main weakness that I identified is the lack of comparison between the proposed framework and the well-studied graphical lasso with concave approximations of the $l_0$-norm. More precisely, the authors show that their framework obtains frequentist solution paths through simulated annealing, therefore, it'd be of great interest to see a comparison between these solution paths and those obtained by iterative algorithms such as iterative reweighted l1-norm for graphical lasso.\"}},\n",
       " 'Matrix Compression via Randomized Low Rank and Low Precision Factorization': {'review_23': {'summary': \"The paper introduces a low rank, quantized/low precision matrix factorization which decomposes an n x d matrix A in the form A= LR, where L (of size n x m) and R (of size m x d) are low rank factors. L and R are computed using a random projection matrix S in the form L = Q(AS) and R = Q'(W^*) where W^* is the matrix minimizing the squared Frobenius norm ||Q(AS)W− A||. Q and Q' are two independent quantizers with specified budgets. \\n\\nThe authors contrast their method with an SVD based method for computing the quantized low rank approximation which instead sets L = Q(U_k S_k) and R = Q'(V_k), where U_k/V_k and S_k are the singular vectors/values respectively. The paper has a theorem deriving a bound on the Frobenious norm of the factorization eror. They apply the approximation on image data (for image compression) and embedding matrices (for an embedding classifation task).\\n\",\n",
       "   'strengths': '+ The paper is very well written and very clear in its presentation\\n+ Clear technical presentation incl. theorems, algorithms etc.\\n+ Novel idea, providing good review of relevant literature (different matrix sketching approaches, quantization etc.)\\n+ Thoughtful experiments to demonstrate real world application (using embedding compression)\\n',\n",
       "   'weaknesses': \"I don't see any weaknesses that need to be addressed at this moment.\"},\n",
       "  'review_24': {'summary': 'The paper studies the low-rank factorization of the matrix in the low-precision setting and proposes a new algorithm which is a combination of randomized low-rank approximation method and quantization.  The paper formally analyzes the guarantee of the proposed algorithms and also give experiments on real world dataset which demonstrate the advantage of the proposed algorithm.',\n",
       "   'strengths': '1. The presentation of the paper is good. The writing of the paper is clear and easy to follow.\\n\\n2. To get the formal guarantee, the authors do a careful analysis, which I think is non-trivial.',\n",
       "   'weaknesses': '1. Technical novelty: the main algorithm (Algorithm 1) seems to just be the standard way in randomized numerical linear algebra then plusing the quantization. Can you authors give more explanations about the technical novelty? (though the analysis I think is not standard)\\n\\n2. Experiment: I have some questions about the setting and details of the experiments section. See the next question.'},\n",
       "  'review_25': {'summary': 'The paper proposed a memory efficient approach to approximate a matrix $A$ by: low-rank approximation $A=LR$ and quantization. The LPLR algorithm first applies a quantized random projection (RP) as the $L$, and then solve a minimization problem for the right loew-rank factor $R$, which is also quantized afterwards. Theoretical approximation error is obtained and compared with an alternative approach that quantized SVD low rank factors instead of RP. Experiments are conducted on image approximation and embedding classification, to show the effectiveness of the proposed method.',\n",
       "   'strengths': '1. The paper is well-organized and easy to follow. The theoretical analysis seems rigorous.\\n\\n2. Experiments on multiple ML tasks and datasets are provided which make the results more grounded.',\n",
       "   'weaknesses': 'In my understanding, the main idea of the paper is to waive the need to compute the SVD of A, by using random projection (RP) as a surrogate. I have the following concerns and suggestions:\\n\\n1. At line 220, the authors wrote that the bits per entry for SVD-quant is $O(nd\\\\sqrt k)$, but in Table 1 and Table 2, it is $O(k\\\\sqrt{nd})$. Please double check and clarify. Also, the authors simply stated that LPLR is better than SVD-quant in terms of bits per query, which is not true with some n, d, m, k (comparing the results in the table). I suggest the authors to carefully compare the results and state the regimes when LPLR is better, and when it is worse.\\n\\n2. In the main Theorem 3.2, $\\\\kappa$ could be negative, right? Is $1-c_4\\\\sigma_k/\\\\sigma_{k-1}$ bounded? Or do we need to further assume an eigen gap for this result to hold?\\n\\n3. I understand that the main usage of LPLR is for matrix (data) approximation, so the first experiments (Figure 1 and Table 3) make sense to me. However, for the second set of experiments on classification, why not directly using $Q(AS)$ (i.e., the quantized random projections)? This saves the storage for W (in other words, we may increase the sketch size m when using Q(AS) only). Some recent references on this include\\n\\nRandom projections with asymmetric quantization, Li and Li NeurIPS 2019\\n\\nGeneralization error analysis of quantized compressive learning, Li and Li, NeurIPS 2019 \\n\\nIndeed, the research on QRP is highly related to this submission, since LPLR essentially does an optimization on W to recover the data from QRP. I suggest to add some discussion on this direction in the paper and some empirical comparisons.\\n\\n4. Also, if LPLR is used for processing or storing the data for classification or search tasks, it might be inconvenient to handle new data points (e.g., in a streaming setting). Thus, it may not be suitable for such tasks. On the other hand, recently people are using low rank approximation in LLM fine-tuning frequently. Experiments related to fine-tuning language models could be a better application scenario for the proposed method.\\n\\n5. Some references on similar results are missing. A similar result as in Appendix D that $S^TQ(AS)$ with uniform quantization has approximation error independent of $d$ has been established in [EDEN: Communication-Efficient and Robust Distributed\\nMean Estimation for Federated Learning, Vargaftik et al., ICML 2022] (or maybe some even earlier paper) for rotation matrix $S$. This related result should be cited. Also, Eq. (2) is a standard result for uniform stochastic rounding. A reference should be added there.\\n\\nIn all, I think the paper proposes a simple but intuitive method for low-rank low-precision matrix approximation from QRPs. The idea is clear, the analysis seems sufficient (despite the above and below questions).The experiments can be improved, but the current results on several tasks and datasets are convincing enough to show the effectiveness of LPLR in matrix approximation. For now, I would recommand borderline accept. '},\n",
       "  'review_26': {'summary': 'The paper studies compression of low-rank matrices by simultaneous low-rank factorization and quantization. It proposes a method that first quantizes the randomized rangefinder as the first low-rank factor and then quantize the minimizer of reconstruction error with respect to the remaining factor as the second. Randomized rangefinder uses random Gaussian matrix which possesses the equalization property to maintain low quantization error, compared to naïve quant. Experiments are provided to demonstrate the benefits of the proposed algorithm.',\n",
       "   'strengths': '1. provide a low rank factorization algorithm that come with quantization for further reducing memory footprint.\\n2. experiments demonstrate the advantage of the algorithm.',\n",
       "   'weaknesses': '1. experimental settings should be made clearer. the current description is a bit confusing. \\n'},\n",
       "  'review_27': {'summary': \"The authors investigate combining low-rank matrix factorization and (uniform scalar) quantization.\\nThrough theoretical analysis and experiments they demonstrate that this can yield much higher accuracy than directly quantizing the input matrix. One natural choice is to compute the SVD of the matrix and quantize the two factors independently. It's shown that quantizing the left factor first and then computing a new right factor that best approximates the input when multiplied with the quantized left factor yields much better result. The choice of SVD is not critical and could be replaced by randomly mixing the columns of the input matrix, i.e. random sketching. In fact sketching has provable benefits as the entries of sketched matrices are bounded with very high probability. This bounded range improves quantization theoretically. The authors prove several theorems (their proofs are in the extensive appendix) and conduct detailed empirical evaluation.\",\n",
       "   'strengths': '1) All the key ideas of the paper (low-rank approximation, sketching) are sound.\\n2) Detailed theoretical analysis with rigorous proofs.\\n3) Extensive experiments.\\n4) Compression of neural network weights and embeddings via low rank approximation and quantization are popular and impactful topics both to reduce memory usage and to speed up training and inference.\\n',\n",
       "   'weaknesses': \"1) Neither the ideas nor the analysis are particularly inventive in my opinion. It's self evident that optimizing the second factor after quantizing the first (LSVD) is superior to independent quantization (DSVD), in fact the process could be iterated further. While I appreciate the 30+ pages of proofs provided by the authors it seems as if they rely on chaining known results and techniques for sketching and random matrices combining with patient algebra.\\n2) Despite its seemingly weaker theoretical bounds LSVD is always one of the most accurate method in the experiments (see Tables 4-7). This is also clearly highlighted by the authors in the limitations section. \\n3) Quantization aware training (not considered in the paper) is highly likely to produce equivalent or better results.\\n\"},\n",
       "  'review_28': {'summary': \"This paper introduces a novel low-rank matrix factorization algorithm that is using sketching matrix idea and quantization, such as they do:\\n\\n1. Use Gaussian RV to generate sketch of the matrix and compute the approximate basis\\n2. Use Quantization with Q - to get Q(AS)\\n3. Use Q(AS) and Q' to get  Q'(W)\\n4. Return Q(AS) and Q'(W)\\n\\nAuthors provide theoretical and numerical analysis of their idea.\",\n",
       "   'strengths': '- introduction section written very well & and very informative and to the point, such as introducing LPLR algorithm briefly, talking about Low-rank approximation and Randomized quantization.\\n\\n- the introduced algorithm clearly communicated and results are theoretically sound.',\n",
       "   'weaknesses': \"- Abstract seem to be a bit wordy - it would be nice if there were formulations and numbers that grabs readers attention with resutls.\\n\\n- i like the way motivating the work - with memory constraints - but i am curious is there any application in real life for low rank decomposition that actually saves memory. some examples would be good\\n\\n- the paper doesn't exactly introduce a new direction - rather seems to be using existing ideas and put them together.\"},\n",
       "  'review_29': {'summary': 'This work studies the problem of computing a low rank approximation when the low rank factors are under a bit budget constraint, that is, we must output factors L and R with bounded bits such that LR approximates a given input matrix A in the Frobenius norm. The authors show that by incorporating sketching into the quantization procedure, one can get improved bounds, due to the fact that a Gaussian sketch can “flatten” the entries of a vector, which is advantageous when rounding (Appendix D). Empirical results show that this algorithm indeed gives improved results over other naive implementations such as directly rounding SVD factors. ',\n",
       "   'strengths': 'The problem of efficiently quantizing low rank approximations is an extremely important problem given that both low rank approximations and low precision is gaining popularity for compressing massive neural networks (https://papers.nips.cc/paper/2020/file/13b919438259814cd5be8cb45877d577-Paper.pdf, https://arxiv.org/abs/2302.03764). This work offers an interesting new method which takes advantage of the “flattening” property of Gaussian sketches in order to obtain improved results for quantization in the context of low rank approximation. This idea is conceptually simple yet interesting. Empirical results are also convincing.',\n",
       "   'weaknesses': 'The contribution is already quite nice, but there are several followup investigations that could strengthen this work much more:\\n* Are there any lower bounds on the trade-off between the approximation accuracy and the bit budget?\\n* There are structured sketching transforms such as the Subsampled Randomized Hadamard Transform (see Theorem 2.4 of http://www.cs.cmu.edu/afs/cs/user/dwoodruf/www/wNow3.pdf) which also have the “equalizing” or “flattening” type of behavior, yet can be applied in much faster time, and furthermore also save on the storage of the sketching matrix since it is an integer matrix. Can this be used to get faster implementations in theory/practice? \\n* Can you report the running time of the experiments?\\n* Can you comment on whether the bit bounds imply actual savings in the memory usage, or are the practical implementations of bit complexity too crude to capture these improvements? '}},\n",
       " 'Color Equivariant Convolutional Networks': {'review_15': {'summary': 'This paper proposes color equivariant convolutional networks (CE-CNNs), a novel convolutional neural network architecture that achieves equivariance to hue changes.&#x20;\\n\\nThey introduce color equivariant convolutions that apply a discrete set of hue rotations to the convolution filters during the forward pass. This makes the network output invariant to corresponding hue changes in the input image.\\nThey propose a group coset pooling layer that pools feature maps over the group of hue transformations to achieve invariance.\\nThey evaluate CE-CNNs on several image classification datasets, showing improved robustness to hue changes at test time compared to regular CNNs. The method also improves absolute classification performance in some cases.\\nOverall, the paper presents a novel and intuitive technique to build invariance to hue changes into CNNs. The evaluations demonstrate its advantages over standard networks, especially under shifted hue distributions between training and test.',\n",
       "   'strengths': 'This paper introduces a clever yet intuitive technique to make convolutional neural networks invariant to hue changes in the input image. The core idea is to apply discrete hue rotations to the convolution filters during the forward pass, essentially \"baking in\" robustness to color changes.\\n\\nThe paper is clearly written and easy to follow. The authors motivate the problem well, explain their proposed method succinctly, and provide thorough experimentation across image datasets. The visualizations offer useful insights, confirming that the networks learn consistent features across hues.\\n\\nOverall, I found this to be an original and significant contribution. Invariance to hue shifts is a practical problem, and this paper tackles it through an elegant approach that outperforms regular CNNs. The concept of encoding transformations into convolutions seems powerful. While not the flashiest technique, the method is thoughtful, principled, and achieves strong results. The paper is presented clearly and comprehensively, making the ideas accessible. In summary, this is a high quality paper with both theoretical and practical value.',\n",
       "   'weaknesses': '-   The method is demonstrated on image classification, but it\\'s unclear how well it would generalize to other tasks like detection or segmentation. Additional experiments on other applications could strengthen the claims.\\n-   The ablation study on number of hue rotations suggests performance varies across different shifts. It would be useful to dig deeper into why - is it an artifact of how shifts are applied? Better understanding this could improve results further.\\n-   The approach encodes discrete hue rotations. An interesting extension could be supporting continuous rotations for finer-grained equivariance.\\n-   The comparisons to \"grayscale\" networks should be interpreted carefully, as removing color information entirely handicaps models. Comparisons to networks pre-trained onImagenet may be more meaningful.\\n-   The Flowers-102 experiments indicate the method doesn\\'t help much on datasets without color bias. Analyzing when color equivariance helps or hurts could guide adoption.'},\n",
       "  'review_16': {'summary': 'Paper proposes color-equivariant CNN layers by imposing equivariance to H_n (a discrete subgroup of SO(3)) in the RGB space which is imposes hue equivariance. Implementation follows the framework of Group-equivariant CNNs. Experiments show marginal improvements over standard CNNs for in-distribution test data but significant improvements when test data is hue-shifted.',\n",
       "   'strengths': '1. Color equivariance in CNNs is a relatively less-studied but an important topic for robustness. The proposed idea of incorporating equivariance to hue transformations via rotations in the RGB space is novel. \\n2. Experiments are setup well clearly showing when color equivariance is helpful vs color invariance vs no symmetry. Proposed approach shows improves over CNN even when in in-distribution test data, but major improvements come when test data is hue-shifted.',\n",
       "   'weaknesses': '1. Definition of color equivariance considered in the paper seems to be restricted as it only considers the hue dimension. One of the motivations for incorporating color equivariance is for robustness to illumination changes which I do not think is guaranteed here. A general definition of color-equivariance should consider other dimensions. Maybe the claims are better justified if Hue-equivariance is emphasized in the title/introduction/method name, etc.\\n2. The definition of hue-equivariance is not precise in the paper. Ideally, it should include all rotations in the RGB space (i.e., SO(3)), but also consider the fact that many of these rotations take the color values out of the RGB space (unit cube). In general, this issue occurs for the discrete subgroup $H_n$ as well. Simply projecting the color values back into the RGB space does not work as it breaks the invertibility property of these transformations. \\n3. Experiments compare with a standard CNN (+grayscale) as baseline. Other baselines can be included, for example [1], that considers invariance to illumination color/intensity. \\n4. Experiments in the main paper only consider the group $H_3$ (i.e., 3 rotations in the RGB space), which seems limited in robustness, as shown in Figure 1 without jitter augmentations. \\n\\n\\nReferences:\\n\\n[1] Lengyel, Attila, et al. \"Zero-shot day-night domain adaptation with a physics prior.\"\\xa0_Proceedings of the IEEE/CVF International Conference on Computer Vision_. 2021.'},\n",
       "  'review_17': {'summary': 'The authors introduce a color equivariant convolutional neural network. To achieve this the authors represent the image in HSV format, and achieve hue equivariance using methods for rotational equivariance. This is possible since hue can be represented by an angle. The authors show that the proposed approach out performs standard CNNs and color invariant CNNs when there is a hue shift between the train and test set.',\n",
       "   'strengths': '* Originality: The presented method of building a color equivariant CNN appears to be original. \\n* Quality: The work appears to be of fairly good quality. \\n* Clarity: The paper is well written. \\n* Significance: The observation that color equivariance can be achieved by identifying hue with the rotation group is interesting. The results show the proposed approach leads to improved performance when there is a color based domain shift.',\n",
       "   'weaknesses': '* Quality: I have some questions about the mathematical presentation, and experiment design (see questions).\\n* Clarity: Some aspects were unclear to me, due to presentation or motivation (see questions)'},\n",
       "  'review_18': {'summary': 'This paper questions the importance of color variations for neural classifiers and proposes to use color-equivariant architectures in the case of unbalanced datasets.\\nTo demonstrate the validity of the presented approach, the authors conduct experiments both on synthetic controlled datasets and on common object recognition benchmarks.\\nAs the experiments show, the injection of color-equivariant layers leads to a slight improvement on almost all common benchmarks when the performance is measured on the original test set but the advantage of the presented method becomes more evident when the test data is corrupted with hue shifts.',\n",
       "   'strengths': 'This paper studies an interesting and underinvestigated question of the importance of color representation for neural networks.\\nThe submission is easy to read, and the motivation is well explained in the example of the Flowers dataset. \\nThe authors have conducted a significant number of experiments to support their claims.\\nAdditional strength is that the demonstrated performance improvement is achieved without increasing the number of trainable parameters (line 238).',\n",
       "   'weaknesses': '1. While the idea of extending equivariance from geometric to photometric transformations is definitely interesting, the submitted manuscript, unfortunately, focuses on the only type of such transformations, i.e. hue shifts. Despite the case of the Flowers dataset is a perfect fit for this transformation, the authors do not discuss other use cases when this type of equivariance may be interesting in practice and just mention \"accidental recording conditions\" (line 3). For other datasets, hue shifts seem less meaningful, and the better robustness of the proposed CE-ResNets to such shifts at test time is explained by the fact the architecture was just intentionally designed for this scenario. Taking this into account, I find the scope of the paper a bit limited.\\n\\n1. In addition to being limited in the number of considered photometric transformations, the paper also considers a single task of object recognition. I would encourage the authors to consider other tasks as well, e.g. unsupervised domain adaptation.\\n\\n1. While the authors claim their approach makes networks more robust to test time corruptions (Tab. 1), they do not demonstrate other baselines aiming to provide robust outputs, e.g. adversarially robust models.'}},\n",
       " 'VideoComposer: Compositional Video Synthesis with Motion Controllability': {'review_13': {'summary': 'The paper presents a method for compositional video synthesis. It introduces motion vectors from compressed videos as a control signal for temporal dynamics. The motion vector can be combined by other conditions such as sketch, and depth map. Both qualitative and quantitative results show that the proposed method can control the spatial-temporal patterns. ',\n",
       "   'strengths': '+ The motion controlled generation result (fig 8) using hand-crafted strokes is interesting. \\n\\n+ Table A1 shows effectiveness of the proposed method quantitatively compared to previous methods.\\n\\n+ The paper is well written and easy to follow.',\n",
       "   'weaknesses': '- There are a few GAN-based video synthesis approaches that are worth discussing in the related work. For example, MoCoGAN [1] approaches the problem by decomposing motion and content. \\n \\n- The two-stage training strategy needs more clarification. What is \"compositional training\" particularly in the second stage?  How does it differentiate from the \"text-to-video\" generation in the first stage?\\n\\n- In line 164-165, the authors \"repeat the spatial conditions of a single image and single sketch along the temporal dimension\". If the input condition is simply repeated, what\\'s the point of applying a temporal Transformer? It will be equivalent to applying the spatial operation only and repeat at the latent space but with higher computation cost, no? (for motion vector, I totally agree that a spatial-temporal modeling would be necessary.)\\n\\n- Motion vectors can be less meaningful in the background due to lack of high-level semantics. It can also be clearly seen from the top row in Fig 4. I wonder if the authors treat the motion vector field equally for all locations. It seems that the generated results with motion conditions has more blurry background.\\n\\n- From Figure 2 and Figure 1(d), my impression is that the conditions (say motion and depth) can be combined together. However, in ablation studies (table 2), only one condition is added at a time. Another ablation that studies all combinations of these conditions will be favored. \\n\\n[1] Tulyakov, Sergey, et al. \"Mocogan: Decomposing motion and content for video generation.\" CVPR 2018.'},\n",
       "  'review_14': {'summary': \"VideoComposer is a tool designed to enhance video synthesis by incorporating textual, spatial, and temporal conditions. It uses motion vectors from compressed videos to guide temporal dynamics and employs a Spatio-Temporal Condition encoder to effectively integrate spatial and temporal relations of inputs. This improves inter-frame consistency and allows for greater control over the synthesized video's spatial and temporal patterns.\\n\",\n",
       "   'strengths': 'The VideoComposer offers better control over video synthesis, temporal guidance using motion vectors, improved inter-frame consistency with its Spatio-Temporal Condition encoder, versatility in accepting various forms of inputs, and high customizability, resulting in more precise and desired synthesized videos.',\n",
       "   'weaknesses': 'An ablation study could be conducted on VideoComposer, where each component is removed in turn to evaluate its impact on overall performance. This would help evaluate the value of training under multiple conditions versus a single condition. \\n\\nAdditionally, comparing VideoComposer to a simpler method like Text2Video-Zero [a] with ControlNet [b] would demonstrate whether the increased complexity of VideoComposer yields significantly better results, hence justifying its sophistication. \\n\\n[a] Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators, L Khachatryan et al.\\n[b] Adding Conditional Control to Text-to-Image Diffusion Models, L. Zhang et al. '},\n",
       "  'review_15': {'summary': 'This work proposes a new method called VideoComposer for conditional video generation, especially for video-to-video translation. VideoComposer is constructed upon the Video Latent Diffusion Model and introduces an STC-encoder to integrate multiple spatial and temporal conditions such as RGB images, sketches, motion vector sequences, etc. The architecture design involves simple 2D convolutions and temporal transformer layers. The conditional features are fed into the U-Net input together with noise. The demonstrated results have good temporal consistency.',\n",
       "   'strengths': '- This is one of the pioneering works in controllable video synthesis. The temporal consistency of the video results is impressive, considering that its conditioning modeling enables several editing abilities such as image-to-video translation and motion/depth/sketch-driven local/global video editing.\\n\\n- The jointly training strategy is good for flexible inference within one model, e.g., video inpainting, without second training.\\n\\n- The paper organization and illustrations are easy to follow.',\n",
       "   'weaknesses': '- The authors could have tried other design choices for integrating Condition Fusion as input into the U-Net, such as integration through cross-attention.\\n\\n- In line 215, it is claimed that “we observe that the inclusion of mask and style guidance can facilitate structure and style control.” However, the corresponding evidence should be presented for the style representation extracted by clip image encoder and concatenated with text embedding.\\n\\n- It seems that a single STC-encoder is used for all different conditions via random dropout. It would be interesting to see if different STC-encoder weights for different conditions are better.\\n\\n- The examples in Figure 6 with reference image look like failure cases. Besides, the tiger texture and box shape are changed in Figure 8. It would be helpful to see more discussion and analysis on this part.\\n\\n- The ablation study of STC-encoder is not presented in a fair way. The main benefit of using STC-encoder comes from the video information condition instead of the network design.\\n\\n- The important comparisons and discussions with other methods are not sufficient, such as VideoP2P and vid2vid-zero mentioned in the related works.'},\n",
       "  'review_16': {'summary': 'This work aims to allows users to flexibly compose a video with textual conditions, spatial conditions, and temporal conditions.\\nIt introduces a novel framework namely VideoComposer based on the paradigm of compositional generation.\\nTo be specific, it introduces the motion vector from compressed videos as an explicit control signal to provide guidance regarding temporal dynamics.\\nMoreover, it develop a Spatio-Temporal Condition encoder (STC-encoder) that serves as a unified interface to effectively incorporate the spatial and temporal relations of sequential inputs, with which the model could make better use of temporal conditions and hence achieve higher inter-frame consistency. \\nExtensive experiments demonstrate that VideoComposer control the spatial and temporal patterns simultaneously within a synthesized video in various forms.',\n",
       "   'strengths': '1. It introduces motion vector as a more flexible user-guided signal.\\n2. It proposes Spatio-Temporal Condition encoder (STC-encoder) that serves as a unified interface to effectively incorporate the spatial and temporal relations of sequential inputs.\\n3. Extensive experiments show the effectiveness and superiority of VideoComposer.',\n",
       "   'weaknesses': '1. What is the difference between the roles of the ``Style`` of CLIP and ``Single Image`` of STC-encoder? They both seem to provide content to videos.\\n2. VideoComposer only obtain comparable performance with prior video generative models. Is it more efficient than previous methods? The authors could give their comparisons in training cost and inference time.\\n3. Lack of extensive visualization comparisons with existing video generative models. The authors are encouraged to provide extensive qualitative comparisons in video generation task.\\n'}},\n",
       " 'SiT Dataset: Socially Interactive Pedestrian Trajectory Dataset for Social Navigation Robots': {},\n",
       " 'Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger': {'review_16': {'summary': 'The script proposed an automatic clipping methods for various DP algorithms. The problem is important because the performance of DP models are sensitive to the choice clipping threshold, yet there is no theorical guidance for tuning it. \\n\\n',\n",
       "   'strengths': 'The writing is clear and the paper is easy to follow. The idea is simple and effective.  Theory and experiments are provided to show the efficacy of the proposed automatic clipping method. I think this result is worth sharing with the DP community. \\n\\n\\n\\n',\n",
       "   'weaknesses': 'See below'},\n",
       "  'review_17': {'summary': \"This paper introduces 'automatic clipping' to replace the usual clipping operation in DP-SGD. The challenge of usual clipping is to choose a good threshold 'R' especially for deep learning models. The authors claim that automatic clipping maintains the same level of privacy and computational efficiency as existing DP optimizers such as DP-SGD, DP-Adam, and DP-LAMB, but without the need for any DP-specific hyperparameters. In fact, automatic clipping uses a kind of normalization to bound the sensitivity of individual gradient. Additionally, they provide a thorough convergence analysis for DP-SGD with automatic clipping in the non-convex setting, demonstrating that it can match the convergence rate of standard SGD under certain conditions. The authors validate their proposal by showing that automatic clipping either matches or surpasses the state-of-the-art performance on a variety of language and vision tasks.\\n\",\n",
       "   'strengths': '1. **Simplicity**: The proposed method of automatic clipping significantly simplifies the process of DP training by eliminating the need for tuning DP-specific hyperparameters, thereby making DP as user-friendly as standard non-private training.\\n\\n2. **Performance**: The paper demonstrates that the automatic clipping method is either on par with, or better than, existing state-of-the-art techniques in a variety of tasks. This suggests that the method does not compromise performance for ease-of-use.\\n\\n3. **Rigorous Analysis**: The authors provide a detailed convergence analysis of automatic DP-SGD in a non-convex setting, showing that it can match the convergence rate of standard SGD under the symmetric gradient noise assumption of per-sample gradients.',\n",
       "   'weaknesses': '**Misleading justification**: In figure 2, the paper present the dot products of $\\\\langle g_i, \\\\sum_i g_i \\\\rangle$. First it does not make sense if the dot product is properly normalized.  Moreover, the distribution of  $\\\\langle g_i, \\\\sum_i g_i \\\\rangle$ does not necessarily align with good performance. The illustration in Figure 2 is rather misleading.\\n\\n**Too strong Assumptions**: The proposed automatic clipping method\\'s performance is based on a symmetric gradient noise assumption of the per-sample gradients. This assumption is too constrained and does not satisfy in practice.\\n\\n**Overclaim**: Section title 4.3 \"Automatic clipping is equally private and maximizes utility\" is somewhat overclaiming. It is not carefully argued why automatic clipping can \"maximize utility given a privacy budget.\\n\\n**Missing reference**: The paper missed a very related reference Yang et al. \"Normalized/clipped sgd with perturbation for differentially private non-convex optimization\" which also studied the DP-SGD with normalization. The paper should have a careful comparison with it.'},\n",
       "  'review_18': {'summary': 'The paper discusses a way to control the sensitivity of DP-SGD by a method that does not require clipping.\\n',\n",
       "   'strengths': '- The motivation for the paper is clear\\n- The authors make a compeling argument that suggest why their method should work\\n- They have sound theoretical guarantees and experiments\\n- The idea is simple yet fully developed\\n- The impact this could have on private learning is huge\\n- Experimental results are compeling\\n',\n",
       "   'weaknesses': 'N/A'},\n",
       "  'review_19': {'summary': 'The author(s) proposed a new gradient clipping technique for differential private training algorithms. It was shown that the new clipping technique is more robust to hyper-parameters and can save the time for hyper-parameter tunning. Convergence of the proposed method under a gradient symmetric assumption is developed and experiments on both vision and language tasks are conducted to evaluate the proposed method.',\n",
       "   'strengths': '- The paper is well-written and easy to follow in general.\\n- The experiments are thorough and the algorithm seems to be useful on the practical side.',\n",
       "   'weaknesses': '- The convergence analysis is based on a gradient symmetric assumption, therefore the utility bound in Theorem 4 is not really comparable to prior works. Please also see my quetions below. Overall, the theoretical contribution seems limited. However, given the strong empirical performance of the proposed method, this might be acceptable.\\n- Some related work should be added [1,2,3].\\n\\n[1] Clip21: Error Feedback for Gradient Clipping, https://arxiv.org/abs/2305.18929\\n\\n[2] Improved Convergence of Differential Private SGD with Gradient Clipping, https://openreview.net/forum?id=FRLswckPXQ5\\n\\n[3] Normalized/Clipped SGD with Perturbation for Differentially Private Non-Convex Optimization, https://arxiv.org/pdf/2206.13033.pdf'},\n",
       "  'review_20': {'summary': 'The paper proposes a new alternative version of the DP-SGD algorithm where the gradients are normalized. This new method allows for a proof of convergence of the gradient when we add a small stability constant to the rescaling factor. This work eliminates the need for a costly 2D gridsearch between learning rate and clipping constant when training DP models. The authors then proceed to run experiments on to show their method equals or outperforms Abadi’s DP-SGD algorithm.',\n",
       "   'strengths': 'The article eliminates a costly operation in DP training and provides strong evidence regarding the convergence of their method. The exhaustive list of datasets on which the method was tested testifies as to how only minimal changes to existing implementations are needed to apply this method.\\n\\n### Originality\\n\\nThe method is original.\\n\\n### Quality\\n\\nThe experiments presented are very complete and yield high quality results. Also, various supporting githubs and ressources are mentionned, making these results reproducible.\\n\\n### Clarity\\n\\nThe article is clear and well written.\\n\\n### Significance\\n\\nThe original motivation of the article is clear. ',\n",
       "   'weaknesses': '## Sensitivity of the hyperparameter optimization\\n\\nThe results are not clear enough to indicate whether the proposed DP training method is superior to the rescaled DP-SGD method which impedes the significance of the article. If the authors of the paper manage to prove that their method is less expensive than the rescaled DP-SGD trick then the contribution is significant. The article lacks a conclusive experiment or statement proving that the sensitivity of the hyperparameter optimization process is easier with this method than with the re-scaled version of Abadi’s DP-SGD. \\n\\nThe paper shows in its appendix H. that the training process of the AUTO-S method is relatively robust to the choice of $\\\\gamma$ on NLP tasks. However the paper doesn’t compare the sensitivity of the **AUTO-S method** to the $\\\\gamma$ factor to the sensitivity of the **rescaled Abadi clipping** to the $R$ factor. In my opinion this is an important experiment to run, since it would justify using this method instead of the widely known rescaled DP-SGD version introduced in De et al. [15]. This could improve the impact and the significance of the contribution.\\n\\n### Actionable feedback\\n\\n> However, R remains and is expensive to tune (l223)\\n\\nThis sentence in particular is a bit of an overclaim in my opinion, see my comments below.\\n\\n**In your experiments you specifiy regarding the range of $\\\\gamma$**\\n> ”under which a wide range of 0.0001 < < 1 gives similar accuracy”\\n\\nand\\n>“Note that the largest good is 1000 times bigger than the smallest good ”\\n\\n\\n**In the comparison to related works on clipping**\\nYou state “Similarly (De et al.) re-parametrizes the per-sample gradient clipping to mimic normalization. However R remains and is expensive to tune (see figure 8 of De et al.)”. However this fig 8. shows that the re-parametrized per-sample gradient clipping seems to stay stable by a similar factor of approximately 1024 on the clipping norm, on a even harder dataset. Even though their experiment are not extensive enough to prove a superior efficiency of the rescaled DP-SGD method to yours, it is not conclusive enough for you to assume that your method is easier to tune.\\n\\nIf you add this missing experiment, or if you modify this claim, I would consider improving my rating.'}},\n",
       " 'A Theoretical Analysis of the Test Error of Finite-Rank Kernel Ridge Regression': {'review_16': {'summary': 'This paper gives a refined analysis of the test error of kernel ridge regression with a finite kernel in the underparametrized regime, where the rank M of the kernel is smaller than the number of data points N. The analysis improves upon previous ones by providing tighter non-asymptotic upper and lower bounds, which remain tight even as the ridge parameter goes to zero. When the target function lies in the RKHS, the bounds show that estimation is consistent as N goes to infinity.',\n",
       "   'strengths': 'The paper is well written and clear. The authors state the contributions clearly and compare carefully with previous work. Establishing tight bounds for this basic learning setting is an important problem.',\n",
       "   'weaknesses': 'No major weaknesses, just some minor typos. I would also suggest that the authors include the explicit lower bounds in the main paper. Given that this a major focus of the paper it should not be required for the reader to go to the appendix. It would also be nice for the appendix to give a bit clearer account for the technical differences in the proof techniques of their bounds versus previous ones.'},\n",
       "  'review_17': {'summary': 'The paper studies the kernel ridge regression under the non-asymptotic setting. The authors give the upper and lower bounds for bias and variance term, respectively. The authors argue the results improve upon those in Bach 2023.',\n",
       "   'strengths': 'The paper is well-structured. The authors give rigorous proofs, following by careful experiments.',\n",
       "   'weaknesses': '1. The paper requires further improvement and polishing in writing. To name a few, line 57-58; line 107-110.\\n\\n2. The paper would benefit from a more consistent and standardized use of symbols and notations. For example, in line 90, it would be better to use L_2(\\\\rho) instead of L_\\\\rho^2. In lien 92, the notation of \\\\tilde{f}(\\\\textbf{X}) is not proper. In Definition 3.1, it would be better to include the decreasing order of eigenvalues in the statement rather than adding an additional remark 3.2. In line 200-207, notation K^{(\\\\infty)}\\n\\n3. As mentioned in Bach 2023, more refined bounds can be found in Rudi et al. 2015, Rudi and Rosasco 2017. However, the authors failed to mention them and other related results in the comparison. In the absence of such comparisons, it is hard to tell the novelty and improvements of the current submission.\\n\\n4. The dependency of \\\\lambda seems to be incorrect for the variance term.\\n\\n5. Given Corollary 4.3.1 in the submission, I cannot see significant improvements against those in Bach 2023. Also, the authors did not give a proper explanation for considering \\\\lambda goes to 0.'},\n",
       "  'review_18': {'summary': 'This paper analyzes the test error of ridge regression with a finite rank kernel. The finite rank kernel appears in several practical settings such as transfer learning and random neural networks. The authors provide a new analysis in this setting using tools from random matrix theory. A detailed comparison to other generalization bounds is presented.',\n",
       "   'strengths': '1. New generalization results in a practical and challenging setting.\\n2. New analysis techniques.\\n',\n",
       "   'weaknesses': '1. The comparison to standard generalization results is not clear (Eq. (12)). Both bounds scale as $\\\\sqrt{\\\\frac{\\\\log(n)}{n}}$. It is not clear which one is tighter.\\n2. The technical details of the proof are not given and the novelty of the analysis is not explained in detail. Instead, most of the paper is devoted to a discussion and experiments.\\n3. There are some unclear technical issues (see questions below).\\n'},\n",
       "  'review_19': {'summary': 'The paper highlights the inadequacy of existing statistical learning guarantees for general kernel regressors when applied to finite-rank kernels. The authors have addressed this issue by developing non-asymptotic upper and lower bounds for the test error of finite-rank kernel ridge regression. These new bounds are more precise than the previously established ones and are applicable for any regularization parameters. This research provides a more dependable framework for utilizing finite-rank kernels in machine learning applications.',\n",
       "   'strengths': '1. The paper addresses an important gap in the current understanding of machine learning algorithms by developing more accurate and reliable bounds for finite-rank kernel ridge regression, which is frequently used in practical applications.\\n\\n2. The research provides a more precise and dependable framework for using finite-rank kernels in machine learning problems, which could result in better performance and more efficient algorithms.',\n",
       "   'weaknesses': '1. The paper only considers under-parameterized regime.\\n\\n2. Low bound is a main argument of this paper, but all details are given in the Appendix.\\n'},\n",
       "  'review_20': {'summary': 'The authors address the problem of kernel ridge regression with a finite rank kernel, in the under-paramatrized regime. They prove sharper upper bounds on the test error, compared to previous existing works.',\n",
       "   'strengths': 'The discussion is very well-written and easy to follow, with a number of illustrations being provided to set up the problem. Careful and detailed comparison to previous work is given, making it easy to understand the novelty of the present manuscript. Overall, the addressed problem is an important one, and I believe the derived bound will be of interest to the community. I have not checked the proof, and therefore give a low confidence score.',\n",
       "   'weaknesses': 'I do not have any major concern. A minor remark is that while all experimental details are provided in Appendix D, it would be good to add at least a short description of the target functions and regularization used in Fig.1 and 2 in the main text or in the corresponding captions.'}},\n",
       " 'Comparing Optimization Targets for Contrast-Consistent Search': {},\n",
       " 'Fine-Tuning Language Models with Just Forward Passes': {'review_13': {'summary': 'This work introduced a memory-efficient zeroth-order optimizer that can fine-tune large language models with the same memory footprint as inference, using only forward passes and gradient estimates. Comprehensive experiments across model types, scales, and tasks, showing that MeZO outperforms zero-shot, in-context learning, and linear probing, and achieves comparable performance to fine-tuning with backpropagation, while reducing memory cost by up to 12 times. Non-differentiable objectives that MeZO can optimize, such as accuracy or F1 score, which are usually not amenable to backpropagation. Theoretical insights that explain why MeZO can optimize LMs with billions of parameters, despite classical zeroth-order analyses suggesting otherwise.\\n',\n",
       "   'strengths': '1. It proposes a novel and memory-efficient method to fine-tune large language models without backpropagation, which can save up to 12x memory compared to standard methods.\\n\\n2. It demonstrates that the proposed method can achieve comparable or superior performance to fine-tuning with backpropagation across various tasks, models, and tuning techniques.\\n\\n3. It shows that the proposed method can optimize non-differentiable objectives, such as accuracy or F1 score, which are useful for many applications.\\n\\n4. It provides theoretical insights on why the proposed method can overcome the classical limitations of zeroth-order optimization and leverage the benefits of pre-training and task prompts.\\n',\n",
       "   'weaknesses': '1. While the experiments demonstrate good performance on the language understanding tasks, it is unknown whether the method is also applicable to the generation tasks.\\n\\n2. It relies on the assumption of low effective rank of the Hessian matrix, which may not hold for all loss functions. It would be great to have a discussion about the scope of application for the proposed method.\\n'},\n",
       "  'review_14': {'summary': 'The paper proposes an enhanced memory efficient zero-order optimization method named MeZO. MeZO only requires the same memory as inference time and thus can enable model tuning for large LMs with limited memory budget. The authors demonstrate the efficacy of MeZO on multiple NLP benchmarks compared with linear probing, in context learning and fine-tuning in few/low shot learning regime. The authors also provided detailed theoretical proof for MeZO. ',\n",
       "   'strengths': \"0 - The authors targeted a not well understood domain (zero order optimization) and open up new opportunities for future works. In the era of LLMs, this method can enable many future work especially for those who don't have access to large-scale GPU clusters. \\n1 - Comprehensive experiments and ablation studies on the proposed method.\\n2 - Strong theoretical support on the proposed method.\\n3 - Good writing and flow which makes the paper easy to follow and understand. \\n4 - Well-articulated future work.\",\n",
       "   'weaknesses': 'No major weaknesses. I left some comments in the questions section and hope  the authors can answer and address. '},\n",
       "  'review_15': {'summary': 'The paper present a new optimiser MeZo based on stochastic approximation using gradient perturbation. \\nThis optimiser is very memory efficient as it only requires to perform 2 forward passes with different deltas/epsilons on the parameters and multiple gaussian samplings.   These algorithms allows \"finetunning\" large language models to specific tasks very efficiently ( up to 30B on a single A100) yielding between x4 to x12 memory reductions. Since the proposed algorithm is an optimizer it can be combined with other standard techniques such as LORA or prefix tunning. All this is applied in finetunning setups similar to ICL. ',\n",
       "   'strengths': 'The algorithm is a new application of well known stochastic gradient approximation but many times forgotten due to their slowness. \\nIt is very surprising that this algorithm works, and the authors provide a theoretical justification of why this could be working in this case. \\nThey also acknowledge that despite of what it might sound this approach only works in prompting fine-tunning scenario [Appendix B.2]. \\n\\nThe results are insight full , the baselines are fair and the theoretical analysis is correct to the best of my knowledge.\\n\\nThis can settle as an alternative to in context learning with prompting, by  fine-tuning with  a limited set of examples (512). \\n\\nThe proposed technique seems to work on the benchmarks used and seems to surpass other techniques such as Zero-shot, LP, ICL, and approaches very close performance to fine-tunning. This can be set a cheap alternative to ICL for some tasks.\\n\\n',\n",
       "   'weaknesses': 'While there was a huge and titanic effort in the paper there were many questions that steam from the technique.\\nThe first area which has not been explored too much and given as true is the need of having a prompt to apply MeZO.\\nThis key ingredient is not well studied but rather given on some preliminary experiments, e.g. Table 5. \\nWhy is MeZO not working w/o prompts, even some very simple prompts ? \\n\\nThe need of the prompt also raises the question of how this is related to ICL , as there are some works that suggest ICL maybe doing some alike to fine-tuning or back-propagation though the attention weights. Is this combination of prompting and MeZo that is guiding the forward propagations ? is there a mixed cooperation between the prompt and the stochastic technique ? How much of the prompt is needed ?\\n\\nAnother question would be how the different techniques behave as a function of the number of examples k. It would have been nice to see a plot for some models at least between ICL , MeZo, and possible ft on the selected tasks. Why have authors stopped at 512 ? why only 16 or 512 ? there are some dataset that contain more training examples. Why didn\\'t they compare fine-tuning and MeZo in other setups with larger examples ?\\n\\nThere is the relationship between the task itself and the optimiser. It is not clear to me, in which tasks this will work properly. I suspect given the prompting above that this might only work on low-perplexity tasks or task in which prompting or ICL can generate good results and not in other more complex tasks. \\n\\nClearly this is maybe too much to address in the paper, but all aspects above point toward the little understanding the reader is left with on under which conditions this technique can be applied. The future work seems to already assume the MeZO algorithm is working and proved, but there is just an hypotheses and a very low link between the experiment conditions and the theory. The link is stablished as \"We attribute these phenomena to the Hessian of the loss exhibiting  small local effective rank.\" . It would have been nice to strengthen this connection with some experiments or computation. Could this explain when or how this algorithm is applied ? if we remove the prompt does this increases the H effective rank ? would other tasks exhibit larger ranks ?  how can we reduce it for each of the tasks ?\\n\\n\\nPlease, I would kindly ask the authors to read above questions and discussion as a signal of the interest the paper brought to the research field and not as criticism on their very interesting work.\\n'},\n",
       "  'review_16': {'summary': 'This paper proposes a new zeroth order optimizer, MeZO, for LM training.  This is proposed as an improvement to ZO-SGD.  The advantage of this approach is a 12x reduction in the amount of memory required for training compared to backpropagation.  This enables the training of much larger models.\\n\\nThe effectiveness of MeZO is shown across a range of benchmarks and model sizes.  The results compare favorably to linear probing and in context learning.',\n",
       "   'strengths': 'The MeZO technique stands to unlock substantial capability for LM training.  This enables training of much larger networks.  The compatibility with LoRA, prefix tuning are important use cases for many LM users.  There is an ability for optimizing non-differentiable objectives which is compelling, and could be expanded in the future.\\n\\nThe empirical behavior are coupled with a section on theory which effectively describes the both the expected behavior, but elaborates on the expected slow convergence by expanding the theoretical analysis to address low effective rank networks.',\n",
       "   'weaknesses': 'While the analysis refers to the convergence rate of MeZO, there is a very brief treatment of convergence behavior in the paper (Appendix E.2) It might be helpful for this to be expanded and possibly compared to backpropagation, especially in the context of the presentation of Section 4 Theory.'},\n",
       "  'review_17': {'summary': 'Fine-tuning with backpropogation becomes infeasible for very large language models because it uses too much memory. While zeroth-order optimization uses far less memory and could in principle fine-tune the model with just forward passes, past theory suggested that the learning rate must scale down with the number of parameters, making convergence prohibitively slow. However, this paper finds that zeroth-order optimization actually performs quite well and converges quickly even on very large language models. They provide theory to explain this fast convergence, where they show that under an assumption they call \"low effective rank,\" the learning rate scales down with the rank rather than the number of parameters. They also provide a memory-efficient implementation of zeroth-order optimization that they call MeZO, along with memory efficient zeroth-order versions of SGD with momentum and Adam. In experiments, the method performs similarly to backpropogation with 1/12 the memory usage, while outperforming in-context learning and linear probing.',\n",
       "   'strengths': '(1) The paper is well-written.\\n\\n(2) The method is simple and easy to understand.\\n\\n(3) The theory provides useful insights into why zeroth-order optimization works for fine-tuning large pre-trained models.\\n\\n(4) The experimental results are strong, and the appendix contains thorough ablations.\\n\\n(5) The idea that zeroth-order optimization works well for fine-tuning LMs seems practically useful and addresses a pressing need in the community for memory-efficient methods.',\n",
       "   'weaknesses': 'The paper seems strong overall, and I support its acceptance regardless of whether the suggested experiments below are run or not during the rebuttal period.\\n\\n(1) From what I understand, the paper does not verify the low effective rank assumption empirically, nor is it verified in the papers cited (which either study the effective rank / Hessian spectra in non-LLMs, or study the LLMs but not the effective rank and instead study the intrinsic dimensionality of fine-tuning). Therefore, to justify the assumption, it seems useful to study the Hessian spectra of the downstream fine-tuning loss in LLMs, at whatever size is feasible.\\n\\n(2) Related to (1), to verify the theory and confirm that the effective rank is indeed the quantity that determines convergence rates, it seems useful to run simulated experiments where one constructs a synthetic model + data and varies the effective rank, and examines whether the convergence rate or gradient norm scales with the effective rank as predicted in the theory.'}},\n",
       " 'PIXIU: A Comprehensive Benchmark, Instruction Dataset and Large Language Model for Finance': {},\n",
       " 'FLAb: Benchmarking deep learning methods for antibody fitness prediction': {},\n",
       " 'Sparse Parameterization for Epitomic Dataset Distillation': {'review_11': {'summary': 'This paper proposes a new parameterization for dataset distillation. The new parameterization considers image patches, use sparse matrix and recurrent feature net to generate synthetic images. The total parameters follows storage constraint. The experimental results show improvement over previous methods.',\n",
       "   'strengths': '+ This paper proposes a new parameterization for synthetic images in Dataset Distillation. \\n+ The proposed method works well across various benchmarks, including imagenet, cifar and cross arch generalization\\n+ This paper is quite interesting in proceeding the research on Dataset Distillation parameters. Spatial redundancies are quite dominant in standard parameterization, and this method can certainly help with alleviating that.',\n",
       "   'weaknesses': '- The paper claims on reducing spatial redundancies. I wonder how the authors compare their method with [19]. Does that also consider reducing spatial redundancies? \\n- The paper provides better empirical performance, but the research messages are not quite surprising.\\n- Have the authors considered using algorithms similar to [a] for sparsification?\\n\\n[a] Parameter-Efficient Transfer Learning with Diff Pruning'},\n",
       "  'review_12': {'summary': 'This work proposes a new memory-saving method of dataset distillation by distilling the dataset into a set of Spatial-Agnostic Epitomic Tokens which are indexed by Sparse Coding Matrices and decoded into images by a Feature-Recurrent Network. This method is plug-and-play compatible with existing distillation methods, allowing them to achieve more efficient storage. State-of-the-art results are shown for many datasets and problem settings. ',\n",
       "   'strengths': 'The overall presentation of the paper is very nice. The figures and equations very clearly explain to the reader the main ideas. The colorfully annotated Eq 7 especially makes the storage budget easy for the reader to digest. \\n\\nThe SPEED method itself is quite interesting, and algorithm 1 very clearly explains the process.\\n\\nThe many ablation studies and side-experiments further explain the effectiveness of the method.',\n",
       "   'weaknesses': 'The biggest issues I have with this paper are the presentation of tables 1 and 2.\\n\\nThis is not an issue specific to this paper, but methods that do re-paramaterization as a means of memory saving should not be directly compared to methods that only propose a matching algorithm.\\n\\nIt should be made extremely clear that IDC, HaBa, RTP and SPEED are solving an inherently different problem than the baseline methods.\\n\\nSynthetic set size should also not be given in \"IPC\" but in the number of learnable parameters, since the given IPC simply isn\\'t true anymore. For example, instead of IPC=10, you could have #Params <= 30,720 (10x3x32x32)'},\n",
       "  'review_13': {'summary': \"The paper proposes a new framework(SPEED) to perform dataset distillation.\\n\\nThe new framework is composed of 3 parts:\\n1. Spatial-Agnostic Epitomic Tokens (SAETs)\\n2. Sparse Coding Matrices (SCMs)\\n3.  A Feature-Recurrent Network (FReeNet)\\n\\nThe paper also employees multi-head attention to ensure the diversity of distilled images, thus achieving new SOTA. \\nThe new framework SPEED is also claimed to work with multiple dataset matching methods and enhance their performances.\\n\\nThrough various experiments, the method shows strong performances on CIFAR-10/100 and TinyImageNet. Similar results are also observed on ImageNet subsets.\\n\\n### I have read the author's response and my concerns are addressed by seeing more experiment results.\",\n",
       "   'strengths': '## originality\\nSPEED is claimed to be the first paper studying the spatial redundancy in the field of dataset distillation/condensation\\n\\nSPEED applies a few methods such as the concepts from ViT, dictionary learning and sparse coding.\\n\\n## quality\\nThe method works very well on dataset with higher resolution.\\n\\n## clarity\\nThe paper is well written and easy to follow\\n\\nThe framework of the method and learned images are visualized which makes it easy to understand.\\n\\n## significance\\nThe proposed methods achieve SOTA performances under most settings.\\n\\nThe paper novelly proposes to distill images at image patch level which shows a new way for dataset distillation.\\n\\nThe proposed method is compatible with multiple matching objectives.',\n",
       "   'weaknesses': '- Incomplete evaluation results in table 2. IPC 1/10/50 are used for CIFAR-10/100, but only IPC 1 for TinyImageNet is used. Why that is the case? From [1], even the trajectory matching method this paper adopts has reported the results on TinyImageNet with IPC 1/10/50.\\n\\n- In table 1, for the parameterization methods including SPEED, can the author include how many synthetic images are generated for evaluations, e.g. 11 for IPC 1 so that we know if the performance gain is due to increased number of images or increased quality of generated images.\\n\\n\\n\\n\\n\\n\\n\\n[1] Dataset Distillation by Matching Training Trajectories'},\n",
       "  'review_14': {'summary': 'This paper introduces the insight of sparse coding into dataset distillation and proposes a sound method. This work can efficiently generate syn data by adopting the multi-head SCMs as the shared source of the syn images and using a recurrent model to generate the syn patches. It can cooperate with various previous matching methods. In extensive experiments, the proposed method shows auspicious results and superiority.',\n",
       "   'strengths': '+ Importing the sparse coding into the syn data is interesting and effective from the experiments. The analysis of the problem of overlooking the syn data sparsity itself is insightful and naturally leads to the proposed method.\\n\\n+ Good writing, easy to follow.\\n\\n+ Extensive experiments, ablations, and visualizations.\\n\\n+ Insightful and valuable discussions and analyses, especially the syn data property, clear formulation, storage analysis, and trade-off between quality and quantity.\\n\\n+ Fig III in the appendix clearly showcases the effects of the proposed method.',\n",
       "   'weaknesses': '- More discussions about the relations between dataset distillation, sparse coding, and corset selection.\\n\\n- Though the recurrent model is sound according to the cost discussion. I still wonder about the performance of adopting a heavier model following the same idea of the proposed method.\\n\\n- Fig. 4: should be more self-contained, please explain the comparison and differences/similarities.'}},\n",
       " 'Truly Scale-Equivariant Deep Nets with Fourier Layers': {'review_15': {'summary': 'This paper proposes a formulation of scale equivariant networks, which takes anti-aliasing into account. This is in contrast to previous works, in which the issue of aliasing is often disregarded. The proposed method achieves competitive classification accuracy on MNIST-scale and STL-10, while maintaining zero equivariance error.',\n",
       "   'strengths': 'This work addresses a problem that has been thus far disregarded when talking about scale equivariance: the aliasing issue. The proposed methods and solutions are sound and are empirically evaluated with very good results.',\n",
       "   'weaknesses': '* My main concern is that, to the best of my understanding, the proposed framework does not consider inter-scale relationships. Instead, it considers multiple scales in parallel which are processed independently of one another. This brings into question whether this work should be defined as a work in group equivariance or rather a work on models aiming to be resolution-agnostic, i.e., able to work regardless of the resolution of the input, e.g., FlexConv [1], S4ND[2], \\\\inf-Diffusion [3].\\n\\n* This method relies heavily on using the Fourier and inverse Fourier transform for each of its layers. In addition, it is well-known that performing convolutions on the spatial domain is faster and requires less memory than performing them in the Fourier domain when convolutional kernels are small O(Nk) vs O(NlogN). However, the proposed method actually relies on small convolutional kernels. These two factors call into question the computational and memory complexity of the proposed method. I believe that this is the main practical limitation of the method, and I would like the authors to discuss this in the paper –in case it is indeed an issue–.\\n\\n* Connecting to the previous point, I believe that having a section in which the limitations of the work are clearly stated and discussed is vital.'},\n",
       "  'review_16': {'summary': 'The submitted paper explores the problem of scale-equivariant neural networks.\\nTo get the desired property by design, the authors propose new building blocks: a spatially local Fourier layer, a novel scale-equivariant pooling layer, and scale-equivariant way of applying activation functions.\\nAll the introduced modifications rely heavily on the Fourier transform of the input feature map. \\nAdditionally, a new loss function is proposed which aims to promote the natural consistency of predictions made at different scales. \\n\\nThe effect of the new approach is demonstrated on the problem of image classification on two datasets: MNIST-scale and STL-10-scale. ',\n",
       "   'strengths': 'I find the proposed modifications well explained and motivated. \\nTo the best of my knowledge, the presented approach is original enough, and it may be interesting for the broad community. \\nQuality of the results seems very satisfactory and I hope they can serve as a reliable baseline for further research on this topic. \\n',\n",
       "   'weaknesses': '1. While the proposed results seem strong enough for the task of object recognition, the authors have not reported the computational or memory overhead introduced by their approach. Without this knowledge, it is hard to understand if their method can be directly scaled to more high-resolution data without any significant changes.\\n\\n1. I admit that most prior papers also mostly report their performance for image classification, it is quite clear that the property of scale equivariance may be even more desirable for the dense prediction tasks, e.g. semantic segmentation. Are there any barriers to applying the same method to the common segmentation architectures?\\n\\n1. Regarding the low performance of baseline models on STL-10-scale data (line 274), have the authors tried other padding schemes than zero-padding, e.g. so-called reflect/replicate/circular strategies (see the [link](https://pytorch.org/docs/stable/generated/torch.nn.functional.pad.html))? I find it suspicious that, e.g. the reported DISCO performance of 91.93% accuracy on STL-10 [1] drops to 47.68% on STL-10-scale (Tab. 4) in the provided evaluation results. I think, more discussion is needed on that matter.\\n\\n[1] Sosnovik et al. DISCO: accurate Discrete Scale Convolutions. In BMVC, 2021.'},\n",
       "  'review_17': {'summary': 'This paper introduces Truly Scale-Equivariant Deep Nets with Fourier Layers, which directly formulate down-scaling in the discrete domain to address the anti-aliasing problem. The proposed methods are validated on the MNIST-scale and STL-10 datasets, demonstrating good classification performance while preserving zero equivariance error.',\n",
       "   'strengths': '1. This paper addresses how to learn scale-equivariant representations in deep neural networks, overcoming the limitation of previous methods that did not account for anti-aliasing.\\n2. The paper proposes a method that can consider the down-scaling operation directly in the discrete domain with anti-aliasing and achieves good performance.\\n',\n",
       "   'weaknesses': \"1. This paper does not provide sufficient experiments to demonstrate the generality of the proposed method. It only tests on two small datasets and a single high-level vision task (image classification), which limits the impact of the proposed method. This paper should also evaluate the method on more larger-scale datasets, more high-level vision tasks (e.g., image segmentation), and more CNN architectures.\\n2. Why does the baseline use zero-padding to the original resolution as the input, instead of resizing to the original resolution? Does this affect baseline's representation learning and performance?\\n3. The paper lacks an analysis of the computational cost of the proposed method and other compared baseline during training and inference.\\n\"},\n",
       "  'review_18': {'summary': 'The authors of this study introduce architectural modifications to the conventional CNN framework by incorporating Fourier layers. Their aim is to achieve scale-equivariance, addressing the anti-aliasing problem that occurs when images are downscaled in the continuous domain. To tackle this issue, the authors propose a discrete domain downsampling formulation and propose corresponding changes to the network architecture. Through experiments on a few datasets, the authors demonstrate that their method achieves zero scale-equivariance error.',\n",
       "   'strengths': \"- The paper is well-written, precise, and easy to follow. In particular, their motivation is stated clearly, they introduce the preliminaries succinctly, and the approach stated is coherent and structured.\\n\\n- To the best of my knowledge the proposed method is novel and the claims that the module modifications achieve scale-equivariance is correct.\\n\\n- I am unaware of any method but this that solves the chosen problem completely, i.e achieves zero scale-equivariance error when downsampling is done via anti-aliasing and subsampling ('ideal' subsampling). The results are also competent when they do 'non-ideal' subsampling when compared to standard baselines. \\n\\n- The motivation that images of higher-scale should achieve better classification accuracy than the ones of lower scales is reasonable and the corresponding proposed constraint is sound.\\n\\nOverall I think the ideas presented in this paper maybe of interest to the broad ML community.\",\n",
       "   'weaknesses': \"- Due to the complexity involved in the several DFT/Inverse-DFT related operations, the baselines they compare to which involve kernel resizing are certainly not as costly as the proposed method. I suggest the authors to discuss how their method compares to the baselines in terms of computational/time complexity.\\n\\n- For the same aforementioned reasons, I suspect that the method might not scale to high dimensional datasets like ImageNet or standard architectures like ResNet50. This I think would be a fundamental limitation, therefore I encourage the authors to discuss the challenges in scaling their method to the mentioned settings. I would be interested to know which modules will be particularly harder to scale.\\n\\n- Some minor text changes:\\n\\n     - Line 119, Claim 1: 'even lower in frequencies' needs to be 'even in lower frequencies.'\\n\\n     - Line 138, Claim 2: 'equivaraint' needs to be 'equivariant.'\\n\\n- Figure 1, Figtitle: “On the other hand, downsampling the high-res feature is guaranteed to achieve the same low-resolution feature.” -> Unclear formulation. It is not clear how the downsampled version of the features was achieved. The text suggests that it has merely been downsampled from the high-resolution version, but then it is not clear which role the new proposed architecture plays. Please rephrase for clarity.\\n\\n\\n- Line 32: “Specifically, these works are derived using a continuous domain down-scaling operation, i.e., there is no need to consider anti-aliasing. However, when performing a down-scaling, the Nyquist theorem [21, 27] tells us that an anti-alias filter is necessary to avoid high-frequency content to alias into lower frequencies. (...) To address this gap, from prior work, we consider the down-scaling operation directly in the discrete domain taking into account of the anti-aliasing.” Several grammar errors and the paragraph is unclear to me. In the first sentence, the authors write that previous works “do not need to consider anti-aliasing”. But then, they aim to bridge the gap and take anti-aliasing into account. Please fix the formulation as it is currently very unclear whether previous works had an issue with anti-aliasing or not.\\n\\n\\n- Line 103: The notation for the definition of g is unclear. It is unclear what is meant by that x is \\\\in {R^1, R^2 … R^N}, which makes it hard to understand the following definitions. The notation of {..} suggests that x can be from R^1, but then how is the Fourier transform of one number even defined? The Fourier transform is needed for D_R(x). I am confused by this definition, please rewrite for clarity. \\n\\n\\n- It would be helpful if the authors would state that small x refers to the spatial domain and big X always refers to the Fourier domain. While this is the common practice, it would still be nice to state it explicitly.\\n\\n\\n- I don’t understand Fig. 2b. Are the yellow regions ones and the gray ones zero?\\n\\n\\n- Line 142: “Element-wise non-linearities, e.g., ReLU, in the spatial domain are generally not scale-equivariant under the ideal downsampling operation DR.” The reasoning of this claim is not obvious to me, please explain / give some intuition.\\n\\n\\n\"}}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_nips_2023 ={}\n",
    "for i in range(len(nips_2023_titles)):\n",
    "    reviews_nips_2023[nips_2023_titles[i]] = get_reviews_fast(nips_2023_titles[i], \"NeurIPS\", 2023, reply_type=\"Official_Review\")\n",
    "\n",
    "reviews_nips_2023\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a7aa3bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'to_parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mreviews_nips_2023\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnips_2023_reviews.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'to_parquet'"
     ]
    }
   ],
   "source": [
    "reviews_nips_2023.to_parquet(\"nips_2023_reviews.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db8f19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"nips_2023_reviews.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reviews_nips_2023, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7ea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(s):\n",
    "    return str(s).strip().lower()\n",
    "\n",
    "def get_title(sub):\n",
    "    t = sub.content.get(\"title\")\n",
    "    return t.get(\"value\") if isinstance(t, dict) else t\n",
    "\n",
    "def unwrap(v):\n",
    "    return v.get(\"value\") if isinstance(v, dict) else v\n",
    "\n",
    "def fetch_reviews_by_titles(conf, year, titles, reply_type=\"Official_Review\"):\n",
    "    \"\"\"\n",
    "    conf: e.g. \"NeurIPS\" or \"ICLR\"\n",
    "    year: int, e.g. 2023\n",
    "    titles: list of paper titles (strings)\n",
    "    reply_type: \"Official_Review\" / \"Meta_Review\" / etc.\n",
    "\n",
    "    Returns: dict {original_title: [review_dicts]}\n",
    "    \"\"\"\n",
    "    venue_id = f\"{conf}.cc/{year}/Conference\"\n",
    "    submissions = client_v2.get_all_notes(\n",
    "        invitation=f\"{venue_id}/-/{submission_name}\",\n",
    "        details=\"replies\"\n",
    "    )\n",
    "\n",
    "    # Build index: normalized title -> list of reviews\n",
    "    index = {}\n",
    "    for submission in submissions:\n",
    "        title_norm = norm(get_title(submission))\n",
    "        reviews = []\n",
    "        for reply in submission.details.get(\"replies\", []):\n",
    "            if any(inv.endswith(reply_type) for inv in reply.get(\"invitations\", [])):\n",
    "                content = reply.get(\"content\", {})\n",
    "                reviews.append({\n",
    "                    \"summary\": unwrap(content.get(\"summary\")),\n",
    "                    \"strengths\": unwrap(content.get(\"strengths\")),\n",
    "                    \"weaknesses\": unwrap(content.get(\"weaknesses\")),\n",
    "                })\n",
    "        index[title_norm] = reviews\n",
    "\n",
    "    # Map back to the original titles given\n",
    "    return {t: index.get(norm(t), []) for t in titles}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab6fdb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nips_2022 = []\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['conference'] == 'NeurIPS' and df.iloc[i]['year'] == 2022:\n",
    "        nips_2022.append(df.iloc[i]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "69ee6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "iclr_2023 = []\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['conference'] == 'ICLR' and df.iloc[i]['year'] == 2023:\n",
    "        iclr_2023.append(df.iloc[i]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c143f1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining',\n",
       " 'StyleMorph: Disentangled 3D-Aware Image Synthesis with a 3D Morphable StyleGAN',\n",
       " 'Revisiting Robustness in Graph Machine Learning']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "80a72f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_iclr_2023 = fetch_reviews_by_titles(\"ICLR\", 2023, iclr_2023, reply_type=\"Official_Review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dee51b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining': [],\n",
       " 'StyleMorph: Disentangled 3D-Aware Image Synthesis with a 3D Morphable StyleGAN': [],\n",
       " 'Revisiting Robustness in Graph Machine Learning': []}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_iclr_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a835cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"iclr_2024_reviews.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reviews_iclr_2024, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4158316d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Biologically-inspired adaptive learning in the Hopfield-network based self-optimization model': [],\n",
       " 'Flexible Attention-Based Multi-Policy Fusion for Efficient Deep Reinforcement Learning': [],\n",
       " 'Conditional Matrix Flows for Gaussian Graphical Models': [],\n",
       " 'Matrix Compression via Randomized Low Rank and Low Precision Factorization': [],\n",
       " 'Color Equivariant Convolutional Networks': [],\n",
       " 'VideoComposer: Compositional Video Synthesis with Motion Controllability': [],\n",
       " 'SiT Dataset: Socially Interactive Pedestrian Trajectory Dataset for Social Navigation Robots': [],\n",
       " 'Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger': [],\n",
       " 'A Theoretical Analysis of the Test Error of Finite-Rank Kernel Ridge Regression': [],\n",
       " 'Comparing Optimization Targets for Contrast-Consistent Search': [],\n",
       " 'Fine-Tuning Language Models with Just Forward Passes': [],\n",
       " 'PIXIU: A Comprehensive Benchmark, Instruction Dataset and Large Language Model for Finance': [],\n",
       " 'FLAb: Benchmarking deep learning methods for antibody fitness prediction': [],\n",
       " 'Sparse Parameterization for Epitomic Dataset Distillation': [],\n",
       " 'Truly Scale-Equivariant Deep Nets with Fourier Layers': []}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_nips_2023_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7688a9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Hessian Screening Rule',\n",
       " 'CW-ERM: Improving Autonomous Driving Planning with Closed-loop Weighted Empirical Risk Minimization',\n",
       " 'Identifying the Context Shift between Test Benchmarks and Production Data',\n",
       " 'Neural Unbalanced Optimal Transport via Cycle-Consistent Semi-Couplings',\n",
       " 'Privacy-Preserving Machine Learning for Collaborative Data Sharing via Auto-encoder Latent Space Embeddings',\n",
       " 'Differentially Private CutMix for Split Learning with Vision Transformer',\n",
       " 'DeepJoint: Robust Survival Modelling Under Clinical Presence Shift',\n",
       " 'Fast kinematics modeling for conjunction with lens image modeling',\n",
       " 'PatchRot: A Self-Supervised Technique for Training Vision Transformers',\n",
       " 'DARTFormer: Finding The Best Type Of Attention',\n",
       " 'Langevin Autoencoders for Learning Deep Latent Variable Models',\n",
       " 'Self-supervised detection of atmospheric phenomena from remotely sensed synthetic aperture radar imagery',\n",
       " 'Deconvolving Detector Effects for Distribution Moments',\n",
       " 'Conformal Semantic Keypoint Detection with Statistical Guarantees',\n",
       " 'Active Learning with Table Language Models',\n",
       " 'A View From Somewhere: Human-Centric Face Representations',\n",
       " 'Towards Reasoning-Aware Explainable VQA',\n",
       " 'Uni[MASK]: Unified Inference in Sequential Decision Problems',\n",
       " '[Re] Graph Edit Networks',\n",
       " 'Generation Probabilities are Not Enough: Improving Error Highlighting for AI Code Suggestions']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nips_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a4832b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "venue_id = \"NeurIPS.cc/2022/Conference\"\n",
    "\n",
    "# list all invitations under this venue\n",
    "invs = client_v1.get_all_invitations(venue_id)\n",
    "\n",
    "# find submission invitations\n",
    "invs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "65da3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = client.get_all_notes(\n",
    "    invitation=\"NeurIPS.cc/2022/Conference/-/Submission\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b0ca5b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "69485883",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Client.get_invitations() got multiple values for argument 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m venue_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeurIPS.cc/2022/Conference\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 1) Find all review invitations under this venue\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m invs \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_invitations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvenue_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m review_invs \u001b[38;5;241m=\u001b[39m [inv\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m inv \u001b[38;5;129;01min\u001b[39;00m invs \u001b[38;5;28;01mif\u001b[39;00m inv\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOfficial_Review\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound review invitations:\u001b[39m\u001b[38;5;124m\"\u001b[39m, review_invs[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: Client.get_invitations() got multiple values for argument 'id'"
     ]
    }
   ],
   "source": [
    "import openreview\n",
    "\n",
    "client = openreview.Client(baseurl=\"https://api.openreview.net\")\n",
    "\n",
    "venue_prefix = \"NeurIPS.cc/2022/Conference\"\n",
    "\n",
    "# 1) Find all review invitations under this venue\n",
    "invs = client.get_invitations(client, id = venue_prefix)\n",
    "review_invs = [inv.id for inv in invs if inv.id.endswith(\"Official_Review\")]\n",
    "\n",
    "print(\"Found review invitations:\", review_invs[:5])\n",
    "\n",
    "# 2) Pull all reviews from those invitations\n",
    "all_reviews = []\n",
    "for inv_id in review_invs:\n",
    "    all_reviews += list(openreview.tools.iterate_notes(client, invitation=inv_id))\n",
    "\n",
    "print(\"Total reviews:\", len(all_reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ae937d0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'openreview.tools' has no attribute 'iterate_invitations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[109], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m client \u001b[38;5;241m=\u001b[39m openreview\u001b[38;5;241m.\u001b[39mClient(baseurl\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openreview.net\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m venue_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeurIPS.cc/2022/Conference\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m invs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterate_invitations\u001b[49m(client, prefix\u001b[38;5;241m=\u001b[39mvenue_prefix))\n\u001b[0;32m      8\u001b[0m review_invs \u001b[38;5;241m=\u001b[39m [inv\u001b[38;5;241m.\u001b[39mid \u001b[38;5;28;01mfor\u001b[39;00m inv \u001b[38;5;129;01min\u001b[39;00m invs \u001b[38;5;28;01mif\u001b[39;00m inv\u001b[38;5;241m.\u001b[39mid\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOfficial_Review\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m      9\u001b[0m review_invs[:\u001b[38;5;241m5\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'openreview.tools' has no attribute 'iterate_invitations'"
     ]
    }
   ],
   "source": [
    "import openreview\n",
    "from openreview import tools\n",
    "\n",
    "client = openreview.Client(baseurl=\"https://api.openreview.net\")\n",
    "venue_prefix = \"NeurIPS.cc/2022/Conference\"\n",
    "\n",
    "invs = list(tools.iterate_invitations(client, prefix=venue_prefix))\n",
    "review_invs = [inv.id for inv in invs if inv.id.endswith(\"Official_Review\")]\n",
    "review_invs[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6c9cc461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V1 Notes: 100%|█████████▉| 2821/2824 [00:40<00:00, 69.54it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'original'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m decision_note \u001b[38;5;129;01min\u001b[39;00m all_decision_notes:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m decision_note[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecision\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 13\u001b[0m         accepted_submissions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mblind_notes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecision_note\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetails\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'original'"
     ]
    }
   ],
   "source": [
    "# Double-blind venues\n",
    "\n",
    "submissions = client_v1.get_all_notes(invitation = 'NeurIPS.cc/2022/Conference/-/Blind_Submission', details='directReplies,original')\n",
    "blind_notes = {note.id: note for note in submissions}\n",
    "all_decision_notes = [] \n",
    "for submission_id, submission in blind_notes.items(): \n",
    "        all_decision_notes = all_decision_notes + [reply for reply in submission.details[\"directReplies\"] if reply[\"invitation\"].endswith(\"Decision\")]\n",
    "\n",
    "accepted_submissions = []\n",
    "\n",
    "for decision_note in all_decision_notes:\n",
    "    if 'Accept' in decision_note[\"content\"]['decision']:\n",
    "        accepted_submissions.append(blind_notes[decision_note['forum']].details['original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f50d1846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V1 Notes: 100%|█████████▉| 2821/2824 [00:39<00:00, 70.69it/s]\n"
     ]
    }
   ],
   "source": [
    "submissions = client_v1.get_all_notes(\n",
    "    invitation=\"NeurIPS.cc/2022/Conference/-/Blind_Submission\", details='directReplies'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0e66e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_2022 = [(sub.content.get('title')) for sub in submissions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b79372d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1977"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_2022.index(\"The Hessian Screening Rule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "eb782016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_reviews_v1(titles, conf, year):\n",
    "    venue_id = f\"{conf}.cc/{year}/Conference\"\n",
    "    submissions = client_v1.get_all_notes(invitation=f\"{venue_id}/-/Blind_Submission\", details=\"directReplies\")\n",
    "    indices = []\n",
    "    indices_without_reviews = []\n",
    "    all_titles = [(sub.content.get('title')) for sub in submissions]\n",
    "    for title in titles:\n",
    "        if title in all_titles:\n",
    "            indices.append(all_titles.index(title))\n",
    "        else:\n",
    "            indices_without_reviews.append(title)\n",
    "    title_to_reviews = {}\n",
    "    for idx in indices:\n",
    "        review_idx_lst = submissions[idx].details.get(\"directReplies\")\n",
    "        reviews = {}\n",
    "        for i in range(len(review_idx_lst)):\n",
    "            summary = review_idx_lst[i].get('content').get('summary') if review_idx_lst[i].get('content').get('summary') else None\n",
    "            strengths_and_weaknesses = review_idx_lst[i].get('content').get('strengths_and_weaknesses') if review_idx_lst[i].get('content').get('strengths_and_weaknesses') else None\n",
    "            reviews[f\"review{i+1}\"] = {\"summary\": summary, \"strengths_and_weaknesses\": strengths_and_weaknesses}\n",
    "        title = submissions[idx].content.get('title')\n",
    "        title_to_reviews[title] = reviews\n",
    "    for title in indices_without_reviews:\n",
    "        title_to_reviews[title] = {}\n",
    "    return title_to_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "818ea8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V1 Notes: 100%|█████████▉| 3788/3792 [00:27<00:00, 136.18it/s]\n"
     ]
    }
   ],
   "source": [
    "reviews_iclr_2023 = fetch_reviews_v1(iclr_2023, \"ICLR\", 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "93582615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UniMax: Fairer and More Effective Language Sampling for Large-Scale Multilingual Pretraining': {'review1': {'summary': None,\n",
       "   'strengths_and_weaknesses': None},\n",
       "  'review2': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review3': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review4': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review5': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review6': {'summary': None, 'strengths_and_weaknesses': None}},\n",
       " 'StyleMorph: Disentangled 3D-Aware Image Synthesis with a 3D Morphable StyleGAN': {'review1': {'summary': None,\n",
       "   'strengths_and_weaknesses': None},\n",
       "  'review2': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review3': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review4': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review5': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review6': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review7': {'summary': None, 'strengths_and_weaknesses': None}},\n",
       " 'Revisiting Robustness in Graph Machine Learning': {'review1': {'summary': None,\n",
       "   'strengths_and_weaknesses': None},\n",
       "  'review2': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review3': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review4': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review5': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review6': {'summary': None, 'strengths_and_weaknesses': None}}}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_iclr_2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "36790679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'The Hessian Screening Rule': {'review1': {'summary': 'The paper proposes a screening strategy for L1 sparse modelings. The basic idea is to use a prediction of an optimal solution as a function of the regularization parameter, derived from optimal conditions (which is aka solution path). The authors further propose combining working set selection screening by predicted solution with so-called strong rule to make screening more efficient. ',\n",
       "   'strengths_and_weaknesses': \"Overall, the paper is easy to follow and technical quality is fine. The purpose is clear and the procedure is written in detail. However, a critical issue is that the idea of main proposal (Hessian screening) is not novel. Approaches based on a similar idea have been studies in the context of the path following though it is not fully mentioned. Detailed comments are as follows.\\n\\nClosely related papers in the path following literature are missed. For example, since the following two papers contains conceptually quite similar approaches, the difference should have been discussed in detail, though currently nothing is mentioned:\\n[Rosset2004] S. Rosset, Following Curved Regularized Optimization Solution Paths, NeurIPS 2004. \\n[Park2006] M. Y. Park and T. Hastie, L1 Regularization Path Algorithm for Generalized Linear Models, Journal of the Royal Statistical Society: Series B (Statistical Methodology), 2006.\\n\\nThe proposed algorithm can be seen as a so-called 'predictor-corrector' method in general (e.g., discussed in [Park2006]). Further, [Park2006] also discusses the working set selection based on the update equation (6).\\n\\nTherefore, most importantly, the idea using Theorem 3.1 to predict the variable c (working set criterion) of the next \\\\lambda has been already known. Therefore, I do not think the concept of 'Hessian screening' is novel.\\n\\n[Rosset2004] also discusses a similar idea of approach (Hessian based update) based on an essentially quite similar theoretical property to Theorem 3.1. Further, this paper also provides the error analysis of the predictor.\\n\\nCombination with strong rule and additional adjustment would be novel, but its technical significance is a bit marginal because these are quite simple heuristics.\\n\\nTechniques in the 'Updating the Hessian' paragraph have been also known (the same techniques repeatedly discussed in the path following literature). \\n\\nThe 'Warm Starts' has also been widely known (e.g., [Park2006]).\\n\\nMinor comments:\\n- Since Theorem 3.1 has been widely known, it should clarify more explicitly rather than noting it only in the footnote.  \"},\n",
       "  'review2': {'summary': 'This paper studies the predictor screening rules over the lasso optimization problem. It proposes a Hessian screening rule which utilizes the second-order information. This rule is effective not only in screening but also in accurate warm starts. Updating the second-order information has high computational complexity, and to deal with it, this work replies on the sweep operator. In the experiments, the proposed rule is compared to many baselines and outperforms them significantly on both simulated and real-world data.\\n\\n',\n",
       "   'strengths_and_weaknesses': 'Originality\\n\\nPrevious works on screening rules overlooked the study on the second-order information. Thus I think the direction of this work novel. The proposed rule takes the warm start and the Hessian matrix computation problems into account, and resolves them soundly. Besides, the insightful discussions on the proposed screening rule are provided. They are helpful to understand the rule and to differentiate this approach with previous methods. Therefore, I think the contributions of the work novel.\\n\\nQuality\\n\\nI am satisfactory with most contents of this paper. The paper presents a clear overview of the question and previous rules both in words and math. The proposed rule is based on the Hessian matrix and is actually in a form of the second-order Taylor approximation. Speeding up the Hessian matrix computation is based on the sweep operator and the warm starts also benefit from the Hessian matrix. These arguments are demonstrated in the experiments. As far as I checked, the theoretical analyses have no problem.\\n\\nHowever, I have a concern with the study method. Normally, people select the predictors for better fitting accuracy, but this paper relies heavily on the time cost and the minimum number of active predictors to measure the performance. I am curious about why not including fitting accuracy.\\n \\nClarity\\n\\nThe paper is clearly written for me. I can easily follow the contents on the approach and the experiment.\\n\\nSignificance\\n\\nThe idea of the approach is sound and practical performance is better than baselines. However, because just the lasso problem is involved, I am afraid that the audience will be very limited. Therefore, I think the significance of this paper is limited.'},\n",
       "  'review3': {'summary': 'A Hessian screening rule for lasso and its generalized linear model extension for logistic regression was presented to take advantage of the high-order information for more efficient screening, specifically in cases with highly correlated predictors/covariates. The proposed Hessian screening rule together with several speedup tricks has been shown to be effective in both simulated and real datasets. ',\n",
       "   'strengths_and_weaknesses': 'The proposed Hessian screening rule extends the Strong Rule and Working Set by taking advantage of the high-order information for more efficient screening, specifically in cases with highly correlated predictors/covariates. The Hessian screening rule together with several speedup tricks has been shown to be effective in both simulated and real datasets. \\n\\nIt is not clear based on the current presentation why the Hessian rule can be less conservation from Section 3. In addition to Theorem 3.1, some theoretical analysis for that may help further improve the quality of the submission. The actual final screening in fact was based on the modifications as described from line 133 to 151. It may be interesting also to have ablation comparison to see clearly what led to improved efficiency. \\n\\nSince, the screening rules are not \"safe\", in particular for logistic regression. In addition to investigating the efficiency, the authors may also need to provide the performance comparison with respect to both predictor selection and model prediction accuracy. \\n\\nIn the real data experiments, the authors may want to provide some explanations why the Hessian rule performs significantly worse on arcene and rcv2 datasets, for which p is much larger than n, especially for arcene. It is clearly not the case when p is similar as n as discussed in Section 5. \\n\\nFinally, there are language problems in the submission. For example, in line 188-189 (page 5): \"... this is not a surprising find.\"  In line 257-258 (page 7), \"we also stop the path whenever the number of coefficients ever to be active predictors exceeds p.\" The number of coefficients can be equal to p but will never exceed p. The authors may need to improve the presentation of the submission. '},\n",
       "  'review4': {'summary': 'The paper proposes a heuristic (non-safe) screening rule to deal with l1-regularized estimation problems such as linear regression and logistic regression. The proposed method can be viewed as a generalization of the strong rule used in the glmnet, which only used first-order information.  The paper reports experiments on both synthetic data and real-world data to illustrate the performance of the proposed method.',\n",
       "   'strengths_and_weaknesses': 'Strengths:\\n* the paper addresses an interesting problem in l1-regularized estimation for linear regression and logistic regression. Screening rules are an effective strategy to speed up such estimation.\\n* Although the proposed rule is heuristic in nature, the simplicity in its formulation and the effectiveness shown in the experiments offers some advantages of the proposed method. This is also a not-so-common approach that makes use of second-order information for screening.\\n* Experiments are exhaustive. six well-known alternative methods are compared on a wide variety of synthetic and real-world data.\\n\\nWeakness:\\n* The authors may consider carrying out experiments on other settings covered by the proposed method such as poison regression and elastic net. It may also be interesting (somewhat orthgonal) to understand how the proposed method performs or scale compared to SGD based approach on very large datasets.'},\n",
       "  'review5': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review6': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review7': {'summary': None, 'strengths_and_weaknesses': None}},\n",
       " 'Langevin Autoencoders for Learning Deep Latent Variable Models': {'review1': {'summary': 'This paper presents Amortized Langevin Dynamics (ALD), a scalable MCMC algorithm that can be used to sample from high dimensional deep latent variable models. \\n\\nUnlike competing MCMC algorithms that need to rely on per-datapoint iterations, ALD can sample from the correct posterior distribution by performing updates to an encoder. This gives rise to Langevin Autoencoders, a family of deep LVMs that relies on ALD. \\n\\nExperiments on a number of benchmark datasets show that Langevin Autoencoders outperform competing models while maintaining scalability. \\n\\n \\n\\n \\n\\n',\n",
       "   'strengths_and_weaknesses': 'STRENGTHS \\n\\nMost applications of deep LVMs use variational methods to approximate the intractable posterior distribution.\\nVariational methods are however inherently biased, since they try to approximate a complex posterior distribution with distributions from a typically simple variational family (e.g. Gaussian). \\n\\nThis is not an issue in sample-based MCMC methods, but they do not scale for high dimensional deep LVMs trained on large datasets, since they require expensive per-datapoint iterations. \\n\\nThis paper provides a novel solution to this, that relies on applying amortization ideas to MCMC methods. \\nThe idea of obtaining samples from the posterior distribution by updating an encoder that data points to latent variables is very interesting to me, as it preserves the scalability of variational methods while not making any strong assumption on the approximate posterior distribution.\\nAlso, theoretical and empirical results show that ALD matches the correct stationary posterior distribution even for the complex posterior distributions that are typical of DLVMs.\\n\\nI believe this paper can have an impact in the neurips community, since it can inspire a new research direction on enoder-based MCMC methods that use amortization and avoid datapoint-wise iterations.\\n\\n\\nWEAKNESSES \\n\\nThere are some experimental improvements that I believe could further increase the impact of this paper.\\n\\n1. You state that the goal of the experiments is to show that ALD works, and not that of achieving SOTA results, which is ok. However, for this type of paper that presents a method that can be readily applied to any deep LVM, trying it out on a more SOTA architecture would have made the results much more compelling. The fact that you have not done it makes me wonder if there are some complications to applying it to more complex architectures.\\n\\n2. How can one monitor the convergence of the MCMC chain? Which convergence diagnostics have you used? \\n\\n3. Did you ever get in situations where the MH acceptance rate was too low/high? \\n\\n4. What are the training times of the different models considered in the experiments?\\n\\n\\n Minor comments:\\n\\n* typo in title: variabel -> variable \\n\\n* line 29. The issue is not that the distribution is tractable as it is implied in the sentence. The issue is that the posterior for these types of models is complex, so the tractable distributions we use are not a good approximation. \\n\\n* line 41: \"in test time\" -> \"at test time\" \\n\\n\\n'},\n",
       "  'review2': {'summary': 'The paper introduces amorized Langevin dynamics (ALD), a method for initializing Langevin dynamics in the function parameter space that makes it efficient to perform posterior sampling. Based on this method, the paper presents the Langevin autoencoder (LAE), a deep latent variable model that is easy to implement and has competitive performance compared to similar existing methods.',\n",
       "   'strengths_and_weaknesses': 'Strengths:\\n- The preliminaries and the core method are explained clearly. The drawbacks of existing MCMC and variational inference methods motivate the main ideas very well.\\n- The algorithm of LAE is presented very clearly (Algorithm 2).\\n- The idea of performing Langevin sampling in encoder parameter space seems quite novel and interesting. Proof is given on why this MCMC in the encoder parameter space will converge to the true data posterior.\\n\\nWeaknesses:\\n- Although it doesn\\'t get in the way of understanding the key ideas, the writing can certainly be improved at a couple of places. Examples include \"a more straightforward and sophisticated framework\" (line 48), \"replacing MCMC on the latent space into the encoder\\'s parameter space\" (line 52) and \"we substitue it for its evidence lower bound\" (line 277, I believe it should be the other way around). Should be easy to fix.\\n- I find the claim that ALD \"completely removes datapoint-wise iterations\" slightly misleading, since it does so trivially by turning datapoint-wise iterations into parameter space iterations. In essence it still relies on the encoder (up to the second to last layer) to initialize the MCMC in a high-density region, which is still pretty similar to Hoffman (2017). Maybe it can be shown that this method can have the same or better performance with less MCMC iterations than Hoffman, at which point it would be interesting to discuss why moving to parameter space gives such an advantage.\\n- Without providing details on hyperparameter search (which can influence results greatly), the experimental results might not be sufficient for concluding that the LAE \"outperforms\" the existing methods. As mentioned in the last point, I think it would be really beneficial to show how the performance of the Hoffman (2017) model is influenced by the number of MCMC steps used.'},\n",
       "  'review3': {'summary': 'The paper deals with performing Langevin dynamics as a form of sampling, only using an amortisation mechanism. This reduces the computational overhead of performing the sampling. The method is then verified on synthetic and generated data sets\\n',\n",
       "   'strengths_and_weaknesses': 'The paper is very clearly written and cleanly presented. It is worth mentioning that the authors also did a very good job introducing other related works (albeit a bit late in the text at section 4).\\nMore so I think The main theorem is an important one. The idea of unfing the generated Markov chains with respect to the data set is novel.\\nIn top of that using amortisation is a fantastic idea for a Markovian process since the lack of time correlation can make this efficient much like Mori Zwanzig operators untangle non markovian processes \\nThat being said, there are a few things I am a bit worried about. It seems like to sample the ELBO there is a need to resample all the chains ?\\n'},\n",
       "  'review4': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review5': {'summary': None, 'strengths_and_weaknesses': None}},\n",
       " 'Uni[MASK]: Unified Inference in Sequential Decision Problems': {'review1': {'summary': 'This submission proposed a new framework, Uni[MASK], which performs unified inference in sequential decision problems, using different masking schemes. \\n\\nThe authors demonstrated that randomly sampling masking schemes help the bidirectional transformer model being able to do behavior cloning, rewarding conditioning, dynamics modeling and more.\\n\\nThe experiments are first on grid-world and then extended to Mujoco-physics Maze2D environment. The comparison between single-task, multi-task, random-task, with finetune are through and solid, integrating the theory with practice, and quite convincing. The experiments in Mujoco-physics Maze2D environment shows that Uni[MASK] framework outperforms baselines, such as Feedforward Neural Network and Decision Transformer.\\n\\nI fully endorse that this submission is a wonderful work: well designed experiments, diplomatic and sound illustration and the novelty of unifying decision making through Uni[MASK] and bidirectional models.',\n",
       "   'strengths_and_weaknesses': 'Strengths:\\n* Uni[MASK] unifies inference task in sequential decision problems.\\n* The illustration of motivation, theory and experiments design is convincing and sound, written and presented very well.\\n* The authors demonstrate how randomly sampling masking schemes at training time produces a single multi-inference-task model that can do behavior cloning, reward-conditioning, dynamics modeling and more.\\n* The authors test how training on many tasks affects single-task performance.\\n* The authors show how fine-tuning models trained with random masking consistently outperforms single-task models.\\n* The proposed Hypothesis H1 ( {multi-task, random-mask, finetune} > single-task) and H2 ( {random-mask > multi-task} ) make sense intuitively, as \"H1 test whether models indeed learn richer representations by training on multiple inference tasks\" and H2 test \"whether training on all possible tasks by randomly sampling maskings at training time is better than selecting a set of specific maskings\"\\n* The results from well designed experiments strongly support hypothesis H1 and H2.\\n* The authors extensively analyze how different training regimes (combination of single-task, multi-task, random mask, fintune) affect performance. The analysis is very convincing to me.\\n* The authors also make experiments comparison with GPT-like architectures, and the analysis is also very convincing: \"We find that while using GPT seems to yield similar performance to BERT for context length five, using GPT seems to give an advantage for longer sequence lengths,\" and \"This suggests that if one were able to use a GPT architecture and train it with random masking and fine-tuning, it might be possible to get the best of both worlds.\"\\n\\nWeakness:\\n* Relative short context lengths, and the experiments is mainly on the grid world (4 * 4), if the grid size increases, it might further improve this work.\\n'},\n",
       "  'review2': {'summary': 'This paper presents the Uni[MASK] framework, which generalizes masked language modeling (in natural language processing) to more general sequence decision problems. Given actions, states and optional property tokens (such as the return-to-go), multiple tasks such as behavioral cloning, reward-conditional offline RL, forward dynamics, etc., may be represented by specific masking schemes. The authors propose to train a model by using a randomized masking scheme (instead of single-task only or with a fixed set of tasks). Such a Uni[Mask] model may also be fine-tuned on a given task afterwards. A pre-trained Uni[MASK] model often performs comparably to single-task training, and fine-tuning further improves results.\\n\\n[Post author response] I updated the rating I assigned to this paper, in particular because of the correction to the originally misleading discussion.\\n',\n",
       "   'strengths_and_weaknesses': \"**Strengths**\\n\\nThe proposed approach neatly formalizes multiple tasks under a general masking framework.\\n\\nTraining a Uni[MASK] model, then finetuning it on a given task, generally leads to better results than single-task training only.\\n\\nThe approach is tested in both discrete (MiniGrid) and continuous (Maze2D) environments.\\n\\n**Weaknesses**\\n\\nThe discussion around line 200 is misleading. In figure 7, multi-task performs worse than single-task (although sometimes negligibly), which doesn't support H1.\\n\\nThe distinction between BERT-like and GPT-like models should be described more clearly (see question below).\\n\\nThe MiniGrid environment appears to be very simple. I would be interested in seeing how well the approach scales with larger grids.\"},\n",
       "  'review3': {'summary': 'Proposes an approach to using a single bidirectional transformer to accomplish many different reinforcement learning tasks, including behavior cloning, (sub)goal conditioning, and conditioning on properties more generally. It accomplishes this by creating a sequence of out of the (state, action, properties) for all timesteps, then either (1) training on a single type of mask, (2) training across many masking styles drawn from fixed set, and (3) randomly masking positions in the sequence. (2) and (3) can be finetuned in single task fashion. They evaluate on a toy gridworld and the mujoco 2d maze tasks. They find that Uni[MASK] performs better across both given a short truncated sequence, but it underperforms a GPT model for longer sequences. They attribute this to difficulties in training BERT models.',\n",
       "   'strengths_and_weaknesses': '\\n\\t- originality\\n\\t\\t- Concurrent work suggests that the core ideas of this paper are in the air (see: foundation posterior, multigame decision transformer, The UL2 paper on unifying masking schemes).\\n\\t- quality\\n\\t\\t- The paper is well executed. It has simple experiments which verify the core claims.\\n\\t\\t- My main concern is that the length 10 context experiments underperforming. Would like to see more study of this instead of alluding to claims that BERT has this known failure mode.\\n\\t- clarity\\n\\t\\t- The paper is well written and a pleasant read. It adequately cites prior work, and it does a great job of explaining and illustrating the core ideas.\\n\\t- significance\\n\\t\\t- The paper is a solid contribution to the literature. Overall, its core findings and technique align with concurrent and prior work.'},\n",
       "  'review4': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review5': {'summary': None, 'strengths_and_weaknesses': None},\n",
       "  'review6': {'summary': None, 'strengths_and_weaknesses': None}},\n",
       " 'CW-ERM: Improving Autonomous Driving Planning with Closed-loop Weighted Empirical Risk Minimization': {},\n",
       " 'Identifying the Context Shift between Test Benchmarks and Production Data': {},\n",
       " 'Neural Unbalanced Optimal Transport via Cycle-Consistent Semi-Couplings': {},\n",
       " 'Privacy-Preserving Machine Learning for Collaborative Data Sharing via Auto-encoder Latent Space Embeddings': {},\n",
       " 'Differentially Private CutMix for Split Learning with Vision Transformer': {},\n",
       " 'DeepJoint: Robust Survival Modelling Under Clinical Presence Shift': {},\n",
       " 'Fast kinematics modeling for conjunction with lens image modeling': {},\n",
       " 'PatchRot: A Self-Supervised Technique for Training Vision Transformers': {},\n",
       " 'DARTFormer: Finding The Best Type Of Attention': {},\n",
       " 'Self-supervised detection of atmospheric phenomena from remotely sensed synthetic aperture radar imagery': {},\n",
       " 'Deconvolving Detector Effects for Distribution Moments': {},\n",
       " 'Conformal Semantic Keypoint Detection with Statistical Guarantees': {},\n",
       " 'Active Learning with Table Language Models': {},\n",
       " 'A View From Somewhere: Human-Centric Face Representations': {},\n",
       " 'Towards Reasoning-Aware Explainable VQA': {},\n",
       " '[Re] Graph Edit Networks': {},\n",
       " 'Generation Probabilities are Not Enough: Improving Error Highlighting for AI Code Suggestions': {}}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2f9d0f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"nips_2022_reviews.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(reviews_2022, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a25482b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Hessian screening rule for lasso and its generalized linear model extension for logistic regression was presented to take advantage of the high-order information for more efficient screening, specifically in cases with highly correlated predictors/covariates. The proposed Hessian screening rule together with several speedup tricks has been shown to be effective in both simulated and real datasets. '"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions[1977].details['directReplies'][2].get('content').get('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ccfd7767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Hessian Screening Rule'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions[1977].content.get('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f62d0c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V1 Notes: 100%|█████████▉| 2821/2824 [00:22<00:00, 126.38it/s]\n"
     ]
    }
   ],
   "source": [
    "def unwrap(v):\n",
    "    return v.get(\"value\") if isinstance(v, dict) else v\n",
    "\n",
    "def get_reviews_v1(conf, year, titles):\n",
    "    venue_id = f\"{conf}.cc/{year}/Conference/-/Blind_Submission\"\n",
    "    submissions = client_v1.get_all_notes(invitation=venue_id, details=\"directReplies\")\n",
    "\n",
    "    wanted = set(titles)\n",
    "    title_to_reviews = {}\n",
    "\n",
    "    for sub in submissions:\n",
    "        title = unwrap(sub.content.get(\"title\"))\n",
    "        if title not in wanted:\n",
    "            continue\n",
    "\n",
    "        reviews = {}\n",
    "        i = 1\n",
    "        for reply in sub.details.get(\"directReplies\", []):\n",
    "            if any(inv.endswith(\"Official_Review\") for inv in reply.get(\"invitations\", [])):\n",
    "                content = reply.get(\"content\")  # same as your working example\n",
    "                reviews[i] = content\n",
    "                i += 1\n",
    "\n",
    "        title_to_reviews[title] = reviews\n",
    "\n",
    "    return title_to_reviews\n",
    "reviews_2022 = get_reviews_v1(\"NeurIPS\", 2022, nips_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f976af39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V1 Notes: 100%|█████████▉| 2821/2824 [00:33<00:00, 83.77it/s]\n"
     ]
    }
   ],
   "source": [
    "def unwrap(v):\n",
    "    return v.get(\"value\") if isinstance(v, dict) else v\n",
    "\n",
    "def get_reviews_v1_once(conf, year, titles):\n",
    "    # One API call (with pagination handled internally)\n",
    "    invitation = f\"{conf}.cc/{year}/Conference/-/Blind_Submission\"\n",
    "    submissions = client_v1.get_all_notes(invitation=invitation, details=\"directReplies\")\n",
    "\n",
    "    wanted = set(titles)\n",
    "    title_to_reviews = {}\n",
    "\n",
    "    for sub in submissions:\n",
    "        title = unwrap(sub.content.get(\"title\"))\n",
    "        if title not in wanted:\n",
    "            continue\n",
    "\n",
    "        reviews = {}\n",
    "        i = 1\n",
    "        for reply in sub.details.get(\"directReplies\", []):\n",
    "            if any(inv.endswith(\"Official_Review\") for inv in reply.get(\"invitations\", [])):\n",
    "                content = reply.get(\"content\", {})\n",
    "                reviews[f\"review{i}\"] = {\n",
    "                    \"summary\": unwrap(content.get(\"summary\")),\n",
    "                    \"strengths_and_weaknesses\": unwrap(content.get(\"strengths_and_weaknesses\")),\n",
    "                }\n",
    "                i += 1\n",
    "\n",
    "        title_to_reviews[title] = reviews\n",
    "\n",
    "    return title_to_reviews\n",
    "reviews_2022 = get_reviews_v1_once(\"NeurIPS\", 2022, nips_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "f2228613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Langevin Autoencoders for Learning Deep Latent Variable Models': {},\n",
       " 'The Hessian Screening Rule': {},\n",
       " 'Uni[MASK]: Unified Inference in Sequential Decision Problems': {}}"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fc38e542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformers, parallel computation, and logarithmic depth'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"conference\"] == \"ICML\"].iloc[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c15194d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
